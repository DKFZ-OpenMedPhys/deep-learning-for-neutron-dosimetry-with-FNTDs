
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-11 16:32:20.316504: Using torch.compile... 
2025-07-11 16:32:21.587437: do_dummy_2d_data_aug: False 
2025-07-11 16:32:21.594439: Using splits from existing split file: /data/nnUNet_preprocessed/Dataset010_PTB_all_energies_1mm_no_background_alldata/splits_final.json 
2025-07-11 16:32:21.600591: The split file contains 5 splits. 
2025-07-11 16:32:21.601878: Desired fold for training: 2 
2025-07-11 16:32:21.603265: This split has 1440 training and 360 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 35, 'patch_size': [512, 512], 'median_image_size_in_voxels': [504.0, 504.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_PTB_all_energies_1mm_no_background_alldata', 'plans_name': 'nnUNetResEncUNetPlans_24G', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 504, 504], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 4282.0, 'mean': 1593.7022300557526, 'median': 1568.0, 'min': 0.0, 'percentile_00_5': 982.0, 'percentile_99_5': 2808.0, 'std': 337.91142407822184}}} 
 
2025-07-11 16:32:27.618914: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-11 16:32:27.682167:  
2025-07-11 16:32:27.683652: Epoch 0 
2025-07-11 16:32:27.684993: Current learning rate: 0.01 
2025-07-11 16:35:33.549814: train_loss -0.0438 
2025-07-11 16:35:33.551631: val_loss -0.3081 
2025-07-11 16:35:33.552724: Pseudo dice [np.float32(0.3668)] 
2025-07-11 16:35:33.553892: Epoch time: 185.87 s 
2025-07-11 16:35:33.555040: Yayy! New best EMA pseudo Dice: 0.3668000102043152 
2025-07-11 16:35:35.455674:  
2025-07-11 16:35:35.457431: Epoch 1 
2025-07-11 16:35:35.458520: Current learning rate: 0.00999 
2025-07-11 16:36:42.055791: train_loss -0.7038 
2025-07-11 16:36:42.057451: val_loss -0.8199 
2025-07-11 16:36:42.058638: Pseudo dice [np.float32(0.8568)] 
2025-07-11 16:36:42.059929: Epoch time: 66.6 s 
2025-07-11 16:36:42.061168: Yayy! New best EMA pseudo Dice: 0.415800005197525 
2025-07-11 16:36:44.344826:  
2025-07-11 16:36:44.346835: Epoch 2 
2025-07-11 16:36:44.348187: Current learning rate: 0.00998 
2025-07-11 16:37:51.327848: train_loss -0.8416 
2025-07-11 16:37:51.332897: val_loss -0.8701 
2025-07-11 16:37:51.333961: Pseudo dice [np.float32(0.9032)] 
2025-07-11 16:37:51.334965: Epoch time: 66.99 s 
2025-07-11 16:37:51.336132: Yayy! New best EMA pseudo Dice: 0.4645000100135803 
2025-07-11 16:37:53.304680:  
2025-07-11 16:37:53.306288: Epoch 3 
2025-07-11 16:37:53.307532: Current learning rate: 0.00997 
2025-07-11 16:39:00.283748: train_loss -0.8755 
2025-07-11 16:39:00.285315: val_loss -0.8804 
2025-07-11 16:39:00.286351: Pseudo dice [np.float32(0.9105)] 
2025-07-11 16:39:00.287519: Epoch time: 66.98 s 
2025-07-11 16:39:00.288917: Yayy! New best EMA pseudo Dice: 0.5091000199317932 
2025-07-11 16:39:02.589534:  
2025-07-11 16:39:02.590745: Epoch 4 
2025-07-11 16:39:02.591802: Current learning rate: 0.00996 
2025-07-11 16:40:09.453321: train_loss -0.8849 
2025-07-11 16:40:09.454654: val_loss -0.8929 
2025-07-11 16:40:09.455626: Pseudo dice [np.float32(0.9182)] 
2025-07-11 16:40:09.456675: Epoch time: 66.87 s 
2025-07-11 16:40:09.457711: Yayy! New best EMA pseudo Dice: 0.550000011920929 
2025-07-11 16:40:11.557613:  
2025-07-11 16:40:11.559267: Epoch 5 
2025-07-11 16:40:11.560403: Current learning rate: 0.00995 
2025-07-11 16:41:18.497797: train_loss -0.8985 
2025-07-11 16:41:18.499061: val_loss -0.9047 
2025-07-11 16:41:18.499937: Pseudo dice [np.float32(0.9269)] 
2025-07-11 16:41:18.500814: Epoch time: 66.94 s 
2025-07-11 16:41:18.501808: Yayy! New best EMA pseudo Dice: 0.5877000093460083 
2025-07-11 16:41:20.769610:  
2025-07-11 16:41:20.771192: Epoch 6 
2025-07-11 16:41:20.772439: Current learning rate: 0.00995 
2025-07-11 16:42:27.889556: train_loss -0.9072 
2025-07-11 16:42:27.890776: val_loss -0.9098 
2025-07-11 16:42:27.892053: Pseudo dice [np.float32(0.9295)] 
2025-07-11 16:42:27.893079: Epoch time: 67.12 s 
2025-07-11 16:42:27.894302: Yayy! New best EMA pseudo Dice: 0.6219000220298767 
2025-07-11 16:42:30.038409:  
2025-07-11 16:42:30.039998: Epoch 7 
2025-07-11 16:42:30.041278: Current learning rate: 0.00994 
2025-07-11 16:43:37.014927: train_loss -0.9133 
2025-07-11 16:43:37.016580: val_loss -0.9143 
2025-07-11 16:43:37.017520: Pseudo dice [np.float32(0.9311)] 
2025-07-11 16:43:37.018623: Epoch time: 66.98 s 
2025-07-11 16:43:37.019668: Yayy! New best EMA pseudo Dice: 0.6528000235557556 
2025-07-11 16:43:40.352554:  
2025-07-11 16:43:40.354328: Epoch 8 
2025-07-11 16:43:40.355507: Current learning rate: 0.00993 
2025-07-11 16:44:47.237666: train_loss -0.9146 
2025-07-11 16:44:47.238957: val_loss -0.9157 
2025-07-11 16:44:47.240092: Pseudo dice [np.float32(0.9325)] 
2025-07-11 16:44:47.241104: Epoch time: 66.89 s 
2025-07-11 16:44:47.242301: Yayy! New best EMA pseudo Dice: 0.6808000206947327 
2025-07-11 16:44:49.537040:  
2025-07-11 16:44:49.538793: Epoch 9 
2025-07-11 16:44:49.540436: Current learning rate: 0.00992 
2025-07-11 16:45:56.465003: train_loss -0.9187 
2025-07-11 16:45:56.466433: val_loss -0.9166 
2025-07-11 16:45:56.467313: Pseudo dice [np.float32(0.9303)] 
2025-07-11 16:45:56.468336: Epoch time: 66.93 s 
2025-07-11 16:45:56.469277: Yayy! New best EMA pseudo Dice: 0.7056999802589417 
2025-07-11 16:45:58.669034:  
2025-07-11 16:45:58.670580: Epoch 10 
2025-07-11 16:45:58.671722: Current learning rate: 0.00991 
2025-07-11 16:47:05.888889: train_loss -0.9214 
2025-07-11 16:47:05.890390: val_loss -0.917 
2025-07-11 16:47:05.891405: Pseudo dice [np.float32(0.932)] 
2025-07-11 16:47:05.892569: Epoch time: 67.22 s 
2025-07-11 16:47:05.893842: Yayy! New best EMA pseudo Dice: 0.7283999919891357 
2025-07-11 16:47:08.170003:  
2025-07-11 16:47:08.171581: Epoch 11 
2025-07-11 16:47:08.172894: Current learning rate: 0.0099 
2025-07-11 16:48:15.311186: train_loss -0.9251 
2025-07-11 16:48:15.312362: val_loss -0.9232 
2025-07-11 16:48:15.313321: Pseudo dice [np.float32(0.9391)] 
2025-07-11 16:48:15.314221: Epoch time: 67.14 s 
2025-07-11 16:48:15.315140: Yayy! New best EMA pseudo Dice: 0.7494000196456909 
2025-07-11 16:48:17.600418:  
2025-07-11 16:48:17.601764: Epoch 12 
2025-07-11 16:48:17.602868: Current learning rate: 0.00989 
2025-07-11 16:49:24.762967: train_loss -0.9256 
2025-07-11 16:49:24.764436: val_loss -0.9241 
2025-07-11 16:49:24.765568: Pseudo dice [np.float32(0.9371)] 
2025-07-11 16:49:24.766571: Epoch time: 67.17 s 
2025-07-11 16:49:24.767655: Yayy! New best EMA pseudo Dice: 0.7681999802589417 
2025-07-11 16:49:27.058031:  
2025-07-11 16:49:27.059615: Epoch 13 
2025-07-11 16:49:27.060807: Current learning rate: 0.00988 
2025-07-11 16:50:34.089601: train_loss -0.9268 
2025-07-11 16:50:34.090974: val_loss -0.927 
2025-07-11 16:50:34.091951: Pseudo dice [np.float32(0.9406)] 
2025-07-11 16:50:34.093003: Epoch time: 67.04 s 
2025-07-11 16:50:34.094091: Yayy! New best EMA pseudo Dice: 0.7853999733924866 
2025-07-11 16:50:36.234570:  
2025-07-11 16:50:36.236188: Epoch 14 
2025-07-11 16:50:36.237245: Current learning rate: 0.00987 
2025-07-11 16:51:43.332884: train_loss -0.9293 
2025-07-11 16:51:43.334213: val_loss -0.9245 
2025-07-11 16:51:43.335453: Pseudo dice [np.float32(0.9369)] 
2025-07-11 16:51:43.336516: Epoch time: 67.1 s 
2025-07-11 16:51:43.337729: Yayy! New best EMA pseudo Dice: 0.800599992275238 
2025-07-11 16:51:45.487830:  
2025-07-11 16:51:45.489110: Epoch 15 
2025-07-11 16:51:45.490285: Current learning rate: 0.00986 
2025-07-11 16:52:52.693302: train_loss -0.9312 
2025-07-11 16:52:52.694525: val_loss -0.9292 
2025-07-11 16:52:52.695787: Pseudo dice [np.float32(0.941)] 
2025-07-11 16:52:52.697023: Epoch time: 67.21 s 
2025-07-11 16:52:52.698071: Yayy! New best EMA pseudo Dice: 0.8145999908447266 
2025-07-11 16:52:55.762276:  
2025-07-11 16:52:55.763849: Epoch 16 
2025-07-11 16:52:55.765471: Current learning rate: 0.00986 
2025-07-11 16:54:03.021882: train_loss -0.932 
2025-07-11 16:54:03.023020: val_loss -0.9265 
2025-07-11 16:54:03.023881: Pseudo dice [np.float32(0.9379)] 
2025-07-11 16:54:03.024813: Epoch time: 67.26 s 
2025-07-11 16:54:03.025743: Yayy! New best EMA pseudo Dice: 0.8270000219345093 
2025-07-11 16:54:05.334420:  
2025-07-11 16:54:05.336118: Epoch 17 
2025-07-11 16:54:05.337161: Current learning rate: 0.00985 
2025-07-11 16:55:12.932308: train_loss -0.9359 
2025-07-11 16:55:12.933654: val_loss -0.9292 
2025-07-11 16:55:12.934848: Pseudo dice [np.float32(0.9411)] 
2025-07-11 16:55:12.936024: Epoch time: 67.6 s 
2025-07-11 16:55:12.936968: Yayy! New best EMA pseudo Dice: 0.8384000062942505 
2025-07-11 16:55:15.294109:  
2025-07-11 16:55:15.295791: Epoch 18 
2025-07-11 16:55:15.296963: Current learning rate: 0.00984 
2025-07-11 16:56:22.632733: train_loss -0.9361 
2025-07-11 16:56:22.633999: val_loss -0.9285 
2025-07-11 16:56:22.635190: Pseudo dice [np.float32(0.9385)] 
2025-07-11 16:56:22.636221: Epoch time: 67.34 s 
2025-07-11 16:56:22.637101: Yayy! New best EMA pseudo Dice: 0.8483999967575073 
2025-07-11 16:56:24.972289:  
2025-07-11 16:56:24.973865: Epoch 19 
2025-07-11 16:56:24.975065: Current learning rate: 0.00983 
2025-07-11 16:57:32.466673: train_loss -0.9377 
2025-07-11 16:57:32.468378: val_loss -0.9312 
2025-07-11 16:57:32.469443: Pseudo dice [np.float32(0.9413)] 
2025-07-11 16:57:32.470402: Epoch time: 67.5 s 
2025-07-11 16:57:32.471436: Yayy! New best EMA pseudo Dice: 0.857699990272522 
2025-07-11 16:57:34.807282:  
2025-07-11 16:57:34.808744: Epoch 20 
2025-07-11 16:57:34.809913: Current learning rate: 0.00982 
2025-07-11 16:58:42.342504: train_loss -0.9383 
2025-07-11 16:58:42.343928: val_loss -0.9318 
2025-07-11 16:58:42.345139: Pseudo dice [np.float32(0.9419)] 
2025-07-11 16:58:42.346162: Epoch time: 67.54 s 
2025-07-11 16:58:42.347336: Yayy! New best EMA pseudo Dice: 0.866100013256073 
2025-07-11 16:58:44.676345:  
2025-07-11 16:58:44.677907: Epoch 21 
2025-07-11 16:58:44.679653: Current learning rate: 0.00981 
2025-07-11 16:59:52.287109: train_loss -0.9408 
2025-07-11 16:59:52.288543: val_loss -0.9322 
2025-07-11 16:59:52.289674: Pseudo dice [np.float32(0.9423)] 
2025-07-11 16:59:52.290675: Epoch time: 67.61 s 
2025-07-11 16:59:52.291637: Yayy! New best EMA pseudo Dice: 0.8737000226974487 
2025-07-11 16:59:54.592939:  
2025-07-11 16:59:54.594394: Epoch 22 
2025-07-11 16:59:54.595518: Current learning rate: 0.0098 
2025-07-11 17:01:02.279873: train_loss -0.9419 
2025-07-11 17:01:02.281051: val_loss -0.9339 
2025-07-11 17:01:02.282270: Pseudo dice [np.float32(0.943)] 
2025-07-11 17:01:02.283613: Epoch time: 67.69 s 
2025-07-11 17:01:02.284598: Yayy! New best EMA pseudo Dice: 0.8805999755859375 
2025-07-11 17:01:04.584339:  
2025-07-11 17:01:04.585880: Epoch 23 
2025-07-11 17:01:04.586953: Current learning rate: 0.00979 
2025-07-11 17:02:12.433540: train_loss -0.9416 
2025-07-11 17:02:12.435006: val_loss -0.9349 
2025-07-11 17:02:12.436373: Pseudo dice [np.float32(0.9442)] 
2025-07-11 17:02:12.437418: Epoch time: 67.85 s 
2025-07-11 17:02:12.438780: Yayy! New best EMA pseudo Dice: 0.8870000243186951 
2025-07-11 17:02:15.577123:  
2025-07-11 17:02:15.578759: Epoch 24 
2025-07-11 17:02:15.579827: Current learning rate: 0.00978 
2025-07-11 17:03:23.481553: train_loss -0.9427 
2025-07-11 17:03:23.482867: val_loss -0.9354 
2025-07-11 17:03:23.483856: Pseudo dice [np.float32(0.9441)] 
2025-07-11 17:03:23.484774: Epoch time: 67.91 s 
2025-07-11 17:03:23.485840: Yayy! New best EMA pseudo Dice: 0.8927000164985657 
2025-07-11 17:03:25.723260:  
2025-07-11 17:03:25.724760: Epoch 25 
2025-07-11 17:03:25.725891: Current learning rate: 0.00977 
2025-07-11 17:04:33.514935: train_loss -0.9445 
2025-07-11 17:04:33.516357: val_loss -0.9341 
2025-07-11 17:04:33.517616: Pseudo dice [np.float32(0.9438)] 
2025-07-11 17:04:33.518781: Epoch time: 67.8 s 
2025-07-11 17:04:33.519992: Yayy! New best EMA pseudo Dice: 0.8978000283241272 
2025-07-11 17:04:35.792984:  
2025-07-11 17:04:35.794487: Epoch 26 
2025-07-11 17:04:35.795634: Current learning rate: 0.00977 
2025-07-11 17:05:43.316510: train_loss -0.9444 
2025-07-11 17:05:43.317847: val_loss -0.936 
2025-07-11 17:05:43.319108: Pseudo dice [np.float32(0.9445)] 
2025-07-11 17:05:43.320109: Epoch time: 67.53 s 
2025-07-11 17:05:43.321338: Yayy! New best EMA pseudo Dice: 0.9024999737739563 
2025-07-11 17:05:45.624701:  
2025-07-11 17:05:45.626340: Epoch 27 
2025-07-11 17:05:45.627722: Current learning rate: 0.00976 
2025-07-11 17:06:53.258876: train_loss -0.9446 
2025-07-11 17:06:53.260085: val_loss -0.9346 
2025-07-11 17:06:53.261009: Pseudo dice [np.float32(0.9437)] 
2025-07-11 17:06:53.262172: Epoch time: 67.64 s 
2025-07-11 17:06:53.263302: Yayy! New best EMA pseudo Dice: 0.9065999984741211 
2025-07-11 17:06:55.564384:  
2025-07-11 17:06:55.565847: Epoch 28 
2025-07-11 17:06:55.567035: Current learning rate: 0.00975 
2025-07-11 17:08:03.166848: train_loss -0.9441 
2025-07-11 17:08:03.168035: val_loss -0.9303 
2025-07-11 17:08:03.169060: Pseudo dice [np.float32(0.9377)] 
2025-07-11 17:08:03.170070: Epoch time: 67.61 s 
2025-07-11 17:08:03.171237: Yayy! New best EMA pseudo Dice: 0.9096999764442444 
2025-07-11 17:08:05.559175:  
2025-07-11 17:08:05.560592: Epoch 29 
2025-07-11 17:08:05.561774: Current learning rate: 0.00974 
2025-07-11 17:09:12.980072: train_loss -0.9459 
2025-07-11 17:09:12.981454: val_loss -0.9388 
2025-07-11 17:09:12.982493: Pseudo dice [np.float32(0.9465)] 
2025-07-11 17:09:12.983529: Epoch time: 67.42 s 
2025-07-11 17:09:12.984425: Yayy! New best EMA pseudo Dice: 0.9133999943733215 
2025-07-11 17:09:15.273914:  
2025-07-11 17:09:15.275678: Epoch 30 
2025-07-11 17:09:15.276750: Current learning rate: 0.00973 
2025-07-11 17:10:22.801637: train_loss -0.9458 
2025-07-11 17:10:22.803120: val_loss -0.9411 
2025-07-11 17:10:22.804224: Pseudo dice [np.float32(0.9486)] 
2025-07-11 17:10:22.805067: Epoch time: 67.53 s 
2025-07-11 17:10:22.806024: Yayy! New best EMA pseudo Dice: 0.9168999791145325 
2025-07-11 17:10:25.084522:  
2025-07-11 17:10:25.086136: Epoch 31 
2025-07-11 17:10:25.087306: Current learning rate: 0.00972 
2025-07-11 17:11:32.415666: train_loss -0.948 
2025-07-11 17:11:32.416966: val_loss -0.9375 
2025-07-11 17:11:32.418055: Pseudo dice [np.float32(0.9453)] 
2025-07-11 17:11:32.418940: Epoch time: 67.33 s 
2025-07-11 17:11:32.419811: Yayy! New best EMA pseudo Dice: 0.9197999835014343 
2025-07-11 17:11:34.703101:  
2025-07-11 17:11:34.704687: Epoch 32 
2025-07-11 17:11:34.705980: Current learning rate: 0.00971 
2025-07-11 17:12:43.187828: train_loss -0.9473 
2025-07-11 17:12:43.189182: val_loss -0.9369 
2025-07-11 17:12:43.190234: Pseudo dice [np.float32(0.9452)] 
2025-07-11 17:12:43.191318: Epoch time: 68.49 s 
2025-07-11 17:12:43.192288: Yayy! New best EMA pseudo Dice: 0.9222999811172485 
2025-07-11 17:12:45.494931:  
2025-07-11 17:12:45.496627: Epoch 33 
2025-07-11 17:12:45.498248: Current learning rate: 0.0097 
2025-07-11 17:13:53.304568: train_loss -0.948 
2025-07-11 17:13:53.305936: val_loss -0.9374 
2025-07-11 17:13:53.306967: Pseudo dice [np.float32(0.9451)] 
2025-07-11 17:13:53.308003: Epoch time: 67.81 s 
2025-07-11 17:13:53.309036: Yayy! New best EMA pseudo Dice: 0.9246000051498413 
2025-07-11 17:13:55.613423:  
2025-07-11 17:13:55.615016: Epoch 34 
2025-07-11 17:13:55.616332: Current learning rate: 0.00969 
2025-07-11 17:15:03.341877: train_loss -0.9497 
2025-07-11 17:15:03.343345: val_loss -0.939 
2025-07-11 17:15:03.344831: Pseudo dice [np.float32(0.9468)] 
2025-07-11 17:15:03.346007: Epoch time: 67.73 s 
2025-07-11 17:15:03.347145: Yayy! New best EMA pseudo Dice: 0.926800012588501 
2025-07-11 17:15:05.652024:  
2025-07-11 17:15:05.653626: Epoch 35 
2025-07-11 17:15:05.654769: Current learning rate: 0.00968 
2025-07-11 17:16:13.280402: train_loss -0.9498 
2025-07-11 17:16:13.281864: val_loss -0.9371 
2025-07-11 17:16:13.283001: Pseudo dice [np.float32(0.9437)] 
2025-07-11 17:16:13.284303: Epoch time: 67.63 s 
2025-07-11 17:16:13.285497: Yayy! New best EMA pseudo Dice: 0.9284999966621399 
2025-07-11 17:16:15.622111:  
2025-07-11 17:16:15.623619: Epoch 36 
2025-07-11 17:16:15.624809: Current learning rate: 0.00968 
2025-07-11 17:17:23.228811: train_loss -0.9496 
2025-07-11 17:17:23.230296: val_loss -0.9385 
2025-07-11 17:17:23.231216: Pseudo dice [np.float32(0.9461)] 
2025-07-11 17:17:23.232241: Epoch time: 67.61 s 
2025-07-11 17:17:23.233293: Yayy! New best EMA pseudo Dice: 0.9301999807357788 
2025-07-11 17:17:25.580388:  
2025-07-11 17:17:25.582065: Epoch 37 
2025-07-11 17:17:25.583301: Current learning rate: 0.00967 
2025-07-11 17:18:33.192603: train_loss -0.946 
2025-07-11 17:18:33.194174: val_loss -0.9409 
2025-07-11 17:18:33.195417: Pseudo dice [np.float32(0.9485)] 
2025-07-11 17:18:33.196334: Epoch time: 67.62 s 
2025-07-11 17:18:33.197290: Yayy! New best EMA pseudo Dice: 0.9320999979972839 
2025-07-11 17:18:35.543171:  
2025-07-11 17:18:35.544460: Epoch 38 
2025-07-11 17:18:35.545595: Current learning rate: 0.00966 
2025-07-11 17:19:43.131471: train_loss -0.9497 
2025-07-11 17:19:43.132755: val_loss -0.9421 
2025-07-11 17:19:43.133881: Pseudo dice [np.float32(0.949)] 
2025-07-11 17:19:43.134887: Epoch time: 67.59 s 
2025-07-11 17:19:43.136088: Yayy! New best EMA pseudo Dice: 0.9337999820709229 
2025-07-11 17:19:45.421693:  
2025-07-11 17:19:45.423404: Epoch 39 
2025-07-11 17:19:45.424892: Current learning rate: 0.00965 
2025-07-11 17:20:52.935507: train_loss -0.9518 
2025-07-11 17:20:52.937058: val_loss -0.9358 
2025-07-11 17:20:52.938149: Pseudo dice [np.float32(0.943)] 
2025-07-11 17:20:52.939039: Epoch time: 67.52 s 
2025-07-11 17:20:52.939974: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2025-07-11 17:20:56.069356:  
2025-07-11 17:20:56.070996: Epoch 40 
2025-07-11 17:20:56.072117: Current learning rate: 0.00964 
2025-07-11 17:22:03.631595: train_loss -0.9515 
2025-07-11 17:22:03.632912: val_loss -0.9395 
2025-07-11 17:22:03.634079: Pseudo dice [np.float32(0.9469)] 
2025-07-11 17:22:03.635210: Epoch time: 67.57 s 
2025-07-11 17:22:03.636481: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-07-11 17:22:05.937343:  
2025-07-11 17:22:05.938737: Epoch 41 
2025-07-11 17:22:05.939823: Current learning rate: 0.00963 
2025-07-11 17:23:13.413804: train_loss -0.9524 
2025-07-11 17:23:13.415160: val_loss -0.9381 
2025-07-11 17:23:13.416060: Pseudo dice [np.float32(0.9447)] 
2025-07-11 17:23:13.417607: Epoch time: 67.48 s 
2025-07-11 17:23:13.418790: Yayy! New best EMA pseudo Dice: 0.9368000030517578 
2025-07-11 17:23:15.712357:  
2025-07-11 17:23:15.713908: Epoch 42 
2025-07-11 17:23:15.715379: Current learning rate: 0.00962 
2025-07-11 17:24:23.347573: train_loss -0.9518 
2025-07-11 17:24:23.348870: val_loss -0.9381 
2025-07-11 17:24:23.350057: Pseudo dice [np.float32(0.9452)] 
2025-07-11 17:24:23.351327: Epoch time: 67.64 s 
2025-07-11 17:24:23.352355: Yayy! New best EMA pseudo Dice: 0.9376000165939331 
2025-07-11 17:24:25.652972:  
2025-07-11 17:24:25.654666: Epoch 43 
2025-07-11 17:24:25.656679: Current learning rate: 0.00961 
2025-07-11 17:25:33.233672: train_loss -0.9518 
2025-07-11 17:25:33.234928: val_loss -0.9416 
2025-07-11 17:25:33.236021: Pseudo dice [np.float32(0.9482)] 
2025-07-11 17:25:33.237182: Epoch time: 67.58 s 
2025-07-11 17:25:33.238178: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-07-11 17:25:35.550666:  
2025-07-11 17:25:35.552256: Epoch 44 
2025-07-11 17:25:35.553309: Current learning rate: 0.0096 
2025-07-11 17:26:43.254837: train_loss -0.9534 
2025-07-11 17:26:43.256298: val_loss -0.9393 
2025-07-11 17:26:43.258924: Pseudo dice [np.float32(0.9451)] 
2025-07-11 17:26:43.260107: Epoch time: 67.71 s 
2025-07-11 17:26:43.261135: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-07-11 17:26:45.591994:  
2025-07-11 17:26:45.593692: Epoch 45 
2025-07-11 17:26:45.595198: Current learning rate: 0.00959 
2025-07-11 17:27:53.444403: train_loss -0.9531 
2025-07-11 17:27:53.445980: val_loss -0.9406 
2025-07-11 17:27:53.447054: Pseudo dice [np.float32(0.9469)] 
2025-07-11 17:27:53.448150: Epoch time: 67.86 s 
2025-07-11 17:27:53.449214: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-07-11 17:27:55.767971:  
2025-07-11 17:27:55.769345: Epoch 46 
2025-07-11 17:27:55.770540: Current learning rate: 0.00959 
2025-07-11 17:29:03.729481: train_loss -0.9533 
2025-07-11 17:29:03.730872: val_loss -0.9434 
2025-07-11 17:29:03.731714: Pseudo dice [np.float32(0.9501)] 
2025-07-11 17:29:03.732767: Epoch time: 67.97 s 
2025-07-11 17:29:03.733799: Yayy! New best EMA pseudo Dice: 0.941100001335144 
2025-07-11 17:29:06.027937:  
2025-07-11 17:29:06.029338: Epoch 47 
2025-07-11 17:29:06.030477: Current learning rate: 0.00958 
2025-07-11 17:30:13.889131: train_loss -0.9529 
2025-07-11 17:30:13.890539: val_loss -0.9445 
2025-07-11 17:30:13.891572: Pseudo dice [np.float32(0.9503)] 
2025-07-11 17:30:13.892386: Epoch time: 67.86 s 
2025-07-11 17:30:13.893699: Yayy! New best EMA pseudo Dice: 0.9419999718666077 
2025-07-11 17:30:16.216782:  
2025-07-11 17:30:16.218164: Epoch 48 
2025-07-11 17:30:16.219326: Current learning rate: 0.00957 
2025-07-11 17:31:24.482507: train_loss -0.9538 
2025-07-11 17:31:24.483944: val_loss -0.941 
2025-07-11 17:31:24.484919: Pseudo dice [np.float32(0.9471)] 
2025-07-11 17:31:24.485955: Epoch time: 68.27 s 
2025-07-11 17:31:24.486919: Yayy! New best EMA pseudo Dice: 0.9424999952316284 
2025-07-11 17:31:26.752196:  
2025-07-11 17:31:26.753801: Epoch 49 
2025-07-11 17:31:26.754960: Current learning rate: 0.00956 
2025-07-11 17:32:34.278870: train_loss -0.9542 
2025-07-11 17:32:34.280387: val_loss -0.9443 
2025-07-11 17:32:34.281760: Pseudo dice [np.float32(0.9511)] 
2025-07-11 17:32:34.282827: Epoch time: 67.53 s 
2025-07-11 17:32:35.544050: Yayy! New best EMA pseudo Dice: 0.9434000253677368 
2025-07-11 17:32:37.809522:  
2025-07-11 17:32:37.811100: Epoch 50 
2025-07-11 17:32:37.812211: Current learning rate: 0.00955 
2025-07-11 17:33:45.328466: train_loss -0.9549 
2025-07-11 17:33:45.329774: val_loss -0.9398 
2025-07-11 17:33:45.330833: Pseudo dice [np.float32(0.9451)] 
2025-07-11 17:33:45.331753: Epoch time: 67.52 s 
2025-07-11 17:33:45.332603: Yayy! New best EMA pseudo Dice: 0.9435999989509583 
2025-07-11 17:33:47.635206:  
2025-07-11 17:33:47.636879: Epoch 51 
2025-07-11 17:33:47.638160: Current learning rate: 0.00954 
2025-07-11 17:34:55.124275: train_loss -0.9558 
2025-07-11 17:34:55.125647: val_loss -0.9426 
2025-07-11 17:34:55.126657: Pseudo dice [np.float32(0.9496)] 
2025-07-11 17:34:55.127724: Epoch time: 67.49 s 
2025-07-11 17:34:55.128686: Yayy! New best EMA pseudo Dice: 0.9441999793052673 
2025-07-11 17:34:57.428547:  
2025-07-11 17:34:57.429745: Epoch 52 
2025-07-11 17:34:57.430948: Current learning rate: 0.00953 
2025-07-11 17:36:05.162932: train_loss -0.9554 
2025-07-11 17:36:05.164083: val_loss -0.9445 
2025-07-11 17:36:05.165177: Pseudo dice [np.float32(0.9515)] 
2025-07-11 17:36:05.166276: Epoch time: 67.74 s 
2025-07-11 17:36:05.167279: Yayy! New best EMA pseudo Dice: 0.9448999762535095 
2025-07-11 17:36:07.496186:  
2025-07-11 17:36:07.497956: Epoch 53 
2025-07-11 17:36:07.499598: Current learning rate: 0.00952 
2025-07-11 17:37:14.935558: train_loss -0.9566 
2025-07-11 17:37:14.936898: val_loss -0.9439 
2025-07-11 17:37:14.937908: Pseudo dice [np.float32(0.95)] 
2025-07-11 17:37:14.938994: Epoch time: 67.44 s 
2025-07-11 17:37:14.939950: Yayy! New best EMA pseudo Dice: 0.9453999996185303 
2025-07-11 17:37:17.258431:  
2025-07-11 17:37:17.260668: Epoch 54 
2025-07-11 17:37:17.262227: Current learning rate: 0.00951 
2025-07-11 17:38:24.655796: train_loss -0.958 
2025-07-11 17:38:24.657302: val_loss -0.9426 
2025-07-11 17:38:24.658339: Pseudo dice [np.float32(0.9469)] 
2025-07-11 17:38:24.660244: Epoch time: 67.4 s 
2025-07-11 17:38:24.661263: Yayy! New best EMA pseudo Dice: 0.9455999732017517 
2025-07-11 17:38:27.065904:  
2025-07-11 17:38:27.067706: Epoch 55 
2025-07-11 17:38:27.069396: Current learning rate: 0.0095 
2025-07-11 17:39:34.483319: train_loss -0.9558 
2025-07-11 17:39:34.484627: val_loss -0.9459 
2025-07-11 17:39:34.485712: Pseudo dice [np.float32(0.9513)] 
2025-07-11 17:39:34.486972: Epoch time: 67.42 s 
2025-07-11 17:39:34.487843: Yayy! New best EMA pseudo Dice: 0.9460999965667725 
2025-07-11 17:39:37.849097:  
2025-07-11 17:39:37.850580: Epoch 56 
2025-07-11 17:39:37.851719: Current learning rate: 0.00949 
2025-07-11 17:40:45.378340: train_loss -0.9549 
2025-07-11 17:40:45.379600: val_loss -0.9417 
2025-07-11 17:40:45.380708: Pseudo dice [np.float32(0.9484)] 
2025-07-11 17:40:45.381724: Epoch time: 67.53 s 
2025-07-11 17:40:45.382847: Yayy! New best EMA pseudo Dice: 0.946399986743927 
2025-07-11 17:40:47.681331:  
2025-07-11 17:40:47.682819: Epoch 57 
2025-07-11 17:40:47.683929: Current learning rate: 0.00949 
2025-07-11 17:41:54.881991: train_loss -0.9569 
2025-07-11 17:41:54.885051: val_loss -0.9403 
2025-07-11 17:41:54.886226: Pseudo dice [np.float32(0.9467)] 
2025-07-11 17:41:54.887128: Epoch time: 67.2 s 
2025-07-11 17:41:54.888291: Yayy! New best EMA pseudo Dice: 0.946399986743927 
2025-07-11 17:41:57.208148:  
2025-07-11 17:41:57.209704: Epoch 58 
2025-07-11 17:41:57.210842: Current learning rate: 0.00948 
2025-07-11 17:43:04.434262: train_loss -0.9586 
2025-07-11 17:43:04.435540: val_loss -0.9462 
2025-07-11 17:43:04.436457: Pseudo dice [np.float32(0.9515)] 
2025-07-11 17:43:04.437521: Epoch time: 67.23 s 
2025-07-11 17:43:04.438508: Yayy! New best EMA pseudo Dice: 0.9469000101089478 
2025-07-11 17:43:06.757957:  
2025-07-11 17:43:06.759672: Epoch 59 
2025-07-11 17:43:06.760879: Current learning rate: 0.00947 
2025-07-11 17:44:13.979960: train_loss -0.9587 
2025-07-11 17:44:13.981290: val_loss -0.9437 
2025-07-11 17:44:13.982532: Pseudo dice [np.float32(0.9492)] 
2025-07-11 17:44:13.983425: Epoch time: 67.23 s 
2025-07-11 17:44:13.984396: Yayy! New best EMA pseudo Dice: 0.9470999836921692 
2025-07-11 17:44:16.316362:  
2025-07-11 17:44:16.317862: Epoch 60 
2025-07-11 17:44:16.319041: Current learning rate: 0.00946 
2025-07-11 17:45:23.766192: train_loss -0.9581 
2025-07-11 17:45:23.767421: val_loss -0.945 
2025-07-11 17:45:23.768501: Pseudo dice [np.float32(0.9507)] 
2025-07-11 17:45:23.769705: Epoch time: 67.45 s 
2025-07-11 17:45:23.770636: Yayy! New best EMA pseudo Dice: 0.9474999904632568 
2025-07-11 17:45:26.113330:  
2025-07-11 17:45:26.114897: Epoch 61 
2025-07-11 17:45:26.116052: Current learning rate: 0.00945 
2025-07-11 17:46:33.720887: train_loss -0.9562 
2025-07-11 17:46:33.722072: val_loss -0.9415 
2025-07-11 17:46:33.723238: Pseudo dice [np.float32(0.9477)] 
2025-07-11 17:46:33.724300: Epoch time: 67.61 s 
2025-07-11 17:46:33.725426: Yayy! New best EMA pseudo Dice: 0.9474999904632568 
2025-07-11 17:46:36.088028:  
2025-07-11 17:46:36.089667: Epoch 62 
2025-07-11 17:46:36.090790: Current learning rate: 0.00944 
2025-07-11 17:47:43.584456: train_loss -0.9562 
2025-07-11 17:47:43.585717: val_loss -0.941 
2025-07-11 17:47:43.586695: Pseudo dice [np.float32(0.9472)] 
2025-07-11 17:47:43.587800: Epoch time: 67.5 s 
2025-07-11 17:47:44.472973:  
2025-07-11 17:47:44.474907: Epoch 63 
2025-07-11 17:47:44.476217: Current learning rate: 0.00943 
2025-07-11 17:48:52.015701: train_loss -0.9581 
2025-07-11 17:48:52.017120: val_loss -0.9427 
2025-07-11 17:48:52.018444: Pseudo dice [np.float32(0.9475)] 
2025-07-11 17:48:52.019705: Epoch time: 67.55 s 
2025-07-11 17:48:52.927363:  
2025-07-11 17:48:52.928933: Epoch 64 
2025-07-11 17:48:52.930139: Current learning rate: 0.00942 
2025-07-11 17:50:01.431179: train_loss -0.9578 
2025-07-11 17:50:01.432513: val_loss -0.947 
2025-07-11 17:50:01.433691: Pseudo dice [np.float32(0.9526)] 
2025-07-11 17:50:01.434756: Epoch time: 68.51 s 
2025-07-11 17:50:01.435890: Yayy! New best EMA pseudo Dice: 0.9480000138282776 
2025-07-11 17:50:03.729465:  
2025-07-11 17:50:03.730664: Epoch 65 
2025-07-11 17:50:03.731936: Current learning rate: 0.00941 
2025-07-11 17:51:11.588129: train_loss -0.9589 
2025-07-11 17:51:11.589550: val_loss -0.944 
2025-07-11 17:51:11.590788: Pseudo dice [np.float32(0.9498)] 
2025-07-11 17:51:11.591998: Epoch time: 67.86 s 
2025-07-11 17:51:11.593114: Yayy! New best EMA pseudo Dice: 0.948199987411499 
2025-07-11 17:51:13.917482:  
2025-07-11 17:51:13.918922: Epoch 66 
2025-07-11 17:51:13.920192: Current learning rate: 0.0094 
2025-07-11 17:52:21.900606: train_loss -0.9585 
2025-07-11 17:52:21.901897: val_loss -0.9361 
2025-07-11 17:52:21.902857: Pseudo dice [np.float32(0.9418)] 
2025-07-11 17:52:21.903854: Epoch time: 67.99 s 
2025-07-11 17:52:22.820396:  
2025-07-11 17:52:22.821948: Epoch 67 
2025-07-11 17:52:22.823079: Current learning rate: 0.00939 
2025-07-11 17:53:30.354343: train_loss -0.9589 
2025-07-11 17:53:30.355626: val_loss -0.9406 
2025-07-11 17:53:30.356766: Pseudo dice [np.float32(0.9471)] 
2025-07-11 17:53:30.357940: Epoch time: 67.54 s 
2025-07-11 17:53:31.281438:  
2025-07-11 17:53:31.282791: Epoch 68 
2025-07-11 17:53:31.283794: Current learning rate: 0.00939 
2025-07-11 17:54:38.589423: train_loss -0.9583 
2025-07-11 17:54:38.590545: val_loss -0.9434 
2025-07-11 17:54:38.591950: Pseudo dice [np.float32(0.9483)] 
2025-07-11 17:54:38.592915: Epoch time: 67.31 s 
2025-07-11 17:54:39.510188:  
2025-07-11 17:54:39.512006: Epoch 69 
2025-07-11 17:54:39.513532: Current learning rate: 0.00938 
2025-07-11 17:55:47.119507: train_loss -0.9614 
2025-07-11 17:55:47.120925: val_loss -0.9437 
2025-07-11 17:55:47.121986: Pseudo dice [np.float32(0.9495)] 
2025-07-11 17:55:47.123075: Epoch time: 67.61 s 
2025-07-11 17:55:48.029839:  
2025-07-11 17:55:48.031461: Epoch 70 
2025-07-11 17:55:48.032510: Current learning rate: 0.00937 
2025-07-11 17:56:55.467653: train_loss -0.9605 
2025-07-11 17:56:55.468980: val_loss -0.9448 
2025-07-11 17:56:55.470287: Pseudo dice [np.float32(0.9507)] 
2025-07-11 17:56:55.471154: Epoch time: 67.44 s 
2025-07-11 17:56:56.381701:  
2025-07-11 17:56:56.383082: Epoch 71 
2025-07-11 17:56:56.384202: Current learning rate: 0.00936 
2025-07-11 17:58:03.761377: train_loss -0.9595 
2025-07-11 17:58:03.762983: val_loss -0.9459 
2025-07-11 17:58:03.764278: Pseudo dice [np.float32(0.951)] 
2025-07-11 17:58:03.765410: Epoch time: 67.38 s 
2025-07-11 17:58:03.766713: Yayy! New best EMA pseudo Dice: 0.9483000040054321 
2025-07-11 17:58:06.134284:  
2025-07-11 17:58:06.135865: Epoch 72 
2025-07-11 17:58:06.137335: Current learning rate: 0.00935 
2025-07-11 17:59:13.574258: train_loss -0.9605 
2025-07-11 17:59:13.575451: val_loss -0.9437 
2025-07-11 17:59:13.576578: Pseudo dice [np.float32(0.9492)] 
2025-07-11 17:59:13.577493: Epoch time: 67.44 s 
2025-07-11 17:59:13.578499: Yayy! New best EMA pseudo Dice: 0.9484000205993652 
2025-07-11 17:59:16.731840:  
2025-07-11 17:59:16.733418: Epoch 73 
2025-07-11 17:59:16.734550: Current learning rate: 0.00934 
2025-07-11 18:00:24.171669: train_loss -0.9604 
2025-07-11 18:00:24.173161: val_loss -0.9461 
2025-07-11 18:00:24.174253: Pseudo dice [np.float32(0.9515)] 
2025-07-11 18:00:24.175279: Epoch time: 67.44 s 
2025-07-11 18:00:24.176210: Yayy! New best EMA pseudo Dice: 0.9487000107765198 
2025-07-11 18:00:26.580005:  
2025-07-11 18:00:26.581914: Epoch 74 
2025-07-11 18:00:26.583609: Current learning rate: 0.00933 
2025-07-11 18:01:33.960339: train_loss -0.9611 
2025-07-11 18:01:33.961763: val_loss -0.9457 
2025-07-11 18:01:33.962790: Pseudo dice [np.float32(0.9516)] 
2025-07-11 18:01:33.963828: Epoch time: 67.38 s 
2025-07-11 18:01:33.964898: Yayy! New best EMA pseudo Dice: 0.9490000009536743 
2025-07-11 18:01:36.324034:  
2025-07-11 18:01:36.325529: Epoch 75 
2025-07-11 18:01:36.326649: Current learning rate: 0.00932 
2025-07-11 18:02:43.740234: train_loss -0.9609 
2025-07-11 18:02:43.742014: val_loss -0.9438 
2025-07-11 18:02:43.743108: Pseudo dice [np.float32(0.9494)] 
2025-07-11 18:02:43.744175: Epoch time: 67.42 s 
2025-07-11 18:02:43.745491: Yayy! New best EMA pseudo Dice: 0.9491000175476074 
2025-07-11 18:02:46.179830:  
2025-07-11 18:02:46.181199: Epoch 76 
2025-07-11 18:02:46.182318: Current learning rate: 0.00931 
2025-07-11 18:03:53.954014: train_loss -0.9615 
2025-07-11 18:03:53.955391: val_loss -0.9436 
2025-07-11 18:03:53.956564: Pseudo dice [np.float32(0.9495)] 
2025-07-11 18:03:53.957716: Epoch time: 67.78 s 
2025-07-11 18:03:53.958709: Yayy! New best EMA pseudo Dice: 0.9491000175476074 
2025-07-11 18:03:56.282201:  
2025-07-11 18:03:56.283972: Epoch 77 
2025-07-11 18:03:56.285101: Current learning rate: 0.0093 
2025-07-11 18:05:03.935128: train_loss -0.9605 
2025-07-11 18:05:03.936643: val_loss -0.9393 
2025-07-11 18:05:03.938113: Pseudo dice [np.float32(0.9448)] 
2025-07-11 18:05:03.939333: Epoch time: 67.66 s 
2025-07-11 18:05:04.887404:  
2025-07-11 18:05:04.889028: Epoch 78 
2025-07-11 18:05:04.890273: Current learning rate: 0.0093 
2025-07-11 18:06:12.711993: train_loss -0.962 
2025-07-11 18:06:12.713424: val_loss -0.945 
2025-07-11 18:06:12.714318: Pseudo dice [np.float32(0.9509)] 
2025-07-11 18:06:12.715686: Epoch time: 67.83 s 
2025-07-11 18:06:13.654601:  
2025-07-11 18:06:13.656563: Epoch 79 
2025-07-11 18:06:13.657836: Current learning rate: 0.00929 
2025-07-11 18:07:21.590513: train_loss -0.9628 
2025-07-11 18:07:21.591886: val_loss -0.9446 
2025-07-11 18:07:21.593071: Pseudo dice [np.float32(0.95)] 
2025-07-11 18:07:21.594361: Epoch time: 67.94 s 
2025-07-11 18:07:22.539701:  
2025-07-11 18:07:22.541260: Epoch 80 
2025-07-11 18:07:22.542479: Current learning rate: 0.00928 
2025-07-11 18:08:30.358808: train_loss -0.9614 
2025-07-11 18:08:30.360110: val_loss -0.9397 
2025-07-11 18:08:30.361230: Pseudo dice [np.float32(0.9458)] 
2025-07-11 18:08:30.362176: Epoch time: 67.82 s 
2025-07-11 18:08:32.323944:  
2025-07-11 18:08:32.325702: Epoch 81 
2025-07-11 18:08:32.326870: Current learning rate: 0.00927 
2025-07-11 18:09:40.207358: train_loss -0.9612 
2025-07-11 18:09:40.208699: val_loss -0.9439 
2025-07-11 18:09:40.209811: Pseudo dice [np.float32(0.9494)] 
2025-07-11 18:09:40.210853: Epoch time: 67.89 s 
2025-07-11 18:09:41.142432:  
2025-07-11 18:09:41.144042: Epoch 82 
2025-07-11 18:09:41.145163: Current learning rate: 0.00926 
2025-07-11 18:10:49.179944: train_loss -0.9607 
2025-07-11 18:10:49.182407: val_loss -0.9456 
2025-07-11 18:10:49.183807: Pseudo dice [np.float32(0.9497)] 
2025-07-11 18:10:49.184699: Epoch time: 68.04 s 
2025-07-11 18:10:50.083418:  
2025-07-11 18:10:50.084920: Epoch 83 
2025-07-11 18:10:50.086112: Current learning rate: 0.00925 
2025-07-11 18:11:58.368553: train_loss -0.9612 
2025-07-11 18:11:58.369782: val_loss -0.9423 
2025-07-11 18:11:58.370999: Pseudo dice [np.float32(0.9475)] 
2025-07-11 18:11:58.372048: Epoch time: 68.29 s 
2025-07-11 18:11:59.283581:  
2025-07-11 18:11:59.285408: Epoch 84 
2025-07-11 18:11:59.286563: Current learning rate: 0.00924 
2025-07-11 18:13:07.553546: train_loss -0.9603 
2025-07-11 18:13:07.554904: val_loss -0.9436 
2025-07-11 18:13:07.556098: Pseudo dice [np.float32(0.9494)] 
2025-07-11 18:13:07.557008: Epoch time: 68.27 s 
2025-07-11 18:13:08.450433:  
2025-07-11 18:13:08.452011: Epoch 85 
2025-07-11 18:13:08.453224: Current learning rate: 0.00923 
2025-07-11 18:14:16.806949: train_loss -0.9611 
2025-07-11 18:14:16.808429: val_loss -0.9433 
2025-07-11 18:14:16.809578: Pseudo dice [np.float32(0.9482)] 
2025-07-11 18:14:16.810688: Epoch time: 68.36 s 
2025-07-11 18:14:17.725211:  
2025-07-11 18:14:17.726825: Epoch 86 
2025-07-11 18:14:17.728053: Current learning rate: 0.00922 
2025-07-11 18:15:25.589175: train_loss -0.9615 
2025-07-11 18:15:25.590395: val_loss -0.942 
2025-07-11 18:15:25.592075: Pseudo dice [np.float32(0.9463)] 
2025-07-11 18:15:25.593186: Epoch time: 67.87 s 
2025-07-11 18:15:26.498848:  
2025-07-11 18:15:26.500384: Epoch 87 
2025-07-11 18:15:26.501720: Current learning rate: 0.00921 
2025-07-11 18:16:34.280927: train_loss -0.9626 
2025-07-11 18:16:34.282019: val_loss -0.9474 
2025-07-11 18:16:34.283107: Pseudo dice [np.float32(0.9522)] 
2025-07-11 18:16:34.284182: Epoch time: 67.79 s 
2025-07-11 18:16:35.184218:  
2025-07-11 18:16:35.185923: Epoch 88 
2025-07-11 18:16:35.186971: Current learning rate: 0.0092 
2025-07-11 18:17:42.813636: train_loss -0.9626 
2025-07-11 18:17:42.814907: val_loss -0.9441 
2025-07-11 18:17:42.816155: Pseudo dice [np.float32(0.9493)] 
2025-07-11 18:17:42.817436: Epoch time: 67.63 s 
2025-07-11 18:17:43.713034:  
2025-07-11 18:17:43.714852: Epoch 89 
2025-07-11 18:17:43.716029: Current learning rate: 0.0092 
2025-07-11 18:18:51.460248: train_loss -0.9616 
2025-07-11 18:18:51.461623: val_loss -0.9442 
2025-07-11 18:18:51.462672: Pseudo dice [np.float32(0.9491)] 
2025-07-11 18:18:51.463860: Epoch time: 67.75 s 
2025-07-11 18:18:52.365886:  
2025-07-11 18:18:52.367423: Epoch 90 
2025-07-11 18:18:52.368534: Current learning rate: 0.00919 
2025-07-11 18:20:01.183479: train_loss -0.9615 
2025-07-11 18:20:01.184765: val_loss -0.941 
2025-07-11 18:20:01.185724: Pseudo dice [np.float32(0.9458)] 
2025-07-11 18:20:01.186909: Epoch time: 68.82 s 
2025-07-11 18:20:02.090729:  
2025-07-11 18:20:02.092403: Epoch 91 
2025-07-11 18:20:02.093559: Current learning rate: 0.00918 
2025-07-11 18:21:10.064824: train_loss -0.9617 
2025-07-11 18:21:10.066073: val_loss -0.9404 
2025-07-11 18:21:10.067235: Pseudo dice [np.float32(0.9459)] 
2025-07-11 18:21:10.068392: Epoch time: 67.98 s 
2025-07-11 18:21:10.955808:  
2025-07-11 18:21:10.957613: Epoch 92 
2025-07-11 18:21:10.958934: Current learning rate: 0.00917 
2025-07-11 18:22:18.656405: train_loss -0.9625 
2025-07-11 18:22:18.657852: val_loss -0.9431 
2025-07-11 18:22:18.658925: Pseudo dice [np.float32(0.9478)] 
2025-07-11 18:22:18.660004: Epoch time: 67.7 s 
2025-07-11 18:22:19.550413:  
2025-07-11 18:22:19.551960: Epoch 93 
2025-07-11 18:22:19.553160: Current learning rate: 0.00916 
2025-07-11 18:23:27.155968: train_loss -0.9636 
2025-07-11 18:23:27.157208: val_loss -0.9474 
2025-07-11 18:23:27.158389: Pseudo dice [np.float32(0.9516)] 
2025-07-11 18:23:27.159425: Epoch time: 67.61 s 
2025-07-11 18:23:28.054466:  
2025-07-11 18:23:28.056249: Epoch 94 
2025-07-11 18:23:28.057317: Current learning rate: 0.00915 
2025-07-11 18:24:35.804083: train_loss -0.9621 
2025-07-11 18:24:35.805335: val_loss -0.9445 
2025-07-11 18:24:35.806443: Pseudo dice [np.float32(0.9491)] 
2025-07-11 18:24:35.807401: Epoch time: 67.75 s 
2025-07-11 18:24:36.695930:  
2025-07-11 18:24:36.697631: Epoch 95 
2025-07-11 18:24:36.698840: Current learning rate: 0.00914 
2025-07-11 18:25:44.407247: train_loss -0.9632 
2025-07-11 18:25:44.408819: val_loss -0.9491 
2025-07-11 18:25:44.410023: Pseudo dice [np.float32(0.9542)] 
2025-07-11 18:25:44.411263: Epoch time: 67.71 s 
2025-07-11 18:25:44.412444: Yayy! New best EMA pseudo Dice: 0.9491999745368958 
2025-07-11 18:25:46.706170:  
2025-07-11 18:25:46.707811: Epoch 96 
2025-07-11 18:25:46.708916: Current learning rate: 0.00913 
2025-07-11 18:26:54.278102: train_loss -0.9626 
2025-07-11 18:26:54.279349: val_loss -0.9434 
2025-07-11 18:26:54.280400: Pseudo dice [np.float32(0.9474)] 
2025-07-11 18:26:54.281570: Epoch time: 67.58 s 
2025-07-11 18:26:55.176570:  
2025-07-11 18:26:55.178087: Epoch 97 
2025-07-11 18:26:55.179306: Current learning rate: 0.00912 
2025-07-11 18:28:03.044420: train_loss -0.9626 
2025-07-11 18:28:03.045980: val_loss -0.9466 
2025-07-11 18:28:03.047148: Pseudo dice [np.float32(0.9516)] 
2025-07-11 18:28:03.048316: Epoch time: 67.87 s 
2025-07-11 18:28:03.049349: Yayy! New best EMA pseudo Dice: 0.9492999911308289 
2025-07-11 18:28:05.369072:  
2025-07-11 18:28:05.370754: Epoch 98 
2025-07-11 18:28:05.371821: Current learning rate: 0.00911 
2025-07-11 18:29:12.909461: train_loss -0.9625 
2025-07-11 18:29:12.910718: val_loss -0.9476 
2025-07-11 18:29:12.911899: Pseudo dice [np.float32(0.9515)] 
2025-07-11 18:29:12.912838: Epoch time: 67.54 s 
2025-07-11 18:29:12.914006: Yayy! New best EMA pseudo Dice: 0.9495000243186951 
2025-07-11 18:29:16.061108:  
2025-07-11 18:29:16.062764: Epoch 99 
2025-07-11 18:29:16.063848: Current learning rate: 0.0091 
2025-07-11 18:30:23.792005: train_loss -0.964 
2025-07-11 18:30:23.793366: val_loss -0.9456 
2025-07-11 18:30:23.794457: Pseudo dice [np.float32(0.9503)] 
2025-07-11 18:30:23.795544: Epoch time: 67.73 s 
2025-07-11 18:30:25.056462: Yayy! New best EMA pseudo Dice: 0.9495999813079834 
2025-07-11 18:30:27.321182:  
2025-07-11 18:30:27.322679: Epoch 100 
2025-07-11 18:30:27.323744: Current learning rate: 0.0091 
2025-07-11 18:31:35.091542: train_loss -0.9639 
2025-07-11 18:31:35.092838: val_loss -0.9481 
2025-07-11 18:31:35.093900: Pseudo dice [np.float32(0.952)] 
2025-07-11 18:31:35.094925: Epoch time: 67.77 s 
2025-07-11 18:31:35.095882: Yayy! New best EMA pseudo Dice: 0.9498000144958496 
2025-07-11 18:31:37.429933:  
2025-07-11 18:31:37.431407: Epoch 101 
2025-07-11 18:31:37.432542: Current learning rate: 0.00909 
2025-07-11 18:32:45.316552: train_loss -0.964 
2025-07-11 18:32:45.318034: val_loss -0.9451 
2025-07-11 18:32:45.319289: Pseudo dice [np.float32(0.9506)] 
2025-07-11 18:32:45.320528: Epoch time: 67.89 s 
2025-07-11 18:32:45.321672: Yayy! New best EMA pseudo Dice: 0.9498999714851379 
2025-07-11 18:32:47.611628:  
2025-07-11 18:32:47.613237: Epoch 102 
2025-07-11 18:32:47.614357: Current learning rate: 0.00908 
2025-07-11 18:33:55.706526: train_loss -0.9629 
2025-07-11 18:33:55.707961: val_loss -0.9446 
2025-07-11 18:33:55.709026: Pseudo dice [np.float32(0.95)] 
2025-07-11 18:33:55.710268: Epoch time: 68.1 s 
2025-07-11 18:33:55.711457: Yayy! New best EMA pseudo Dice: 0.9498999714851379 
2025-07-11 18:33:58.032240:  
2025-07-11 18:33:58.033867: Epoch 103 
2025-07-11 18:33:58.034994: Current learning rate: 0.00907 
2025-07-11 18:35:06.153937: train_loss -0.9636 
2025-07-11 18:35:06.155071: val_loss -0.9469 
2025-07-11 18:35:06.156161: Pseudo dice [np.float32(0.952)] 
2025-07-11 18:35:06.157382: Epoch time: 68.13 s 
2025-07-11 18:35:06.158251: Yayy! New best EMA pseudo Dice: 0.9501000046730042 
2025-07-11 18:35:08.458112:  
2025-07-11 18:35:08.459789: Epoch 104 
2025-07-11 18:35:08.460974: Current learning rate: 0.00906 
2025-07-11 18:36:16.509637: train_loss -0.9634 
2025-07-11 18:36:16.511014: val_loss -0.9412 
2025-07-11 18:36:16.512125: Pseudo dice [np.float32(0.9463)] 
2025-07-11 18:36:16.513237: Epoch time: 68.06 s 
2025-07-11 18:36:17.430480:  
2025-07-11 18:36:17.432119: Epoch 105 
2025-07-11 18:36:17.433199: Current learning rate: 0.00905 
2025-07-11 18:37:25.217603: train_loss -0.9639 
2025-07-11 18:37:25.218958: val_loss -0.9409 
2025-07-11 18:37:25.219973: Pseudo dice [np.float32(0.9458)] 
2025-07-11 18:37:25.220998: Epoch time: 67.79 s 
2025-07-11 18:37:26.098267:  
2025-07-11 18:37:26.099608: Epoch 106 
2025-07-11 18:37:26.100765: Current learning rate: 0.00904 
2025-07-11 18:38:33.670099: train_loss -0.9628 
2025-07-11 18:38:33.671602: val_loss -0.9464 
2025-07-11 18:38:33.672714: Pseudo dice [np.float32(0.9508)] 
2025-07-11 18:38:33.673891: Epoch time: 67.58 s 
2025-07-11 18:38:34.568541:  
2025-07-11 18:38:34.570006: Epoch 107 
2025-07-11 18:38:34.571377: Current learning rate: 0.00903 
2025-07-11 18:39:42.949591: train_loss -0.9642 
2025-07-11 18:39:42.950758: val_loss -0.9466 
2025-07-11 18:39:42.951714: Pseudo dice [np.float32(0.9515)] 
2025-07-11 18:39:42.952718: Epoch time: 68.38 s 
2025-07-11 18:39:43.849432:  
2025-07-11 18:39:43.851123: Epoch 108 
2025-07-11 18:39:43.852326: Current learning rate: 0.00902 
2025-07-11 18:40:51.401066: train_loss -0.9629 
2025-07-11 18:40:51.402330: val_loss -0.9473 
2025-07-11 18:40:51.403640: Pseudo dice [np.float32(0.9522)] 
2025-07-11 18:40:51.404715: Epoch time: 67.56 s 
2025-07-11 18:40:52.300072:  
2025-07-11 18:40:52.301675: Epoch 109 
2025-07-11 18:40:52.302866: Current learning rate: 0.00901 
2025-07-11 18:41:59.910309: train_loss -0.9633 
2025-07-11 18:41:59.911731: val_loss -0.9477 
2025-07-11 18:41:59.912933: Pseudo dice [np.float32(0.9524)] 
2025-07-11 18:41:59.913979: Epoch time: 67.61 s 
2025-07-11 18:41:59.915195: Yayy! New best EMA pseudo Dice: 0.9502000212669373 
2025-07-11 18:42:02.258919:  
2025-07-11 18:42:02.260752: Epoch 110 
2025-07-11 18:42:02.261901: Current learning rate: 0.009 
2025-07-11 18:43:09.929168: train_loss -0.9657 
2025-07-11 18:43:09.930663: val_loss -0.9434 
2025-07-11 18:43:09.931692: Pseudo dice [np.float32(0.9479)] 
2025-07-11 18:43:09.932511: Epoch time: 67.67 s 
2025-07-11 18:43:10.827925:  
2025-07-11 18:43:10.829670: Epoch 111 
2025-07-11 18:43:10.830815: Current learning rate: 0.009 
2025-07-11 18:44:18.426611: train_loss -0.9639 
2025-07-11 18:44:18.427891: val_loss -0.9406 
2025-07-11 18:44:18.429048: Pseudo dice [np.float32(0.9455)] 
2025-07-11 18:44:18.430495: Epoch time: 67.6 s 
2025-07-11 18:44:19.342378:  
2025-07-11 18:44:19.344430: Epoch 112 
2025-07-11 18:44:19.345755: Current learning rate: 0.00899 
2025-07-11 18:45:27.039560: train_loss -0.9631 
2025-07-11 18:45:27.041080: val_loss -0.9416 
2025-07-11 18:45:27.042179: Pseudo dice [np.float32(0.9477)] 
2025-07-11 18:45:27.043262: Epoch time: 67.7 s 
2025-07-11 18:45:27.943012:  
2025-07-11 18:45:27.944579: Epoch 113 
2025-07-11 18:45:27.945736: Current learning rate: 0.00898 
2025-07-11 18:46:35.896466: train_loss -0.9636 
2025-07-11 18:46:35.897794: val_loss -0.9404 
2025-07-11 18:46:35.898864: Pseudo dice [np.float32(0.9455)] 
2025-07-11 18:46:35.899824: Epoch time: 67.96 s 
2025-07-11 18:46:36.792382:  
2025-07-11 18:46:36.793931: Epoch 114 
2025-07-11 18:46:36.795104: Current learning rate: 0.00897 
2025-07-11 18:47:44.771064: train_loss -0.9624 
2025-07-11 18:47:44.772398: val_loss -0.9426 
2025-07-11 18:47:44.773449: Pseudo dice [np.float32(0.9476)] 
2025-07-11 18:47:44.774622: Epoch time: 67.98 s 
2025-07-11 18:47:45.674146:  
2025-07-11 18:47:45.675745: Epoch 115 
2025-07-11 18:47:45.676972: Current learning rate: 0.00896 
2025-07-11 18:48:53.539255: train_loss -0.9649 
2025-07-11 18:48:53.540659: val_loss -0.9433 
2025-07-11 18:48:53.541822: Pseudo dice [np.float32(0.9478)] 
2025-07-11 18:48:53.542938: Epoch time: 67.87 s 
2025-07-11 18:48:54.456278:  
2025-07-11 18:48:54.457978: Epoch 116 
2025-07-11 18:48:54.459140: Current learning rate: 0.00895 
2025-07-11 18:50:03.148528: train_loss -0.966 
2025-07-11 18:50:03.149963: val_loss -0.9455 
2025-07-11 18:50:03.151184: Pseudo dice [np.float32(0.9503)] 
2025-07-11 18:50:03.152308: Epoch time: 68.7 s 
2025-07-11 18:50:04.062161:  
2025-07-11 18:50:04.063921: Epoch 117 
2025-07-11 18:50:04.065035: Current learning rate: 0.00894 
2025-07-11 18:51:12.022922: train_loss -0.965 
2025-07-11 18:51:12.024250: val_loss -0.9456 
2025-07-11 18:51:12.025422: Pseudo dice [np.float32(0.9505)] 
2025-07-11 18:51:12.026550: Epoch time: 67.96 s 
2025-07-11 18:51:12.942492:  
2025-07-11 18:51:12.944062: Epoch 118 
2025-07-11 18:51:12.945214: Current learning rate: 0.00893 
2025-07-11 18:52:20.603873: train_loss -0.9644 
2025-07-11 18:52:20.605376: val_loss -0.9446 
2025-07-11 18:52:20.606438: Pseudo dice [np.float32(0.9499)] 
2025-07-11 18:52:20.607561: Epoch time: 67.66 s 
2025-07-11 18:52:21.510435:  
2025-07-11 18:52:21.511963: Epoch 119 
2025-07-11 18:52:21.513150: Current learning rate: 0.00892 
2025-07-11 18:53:29.345066: train_loss -0.9638 
2025-07-11 18:53:29.346269: val_loss -0.9473 
2025-07-11 18:53:29.347332: Pseudo dice [np.float32(0.9519)] 
2025-07-11 18:53:29.348309: Epoch time: 67.84 s 
2025-07-11 18:53:30.244553:  
2025-07-11 18:53:30.246001: Epoch 120 
2025-07-11 18:53:30.247228: Current learning rate: 0.00891 
2025-07-11 18:54:38.079879: train_loss -0.964 
2025-07-11 18:54:38.081172: val_loss -0.9436 
2025-07-11 18:54:38.082338: Pseudo dice [np.float32(0.9487)] 
2025-07-11 18:54:38.083519: Epoch time: 67.84 s 
2025-07-11 18:54:38.988349:  
2025-07-11 18:54:38.989982: Epoch 121 
2025-07-11 18:54:38.991164: Current learning rate: 0.0089 
2025-07-11 18:55:47.163976: train_loss -0.9642 
2025-07-11 18:55:47.165999: val_loss -0.9395 
2025-07-11 18:55:47.167059: Pseudo dice [np.float32(0.9449)] 
2025-07-11 18:55:47.168361: Epoch time: 68.18 s 
2025-07-11 18:55:48.062282:  
2025-07-11 18:55:48.063878: Epoch 122 
2025-07-11 18:55:48.065012: Current learning rate: 0.00889 
2025-07-11 18:56:56.206224: train_loss -0.9641 
2025-07-11 18:56:56.207570: val_loss -0.946 
2025-07-11 18:56:56.208638: Pseudo dice [np.float32(0.9516)] 
2025-07-11 18:56:56.209852: Epoch time: 68.15 s 
2025-07-11 18:56:57.096816:  
2025-07-11 18:56:57.098521: Epoch 123 
2025-07-11 18:56:57.099749: Current learning rate: 0.00889 
2025-07-11 18:58:05.128714: train_loss -0.9639 
2025-07-11 18:58:05.130202: val_loss -0.9453 
2025-07-11 18:58:05.131204: Pseudo dice [np.float32(0.951)] 
2025-07-11 18:58:05.132249: Epoch time: 68.04 s 
2025-07-11 18:58:06.033039:  
2025-07-11 18:58:06.034871: Epoch 124 
2025-07-11 18:58:06.036067: Current learning rate: 0.00888 
2025-07-11 18:59:13.775305: train_loss -0.9639 
2025-07-11 18:59:13.776535: val_loss -0.9427 
2025-07-11 18:59:13.777691: Pseudo dice [np.float32(0.9471)] 
2025-07-11 18:59:13.778771: Epoch time: 67.75 s 
2025-07-11 18:59:14.674422:  
2025-07-11 18:59:14.676145: Epoch 125 
2025-07-11 18:59:14.677286: Current learning rate: 0.00887 
2025-07-11 19:00:23.118172: train_loss -0.9635 
2025-07-11 19:00:23.119573: val_loss -0.949 
2025-07-11 19:00:23.120771: Pseudo dice [np.float32(0.9535)] 
2025-07-11 19:00:23.121942: Epoch time: 68.45 s 
2025-07-11 19:00:24.020689:  
2025-07-11 19:00:24.022428: Epoch 126 
2025-07-11 19:00:24.023646: Current learning rate: 0.00886 
2025-07-11 19:01:31.731649: train_loss -0.9645 
2025-07-11 19:01:31.732956: val_loss -0.9452 
2025-07-11 19:01:31.734149: Pseudo dice [np.float32(0.95)] 
2025-07-11 19:01:31.735512: Epoch time: 67.71 s 
2025-07-11 19:01:32.632737:  
2025-07-11 19:01:32.634466: Epoch 127 
2025-07-11 19:01:32.635779: Current learning rate: 0.00885 
2025-07-11 19:02:40.097637: train_loss -0.9636 
2025-07-11 19:02:40.098907: val_loss -0.9406 
2025-07-11 19:02:40.100054: Pseudo dice [np.float32(0.9455)] 
2025-07-11 19:02:40.101311: Epoch time: 67.47 s 
2025-07-11 19:02:41.005258:  
2025-07-11 19:02:41.006932: Epoch 128 
2025-07-11 19:02:41.008348: Current learning rate: 0.00884 
2025-07-11 19:03:48.535870: train_loss -0.9637 
2025-07-11 19:03:48.537102: val_loss -0.9432 
2025-07-11 19:03:48.538320: Pseudo dice [np.float32(0.9487)] 
2025-07-11 19:03:48.539395: Epoch time: 67.53 s 
2025-07-11 19:03:49.437617:  
2025-07-11 19:03:49.439192: Epoch 129 
2025-07-11 19:03:49.440366: Current learning rate: 0.00883 
2025-07-11 19:04:57.074422: train_loss -0.9643 
2025-07-11 19:04:57.075783: val_loss -0.9464 
2025-07-11 19:04:57.077039: Pseudo dice [np.float32(0.9513)] 
2025-07-11 19:04:57.078066: Epoch time: 67.64 s 
2025-07-11 19:04:57.976155:  
2025-07-11 19:04:57.977788: Epoch 130 
2025-07-11 19:04:57.978893: Current learning rate: 0.00882 
2025-07-11 19:06:05.731544: train_loss -0.9659 
2025-07-11 19:06:05.732801: val_loss -0.9433 
2025-07-11 19:06:05.733765: Pseudo dice [np.float32(0.9478)] 
2025-07-11 19:06:05.734731: Epoch time: 67.76 s 
2025-07-11 19:06:06.633684:  
2025-07-11 19:06:06.635444: Epoch 131 
2025-07-11 19:06:06.636636: Current learning rate: 0.00881 
2025-07-11 19:07:14.233186: train_loss -0.9655 
2025-07-11 19:07:14.234534: val_loss -0.9458 
2025-07-11 19:07:14.235498: Pseudo dice [np.float32(0.951)] 
2025-07-11 19:07:14.236522: Epoch time: 67.6 s 
2025-07-11 19:07:15.119375:  
2025-07-11 19:07:15.121045: Epoch 132 
2025-07-11 19:07:15.122224: Current learning rate: 0.0088 
2025-07-11 19:08:22.942265: train_loss -0.9653 
2025-07-11 19:08:22.943638: val_loss -0.9481 
2025-07-11 19:08:22.944714: Pseudo dice [np.float32(0.9534)] 
2025-07-11 19:08:22.945789: Epoch time: 67.83 s 
2025-07-11 19:08:23.850690:  
2025-07-11 19:08:23.852395: Epoch 133 
2025-07-11 19:08:23.853648: Current learning rate: 0.00879 
2025-07-11 19:09:31.542637: train_loss -0.9652 
2025-07-11 19:09:31.543942: val_loss -0.9479 
2025-07-11 19:09:31.545090: Pseudo dice [np.float32(0.9524)] 
2025-07-11 19:09:31.546254: Epoch time: 67.7 s 
2025-07-11 19:09:32.442425:  
2025-07-11 19:09:32.443967: Epoch 134 
2025-07-11 19:09:32.445130: Current learning rate: 0.00879 
2025-07-11 19:10:40.804041: train_loss -0.9652 
2025-07-11 19:10:40.805505: val_loss -0.9429 
2025-07-11 19:10:40.806537: Pseudo dice [np.float32(0.9478)] 
2025-07-11 19:10:40.807554: Epoch time: 68.37 s 
2025-07-11 19:10:41.723620:  
2025-07-11 19:10:41.725277: Epoch 135 
2025-07-11 19:10:41.726471: Current learning rate: 0.00878 
2025-07-11 19:11:49.598899: train_loss -0.965 
2025-07-11 19:11:49.600338: val_loss -0.9443 
2025-07-11 19:11:49.601516: Pseudo dice [np.float32(0.95)] 
2025-07-11 19:11:49.602754: Epoch time: 67.88 s 
2025-07-11 19:11:50.514706:  
2025-07-11 19:11:50.516378: Epoch 136 
2025-07-11 19:11:50.517961: Current learning rate: 0.00877 
2025-07-11 19:12:58.010741: train_loss -0.9655 
2025-07-11 19:12:58.011894: val_loss -0.9451 
2025-07-11 19:12:58.013093: Pseudo dice [np.float32(0.9497)] 
2025-07-11 19:12:58.014274: Epoch time: 67.5 s 
2025-07-11 19:12:58.924088:  
2025-07-11 19:12:58.925781: Epoch 137 
2025-07-11 19:12:58.926912: Current learning rate: 0.00876 
2025-07-11 19:14:06.590175: train_loss -0.9659 
2025-07-11 19:14:06.591295: val_loss -0.9461 
2025-07-11 19:14:06.592426: Pseudo dice [np.float32(0.9506)] 
2025-07-11 19:14:06.593573: Epoch time: 67.67 s 
2025-07-11 19:14:07.493850:  
2025-07-11 19:14:07.495513: Epoch 138 
2025-07-11 19:14:07.496689: Current learning rate: 0.00875 
2025-07-11 19:15:15.185642: train_loss -0.9665 
2025-07-11 19:15:15.186906: val_loss -0.9432 
2025-07-11 19:15:15.188281: Pseudo dice [np.float32(0.9482)] 
2025-07-11 19:15:15.189351: Epoch time: 67.7 s 
2025-07-11 19:15:16.109247:  
2025-07-11 19:15:16.110916: Epoch 139 
2025-07-11 19:15:16.112021: Current learning rate: 0.00874 
2025-07-11 19:16:24.166832: train_loss -0.9659 
2025-07-11 19:16:24.168711: val_loss -0.9485 
2025-07-11 19:16:24.169643: Pseudo dice [np.float32(0.9532)] 
2025-07-11 19:16:24.170603: Epoch time: 68.06 s 
2025-07-11 19:16:25.073994:  
2025-07-11 19:16:25.075742: Epoch 140 
2025-07-11 19:16:25.076908: Current learning rate: 0.00873 
2025-07-11 19:17:33.228566: train_loss -0.966 
2025-07-11 19:17:33.229812: val_loss -0.9426 
2025-07-11 19:17:33.230880: Pseudo dice [np.float32(0.9477)] 
2025-07-11 19:17:33.231828: Epoch time: 68.16 s 
2025-07-11 19:17:34.138456:  
2025-07-11 19:17:34.140081: Epoch 141 
2025-07-11 19:17:34.141160: Current learning rate: 0.00872 
2025-07-11 19:18:42.166457: train_loss -0.9653 
2025-07-11 19:18:42.167768: val_loss -0.9497 
2025-07-11 19:18:42.168900: Pseudo dice [np.float32(0.9539)] 
2025-07-11 19:18:42.170143: Epoch time: 68.03 s 
2025-07-11 19:18:42.171237: Yayy! New best EMA pseudo Dice: 0.9502000212669373 
2025-07-11 19:18:44.493705:  
2025-07-11 19:18:44.495296: Epoch 142 
2025-07-11 19:18:44.496424: Current learning rate: 0.00871 
2025-07-11 19:19:52.342860: train_loss -0.9662 
2025-07-11 19:19:52.344152: val_loss -0.948 
2025-07-11 19:19:52.345339: Pseudo dice [np.float32(0.9522)] 
2025-07-11 19:19:52.346525: Epoch time: 67.85 s 
2025-07-11 19:19:52.347633: Yayy! New best EMA pseudo Dice: 0.9503999948501587 
2025-07-11 19:19:55.478286:  
2025-07-11 19:19:55.479831: Epoch 143 
2025-07-11 19:19:55.481073: Current learning rate: 0.0087 
2025-07-11 19:21:03.390281: train_loss -0.9645 
2025-07-11 19:21:03.391568: val_loss -0.9416 
2025-07-11 19:21:03.392757: Pseudo dice [np.float32(0.9473)] 
2025-07-11 19:21:03.393836: Epoch time: 67.92 s 
2025-07-11 19:21:04.292587:  
2025-07-11 19:21:04.294162: Epoch 144 
2025-07-11 19:21:04.295658: Current learning rate: 0.00869 
2025-07-11 19:22:12.127270: train_loss -0.9648 
2025-07-11 19:22:12.128481: val_loss -0.944 
2025-07-11 19:22:12.129637: Pseudo dice [np.float32(0.9496)] 
2025-07-11 19:22:12.130829: Epoch time: 67.84 s 
2025-07-11 19:22:13.041759:  
2025-07-11 19:22:13.043413: Epoch 145 
2025-07-11 19:22:13.044673: Current learning rate: 0.00868 
2025-07-11 19:23:20.613175: train_loss -0.9655 
2025-07-11 19:23:20.614577: val_loss -0.946 
2025-07-11 19:23:20.615767: Pseudo dice [np.float32(0.9501)] 
2025-07-11 19:23:20.616830: Epoch time: 67.57 s 
2025-07-11 19:23:21.525311:  
2025-07-11 19:23:21.527094: Epoch 146 
2025-07-11 19:23:21.528255: Current learning rate: 0.00868 
2025-07-11 19:24:28.938556: train_loss -0.965 
2025-07-11 19:24:28.939900: val_loss -0.9453 
2025-07-11 19:24:28.940915: Pseudo dice [np.float32(0.9497)] 
2025-07-11 19:24:28.942198: Epoch time: 67.42 s 
2025-07-11 19:24:29.852738:  
2025-07-11 19:24:29.854728: Epoch 147 
2025-07-11 19:24:29.855831: Current learning rate: 0.00867 
2025-07-11 19:25:37.748168: train_loss -0.9659 
2025-07-11 19:25:37.749520: val_loss -0.9486 
2025-07-11 19:25:37.750658: Pseudo dice [np.float32(0.9527)] 
2025-07-11 19:25:37.751951: Epoch time: 67.9 s 
2025-07-11 19:25:38.668584:  
2025-07-11 19:25:38.670275: Epoch 148 
2025-07-11 19:25:38.671364: Current learning rate: 0.00866 
2025-07-11 19:26:46.421838: train_loss -0.9661 
2025-07-11 19:26:46.423055: val_loss -0.9455 
2025-07-11 19:26:46.424036: Pseudo dice [np.float32(0.95)] 
2025-07-11 19:26:46.425359: Epoch time: 67.76 s 
2025-07-11 19:26:47.345058:  
2025-07-11 19:26:47.346744: Epoch 149 
2025-07-11 19:26:47.347863: Current learning rate: 0.00865 
2025-07-11 19:27:55.021293: train_loss -0.9671 
2025-07-11 19:27:55.022700: val_loss -0.9446 
2025-07-11 19:27:55.023796: Pseudo dice [np.float32(0.9495)] 
2025-07-11 19:27:55.024779: Epoch time: 67.68 s 
2025-07-11 19:27:57.214216:  
2025-07-11 19:27:57.215772: Epoch 150 
2025-07-11 19:27:57.216890: Current learning rate: 0.00864 
2025-07-11 19:29:04.787400: train_loss -0.9658 
2025-07-11 19:29:04.788628: val_loss -0.9458 
2025-07-11 19:29:04.789780: Pseudo dice [np.float32(0.9502)] 
2025-07-11 19:29:04.790771: Epoch time: 67.58 s 
2025-07-11 19:29:05.700334:  
2025-07-11 19:29:05.702099: Epoch 151 
2025-07-11 19:29:05.703302: Current learning rate: 0.00863 
2025-07-11 19:30:14.137582: train_loss -0.9648 
2025-07-11 19:30:14.138890: val_loss -0.9456 
2025-07-11 19:30:14.139959: Pseudo dice [np.float32(0.9505)] 
2025-07-11 19:30:14.140983: Epoch time: 68.44 s 
2025-07-11 19:30:15.053326:  
2025-07-11 19:30:15.055094: Epoch 152 
2025-07-11 19:30:15.056232: Current learning rate: 0.00862 
2025-07-11 19:31:22.603274: train_loss -0.9652 
2025-07-11 19:31:22.604800: val_loss -0.9442 
2025-07-11 19:31:22.605843: Pseudo dice [np.float32(0.9492)] 
2025-07-11 19:31:22.606896: Epoch time: 67.55 s 
2025-07-11 19:31:23.503589:  
2025-07-11 19:31:23.505200: Epoch 153 
2025-07-11 19:31:23.506311: Current learning rate: 0.00861 
2025-07-11 19:32:31.076388: train_loss -0.9651 
2025-07-11 19:32:31.077851: val_loss -0.9463 
2025-07-11 19:32:31.079103: Pseudo dice [np.float32(0.9507)] 
2025-07-11 19:32:31.080298: Epoch time: 67.58 s 
2025-07-11 19:32:32.008134:  
2025-07-11 19:32:32.009804: Epoch 154 
2025-07-11 19:32:32.011169: Current learning rate: 0.0086 
2025-07-11 19:33:39.412210: train_loss -0.9647 
2025-07-11 19:33:39.413672: val_loss -0.9476 
2025-07-11 19:33:39.414818: Pseudo dice [np.float32(0.9517)] 
2025-07-11 19:33:39.415952: Epoch time: 67.41 s 
2025-07-11 19:33:40.333678:  
2025-07-11 19:33:40.335097: Epoch 155 
2025-07-11 19:33:40.336278: Current learning rate: 0.00859 
2025-07-11 19:34:48.042430: train_loss -0.9644 
2025-07-11 19:34:48.043684: val_loss -0.9429 
2025-07-11 19:34:48.044633: Pseudo dice [np.float32(0.9471)] 
2025-07-11 19:34:48.045706: Epoch time: 67.71 s 
2025-07-11 19:34:48.947359:  
2025-07-11 19:34:48.949125: Epoch 156 
2025-07-11 19:34:48.950380: Current learning rate: 0.00858 
2025-07-11 19:35:56.602056: train_loss -0.9644 
2025-07-11 19:35:56.603523: val_loss -0.944 
2025-07-11 19:35:56.604678: Pseudo dice [np.float32(0.9486)] 
2025-07-11 19:35:56.605837: Epoch time: 67.66 s 
2025-07-11 19:35:57.527907:  
2025-07-11 19:35:57.529562: Epoch 157 
2025-07-11 19:35:57.530711: Current learning rate: 0.00858 
2025-07-11 19:37:05.386052: train_loss -0.9645 
2025-07-11 19:37:05.387321: val_loss -0.9404 
2025-07-11 19:37:05.388384: Pseudo dice [np.float32(0.9456)] 
2025-07-11 19:37:05.389444: Epoch time: 67.86 s 
2025-07-11 19:37:06.304558:  
2025-07-11 19:37:06.306207: Epoch 158 
2025-07-11 19:37:06.307319: Current learning rate: 0.00857 
2025-07-11 19:38:14.205699: train_loss -0.9657 
2025-07-11 19:38:14.207004: val_loss -0.9457 
2025-07-11 19:38:14.208028: Pseudo dice [np.float32(0.9504)] 
2025-07-11 19:38:14.209066: Epoch time: 67.9 s 
2025-07-11 19:38:15.131135:  
2025-07-11 19:38:15.132757: Epoch 159 
2025-07-11 19:38:15.134048: Current learning rate: 0.00856 
2025-07-11 19:39:23.196507: train_loss -0.9659 
2025-07-11 19:39:23.198021: val_loss -0.9443 
2025-07-11 19:39:23.199025: Pseudo dice [np.float32(0.9486)] 
2025-07-11 19:39:23.200085: Epoch time: 68.07 s 
2025-07-11 19:39:24.129811:  
2025-07-11 19:39:24.130992: Epoch 160 
2025-07-11 19:39:24.132108: Current learning rate: 0.00855 
2025-07-11 19:40:32.829343: train_loss -0.9651 
2025-07-11 19:40:32.830590: val_loss -0.9462 
2025-07-11 19:40:32.831820: Pseudo dice [np.float32(0.9517)] 
2025-07-11 19:40:32.833009: Epoch time: 68.7 s 
2025-07-11 19:40:33.749207:  
2025-07-11 19:40:33.750748: Epoch 161 
2025-07-11 19:40:33.751960: Current learning rate: 0.00854 
2025-07-11 19:41:41.579120: train_loss -0.9666 
2025-07-11 19:41:41.580510: val_loss -0.9403 
2025-07-11 19:41:41.581581: Pseudo dice [np.float32(0.9458)] 
2025-07-11 19:41:41.582800: Epoch time: 67.83 s 
2025-07-11 19:41:42.497872:  
2025-07-11 19:41:42.499549: Epoch 162 
2025-07-11 19:41:42.500725: Current learning rate: 0.00853 
2025-07-11 19:42:49.999000: train_loss -0.9671 
2025-07-11 19:42:50.000390: val_loss -0.9485 
2025-07-11 19:42:50.001667: Pseudo dice [np.float32(0.9535)] 
2025-07-11 19:42:50.002941: Epoch time: 67.5 s 
2025-07-11 19:42:50.915252:  
2025-07-11 19:42:50.916982: Epoch 163 
2025-07-11 19:42:50.918217: Current learning rate: 0.00852 
2025-07-11 19:43:58.423582: train_loss -0.9647 
2025-07-11 19:43:58.424926: val_loss -0.951 
2025-07-11 19:43:58.426118: Pseudo dice [np.float32(0.9548)] 
2025-07-11 19:43:58.426996: Epoch time: 67.51 s 
2025-07-11 19:43:59.342592:  
2025-07-11 19:43:59.344358: Epoch 164 
2025-07-11 19:43:59.345485: Current learning rate: 0.00851 
2025-07-11 19:45:06.907593: train_loss -0.9669 
2025-07-11 19:45:06.908874: val_loss -0.9442 
2025-07-11 19:45:06.909930: Pseudo dice [np.float32(0.9485)] 
2025-07-11 19:45:06.911001: Epoch time: 67.57 s 
2025-07-11 19:45:07.818944:  
2025-07-11 19:45:07.820819: Epoch 165 
2025-07-11 19:45:07.822005: Current learning rate: 0.0085 
2025-07-11 19:46:15.477903: train_loss -0.9679 
2025-07-11 19:46:15.479241: val_loss -0.948 
2025-07-11 19:46:15.480321: Pseudo dice [np.float32(0.9521)] 
2025-07-11 19:46:15.481588: Epoch time: 67.66 s 
2025-07-11 19:46:16.383296:  
2025-07-11 19:46:16.385090: Epoch 166 
2025-07-11 19:46:16.386317: Current learning rate: 0.00849 
2025-07-11 19:47:23.911034: train_loss -0.9676 
2025-07-11 19:47:23.912468: val_loss -0.9464 
2025-07-11 19:47:23.913431: Pseudo dice [np.float32(0.9504)] 
2025-07-11 19:47:23.914488: Epoch time: 67.53 s 
2025-07-11 19:47:24.814189:  
2025-07-11 19:47:24.816100: Epoch 167 
2025-07-11 19:47:24.817266: Current learning rate: 0.00848 
2025-07-11 19:48:32.482488: train_loss -0.9672 
2025-07-11 19:48:32.483633: val_loss -0.9479 
2025-07-11 19:48:32.484848: Pseudo dice [np.float32(0.9524)] 
2025-07-11 19:48:32.485745: Epoch time: 67.67 s 
2025-07-11 19:48:32.486784: Yayy! New best EMA pseudo Dice: 0.9505000114440918 
2025-07-11 19:48:34.801754:  
2025-07-11 19:48:34.803307: Epoch 168 
2025-07-11 19:48:34.804423: Current learning rate: 0.00847 
2025-07-11 19:49:42.558527: train_loss -0.9672 
2025-07-11 19:49:42.559940: val_loss -0.9462 
2025-07-11 19:49:42.561145: Pseudo dice [np.float32(0.9511)] 
2025-07-11 19:49:42.562343: Epoch time: 67.76 s 
2025-07-11 19:49:42.563481: Yayy! New best EMA pseudo Dice: 0.9505000114440918 
2025-07-11 19:49:45.691559:  
2025-07-11 19:49:45.693221: Epoch 169 
2025-07-11 19:49:45.694488: Current learning rate: 0.00847 
2025-07-11 19:50:53.323985: train_loss -0.9669 
2025-07-11 19:50:53.325333: val_loss -0.9445 
2025-07-11 19:50:53.326395: Pseudo dice [np.float32(0.9502)] 
2025-07-11 19:50:53.327689: Epoch time: 67.64 s 
2025-07-11 19:50:54.258276:  
2025-07-11 19:50:54.259876: Epoch 170 
2025-07-11 19:50:54.261037: Current learning rate: 0.00846 
2025-07-11 19:52:01.846493: train_loss -0.9675 
2025-07-11 19:52:01.847837: val_loss -0.9471 
2025-07-11 19:52:01.848990: Pseudo dice [np.float32(0.9511)] 
2025-07-11 19:52:01.850147: Epoch time: 67.59 s 
2025-07-11 19:52:01.851308: Yayy! New best EMA pseudo Dice: 0.9506000280380249 
2025-07-11 19:52:04.161490:  
2025-07-11 19:52:04.163070: Epoch 171 
2025-07-11 19:52:04.164230: Current learning rate: 0.00845 
2025-07-11 19:53:11.921724: train_loss -0.966 
2025-07-11 19:53:11.923109: val_loss -0.9452 
2025-07-11 19:53:11.924406: Pseudo dice [np.float32(0.9499)] 
2025-07-11 19:53:11.925308: Epoch time: 67.76 s 
2025-07-11 19:53:12.844416:  
2025-07-11 19:53:12.845889: Epoch 172 
2025-07-11 19:53:12.847035: Current learning rate: 0.00844 
2025-07-11 19:54:20.590116: train_loss -0.9668 
2025-07-11 19:54:20.592715: val_loss -0.9455 
2025-07-11 19:54:20.593789: Pseudo dice [np.float32(0.9504)] 
2025-07-11 19:54:20.594893: Epoch time: 67.75 s 
2025-07-11 19:54:21.510638:  
2025-07-11 19:54:21.512548: Epoch 173 
2025-07-11 19:54:21.513726: Current learning rate: 0.00843 
2025-07-11 19:55:29.384915: train_loss -0.9667 
2025-07-11 19:55:29.386244: val_loss -0.9477 
2025-07-11 19:55:29.387491: Pseudo dice [np.float32(0.9526)] 
2025-07-11 19:55:29.388710: Epoch time: 67.88 s 
2025-07-11 19:55:29.389656: Yayy! New best EMA pseudo Dice: 0.9506999850273132 
2025-07-11 19:55:31.739553:  
2025-07-11 19:55:31.741299: Epoch 174 
2025-07-11 19:55:31.742739: Current learning rate: 0.00842 
2025-07-11 19:56:39.432637: train_loss -0.9666 
2025-07-11 19:56:39.434152: val_loss -0.9458 
2025-07-11 19:56:39.435161: Pseudo dice [np.float32(0.9504)] 
2025-07-11 19:56:39.436320: Epoch time: 67.7 s 
2025-07-11 19:56:40.349804:  
2025-07-11 19:56:40.351764: Epoch 175 
2025-07-11 19:56:40.353070: Current learning rate: 0.00841 
2025-07-11 19:57:47.859916: train_loss -0.9674 
2025-07-11 19:57:47.861183: val_loss -0.9473 
2025-07-11 19:57:47.862320: Pseudo dice [np.float32(0.9523)] 
2025-07-11 19:57:47.863524: Epoch time: 67.51 s 
2025-07-11 19:57:47.864693: Yayy! New best EMA pseudo Dice: 0.9508000016212463 
2025-07-11 19:57:49.987568:  
2025-07-11 19:57:49.989316: Epoch 176 
2025-07-11 19:57:49.990508: Current learning rate: 0.0084 
2025-07-11 19:58:57.679840: train_loss -0.9665 
2025-07-11 19:58:57.681011: val_loss -0.9493 
2025-07-11 19:58:57.682169: Pseudo dice [np.float32(0.9537)] 
2025-07-11 19:58:57.683500: Epoch time: 67.7 s 
2025-07-11 19:58:57.684573: Yayy! New best EMA pseudo Dice: 0.9510999917984009 
2025-07-11 19:58:59.841321:  
2025-07-11 19:58:59.843174: Epoch 177 
2025-07-11 19:58:59.844440: Current learning rate: 0.00839 
2025-07-11 20:00:08.232490: train_loss -0.9678 
2025-07-11 20:00:08.233733: val_loss -0.9445 
2025-07-11 20:00:08.234868: Pseudo dice [np.float32(0.9493)] 
2025-07-11 20:00:08.235920: Epoch time: 68.39 s 
2025-07-11 20:00:09.154948:  
2025-07-11 20:00:09.156881: Epoch 178 
2025-07-11 20:00:09.158006: Current learning rate: 0.00838 
2025-07-11 20:01:17.050136: train_loss -0.9671 
2025-07-11 20:01:17.051501: val_loss -0.9476 
2025-07-11 20:01:17.052636: Pseudo dice [np.float32(0.9517)] 
2025-07-11 20:01:17.053734: Epoch time: 67.9 s 
2025-07-11 20:01:17.969705:  
2025-07-11 20:01:17.971380: Epoch 179 
2025-07-11 20:01:17.974156: Current learning rate: 0.00837 
2025-07-11 20:02:25.962815: train_loss -0.967 
2025-07-11 20:02:25.964125: val_loss -0.9501 
2025-07-11 20:02:25.965254: Pseudo dice [np.float32(0.9542)] 
2025-07-11 20:02:25.966739: Epoch time: 68.0 s 
2025-07-11 20:02:25.967844: Yayy! New best EMA pseudo Dice: 0.9513000249862671 
2025-07-11 20:02:28.312139:  
2025-07-11 20:02:28.313836: Epoch 180 
2025-07-11 20:02:28.314993: Current learning rate: 0.00836 
2025-07-11 20:03:36.053126: train_loss -0.967 
2025-07-11 20:03:36.054442: val_loss -0.9455 
2025-07-11 20:03:36.055376: Pseudo dice [np.float32(0.9505)] 
2025-07-11 20:03:36.056434: Epoch time: 67.74 s 
2025-07-11 20:03:36.975540:  
2025-07-11 20:03:36.977249: Epoch 181 
2025-07-11 20:03:36.978442: Current learning rate: 0.00836 
2025-07-11 20:04:44.827403: train_loss -0.9676 
2025-07-11 20:04:44.828736: val_loss -0.9473 
2025-07-11 20:04:44.829738: Pseudo dice [np.float32(0.9518)] 
2025-07-11 20:04:44.830744: Epoch time: 67.86 s 
2025-07-11 20:04:45.748453:  
2025-07-11 20:04:45.750422: Epoch 182 
2025-07-11 20:04:45.751647: Current learning rate: 0.00835 
2025-07-11 20:05:53.388857: train_loss -0.9667 
2025-07-11 20:05:53.390240: val_loss -0.9488 
2025-07-11 20:05:53.391492: Pseudo dice [np.float32(0.9532)] 
2025-07-11 20:05:53.392644: Epoch time: 67.64 s 
2025-07-11 20:05:53.393695: Yayy! New best EMA pseudo Dice: 0.9514999985694885 
2025-07-11 20:05:55.708245:  
2025-07-11 20:05:55.709668: Epoch 183 
2025-07-11 20:05:55.710856: Current learning rate: 0.00834 
2025-07-11 20:07:03.463247: train_loss -0.9673 
2025-07-11 20:07:03.464605: val_loss -0.9477 
2025-07-11 20:07:03.465781: Pseudo dice [np.float32(0.952)] 
2025-07-11 20:07:03.467149: Epoch time: 67.76 s 
2025-07-11 20:07:03.468257: Yayy! New best EMA pseudo Dice: 0.9516000151634216 
2025-07-11 20:07:05.846509:  
2025-07-11 20:07:05.848133: Epoch 184 
2025-07-11 20:07:05.849304: Current learning rate: 0.00833 
2025-07-11 20:08:13.520101: train_loss -0.968 
2025-07-11 20:08:13.521264: val_loss -0.9459 
2025-07-11 20:08:13.522635: Pseudo dice [np.float32(0.951)] 
2025-07-11 20:08:13.523792: Epoch time: 67.68 s 
2025-07-11 20:08:14.429045:  
2025-07-11 20:08:14.430619: Epoch 185 
2025-07-11 20:08:14.431726: Current learning rate: 0.00832 
2025-07-11 20:09:22.086035: train_loss -0.9674 
2025-07-11 20:09:22.087401: val_loss -0.9437 
2025-07-11 20:09:22.088519: Pseudo dice [np.float32(0.9486)] 
2025-07-11 20:09:22.089708: Epoch time: 67.66 s 
2025-07-11 20:09:23.769298:  
2025-07-11 20:09:23.770952: Epoch 186 
2025-07-11 20:09:23.772078: Current learning rate: 0.00831 
2025-07-11 20:10:31.493612: train_loss -0.9662 
2025-07-11 20:10:31.494814: val_loss -0.9462 
2025-07-11 20:10:31.495745: Pseudo dice [np.float32(0.9506)] 
2025-07-11 20:10:31.496894: Epoch time: 67.73 s 
2025-07-11 20:10:32.401738:  
2025-07-11 20:10:32.403147: Epoch 187 
2025-07-11 20:10:32.404260: Current learning rate: 0.0083 
2025-07-11 20:11:39.901346: train_loss -0.9676 
2025-07-11 20:11:39.902567: val_loss -0.9489 
2025-07-11 20:11:39.903587: Pseudo dice [np.float32(0.953)] 
2025-07-11 20:11:39.904685: Epoch time: 67.5 s 
2025-07-11 20:11:40.826847:  
2025-07-11 20:11:40.828717: Epoch 188 
2025-07-11 20:11:40.829850: Current learning rate: 0.00829 
2025-07-11 20:12:48.391488: train_loss -0.9675 
2025-07-11 20:12:48.392940: val_loss -0.9444 
2025-07-11 20:12:48.393880: Pseudo dice [np.float32(0.9492)] 
2025-07-11 20:12:48.394964: Epoch time: 67.57 s 
2025-07-11 20:12:49.306694:  
2025-07-11 20:12:49.308357: Epoch 189 
2025-07-11 20:12:49.309503: Current learning rate: 0.00828 
2025-07-11 20:13:56.960415: train_loss -0.9683 
2025-07-11 20:13:56.961688: val_loss -0.9472 
2025-07-11 20:13:56.962760: Pseudo dice [np.float32(0.9512)] 
2025-07-11 20:13:56.963992: Epoch time: 67.66 s 
2025-07-11 20:13:57.863595:  
2025-07-11 20:13:57.865104: Epoch 190 
2025-07-11 20:13:57.866214: Current learning rate: 0.00827 
2025-07-11 20:15:05.644446: train_loss -0.9681 
2025-07-11 20:15:05.645793: val_loss -0.9474 
2025-07-11 20:15:05.647034: Pseudo dice [np.float32(0.9507)] 
2025-07-11 20:15:05.648114: Epoch time: 67.78 s 
2025-07-11 20:15:06.563808:  
2025-07-11 20:15:06.565311: Epoch 191 
2025-07-11 20:15:06.566416: Current learning rate: 0.00826 
2025-07-11 20:16:14.488673: train_loss -0.969 
2025-07-11 20:16:14.490039: val_loss -0.9493 
2025-07-11 20:16:14.491152: Pseudo dice [np.float32(0.9526)] 
2025-07-11 20:16:14.492206: Epoch time: 67.93 s 
2025-07-11 20:16:15.404226:  
2025-07-11 20:16:15.405531: Epoch 192 
2025-07-11 20:16:15.406739: Current learning rate: 0.00825 
2025-07-11 20:17:23.110247: train_loss -0.9669 
2025-07-11 20:17:23.111459: val_loss -0.9473 
2025-07-11 20:17:23.112603: Pseudo dice [np.float32(0.951)] 
2025-07-11 20:17:23.113705: Epoch time: 67.71 s 
2025-07-11 20:17:24.025013:  
2025-07-11 20:17:24.026803: Epoch 193 
2025-07-11 20:17:24.027918: Current learning rate: 0.00824 
2025-07-11 20:18:32.115736: train_loss -0.9665 
2025-07-11 20:18:32.116940: val_loss -0.9426 
2025-07-11 20:18:32.117923: Pseudo dice [np.float32(0.9469)] 
2025-07-11 20:18:32.119098: Epoch time: 68.09 s 
2025-07-11 20:18:33.040265:  
2025-07-11 20:18:33.041840: Epoch 194 
2025-07-11 20:18:33.042918: Current learning rate: 0.00824 
2025-07-11 20:19:40.862381: train_loss -0.9673 
2025-07-11 20:19:40.863713: val_loss -0.9447 
2025-07-11 20:19:40.864769: Pseudo dice [np.float32(0.95)] 
2025-07-11 20:19:40.865869: Epoch time: 67.83 s 
2025-07-11 20:19:42.554447:  
2025-07-11 20:19:42.555856: Epoch 195 
2025-07-11 20:19:42.556960: Current learning rate: 0.00823 
2025-07-11 20:20:50.405976: train_loss -0.968 
2025-07-11 20:20:50.407166: val_loss -0.943 
2025-07-11 20:20:50.408517: Pseudo dice [np.float32(0.9469)] 
2025-07-11 20:20:50.409630: Epoch time: 67.86 s 
2025-07-11 20:20:51.332478:  
2025-07-11 20:20:51.334069: Epoch 196 
2025-07-11 20:20:51.335238: Current learning rate: 0.00822 
2025-07-11 20:21:59.405432: train_loss -0.9692 
2025-07-11 20:21:59.406582: val_loss -0.9441 
2025-07-11 20:21:59.407696: Pseudo dice [np.float32(0.948)] 
2025-07-11 20:21:59.408628: Epoch time: 68.08 s 
2025-07-11 20:22:00.327197:  
2025-07-11 20:22:00.328562: Epoch 197 
2025-07-11 20:22:00.329806: Current learning rate: 0.00821 
2025-07-11 20:23:08.160837: train_loss -0.9686 
2025-07-11 20:23:08.162133: val_loss -0.9464 
2025-07-11 20:23:08.163214: Pseudo dice [np.float32(0.9506)] 
2025-07-11 20:23:08.164391: Epoch time: 67.84 s 
2025-07-11 20:23:09.099704:  
2025-07-11 20:23:09.101295: Epoch 198 
2025-07-11 20:23:09.102526: Current learning rate: 0.0082 
2025-07-11 20:24:16.741570: train_loss -0.9678 
2025-07-11 20:24:16.742851: val_loss -0.9474 
2025-07-11 20:24:16.743974: Pseudo dice [np.float32(0.9522)] 
2025-07-11 20:24:16.745051: Epoch time: 67.65 s 
2025-07-11 20:24:17.662644:  
2025-07-11 20:24:17.664220: Epoch 199 
2025-07-11 20:24:17.665343: Current learning rate: 0.00819 
2025-07-11 20:25:25.131698: train_loss -0.9685 
2025-07-11 20:25:25.132977: val_loss -0.9481 
2025-07-11 20:25:25.134326: Pseudo dice [np.float32(0.9524)] 
2025-07-11 20:25:25.135960: Epoch time: 67.47 s 
2025-07-11 20:25:27.294377:  
2025-07-11 20:25:27.296005: Epoch 200 
2025-07-11 20:25:27.297165: Current learning rate: 0.00818 
2025-07-11 20:26:34.998684: train_loss -0.9685 
2025-07-11 20:26:35.000010: val_loss -0.9474 
2025-07-11 20:26:35.001127: Pseudo dice [np.float32(0.9521)] 
2025-07-11 20:26:35.002136: Epoch time: 67.71 s 
2025-07-11 20:26:35.930434:  
2025-07-11 20:26:35.931957: Epoch 201 
2025-07-11 20:26:35.933108: Current learning rate: 0.00817 
2025-07-11 20:27:43.575283: train_loss -0.9695 
2025-07-11 20:27:43.576662: val_loss -0.9488 
2025-07-11 20:27:43.577645: Pseudo dice [np.float32(0.9529)] 
2025-07-11 20:27:43.578754: Epoch time: 67.65 s 
2025-07-11 20:27:44.499659:  
2025-07-11 20:27:44.501354: Epoch 202 
2025-07-11 20:27:44.502523: Current learning rate: 0.00816 
2025-07-11 20:28:52.015568: train_loss -0.9689 
2025-07-11 20:28:52.016816: val_loss -0.9447 
2025-07-11 20:28:52.017971: Pseudo dice [np.float32(0.949)] 
2025-07-11 20:28:52.019116: Epoch time: 67.52 s 
2025-07-11 20:28:52.942206:  
2025-07-11 20:28:52.943783: Epoch 203 
2025-07-11 20:28:52.944880: Current learning rate: 0.00815 
2025-07-11 20:30:01.178865: train_loss -0.9674 
2025-07-11 20:30:01.179924: val_loss -0.9439 
2025-07-11 20:30:01.180935: Pseudo dice [np.float32(0.9486)] 
2025-07-11 20:30:01.182026: Epoch time: 68.24 s 
2025-07-11 20:30:02.102169:  
2025-07-11 20:30:02.103994: Epoch 204 
2025-07-11 20:30:02.105257: Current learning rate: 0.00814 
2025-07-11 20:31:09.687029: train_loss -0.9668 
2025-07-11 20:31:09.688356: val_loss -0.9463 
2025-07-11 20:31:09.689546: Pseudo dice [np.float32(0.9504)] 
2025-07-11 20:31:09.690713: Epoch time: 67.59 s 
2025-07-11 20:31:10.617739:  
2025-07-11 20:31:10.619398: Epoch 205 
2025-07-11 20:31:10.620832: Current learning rate: 0.00813 
2025-07-11 20:32:18.228780: train_loss -0.9656 
2025-07-11 20:32:18.230175: val_loss -0.9471 
2025-07-11 20:32:18.231256: Pseudo dice [np.float32(0.9517)] 
2025-07-11 20:32:18.232471: Epoch time: 67.61 s 
2025-07-11 20:32:19.124843:  
2025-07-11 20:32:19.126320: Epoch 206 
2025-07-11 20:32:19.127447: Current learning rate: 0.00813 
2025-07-11 20:33:26.806684: train_loss -0.9661 
2025-07-11 20:33:26.807988: val_loss -0.9431 
2025-07-11 20:33:26.809174: Pseudo dice [np.float32(0.9474)] 
2025-07-11 20:33:26.810344: Epoch time: 67.69 s 
2025-07-11 20:33:27.700079:  
2025-07-11 20:33:27.701683: Epoch 207 
2025-07-11 20:33:27.702843: Current learning rate: 0.00812 
2025-07-11 20:34:35.394323: train_loss -0.9646 
2025-07-11 20:34:35.395777: val_loss -0.9488 
2025-07-11 20:34:35.396991: Pseudo dice [np.float32(0.9533)] 
2025-07-11 20:34:35.397949: Epoch time: 67.7 s 
2025-07-11 20:34:36.284996:  
2025-07-11 20:34:36.286444: Epoch 208 
2025-07-11 20:34:36.287668: Current learning rate: 0.00811 
2025-07-11 20:35:43.915606: train_loss -0.967 
2025-07-11 20:35:43.917052: val_loss -0.9486 
2025-07-11 20:35:43.918143: Pseudo dice [np.float32(0.9528)] 
2025-07-11 20:35:43.919288: Epoch time: 67.63 s 
2025-07-11 20:35:44.805977:  
2025-07-11 20:35:44.807555: Epoch 209 
2025-07-11 20:35:44.808714: Current learning rate: 0.0081 
2025-07-11 20:36:52.486234: train_loss -0.9673 
2025-07-11 20:36:52.487700: val_loss -0.9474 
2025-07-11 20:36:52.488800: Pseudo dice [np.float32(0.9507)] 
2025-07-11 20:36:52.489791: Epoch time: 67.68 s 
2025-07-11 20:36:53.387712:  
2025-07-11 20:36:53.389496: Epoch 210 
2025-07-11 20:36:53.390747: Current learning rate: 0.00809 
2025-07-11 20:38:01.181446: train_loss -0.968 
2025-07-11 20:38:01.182895: val_loss -0.9462 
2025-07-11 20:38:01.184000: Pseudo dice [np.float32(0.9504)] 
2025-07-11 20:38:01.185218: Epoch time: 67.8 s 
2025-07-11 20:38:02.078936:  
2025-07-11 20:38:02.080644: Epoch 211 
2025-07-11 20:38:02.081855: Current learning rate: 0.00808 
2025-07-11 20:39:09.696835: train_loss -0.967 
2025-07-11 20:39:09.698312: val_loss -0.9515 
2025-07-11 20:39:09.699314: Pseudo dice [np.float32(0.956)] 
2025-07-11 20:39:09.700316: Epoch time: 67.62 s 
2025-07-11 20:39:10.593163:  
2025-07-11 20:39:10.594808: Epoch 212 
2025-07-11 20:39:10.595946: Current learning rate: 0.00807 
2025-07-11 20:40:18.702376: train_loss -0.9689 
2025-07-11 20:40:18.703882: val_loss -0.9455 
2025-07-11 20:40:18.704809: Pseudo dice [np.float32(0.9497)] 
2025-07-11 20:40:18.705937: Epoch time: 68.11 s 
2025-07-11 20:40:19.586221:  
2025-07-11 20:40:19.587550: Epoch 213 
2025-07-11 20:40:19.588731: Current learning rate: 0.00806 
2025-07-11 20:41:27.386289: train_loss -0.9687 
2025-07-11 20:41:27.387608: val_loss -0.9438 
2025-07-11 20:41:27.388825: Pseudo dice [np.float32(0.9481)] 
2025-07-11 20:41:27.389950: Epoch time: 67.8 s 
2025-07-11 20:41:28.267420:  
2025-07-11 20:41:28.269006: Epoch 214 
2025-07-11 20:41:28.270093: Current learning rate: 0.00805 
2025-07-11 20:42:36.084029: train_loss -0.9692 
2025-07-11 20:42:36.085303: val_loss -0.9488 
2025-07-11 20:42:36.086528: Pseudo dice [np.float32(0.9526)] 
2025-07-11 20:42:36.087835: Epoch time: 67.82 s 
2025-07-11 20:42:36.987638:  
2025-07-11 20:42:36.989212: Epoch 215 
2025-07-11 20:42:36.990327: Current learning rate: 0.00804 
2025-07-11 20:43:45.104027: train_loss -0.9692 
2025-07-11 20:43:45.105533: val_loss -0.9444 
2025-07-11 20:43:45.106650: Pseudo dice [np.float32(0.9494)] 
2025-07-11 20:43:45.107876: Epoch time: 68.12 s 
2025-07-11 20:43:46.003841:  
2025-07-11 20:43:46.005031: Epoch 216 
2025-07-11 20:43:46.006009: Current learning rate: 0.00803 
2025-07-11 20:44:54.096347: train_loss -0.9685 
2025-07-11 20:44:54.097536: val_loss -0.9473 
2025-07-11 20:44:54.098707: Pseudo dice [np.float32(0.9517)] 
2025-07-11 20:44:54.099819: Epoch time: 68.1 s 
2025-07-11 20:44:54.977167:  
2025-07-11 20:44:54.979140: Epoch 217 
2025-07-11 20:44:54.980297: Current learning rate: 0.00802 
2025-07-11 20:46:03.116223: train_loss -0.9672 
2025-07-11 20:46:03.117455: val_loss -0.9448 
2025-07-11 20:46:03.118560: Pseudo dice [np.float32(0.95)] 
2025-07-11 20:46:03.119787: Epoch time: 68.14 s 
2025-07-11 20:46:04.008413:  
2025-07-11 20:46:04.010006: Epoch 218 
2025-07-11 20:46:04.011150: Current learning rate: 0.00801 
2025-07-11 20:47:12.048481: train_loss -0.9671 
2025-07-11 20:47:12.049920: val_loss -0.9458 
2025-07-11 20:47:12.051045: Pseudo dice [np.float32(0.9501)] 
2025-07-11 20:47:12.052033: Epoch time: 68.04 s 
2025-07-11 20:47:12.941648:  
2025-07-11 20:47:12.943090: Epoch 219 
2025-07-11 20:47:12.944352: Current learning rate: 0.00801 
2025-07-11 20:48:21.051809: train_loss -0.9683 
2025-07-11 20:48:21.053075: val_loss -0.9478 
2025-07-11 20:48:21.054115: Pseudo dice [np.float32(0.9524)] 
2025-07-11 20:48:21.055073: Epoch time: 68.11 s 
2025-07-11 20:48:21.931465:  
2025-07-11 20:48:21.933126: Epoch 220 
2025-07-11 20:48:21.934405: Current learning rate: 0.008 
2025-07-11 20:49:30.115017: train_loss -0.9686 
2025-07-11 20:49:30.116194: val_loss -0.9466 
2025-07-11 20:49:30.117145: Pseudo dice [np.float32(0.9504)] 
2025-07-11 20:49:30.118154: Epoch time: 68.19 s 
2025-07-11 20:49:31.009979:  
2025-07-11 20:49:31.011339: Epoch 221 
2025-07-11 20:49:31.012485: Current learning rate: 0.00799 
2025-07-11 20:50:39.305629: train_loss -0.968 
2025-07-11 20:50:39.307110: val_loss -0.9452 
2025-07-11 20:50:39.308279: Pseudo dice [np.float32(0.9497)] 
2025-07-11 20:50:39.309390: Epoch time: 68.3 s 
2025-07-11 20:50:40.199228:  
2025-07-11 20:50:40.200985: Epoch 222 
2025-07-11 20:50:40.202148: Current learning rate: 0.00798 
2025-07-11 20:51:47.573792: train_loss -0.9673 
2025-07-11 20:51:47.575048: val_loss -0.9449 
2025-07-11 20:51:47.576085: Pseudo dice [np.float32(0.949)] 
2025-07-11 20:51:47.577260: Epoch time: 67.38 s 
2025-07-11 20:51:48.464003:  
2025-07-11 20:51:48.465583: Epoch 223 
2025-07-11 20:51:48.466818: Current learning rate: 0.00797 
2025-07-11 20:52:56.214430: train_loss -0.9686 
2025-07-11 20:52:56.215677: val_loss -0.9473 
2025-07-11 20:52:56.216923: Pseudo dice [np.float32(0.9503)] 
2025-07-11 20:52:56.218286: Epoch time: 67.75 s 
2025-07-11 20:52:57.113213:  
2025-07-11 20:52:57.115057: Epoch 224 
2025-07-11 20:52:57.116269: Current learning rate: 0.00796 
2025-07-11 20:54:04.884938: train_loss -0.9689 
2025-07-11 20:54:04.886396: val_loss -0.9455 
2025-07-11 20:54:04.887713: Pseudo dice [np.float32(0.9501)] 
2025-07-11 20:54:04.888940: Epoch time: 67.78 s 
2025-07-11 20:54:05.785547:  
2025-07-11 20:54:05.787228: Epoch 225 
2025-07-11 20:54:05.788428: Current learning rate: 0.00795 
2025-07-11 20:55:13.605245: train_loss -0.9687 
2025-07-11 20:55:13.606598: val_loss -0.9425 
2025-07-11 20:55:13.607782: Pseudo dice [np.float32(0.948)] 
2025-07-11 20:55:13.608799: Epoch time: 67.82 s 
2025-07-11 20:55:14.489334:  
2025-07-11 20:55:14.491062: Epoch 226 
2025-07-11 20:55:14.492166: Current learning rate: 0.00794 
2025-07-11 20:56:22.066352: train_loss -0.9672 
2025-07-11 20:56:22.067669: val_loss -0.9475 
2025-07-11 20:56:22.069062: Pseudo dice [np.float32(0.9522)] 
2025-07-11 20:56:22.070366: Epoch time: 67.58 s 
2025-07-11 20:56:22.944518:  
2025-07-11 20:56:22.946274: Epoch 227 
2025-07-11 20:56:22.947423: Current learning rate: 0.00793 
2025-07-11 20:57:30.536321: train_loss -0.9678 
2025-07-11 20:57:30.538445: val_loss -0.9461 
2025-07-11 20:57:30.539430: Pseudo dice [np.float32(0.9504)] 
2025-07-11 20:57:30.540474: Epoch time: 67.6 s 
2025-07-11 20:57:31.422723:  
2025-07-11 20:57:31.424237: Epoch 228 
2025-07-11 20:57:31.425413: Current learning rate: 0.00792 
2025-07-11 20:58:39.035311: train_loss -0.9684 
2025-07-11 20:58:39.036649: val_loss -0.9441 
2025-07-11 20:58:39.037785: Pseudo dice [np.float32(0.9487)] 
2025-07-11 20:58:39.039010: Epoch time: 67.62 s 
2025-07-11 20:58:39.912150:  
2025-07-11 20:58:39.913877: Epoch 229 
2025-07-11 20:58:39.915034: Current learning rate: 0.00791 
2025-07-11 20:59:47.769534: train_loss -0.9673 
2025-07-11 20:59:47.771007: val_loss -0.9458 
2025-07-11 20:59:47.771912: Pseudo dice [np.float32(0.9506)] 
2025-07-11 20:59:47.773247: Epoch time: 67.86 s 
2025-07-11 20:59:48.649542:  
2025-07-11 20:59:48.650981: Epoch 230 
2025-07-11 20:59:48.652112: Current learning rate: 0.0079 
2025-07-11 21:00:56.841596: train_loss -0.9682 
2025-07-11 21:00:56.842930: val_loss -0.946 
2025-07-11 21:00:56.843946: Pseudo dice [np.float32(0.9497)] 
2025-07-11 21:00:56.845063: Epoch time: 68.2 s 
2025-07-11 21:00:57.729308:  
2025-07-11 21:00:57.730821: Epoch 231 
2025-07-11 21:00:57.732043: Current learning rate: 0.00789 
2025-07-11 21:02:05.342028: train_loss -0.9676 
2025-07-11 21:02:05.343463: val_loss -0.9473 
2025-07-11 21:02:05.344506: Pseudo dice [np.float32(0.9515)] 
2025-07-11 21:02:05.345668: Epoch time: 67.62 s 
2025-07-11 21:02:06.225810:  
2025-07-11 21:02:06.227806: Epoch 232 
2025-07-11 21:02:06.228936: Current learning rate: 0.00789 
2025-07-11 21:03:13.616389: train_loss -0.9685 
2025-07-11 21:03:13.617743: val_loss -0.9425 
2025-07-11 21:03:13.618870: Pseudo dice [np.float32(0.947)] 
2025-07-11 21:03:13.619874: Epoch time: 67.39 s 
2025-07-11 21:03:14.483861:  
2025-07-11 21:03:14.485312: Epoch 233 
2025-07-11 21:03:14.486449: Current learning rate: 0.00788 
2025-07-11 21:04:22.072081: train_loss -0.9692 
2025-07-11 21:04:22.073163: val_loss -0.946 
2025-07-11 21:04:22.074139: Pseudo dice [np.float32(0.9506)] 
2025-07-11 21:04:22.075382: Epoch time: 67.59 s 
2025-07-11 21:04:22.965502:  
2025-07-11 21:04:22.966918: Epoch 234 
2025-07-11 21:04:22.968076: Current learning rate: 0.00787 
2025-07-11 21:05:30.817618: train_loss -0.9688 
2025-07-11 21:05:30.818884: val_loss -0.9499 
2025-07-11 21:05:30.819839: Pseudo dice [np.float32(0.9542)] 
2025-07-11 21:05:30.820890: Epoch time: 67.86 s 
2025-07-11 21:05:31.705820:  
2025-07-11 21:05:31.707420: Epoch 235 
2025-07-11 21:05:31.708534: Current learning rate: 0.00786 
2025-07-11 21:06:39.871547: train_loss -0.9676 
2025-07-11 21:06:39.872931: val_loss -0.9466 
2025-07-11 21:06:39.874022: Pseudo dice [np.float32(0.9507)] 
2025-07-11 21:06:39.874873: Epoch time: 68.17 s 
2025-07-11 21:06:40.748411:  
2025-07-11 21:06:40.750190: Epoch 236 
2025-07-11 21:06:40.751340: Current learning rate: 0.00785 
2025-07-11 21:07:48.553905: train_loss -0.9696 
2025-07-11 21:07:48.555299: val_loss -0.9464 
2025-07-11 21:07:48.556674: Pseudo dice [np.float32(0.9504)] 
2025-07-11 21:07:48.557620: Epoch time: 67.81 s 
2025-07-11 21:07:49.438985:  
2025-07-11 21:07:49.440386: Epoch 237 
2025-07-11 21:07:49.441750: Current learning rate: 0.00784 
2025-07-11 21:08:57.519912: train_loss -0.9677 
2025-07-11 21:08:57.521434: val_loss -0.947 
2025-07-11 21:08:57.522667: Pseudo dice [np.float32(0.9516)] 
2025-07-11 21:08:57.523831: Epoch time: 68.08 s 
2025-07-11 21:08:58.401390:  
2025-07-11 21:08:58.402702: Epoch 238 
2025-07-11 21:08:58.403862: Current learning rate: 0.00783 
2025-07-11 21:10:06.343265: train_loss -0.9676 
2025-07-11 21:10:06.344596: val_loss -0.9417 
2025-07-11 21:10:06.345603: Pseudo dice [np.float32(0.9461)] 
2025-07-11 21:10:06.346627: Epoch time: 67.95 s 
2025-07-11 21:10:07.225057:  
2025-07-11 21:10:07.226472: Epoch 239 
2025-07-11 21:10:07.227627: Current learning rate: 0.00782 
2025-07-11 21:11:15.599136: train_loss -0.9682 
2025-07-11 21:11:15.600295: val_loss -0.945 
2025-07-11 21:11:15.601507: Pseudo dice [np.float32(0.9492)] 
2025-07-11 21:11:15.602623: Epoch time: 68.38 s 
2025-07-11 21:11:16.487618:  
2025-07-11 21:11:16.489081: Epoch 240 
2025-07-11 21:11:16.490284: Current learning rate: 0.00781 
2025-07-11 21:12:23.897231: train_loss -0.9687 
2025-07-11 21:12:23.898415: val_loss -0.9468 
2025-07-11 21:12:23.899532: Pseudo dice [np.float32(0.9517)] 
2025-07-11 21:12:23.900577: Epoch time: 67.41 s 
2025-07-11 21:12:24.787975:  
2025-07-11 21:12:24.789515: Epoch 241 
2025-07-11 21:12:24.790720: Current learning rate: 0.0078 
2025-07-11 21:13:32.117742: train_loss -0.9687 
2025-07-11 21:13:32.119108: val_loss -0.945 
2025-07-11 21:13:32.120008: Pseudo dice [np.float32(0.9492)] 
2025-07-11 21:13:32.121028: Epoch time: 67.33 s 
2025-07-11 21:13:33.015285:  
2025-07-11 21:13:33.017089: Epoch 242 
2025-07-11 21:13:33.018205: Current learning rate: 0.00779 
2025-07-11 21:14:40.661377: train_loss -0.9698 
2025-07-11 21:14:40.662812: val_loss -0.9478 
2025-07-11 21:14:40.664001: Pseudo dice [np.float32(0.9515)] 
2025-07-11 21:14:40.665028: Epoch time: 67.65 s 
2025-07-11 21:14:41.550533:  
2025-07-11 21:14:41.552142: Epoch 243 
2025-07-11 21:14:41.553469: Current learning rate: 0.00778 
2025-07-11 21:15:49.290211: train_loss -0.9699 
2025-07-11 21:15:49.291560: val_loss -0.9452 
2025-07-11 21:15:49.292599: Pseudo dice [np.float32(0.9501)] 
2025-07-11 21:15:49.293792: Epoch time: 67.74 s 
2025-07-11 21:15:50.184099:  
2025-07-11 21:15:50.186018: Epoch 244 
2025-07-11 21:15:50.187106: Current learning rate: 0.00777 
2025-07-11 21:16:58.075353: train_loss -0.9707 
2025-07-11 21:16:58.076470: val_loss -0.9471 
2025-07-11 21:16:58.077511: Pseudo dice [np.float32(0.9516)] 
2025-07-11 21:16:58.078675: Epoch time: 67.89 s 
2025-07-11 21:16:58.977905:  
2025-07-11 21:16:58.979717: Epoch 245 
2025-07-11 21:16:58.980932: Current learning rate: 0.00777 
2025-07-11 21:18:06.477880: train_loss -0.9683 
2025-07-11 21:18:06.479435: val_loss -0.942 
2025-07-11 21:18:06.480366: Pseudo dice [np.float32(0.9469)] 
2025-07-11 21:18:06.481264: Epoch time: 67.5 s 
2025-07-11 21:18:07.371300:  
2025-07-11 21:18:07.372985: Epoch 246 
2025-07-11 21:18:07.374097: Current learning rate: 0.00776 
2025-07-11 21:19:14.982666: train_loss -0.9691 
2025-07-11 21:19:14.984127: val_loss -0.9472 
2025-07-11 21:19:14.985316: Pseudo dice [np.float32(0.9505)] 
2025-07-11 21:19:14.986388: Epoch time: 67.61 s 
2025-07-11 21:19:15.871396:  
2025-07-11 21:19:15.873306: Epoch 247 
2025-07-11 21:19:15.874448: Current learning rate: 0.00775 
2025-07-11 21:20:23.630750: train_loss -0.9671 
2025-07-11 21:20:23.632010: val_loss -0.9508 
2025-07-11 21:20:23.633311: Pseudo dice [np.float32(0.955)] 
2025-07-11 21:20:23.634579: Epoch time: 67.76 s 
2025-07-11 21:20:24.516701:  
2025-07-11 21:20:24.518280: Epoch 248 
2025-07-11 21:20:24.519464: Current learning rate: 0.00774 
2025-07-11 21:21:32.874625: train_loss -0.9686 
2025-07-11 21:21:32.875684: val_loss -0.9478 
2025-07-11 21:21:32.876985: Pseudo dice [np.float32(0.9533)] 
2025-07-11 21:21:32.877973: Epoch time: 68.36 s 
2025-07-11 21:21:33.765253:  
2025-07-11 21:21:33.766838: Epoch 249 
2025-07-11 21:21:33.767944: Current learning rate: 0.00773 
2025-07-11 21:22:41.334406: train_loss -0.969 
2025-07-11 21:22:41.335870: val_loss -0.9456 
2025-07-11 21:22:41.337072: Pseudo dice [np.float32(0.9495)] 
2025-07-11 21:22:41.338230: Epoch time: 67.57 s 
2025-07-11 21:22:43.629178:  
2025-07-11 21:22:43.630681: Epoch 250 
2025-07-11 21:22:43.631801: Current learning rate: 0.00772 
2025-07-11 21:23:51.274354: train_loss -0.9683 
2025-07-11 21:23:51.275644: val_loss -0.9495 
2025-07-11 21:23:51.276965: Pseudo dice [np.float32(0.954)] 
2025-07-11 21:23:51.278200: Epoch time: 67.65 s 
2025-07-11 21:23:52.172793:  
2025-07-11 21:23:52.174345: Epoch 251 
2025-07-11 21:23:52.175395: Current learning rate: 0.00771 
2025-07-11 21:25:00.035826: train_loss -0.9687 
2025-07-11 21:25:00.037027: val_loss -0.9446 
2025-07-11 21:25:00.038054: Pseudo dice [np.float32(0.949)] 
2025-07-11 21:25:00.039196: Epoch time: 67.87 s 
2025-07-11 21:25:00.935053:  
2025-07-11 21:25:00.936792: Epoch 252 
2025-07-11 21:25:00.937961: Current learning rate: 0.0077 
2025-07-11 21:26:08.794231: train_loss -0.9697 
2025-07-11 21:26:08.795496: val_loss -0.9464 
2025-07-11 21:26:08.796535: Pseudo dice [np.float32(0.9508)] 
2025-07-11 21:26:08.797444: Epoch time: 67.86 s 
2025-07-11 21:26:09.697076:  
2025-07-11 21:26:09.699044: Epoch 253 
2025-07-11 21:26:09.700326: Current learning rate: 0.00769 
2025-07-11 21:27:17.629997: train_loss -0.9689 
2025-07-11 21:27:17.631167: val_loss -0.9466 
2025-07-11 21:27:17.632321: Pseudo dice [np.float32(0.9505)] 
2025-07-11 21:27:17.633434: Epoch time: 67.94 s 
2025-07-11 21:27:18.817470:  
2025-07-11 21:27:18.819098: Epoch 254 
2025-07-11 21:27:18.820229: Current learning rate: 0.00768 
2025-07-11 21:28:26.793744: train_loss -0.9704 
2025-07-11 21:28:26.795101: val_loss -0.9498 
2025-07-11 21:28:26.796392: Pseudo dice [np.float32(0.9543)] 
2025-07-11 21:28:26.797564: Epoch time: 67.98 s 
2025-07-11 21:28:27.694193:  
2025-07-11 21:28:27.695683: Epoch 255 
2025-07-11 21:28:27.696768: Current learning rate: 0.00767 
2025-07-11 21:29:35.589916: train_loss -0.9695 
2025-07-11 21:29:35.591266: val_loss -0.9457 
2025-07-11 21:29:35.592385: Pseudo dice [np.float32(0.9493)] 
2025-07-11 21:29:35.593487: Epoch time: 67.9 s 
2025-07-11 21:29:36.487191:  
2025-07-11 21:29:36.488796: Epoch 256 
2025-07-11 21:29:36.489826: Current learning rate: 0.00766 
2025-07-11 21:30:44.128541: train_loss -0.9618 
2025-07-11 21:30:44.129750: val_loss -0.9416 
2025-07-11 21:30:44.130632: Pseudo dice [np.float32(0.947)] 
2025-07-11 21:30:44.131829: Epoch time: 67.64 s 
2025-07-11 21:30:45.025847:  
2025-07-11 21:30:45.027602: Epoch 257 
2025-07-11 21:30:45.028717: Current learning rate: 0.00765 
2025-07-11 21:31:53.229958: train_loss -0.9663 
2025-07-11 21:31:53.231286: val_loss -0.9493 
2025-07-11 21:31:53.232456: Pseudo dice [np.float32(0.9529)] 
2025-07-11 21:31:53.233547: Epoch time: 68.21 s 
2025-07-11 21:31:54.128609:  
2025-07-11 21:31:54.130309: Epoch 258 
2025-07-11 21:31:54.131551: Current learning rate: 0.00764 
2025-07-11 21:33:01.465532: train_loss -0.9679 
2025-07-11 21:33:01.466700: val_loss -0.9495 
2025-07-11 21:33:01.467812: Pseudo dice [np.float32(0.9529)] 
2025-07-11 21:33:01.468948: Epoch time: 67.34 s 
2025-07-11 21:33:02.339962:  
2025-07-11 21:33:02.341305: Epoch 259 
2025-07-11 21:33:02.342427: Current learning rate: 0.00764 
2025-07-11 21:34:09.845645: train_loss -0.9678 
2025-07-11 21:34:09.846940: val_loss -0.9473 
2025-07-11 21:34:09.848157: Pseudo dice [np.float32(0.9514)] 
2025-07-11 21:34:09.849236: Epoch time: 67.51 s 
2025-07-11 21:34:10.740911:  
2025-07-11 21:34:10.742645: Epoch 260 
2025-07-11 21:34:10.743773: Current learning rate: 0.00763 
2025-07-11 21:35:18.340376: train_loss -0.9684 
2025-07-11 21:35:18.341729: val_loss -0.9456 
2025-07-11 21:35:18.342818: Pseudo dice [np.float32(0.9499)] 
2025-07-11 21:35:18.343896: Epoch time: 67.6 s 
2025-07-11 21:35:19.235978:  
2025-07-11 21:35:19.237986: Epoch 261 
2025-07-11 21:35:19.239105: Current learning rate: 0.00762 
2025-07-11 21:36:26.802196: train_loss -0.9684 
2025-07-11 21:36:26.803719: val_loss -0.9493 
2025-07-11 21:36:26.804891: Pseudo dice [np.float32(0.9532)] 
2025-07-11 21:36:26.805965: Epoch time: 67.57 s 
2025-07-11 21:36:27.704341:  
2025-07-11 21:36:27.706037: Epoch 262 
2025-07-11 21:36:27.707158: Current learning rate: 0.00761 
2025-07-11 21:37:35.092296: train_loss -0.9707 
2025-07-11 21:37:35.094003: val_loss -0.9462 
2025-07-11 21:37:35.095086: Pseudo dice [np.float32(0.9505)] 
2025-07-11 21:37:35.096235: Epoch time: 67.39 s 
2025-07-11 21:37:35.985275:  
2025-07-11 21:37:35.986760: Epoch 263 
2025-07-11 21:37:35.987947: Current learning rate: 0.0076 
2025-07-11 21:38:43.526374: train_loss -0.9697 
2025-07-11 21:38:43.527713: val_loss -0.9466 
2025-07-11 21:38:43.528930: Pseudo dice [np.float32(0.9504)] 
2025-07-11 21:38:43.529895: Epoch time: 67.54 s 
2025-07-11 21:38:44.420117:  
2025-07-11 21:38:44.421774: Epoch 264 
2025-07-11 21:38:44.422808: Current learning rate: 0.00759 
2025-07-11 21:39:52.035916: train_loss -0.969 
2025-07-11 21:39:52.037226: val_loss -0.9485 
2025-07-11 21:39:52.038398: Pseudo dice [np.float32(0.9527)] 
2025-07-11 21:39:52.039438: Epoch time: 67.62 s 
2025-07-11 21:39:52.923140:  
2025-07-11 21:39:52.924496: Epoch 265 
2025-07-11 21:39:52.925655: Current learning rate: 0.00758 
2025-07-11 21:41:00.400806: train_loss -0.9698 
2025-07-11 21:41:00.402158: val_loss -0.9485 
2025-07-11 21:41:00.403328: Pseudo dice [np.float32(0.9532)] 
2025-07-11 21:41:00.404312: Epoch time: 67.48 s 
2025-07-11 21:41:01.284440:  
2025-07-11 21:41:01.286014: Epoch 266 
2025-07-11 21:41:01.287181: Current learning rate: 0.00757 
2025-07-11 21:42:09.615843: train_loss -0.9708 
2025-07-11 21:42:09.617084: val_loss -0.9485 
2025-07-11 21:42:09.618008: Pseudo dice [np.float32(0.9529)] 
2025-07-11 21:42:09.619107: Epoch time: 68.33 s 
2025-07-11 21:42:10.498096:  
2025-07-11 21:42:10.499717: Epoch 267 
2025-07-11 21:42:10.500893: Current learning rate: 0.00756 
2025-07-11 21:43:18.058593: train_loss -0.9696 
2025-07-11 21:43:18.059802: val_loss -0.9484 
2025-07-11 21:43:18.060864: Pseudo dice [np.float32(0.9524)] 
2025-07-11 21:43:18.061746: Epoch time: 67.56 s 
2025-07-11 21:43:18.062798: Yayy! New best EMA pseudo Dice: 0.9516000151634216 
2025-07-11 21:43:20.019105:  
2025-07-11 21:43:20.020910: Epoch 268 
2025-07-11 21:43:20.022065: Current learning rate: 0.00755 
2025-07-11 21:44:27.447299: train_loss -0.9706 
2025-07-11 21:44:27.448467: val_loss -0.9508 
2025-07-11 21:44:27.449659: Pseudo dice [np.float32(0.9546)] 
2025-07-11 21:44:27.450835: Epoch time: 67.43 s 
2025-07-11 21:44:27.451831: Yayy! New best EMA pseudo Dice: 0.9519000053405762 
2025-07-11 21:44:29.543340:  
2025-07-11 21:44:29.545044: Epoch 269 
2025-07-11 21:44:29.546291: Current learning rate: 0.00754 
2025-07-11 21:45:37.153567: train_loss -0.9686 
2025-07-11 21:45:37.154904: val_loss -0.9405 
2025-07-11 21:45:37.156008: Pseudo dice [np.float32(0.945)] 
2025-07-11 21:45:37.157071: Epoch time: 67.61 s 
2025-07-11 21:45:38.044148:  
2025-07-11 21:45:38.045880: Epoch 270 
2025-07-11 21:45:38.046999: Current learning rate: 0.00753 
2025-07-11 21:46:45.818731: train_loss -0.9669 
2025-07-11 21:46:45.820085: val_loss -0.9487 
2025-07-11 21:46:45.821491: Pseudo dice [np.float32(0.9528)] 
2025-07-11 21:46:45.822619: Epoch time: 67.78 s 
2025-07-11 21:46:46.712203:  
2025-07-11 21:46:46.713955: Epoch 271 
2025-07-11 21:46:46.715183: Current learning rate: 0.00752 
2025-07-11 21:47:54.857275: train_loss -0.9692 
2025-07-11 21:47:54.858751: val_loss -0.9471 
2025-07-11 21:47:54.860043: Pseudo dice [np.float32(0.9517)] 
2025-07-11 21:47:54.861138: Epoch time: 68.15 s 
2025-07-11 21:47:55.751361:  
2025-07-11 21:47:55.753110: Epoch 272 
2025-07-11 21:47:55.754292: Current learning rate: 0.00751 
2025-07-11 21:49:03.717486: train_loss -0.9699 
2025-07-11 21:49:03.718896: val_loss -0.9461 
2025-07-11 21:49:03.720083: Pseudo dice [np.float32(0.9499)] 
2025-07-11 21:49:03.721335: Epoch time: 67.97 s 
2025-07-11 21:49:04.608905:  
2025-07-11 21:49:04.610388: Epoch 273 
2025-07-11 21:49:04.611476: Current learning rate: 0.00751 
2025-07-11 21:50:12.699656: train_loss -0.9702 
2025-07-11 21:50:12.700934: val_loss -0.9482 
2025-07-11 21:50:12.702171: Pseudo dice [np.float32(0.9532)] 
2025-07-11 21:50:12.703296: Epoch time: 68.09 s 
2025-07-11 21:50:13.587993:  
2025-07-11 21:50:13.589351: Epoch 274 
2025-07-11 21:50:13.590754: Current learning rate: 0.0075 
2025-07-11 21:51:21.639028: train_loss -0.9706 
2025-07-11 21:51:21.640405: val_loss -0.948 
2025-07-11 21:51:21.641428: Pseudo dice [np.float32(0.9526)] 
2025-07-11 21:51:21.642434: Epoch time: 68.05 s 
2025-07-11 21:51:22.529670:  
2025-07-11 21:51:22.531595: Epoch 275 
2025-07-11 21:51:22.532700: Current learning rate: 0.00749 
2025-07-11 21:52:30.958584: train_loss -0.9706 
2025-07-11 21:52:30.960225: val_loss -0.9487 
2025-07-11 21:52:30.961462: Pseudo dice [np.float32(0.9529)] 
2025-07-11 21:52:30.962539: Epoch time: 68.43 s 
2025-07-11 21:52:31.852869:  
2025-07-11 21:52:31.854730: Epoch 276 
2025-07-11 21:52:31.855831: Current learning rate: 0.00748 
2025-07-11 21:53:39.533375: train_loss -0.9708 
2025-07-11 21:53:39.534890: val_loss -0.9434 
2025-07-11 21:53:39.535883: Pseudo dice [np.float32(0.9471)] 
2025-07-11 21:53:39.536832: Epoch time: 67.68 s 
2025-07-11 21:53:40.433375:  
2025-07-11 21:53:40.435216: Epoch 277 
2025-07-11 21:53:40.436437: Current learning rate: 0.00747 
2025-07-11 21:54:47.843630: train_loss -0.971 
2025-07-11 21:54:47.844879: val_loss -0.9458 
2025-07-11 21:54:47.845878: Pseudo dice [np.float32(0.95)] 
2025-07-11 21:54:47.847064: Epoch time: 67.41 s 
2025-07-11 21:54:48.738842:  
2025-07-11 21:54:48.740565: Epoch 278 
2025-07-11 21:54:48.741724: Current learning rate: 0.00746 
2025-07-11 21:55:56.334507: train_loss -0.9712 
2025-07-11 21:55:56.335787: val_loss -0.9497 
2025-07-11 21:55:56.337066: Pseudo dice [np.float32(0.9532)] 
2025-07-11 21:55:56.338524: Epoch time: 67.6 s 
2025-07-11 21:55:57.233620:  
2025-07-11 21:55:57.235309: Epoch 279 
2025-07-11 21:55:57.236413: Current learning rate: 0.00745 
2025-07-11 21:57:04.800842: train_loss -0.9716 
2025-07-11 21:57:04.802310: val_loss -0.9505 
2025-07-11 21:57:04.803580: Pseudo dice [np.float32(0.9541)] 
2025-07-11 21:57:04.804760: Epoch time: 67.57 s 
2025-07-11 21:57:05.676809:  
2025-07-11 21:57:05.678749: Epoch 280 
2025-07-11 21:57:05.679847: Current learning rate: 0.00744 
2025-07-11 21:58:13.527531: train_loss -0.9708 
2025-07-11 21:58:13.528768: val_loss -0.9467 
2025-07-11 21:58:13.529796: Pseudo dice [np.float32(0.9512)] 
2025-07-11 21:58:13.530710: Epoch time: 67.85 s 
2025-07-11 21:58:14.423399:  
2025-07-11 21:58:14.425274: Epoch 281 
2025-07-11 21:58:14.426337: Current learning rate: 0.00743 
2025-07-11 21:59:22.114710: train_loss -0.9696 
2025-07-11 21:59:22.115970: val_loss -0.9433 
2025-07-11 21:59:22.117025: Pseudo dice [np.float32(0.9481)] 
2025-07-11 21:59:22.117926: Epoch time: 67.69 s 
2025-07-11 21:59:23.005379:  
2025-07-11 21:59:23.006910: Epoch 282 
2025-07-11 21:59:23.008013: Current learning rate: 0.00742 
2025-07-11 22:00:30.798355: train_loss -0.9692 
2025-07-11 22:00:30.799976: val_loss -0.9485 
2025-07-11 22:00:30.800967: Pseudo dice [np.float32(0.952)] 
2025-07-11 22:00:30.801951: Epoch time: 67.8 s 
2025-07-11 22:00:31.688167:  
2025-07-11 22:00:31.689751: Epoch 283 
2025-07-11 22:00:31.690901: Current learning rate: 0.00741 
2025-07-11 22:01:39.354577: train_loss -0.9714 
2025-07-11 22:01:39.355776: val_loss -0.947 
2025-07-11 22:01:39.356675: Pseudo dice [np.float32(0.9512)] 
2025-07-11 22:01:39.357808: Epoch time: 67.67 s 
2025-07-11 22:01:40.248405:  
2025-07-11 22:01:40.249912: Epoch 284 
2025-07-11 22:01:40.251065: Current learning rate: 0.0074 
2025-07-11 22:02:48.574995: train_loss -0.9707 
2025-07-11 22:02:48.577388: val_loss -0.9438 
2025-07-11 22:02:48.578299: Pseudo dice [np.float32(0.9485)] 
2025-07-11 22:02:48.579268: Epoch time: 68.33 s 
2025-07-11 22:02:49.467722:  
2025-07-11 22:02:49.469397: Epoch 285 
2025-07-11 22:02:49.470552: Current learning rate: 0.00739 
2025-07-11 22:03:56.999924: train_loss -0.9694 
2025-07-11 22:03:57.001324: val_loss -0.9441 
2025-07-11 22:03:57.002493: Pseudo dice [np.float32(0.9487)] 
2025-07-11 22:03:57.003780: Epoch time: 67.54 s 
2025-07-11 22:03:57.885828:  
2025-07-11 22:03:57.887668: Epoch 286 
2025-07-11 22:03:57.888808: Current learning rate: 0.00738 
2025-07-11 22:05:05.872580: train_loss -0.9703 
2025-07-11 22:05:05.873831: val_loss -0.9437 
2025-07-11 22:05:05.874724: Pseudo dice [np.float32(0.9481)] 
2025-07-11 22:05:05.876038: Epoch time: 67.99 s 
2025-07-11 22:05:06.776199:  
2025-07-11 22:05:06.777614: Epoch 287 
2025-07-11 22:05:06.778777: Current learning rate: 0.00738 
2025-07-11 22:06:14.869349: train_loss -0.9701 
2025-07-11 22:06:14.870570: val_loss -0.9481 
2025-07-11 22:06:14.871698: Pseudo dice [np.float32(0.9523)] 
2025-07-11 22:06:14.872839: Epoch time: 68.1 s 
2025-07-11 22:06:15.754296:  
2025-07-11 22:06:15.755991: Epoch 288 
2025-07-11 22:06:15.757093: Current learning rate: 0.00737 
2025-07-11 22:07:23.654339: train_loss -0.9708 
2025-07-11 22:07:23.655574: val_loss -0.9494 
2025-07-11 22:07:23.656519: Pseudo dice [np.float32(0.9536)] 
2025-07-11 22:07:23.657637: Epoch time: 67.9 s 
2025-07-11 22:07:24.548304:  
2025-07-11 22:07:24.549869: Epoch 289 
2025-07-11 22:07:24.551042: Current learning rate: 0.00736 
2025-07-11 22:08:32.636997: train_loss -0.9712 
2025-07-11 22:08:32.638105: val_loss -0.9485 
2025-07-11 22:08:32.639286: Pseudo dice [np.float32(0.952)] 
2025-07-11 22:08:32.640199: Epoch time: 68.09 s 
2025-07-11 22:08:33.538726:  
2025-07-11 22:08:33.540179: Epoch 290 
2025-07-11 22:08:33.541399: Current learning rate: 0.00735 
2025-07-11 22:09:40.896549: train_loss -0.9712 
2025-07-11 22:09:40.897562: val_loss -0.9466 
2025-07-11 22:09:40.898573: Pseudo dice [np.float32(0.9512)] 
2025-07-11 22:09:40.899704: Epoch time: 67.36 s 
2025-07-11 22:09:41.783351:  
2025-07-11 22:09:41.785117: Epoch 291 
2025-07-11 22:09:41.786387: Current learning rate: 0.00734 
2025-07-11 22:10:49.277012: train_loss -0.9718 
2025-07-11 22:10:49.278136: val_loss -0.9471 
2025-07-11 22:10:49.279312: Pseudo dice [np.float32(0.9517)] 
2025-07-11 22:10:49.280636: Epoch time: 67.5 s 
2025-07-11 22:10:50.180957:  
2025-07-11 22:10:50.182729: Epoch 292 
2025-07-11 22:10:50.183905: Current learning rate: 0.00733 
2025-07-11 22:11:58.085673: train_loss -0.9719 
2025-07-11 22:11:58.087009: val_loss -0.9487 
2025-07-11 22:11:58.088233: Pseudo dice [np.float32(0.9527)] 
2025-07-11 22:11:58.089254: Epoch time: 67.91 s 
2025-07-11 22:11:58.992465:  
2025-07-11 22:11:58.994294: Epoch 293 
2025-07-11 22:11:58.995437: Current learning rate: 0.00732 
2025-07-11 22:13:07.306724: train_loss -0.9717 
2025-07-11 22:13:07.308073: val_loss -0.9416 
2025-07-11 22:13:07.309221: Pseudo dice [np.float32(0.9469)] 
2025-07-11 22:13:07.310326: Epoch time: 68.32 s 
2025-07-11 22:13:08.204827:  
2025-07-11 22:13:08.206515: Epoch 294 
2025-07-11 22:13:08.207620: Current learning rate: 0.00731 
2025-07-11 22:14:15.686876: train_loss -0.9715 
2025-07-11 22:14:15.688451: val_loss -0.9481 
2025-07-11 22:14:15.689635: Pseudo dice [np.float32(0.952)] 
2025-07-11 22:14:15.690823: Epoch time: 67.49 s 
2025-07-11 22:14:16.588440:  
2025-07-11 22:14:16.589950: Epoch 295 
2025-07-11 22:14:16.591107: Current learning rate: 0.0073 
2025-07-11 22:15:24.245655: train_loss -0.9705 
2025-07-11 22:15:24.246908: val_loss -0.9458 
2025-07-11 22:15:24.248193: Pseudo dice [np.float32(0.9496)] 
2025-07-11 22:15:24.249198: Epoch time: 67.66 s 
2025-07-11 22:15:25.150010:  
2025-07-11 22:15:25.151443: Epoch 296 
2025-07-11 22:15:25.152576: Current learning rate: 0.00729 
2025-07-11 22:16:32.568495: train_loss -0.9703 
2025-07-11 22:16:32.570047: val_loss -0.945 
2025-07-11 22:16:32.571278: Pseudo dice [np.float32(0.9495)] 
2025-07-11 22:16:32.572312: Epoch time: 67.42 s 
2025-07-11 22:16:33.469672:  
2025-07-11 22:16:33.471192: Epoch 297 
2025-07-11 22:16:33.472308: Current learning rate: 0.00728 
2025-07-11 22:17:40.949843: train_loss -0.971 
2025-07-11 22:17:40.951209: val_loss -0.9473 
2025-07-11 22:17:40.952389: Pseudo dice [np.float32(0.9511)] 
2025-07-11 22:17:40.953579: Epoch time: 67.48 s 
2025-07-11 22:17:41.846293:  
2025-07-11 22:17:41.847892: Epoch 298 
2025-07-11 22:17:41.849051: Current learning rate: 0.00727 
2025-07-11 22:18:49.354282: train_loss -0.9725 
2025-07-11 22:18:49.355720: val_loss -0.9483 
2025-07-11 22:18:49.356899: Pseudo dice [np.float32(0.9521)] 
2025-07-11 22:18:49.358097: Epoch time: 67.51 s 
2025-07-11 22:18:50.251333:  
2025-07-11 22:18:50.252717: Epoch 299 
2025-07-11 22:18:50.253829: Current learning rate: 0.00726 
2025-07-11 22:19:57.848718: train_loss -0.9713 
2025-07-11 22:19:57.849979: val_loss -0.9479 
2025-07-11 22:19:57.851190: Pseudo dice [np.float32(0.9528)] 
2025-07-11 22:19:57.852302: Epoch time: 67.6 s 
2025-07-11 22:20:00.201032:  
2025-07-11 22:20:00.202857: Epoch 300 
2025-07-11 22:20:00.203987: Current learning rate: 0.00725 
2025-07-11 22:21:07.582596: train_loss -0.9712 
2025-07-11 22:21:07.583812: val_loss -0.9493 
2025-07-11 22:21:07.585089: Pseudo dice [np.float32(0.9539)] 
2025-07-11 22:21:07.586260: Epoch time: 67.39 s 
2025-07-11 22:21:08.468234:  
2025-07-11 22:21:08.469706: Epoch 301 
2025-07-11 22:21:08.470803: Current learning rate: 0.00724 
2025-07-11 22:22:15.877249: train_loss -0.9717 
2025-07-11 22:22:15.878501: val_loss -0.9464 
2025-07-11 22:22:15.879570: Pseudo dice [np.float32(0.9506)] 
2025-07-11 22:22:15.880678: Epoch time: 67.41 s 
2025-07-11 22:22:16.775950:  
2025-07-11 22:22:16.777567: Epoch 302 
2025-07-11 22:22:16.778753: Current learning rate: 0.00724 
2025-07-11 22:23:25.087282: train_loss -0.9712 
2025-07-11 22:23:25.088516: val_loss -0.9428 
2025-07-11 22:23:25.089843: Pseudo dice [np.float32(0.9468)] 
2025-07-11 22:23:25.091059: Epoch time: 68.31 s 
2025-07-11 22:23:25.994099:  
2025-07-11 22:23:25.996028: Epoch 303 
2025-07-11 22:23:25.997387: Current learning rate: 0.00723 
2025-07-11 22:24:33.627779: train_loss -0.971 
2025-07-11 22:24:33.629128: val_loss -0.9447 
2025-07-11 22:24:33.630284: Pseudo dice [np.float32(0.9486)] 
2025-07-11 22:24:33.631339: Epoch time: 67.64 s 
2025-07-11 22:24:34.526003:  
2025-07-11 22:24:34.527694: Epoch 304 
2025-07-11 22:24:34.529749: Current learning rate: 0.00722 
2025-07-11 22:25:42.521486: train_loss -0.9711 
2025-07-11 22:25:42.522799: val_loss -0.9465 
2025-07-11 22:25:42.524089: Pseudo dice [np.float32(0.95)] 
2025-07-11 22:25:42.525229: Epoch time: 68.0 s 
2025-07-11 22:25:43.424099:  
2025-07-11 22:25:43.425744: Epoch 305 
2025-07-11 22:25:43.426914: Current learning rate: 0.00721 
2025-07-11 22:26:51.559886: train_loss -0.9705 
2025-07-11 22:26:51.561256: val_loss -0.9452 
2025-07-11 22:26:51.562512: Pseudo dice [np.float32(0.9487)] 
2025-07-11 22:26:51.563646: Epoch time: 68.14 s 
2025-07-11 22:26:52.461280:  
2025-07-11 22:26:52.462857: Epoch 306 
2025-07-11 22:26:52.463968: Current learning rate: 0.0072 
2025-07-11 22:28:00.388196: train_loss -0.9702 
2025-07-11 22:28:00.389572: val_loss -0.943 
2025-07-11 22:28:00.390753: Pseudo dice [np.float32(0.9467)] 
2025-07-11 22:28:00.391811: Epoch time: 67.93 s 
2025-07-11 22:28:01.292794:  
2025-07-11 22:28:01.294541: Epoch 307 
2025-07-11 22:28:01.295943: Current learning rate: 0.00719 
2025-07-11 22:29:09.325727: train_loss -0.9708 
2025-07-11 22:29:09.326913: val_loss -0.9438 
2025-07-11 22:29:09.328123: Pseudo dice [np.float32(0.9475)] 
2025-07-11 22:29:09.329269: Epoch time: 68.04 s 
2025-07-11 22:29:10.229300:  
2025-07-11 22:29:10.230422: Epoch 308 
2025-07-11 22:29:10.231604: Current learning rate: 0.00718 
2025-07-11 22:30:17.971856: train_loss -0.9698 
2025-07-11 22:30:17.973274: val_loss -0.9455 
2025-07-11 22:30:17.974334: Pseudo dice [np.float32(0.9494)] 
2025-07-11 22:30:17.975611: Epoch time: 67.75 s 
2025-07-11 22:30:18.876446:  
2025-07-11 22:30:18.877870: Epoch 309 
2025-07-11 22:30:18.878996: Current learning rate: 0.00717 
2025-07-11 22:31:26.402677: train_loss -0.9706 
2025-07-11 22:31:26.403877: val_loss -0.9454 
2025-07-11 22:31:26.405025: Pseudo dice [np.float32(0.9501)] 
2025-07-11 22:31:26.406099: Epoch time: 67.53 s 
2025-07-11 22:31:27.282041:  
2025-07-11 22:31:27.283678: Epoch 310 
2025-07-11 22:31:27.284936: Current learning rate: 0.00716 
2025-07-11 22:32:34.823574: train_loss -0.9707 
2025-07-11 22:32:34.824848: val_loss -0.9456 
2025-07-11 22:32:34.825941: Pseudo dice [np.float32(0.9504)] 
2025-07-11 22:32:34.827040: Epoch time: 67.55 s 
2025-07-11 22:32:35.731252:  
2025-07-11 22:32:35.732654: Epoch 311 
2025-07-11 22:32:35.733771: Current learning rate: 0.00715 
2025-07-11 22:33:44.100244: train_loss -0.9709 
2025-07-11 22:33:44.101588: val_loss -0.9471 
2025-07-11 22:33:44.102663: Pseudo dice [np.float32(0.9514)] 
2025-07-11 22:33:44.103688: Epoch time: 68.37 s 
2025-07-11 22:33:44.998362:  
2025-07-11 22:33:45.000167: Epoch 312 
2025-07-11 22:33:45.001330: Current learning rate: 0.00714 
2025-07-11 22:34:52.613095: train_loss -0.971 
2025-07-11 22:34:52.614392: val_loss -0.946 
2025-07-11 22:34:52.615338: Pseudo dice [np.float32(0.9498)] 
2025-07-11 22:34:52.616444: Epoch time: 67.62 s 
2025-07-11 22:34:53.495046:  
2025-07-11 22:34:53.496621: Epoch 313 
2025-07-11 22:34:53.497836: Current learning rate: 0.00713 
2025-07-11 22:36:01.148983: train_loss -0.9711 
2025-07-11 22:36:01.150201: val_loss -0.9486 
2025-07-11 22:36:01.151164: Pseudo dice [np.float32(0.9527)] 
2025-07-11 22:36:01.152178: Epoch time: 67.66 s 
2025-07-11 22:36:02.057641:  
2025-07-11 22:36:02.059372: Epoch 314 
2025-07-11 22:36:02.060712: Current learning rate: 0.00712 
2025-07-11 22:37:09.475951: train_loss -0.9717 
2025-07-11 22:37:09.477213: val_loss -0.9439 
2025-07-11 22:37:09.478206: Pseudo dice [np.float32(0.9483)] 
2025-07-11 22:37:09.479268: Epoch time: 67.42 s 
2025-07-11 22:37:10.389238:  
2025-07-11 22:37:10.390784: Epoch 315 
2025-07-11 22:37:10.391905: Current learning rate: 0.00711 
2025-07-11 22:38:18.029380: train_loss -0.9719 
2025-07-11 22:38:18.030939: val_loss -0.9466 
2025-07-11 22:38:18.032174: Pseudo dice [np.float32(0.9518)] 
2025-07-11 22:38:18.033265: Epoch time: 67.64 s 
2025-07-11 22:38:18.934293:  
2025-07-11 22:38:18.935930: Epoch 316 
2025-07-11 22:38:18.937035: Current learning rate: 0.0071 
2025-07-11 22:39:26.441362: train_loss -0.972 
2025-07-11 22:39:26.442797: val_loss -0.946 
2025-07-11 22:39:26.443890: Pseudo dice [np.float32(0.9506)] 
2025-07-11 22:39:26.445039: Epoch time: 67.51 s 
2025-07-11 22:39:27.339020:  
2025-07-11 22:39:27.340922: Epoch 317 
2025-07-11 22:39:27.342080: Current learning rate: 0.0071 
2025-07-11 22:40:34.740896: train_loss -0.971 
2025-07-11 22:40:34.742191: val_loss -0.9473 
2025-07-11 22:40:34.743320: Pseudo dice [np.float32(0.9511)] 
2025-07-11 22:40:34.744715: Epoch time: 67.41 s 
2025-07-11 22:40:35.643780:  
2025-07-11 22:40:35.645219: Epoch 318 
2025-07-11 22:40:35.646398: Current learning rate: 0.00709 
2025-07-11 22:41:43.094193: train_loss -0.9723 
2025-07-11 22:41:43.095553: val_loss -0.9491 
2025-07-11 22:41:43.096710: Pseudo dice [np.float32(0.952)] 
2025-07-11 22:41:43.097910: Epoch time: 67.45 s 
2025-07-11 22:41:44.002903:  
2025-07-11 22:41:44.004503: Epoch 319 
2025-07-11 22:41:44.005574: Current learning rate: 0.00708 
2025-07-11 22:42:51.510216: train_loss -0.9712 
2025-07-11 22:42:51.511624: val_loss -0.9474 
2025-07-11 22:42:51.512699: Pseudo dice [np.float32(0.9506)] 
2025-07-11 22:42:51.513882: Epoch time: 67.51 s 
2025-07-11 22:42:52.419579:  
2025-07-11 22:42:52.421223: Epoch 320 
2025-07-11 22:42:52.422477: Current learning rate: 0.00707 
2025-07-11 22:44:00.934076: train_loss -0.9711 
2025-07-11 22:44:00.935332: val_loss -0.948 
2025-07-11 22:44:00.936498: Pseudo dice [np.float32(0.9516)] 
2025-07-11 22:44:00.937798: Epoch time: 68.52 s 
2025-07-11 22:44:01.833435:  
2025-07-11 22:44:01.834884: Epoch 321 
2025-07-11 22:44:01.836047: Current learning rate: 0.00706 
2025-07-11 22:45:09.932438: train_loss -0.9714 
2025-07-11 22:45:09.933972: val_loss -0.9453 
2025-07-11 22:45:09.935188: Pseudo dice [np.float32(0.9498)] 
2025-07-11 22:45:09.936336: Epoch time: 68.1 s 
2025-07-11 22:45:10.835295:  
2025-07-11 22:45:10.836706: Epoch 322 
2025-07-11 22:45:10.837787: Current learning rate: 0.00705 
2025-07-11 22:46:18.866310: train_loss -0.9716 
2025-07-11 22:46:18.867791: val_loss -0.9475 
2025-07-11 22:46:18.868810: Pseudo dice [np.float32(0.9514)] 
2025-07-11 22:46:18.869879: Epoch time: 68.03 s 
2025-07-11 22:46:19.775265:  
2025-07-11 22:46:19.776939: Epoch 323 
2025-07-11 22:46:19.778076: Current learning rate: 0.00704 
2025-07-11 22:47:27.761076: train_loss -0.9713 
2025-07-11 22:47:27.762472: val_loss -0.9456 
2025-07-11 22:47:27.763669: Pseudo dice [np.float32(0.9495)] 
2025-07-11 22:47:27.764693: Epoch time: 67.99 s 
2025-07-11 22:47:28.660146:  
2025-07-11 22:47:28.661816: Epoch 324 
2025-07-11 22:47:28.662928: Current learning rate: 0.00703 
2025-07-11 22:48:36.692360: train_loss -0.9707 
2025-07-11 22:48:36.693662: val_loss -0.9452 
2025-07-11 22:48:36.694820: Pseudo dice [np.float32(0.9488)] 
2025-07-11 22:48:36.695821: Epoch time: 68.04 s 
2025-07-11 22:48:37.591010:  
2025-07-11 22:48:37.592345: Epoch 325 
2025-07-11 22:48:37.593507: Current learning rate: 0.00702 
2025-07-11 22:49:45.461967: train_loss -0.971 
2025-07-11 22:49:45.463388: val_loss -0.9494 
2025-07-11 22:49:45.464350: Pseudo dice [np.float32(0.9534)] 
2025-07-11 22:49:45.465386: Epoch time: 67.87 s 
2025-07-11 22:49:46.379168:  
2025-07-11 22:49:46.380727: Epoch 326 
2025-07-11 22:49:46.381822: Current learning rate: 0.00701 
2025-07-11 22:50:53.857631: train_loss -0.9722 
2025-07-11 22:50:53.858937: val_loss -0.9503 
2025-07-11 22:50:53.860041: Pseudo dice [np.float32(0.9544)] 
2025-07-11 22:50:53.861214: Epoch time: 67.48 s 
2025-07-11 22:50:54.762322:  
2025-07-11 22:50:54.764149: Epoch 327 
2025-07-11 22:50:54.765270: Current learning rate: 0.007 
2025-07-11 22:52:02.051430: train_loss -0.9716 
2025-07-11 22:52:02.052755: val_loss -0.9461 
2025-07-11 22:52:02.053911: Pseudo dice [np.float32(0.9507)] 
2025-07-11 22:52:02.054812: Epoch time: 67.29 s 
2025-07-11 22:52:02.948986:  
2025-07-11 22:52:02.950404: Epoch 328 
2025-07-11 22:52:02.951516: Current learning rate: 0.00699 
2025-07-11 22:53:10.383717: train_loss -0.973 
2025-07-11 22:53:10.385067: val_loss -0.9515 
2025-07-11 22:53:10.386321: Pseudo dice [np.float32(0.9543)] 
2025-07-11 22:53:10.387341: Epoch time: 67.44 s 
2025-07-11 22:53:11.289480:  
2025-07-11 22:53:11.290986: Epoch 329 
2025-07-11 22:53:11.292045: Current learning rate: 0.00698 
2025-07-11 22:54:19.660019: train_loss -0.9722 
2025-07-11 22:54:19.661269: val_loss -0.9503 
2025-07-11 22:54:19.662326: Pseudo dice [np.float32(0.9536)] 
2025-07-11 22:54:19.663258: Epoch time: 68.37 s 
2025-07-11 22:54:20.561340:  
2025-07-11 22:54:20.562862: Epoch 330 
2025-07-11 22:54:20.563979: Current learning rate: 0.00697 
2025-07-11 22:55:27.989322: train_loss -0.9718 
2025-07-11 22:55:27.990630: val_loss -0.9498 
2025-07-11 22:55:27.991851: Pseudo dice [np.float32(0.9537)] 
2025-07-11 22:55:27.993046: Epoch time: 67.43 s 
2025-07-11 22:55:28.891430:  
2025-07-11 22:55:28.893058: Epoch 331 
2025-07-11 22:55:28.894290: Current learning rate: 0.00696 
2025-07-11 22:56:36.420259: train_loss -0.9696 
2025-07-11 22:56:36.421654: val_loss -0.9453 
2025-07-11 22:56:36.422903: Pseudo dice [np.float32(0.9495)] 
2025-07-11 22:56:36.423957: Epoch time: 67.53 s 
2025-07-11 22:56:37.321253:  
2025-07-11 22:56:37.323089: Epoch 332 
2025-07-11 22:56:37.324280: Current learning rate: 0.00696 
2025-07-11 22:57:45.046500: train_loss -0.9707 
2025-07-11 22:57:45.047903: val_loss -0.9469 
2025-07-11 22:57:45.049031: Pseudo dice [np.float32(0.9516)] 
2025-07-11 22:57:45.050287: Epoch time: 67.73 s 
2025-07-11 22:57:45.955283:  
2025-07-11 22:57:45.957118: Epoch 333 
2025-07-11 22:57:45.958273: Current learning rate: 0.00695 
2025-07-11 22:58:53.804849: train_loss -0.9707 
2025-07-11 22:58:53.806109: val_loss -0.9456 
2025-07-11 22:58:53.807269: Pseudo dice [np.float32(0.9489)] 
2025-07-11 22:58:53.808300: Epoch time: 67.85 s 
2025-07-11 22:58:54.709834:  
2025-07-11 22:58:54.711555: Epoch 334 
2025-07-11 22:58:54.712655: Current learning rate: 0.00694 
2025-07-11 23:00:02.212867: train_loss -0.9718 
2025-07-11 23:00:02.214247: val_loss -0.9511 
2025-07-11 23:00:02.215417: Pseudo dice [np.float32(0.9552)] 
2025-07-11 23:00:02.216651: Epoch time: 67.51 s 
2025-07-11 23:00:03.129290:  
2025-07-11 23:00:03.130960: Epoch 335 
2025-07-11 23:00:03.132110: Current learning rate: 0.00693 
2025-07-11 23:01:10.751040: train_loss -0.97 
2025-07-11 23:01:10.752467: val_loss -0.9471 
2025-07-11 23:01:10.753385: Pseudo dice [np.float32(0.9507)] 
2025-07-11 23:01:10.754341: Epoch time: 67.63 s 
2025-07-11 23:01:11.652784:  
2025-07-11 23:01:11.654424: Epoch 336 
2025-07-11 23:01:11.655645: Current learning rate: 0.00692 
2025-07-11 23:02:19.278904: train_loss -0.9718 
2025-07-11 23:02:19.280235: val_loss -0.9455 
2025-07-11 23:02:19.281356: Pseudo dice [np.float32(0.9489)] 
2025-07-11 23:02:19.282331: Epoch time: 67.63 s 
2025-07-11 23:02:20.197462:  
2025-07-11 23:02:20.199013: Epoch 337 
2025-07-11 23:02:20.200151: Current learning rate: 0.00691 
2025-07-11 23:03:27.919608: train_loss -0.9724 
2025-07-11 23:03:27.921117: val_loss -0.949 
2025-07-11 23:03:27.922264: Pseudo dice [np.float32(0.9536)] 
2025-07-11 23:03:27.923414: Epoch time: 67.73 s 
2025-07-11 23:03:29.611781:  
2025-07-11 23:03:29.613701: Epoch 338 
2025-07-11 23:03:29.614810: Current learning rate: 0.0069 
2025-07-11 23:04:37.622676: train_loss -0.973 
2025-07-11 23:04:37.623969: val_loss -0.9471 
2025-07-11 23:04:37.625131: Pseudo dice [np.float32(0.9512)] 
2025-07-11 23:04:37.626260: Epoch time: 68.01 s 
2025-07-11 23:04:38.530874:  
2025-07-11 23:04:38.532730: Epoch 339 
2025-07-11 23:04:38.533836: Current learning rate: 0.00689 
2025-07-11 23:05:46.548569: train_loss -0.9713 
2025-07-11 23:05:46.549819: val_loss -0.9464 
2025-07-11 23:05:46.550921: Pseudo dice [np.float32(0.9503)] 
2025-07-11 23:05:46.551904: Epoch time: 68.02 s 
2025-07-11 23:05:47.499551:  
2025-07-11 23:05:47.501426: Epoch 340 
2025-07-11 23:05:47.502597: Current learning rate: 0.00688 
2025-07-11 23:06:55.623924: train_loss -0.9709 
2025-07-11 23:06:55.625267: val_loss -0.947 
2025-07-11 23:06:55.626401: Pseudo dice [np.float32(0.9511)] 
2025-07-11 23:06:55.627341: Epoch time: 68.13 s 
2025-07-11 23:06:56.537791:  
2025-07-11 23:06:56.539382: Epoch 341 
2025-07-11 23:06:56.540739: Current learning rate: 0.00687 
2025-07-11 23:08:04.432315: train_loss -0.9722 
2025-07-11 23:08:04.434378: val_loss -0.9473 
2025-07-11 23:08:04.435339: Pseudo dice [np.float32(0.9509)] 
2025-07-11 23:08:04.436557: Epoch time: 67.9 s 
2025-07-11 23:08:05.361570:  
2025-07-11 23:08:05.363374: Epoch 342 
2025-07-11 23:08:05.364541: Current learning rate: 0.00686 
2025-07-11 23:09:12.933046: train_loss -0.972 
2025-07-11 23:09:12.934426: val_loss -0.9434 
2025-07-11 23:09:12.935470: Pseudo dice [np.float32(0.9474)] 
2025-07-11 23:09:12.936602: Epoch time: 67.57 s 
2025-07-11 23:09:13.849942:  
2025-07-11 23:09:13.851390: Epoch 343 
2025-07-11 23:09:13.852481: Current learning rate: 0.00685 
2025-07-11 23:10:21.312820: train_loss -0.972 
2025-07-11 23:10:21.313993: val_loss -0.9489 
2025-07-11 23:10:21.315024: Pseudo dice [np.float32(0.9528)] 
2025-07-11 23:10:21.316116: Epoch time: 67.47 s 
2025-07-11 23:10:22.226279:  
2025-07-11 23:10:22.228045: Epoch 344 
2025-07-11 23:10:22.229194: Current learning rate: 0.00684 
2025-07-11 23:11:29.695120: train_loss -0.9727 
2025-07-11 23:11:29.696425: val_loss -0.9476 
2025-07-11 23:11:29.697587: Pseudo dice [np.float32(0.9513)] 
2025-07-11 23:11:29.698584: Epoch time: 67.47 s 
2025-07-11 23:11:30.605726:  
2025-07-11 23:11:30.607706: Epoch 345 
2025-07-11 23:11:30.608827: Current learning rate: 0.00683 
2025-07-11 23:12:38.057390: train_loss -0.9728 
2025-07-11 23:12:38.058699: val_loss -0.9455 
2025-07-11 23:12:38.059912: Pseudo dice [np.float32(0.9495)] 
2025-07-11 23:12:38.061050: Epoch time: 67.46 s 
2025-07-11 23:12:38.975395:  
2025-07-11 23:12:38.976951: Epoch 346 
2025-07-11 23:12:38.978084: Current learning rate: 0.00682 
2025-07-11 23:13:46.308794: train_loss -0.9724 
2025-07-11 23:13:46.310231: val_loss -0.9472 
2025-07-11 23:13:46.311530: Pseudo dice [np.float32(0.9501)] 
2025-07-11 23:13:46.312685: Epoch time: 67.34 s 
2025-07-11 23:13:48.010432:  
2025-07-11 23:13:48.012103: Epoch 347 
2025-07-11 23:13:48.013264: Current learning rate: 0.00681 
2025-07-11 23:14:55.574233: train_loss -0.9722 
2025-07-11 23:14:55.575660: val_loss -0.949 
2025-07-11 23:14:55.576839: Pseudo dice [np.float32(0.9529)] 
2025-07-11 23:14:55.577894: Epoch time: 67.57 s 
2025-07-11 23:14:56.477601:  
2025-07-11 23:14:56.479233: Epoch 348 
2025-07-11 23:14:56.480397: Current learning rate: 0.0068 
2025-07-11 23:16:04.015821: train_loss -0.9737 
2025-07-11 23:16:04.017141: val_loss -0.9462 
2025-07-11 23:16:04.018461: Pseudo dice [np.float32(0.9503)] 
2025-07-11 23:16:04.019471: Epoch time: 67.54 s 
2025-07-11 23:16:04.930598:  
2025-07-11 23:16:04.932281: Epoch 349 
2025-07-11 23:16:04.933444: Current learning rate: 0.0068 
2025-07-11 23:17:12.394106: train_loss -0.9709 
2025-07-11 23:17:12.395376: val_loss -0.9485 
2025-07-11 23:17:12.396486: Pseudo dice [np.float32(0.953)] 
2025-07-11 23:17:12.397552: Epoch time: 67.47 s 
2025-07-11 23:17:14.594310:  
2025-07-11 23:17:14.595899: Epoch 350 
2025-07-11 23:17:14.597101: Current learning rate: 0.00679 
2025-07-11 23:18:22.157872: train_loss -0.9722 
2025-07-11 23:18:22.159297: val_loss -0.9485 
2025-07-11 23:18:22.160275: Pseudo dice [np.float32(0.9525)] 
2025-07-11 23:18:22.161310: Epoch time: 67.57 s 
2025-07-11 23:18:23.061994:  
2025-07-11 23:18:23.063335: Epoch 351 
2025-07-11 23:18:23.064597: Current learning rate: 0.00678 
2025-07-11 23:19:30.884361: train_loss -0.9719 
2025-07-11 23:19:30.885735: val_loss -0.9498 
2025-07-11 23:19:30.886761: Pseudo dice [np.float32(0.9534)] 
2025-07-11 23:19:30.887836: Epoch time: 67.83 s 
2025-07-11 23:19:31.796559:  
2025-07-11 23:19:31.797941: Epoch 352 
2025-07-11 23:19:31.799078: Current learning rate: 0.00677 
2025-07-11 23:20:39.747103: train_loss -0.9725 
2025-07-11 23:20:39.748430: val_loss -0.9507 
2025-07-11 23:20:39.749508: Pseudo dice [np.float32(0.9539)] 
2025-07-11 23:20:39.750515: Epoch time: 67.95 s 
2025-07-11 23:20:40.662796:  
2025-07-11 23:20:40.664236: Epoch 353 
2025-07-11 23:20:40.665466: Current learning rate: 0.00676 
2025-07-11 23:21:48.279647: train_loss -0.973 
2025-07-11 23:21:48.281069: val_loss -0.951 
2025-07-11 23:21:48.282154: Pseudo dice [np.float32(0.9538)] 
2025-07-11 23:21:48.283738: Epoch time: 67.62 s 
2025-07-11 23:21:48.284758: Yayy! New best EMA pseudo Dice: 0.9520000219345093 
2025-07-11 23:21:50.280313:  
2025-07-11 23:21:50.282003: Epoch 354 
2025-07-11 23:21:50.283051: Current learning rate: 0.00675 
2025-07-11 23:22:57.836599: train_loss -0.9741 
2025-07-11 23:22:57.837823: val_loss -0.9493 
2025-07-11 23:22:57.839097: Pseudo dice [np.float32(0.9538)] 
2025-07-11 23:22:57.840199: Epoch time: 67.56 s 
2025-07-11 23:22:57.841179: Yayy! New best EMA pseudo Dice: 0.9521999955177307 
2025-07-11 23:22:59.954532:  
2025-07-11 23:22:59.955778: Epoch 355 
2025-07-11 23:22:59.956895: Current learning rate: 0.00674 
2025-07-11 23:24:08.737826: train_loss -0.9724 
2025-07-11 23:24:08.739222: val_loss -0.943 
2025-07-11 23:24:08.740481: Pseudo dice [np.float32(0.9466)] 
2025-07-11 23:24:08.741531: Epoch time: 68.79 s 
2025-07-11 23:24:09.647664:  
2025-07-11 23:24:09.649416: Epoch 356 
2025-07-11 23:24:09.650625: Current learning rate: 0.00673 
2025-07-11 23:25:17.613942: train_loss -0.9729 
2025-07-11 23:25:17.615221: val_loss -0.9505 
2025-07-11 23:25:17.616553: Pseudo dice [np.float32(0.9535)] 
2025-07-11 23:25:17.617589: Epoch time: 67.97 s 
2025-07-11 23:25:18.536869:  
2025-07-11 23:25:18.538288: Epoch 357 
2025-07-11 23:25:18.539312: Current learning rate: 0.00672 
2025-07-11 23:26:26.477900: train_loss -0.9724 
2025-07-11 23:26:26.479314: val_loss -0.9476 
2025-07-11 23:26:26.480447: Pseudo dice [np.float32(0.9516)] 
2025-07-11 23:26:26.481561: Epoch time: 67.94 s 
2025-07-11 23:26:27.379008:  
2025-07-11 23:26:27.380397: Epoch 358 
2025-07-11 23:26:27.381614: Current learning rate: 0.00671 
2025-07-11 23:27:35.180284: train_loss -0.9729 
2025-07-11 23:27:35.181543: val_loss -0.9469 
2025-07-11 23:27:35.182750: Pseudo dice [np.float32(0.9516)] 
2025-07-11 23:27:35.183871: Epoch time: 67.8 s 
2025-07-11 23:27:36.101378:  
2025-07-11 23:27:36.102820: Epoch 359 
2025-07-11 23:27:36.103953: Current learning rate: 0.0067 
2025-07-11 23:28:43.681378: train_loss -0.9727 
2025-07-11 23:28:43.682760: val_loss -0.9478 
2025-07-11 23:28:43.683933: Pseudo dice [np.float32(0.9514)] 
2025-07-11 23:28:43.685165: Epoch time: 67.58 s 
2025-07-11 23:28:44.597842:  
2025-07-11 23:28:44.599380: Epoch 360 
2025-07-11 23:28:44.600549: Current learning rate: 0.00669 
2025-07-11 23:29:52.198347: train_loss -0.9724 
2025-07-11 23:29:52.199455: val_loss -0.9466 
2025-07-11 23:29:52.200421: Pseudo dice [np.float32(0.95)] 
2025-07-11 23:29:52.201388: Epoch time: 67.6 s 
2025-07-11 23:29:53.100100:  
2025-07-11 23:29:53.101841: Epoch 361 
2025-07-11 23:29:53.102962: Current learning rate: 0.00668 
2025-07-11 23:31:00.683173: train_loss -0.9721 
2025-07-11 23:31:00.684609: val_loss -0.9451 
2025-07-11 23:31:00.685853: Pseudo dice [np.float32(0.9484)] 
2025-07-11 23:31:00.686944: Epoch time: 67.59 s 
2025-07-11 23:31:01.596164:  
2025-07-11 23:31:01.597897: Epoch 362 
2025-07-11 23:31:01.599109: Current learning rate: 0.00667 
2025-07-11 23:32:09.371207: train_loss -0.971 
2025-07-11 23:32:09.372518: val_loss -0.9501 
2025-07-11 23:32:09.373461: Pseudo dice [np.float32(0.9535)] 
2025-07-11 23:32:09.374424: Epoch time: 67.78 s 
2025-07-11 23:32:10.278600:  
2025-07-11 23:32:10.280380: Epoch 363 
2025-07-11 23:32:10.281500: Current learning rate: 0.00666 
2025-07-11 23:33:17.834873: train_loss -0.9724 
2025-07-11 23:33:17.836114: val_loss -0.9488 
2025-07-11 23:33:17.837438: Pseudo dice [np.float32(0.9524)] 
2025-07-11 23:33:17.838595: Epoch time: 67.56 s 
2025-07-11 23:33:18.756631:  
2025-07-11 23:33:18.758280: Epoch 364 
2025-07-11 23:33:18.759432: Current learning rate: 0.00665 
2025-07-11 23:34:26.811591: train_loss -0.9714 
2025-07-11 23:34:26.812737: val_loss -0.9472 
2025-07-11 23:34:26.813653: Pseudo dice [np.float32(0.9514)] 
2025-07-11 23:34:26.814572: Epoch time: 68.06 s 
2025-07-11 23:34:27.722564:  
2025-07-11 23:34:27.724345: Epoch 365 
2025-07-11 23:34:27.725803: Current learning rate: 0.00665 
2025-07-11 23:35:35.335058: train_loss -0.9723 
2025-07-11 23:35:35.336110: val_loss -0.9475 
2025-07-11 23:35:35.337247: Pseudo dice [np.float32(0.9513)] 
2025-07-11 23:35:35.338402: Epoch time: 67.62 s 
2025-07-11 23:35:36.251301:  
2025-07-11 23:35:36.252971: Epoch 366 
2025-07-11 23:35:36.254154: Current learning rate: 0.00664 
2025-07-11 23:36:44.117308: train_loss -0.9716 
2025-07-11 23:36:44.118710: val_loss -0.9429 
2025-07-11 23:36:44.119794: Pseudo dice [np.float32(0.9464)] 
2025-07-11 23:36:44.121003: Epoch time: 67.87 s 
2025-07-11 23:36:45.025988:  
2025-07-11 23:36:45.027437: Epoch 367 
2025-07-11 23:36:45.028629: Current learning rate: 0.00663 
2025-07-11 23:37:52.705000: train_loss -0.9725 
2025-07-11 23:37:52.706354: val_loss -0.9502 
2025-07-11 23:37:52.707326: Pseudo dice [np.float32(0.9538)] 
2025-07-11 23:37:52.708583: Epoch time: 67.68 s 
2025-07-11 23:37:53.623698:  
2025-07-11 23:37:53.625333: Epoch 368 
2025-07-11 23:37:53.626529: Current learning rate: 0.00662 
2025-07-11 23:39:01.283635: train_loss -0.9724 
2025-07-11 23:39:01.284984: val_loss -0.9467 
2025-07-11 23:39:01.286165: Pseudo dice [np.float32(0.9512)] 
2025-07-11 23:39:01.287230: Epoch time: 67.66 s 
2025-07-11 23:39:02.200216:  
2025-07-11 23:39:02.201796: Epoch 369 
2025-07-11 23:39:02.202902: Current learning rate: 0.00661 
2025-07-11 23:40:09.807012: train_loss -0.9719 
2025-07-11 23:40:09.808465: val_loss -0.947 
2025-07-11 23:40:09.809591: Pseudo dice [np.float32(0.9511)] 
2025-07-11 23:40:09.810813: Epoch time: 67.61 s 
2025-07-11 23:40:10.726673:  
2025-07-11 23:40:10.728436: Epoch 370 
2025-07-11 23:40:10.729801: Current learning rate: 0.0066 
2025-07-11 23:41:18.314505: train_loss -0.972 
2025-07-11 23:41:18.316103: val_loss -0.9421 
2025-07-11 23:41:18.317340: Pseudo dice [np.float32(0.9461)] 
2025-07-11 23:41:18.318496: Epoch time: 67.59 s 
2025-07-11 23:41:19.231098:  
2025-07-11 23:41:19.232782: Epoch 371 
2025-07-11 23:41:19.234047: Current learning rate: 0.00659 
2025-07-11 23:42:27.141601: train_loss -0.9714 
2025-07-11 23:42:27.143075: val_loss -0.9491 
2025-07-11 23:42:27.143978: Pseudo dice [np.float32(0.9531)] 
2025-07-11 23:42:27.145126: Epoch time: 67.91 s 
2025-07-11 23:42:28.062063:  
2025-07-11 23:42:28.063701: Epoch 372 
2025-07-11 23:42:28.064822: Current learning rate: 0.00658 
2025-07-11 23:43:36.272332: train_loss -0.9731 
2025-07-11 23:43:36.273856: val_loss -0.9503 
2025-07-11 23:43:36.275066: Pseudo dice [np.float32(0.9537)] 
2025-07-11 23:43:36.276319: Epoch time: 68.21 s 
2025-07-11 23:43:37.186749:  
2025-07-11 23:43:37.188459: Epoch 373 
2025-07-11 23:43:37.189941: Current learning rate: 0.00657 
2025-07-11 23:44:45.945209: train_loss -0.9724 
2025-07-11 23:44:45.946578: val_loss -0.9469 
2025-07-11 23:44:45.947575: Pseudo dice [np.float32(0.9513)] 
2025-07-11 23:44:45.948753: Epoch time: 68.76 s 
2025-07-11 23:44:46.838463:  
2025-07-11 23:44:46.839981: Epoch 374 
2025-07-11 23:44:46.841133: Current learning rate: 0.00656 
2025-07-11 23:45:54.671296: train_loss -0.9731 
2025-07-11 23:45:54.672798: val_loss -0.9445 
2025-07-11 23:45:54.673967: Pseudo dice [np.float32(0.9483)] 
2025-07-11 23:45:54.675018: Epoch time: 67.84 s 
2025-07-11 23:45:55.589618:  
2025-07-11 23:45:55.591577: Epoch 375 
2025-07-11 23:45:55.592753: Current learning rate: 0.00655 
2025-07-11 23:47:03.229246: train_loss -0.973 
2025-07-11 23:47:03.230438: val_loss -0.949 
2025-07-11 23:47:03.231600: Pseudo dice [np.float32(0.9529)] 
2025-07-11 23:47:03.232718: Epoch time: 67.64 s 
2025-07-11 23:47:04.152531:  
2025-07-11 23:47:04.154218: Epoch 376 
2025-07-11 23:47:04.155310: Current learning rate: 0.00654 
2025-07-11 23:48:12.206372: train_loss -0.9731 
2025-07-11 23:48:12.207597: val_loss -0.9493 
2025-07-11 23:48:12.208763: Pseudo dice [np.float32(0.9528)] 
2025-07-11 23:48:12.209762: Epoch time: 68.06 s 
2025-07-11 23:48:13.132041:  
2025-07-11 23:48:13.133448: Epoch 377 
2025-07-11 23:48:13.134616: Current learning rate: 0.00653 
2025-07-11 23:49:21.285060: train_loss -0.9727 
2025-07-11 23:49:21.286385: val_loss -0.9435 
2025-07-11 23:49:21.287375: Pseudo dice [np.float32(0.9477)] 
2025-07-11 23:49:21.288458: Epoch time: 68.16 s 
2025-07-11 23:49:22.193306:  
2025-07-11 23:49:22.194953: Epoch 378 
2025-07-11 23:49:22.196072: Current learning rate: 0.00652 
2025-07-11 23:50:30.325189: train_loss -0.972 
2025-07-11 23:50:30.326711: val_loss -0.949 
2025-07-11 23:50:30.327833: Pseudo dice [np.float32(0.9535)] 
2025-07-11 23:50:30.328965: Epoch time: 68.14 s 
2025-07-11 23:50:31.246991:  
2025-07-11 23:50:31.248891: Epoch 379 
2025-07-11 23:50:31.250015: Current learning rate: 0.00651 
2025-07-11 23:51:39.204713: train_loss -0.9713 
2025-07-11 23:51:39.206172: val_loss -0.9486 
2025-07-11 23:51:39.207576: Pseudo dice [np.float32(0.9526)] 
2025-07-11 23:51:39.208731: Epoch time: 67.96 s 
2025-07-11 23:51:40.117566:  
2025-07-11 23:51:40.119531: Epoch 380 
2025-07-11 23:51:40.120679: Current learning rate: 0.0065 
2025-07-11 23:52:47.639882: train_loss -0.972 
2025-07-11 23:52:47.641284: val_loss -0.9464 
2025-07-11 23:52:47.642365: Pseudo dice [np.float32(0.9511)] 
2025-07-11 23:52:47.643352: Epoch time: 67.53 s 
2025-07-11 23:52:48.551966:  
2025-07-11 23:52:48.553729: Epoch 381 
2025-07-11 23:52:48.554870: Current learning rate: 0.00649 
2025-07-11 23:53:55.969181: train_loss -0.972 
2025-07-11 23:53:55.970302: val_loss -0.949 
2025-07-11 23:53:55.971417: Pseudo dice [np.float32(0.9532)] 
2025-07-11 23:53:55.972511: Epoch time: 67.42 s 
2025-07-11 23:53:57.661606:  
2025-07-11 23:53:57.663346: Epoch 382 
2025-07-11 23:53:57.664751: Current learning rate: 0.00648 
2025-07-11 23:55:05.101114: train_loss -0.9723 
2025-07-11 23:55:05.102505: val_loss -0.9466 
2025-07-11 23:55:05.103755: Pseudo dice [np.float32(0.9506)] 
2025-07-11 23:55:05.104717: Epoch time: 67.44 s 
2025-07-11 23:55:06.032520:  
2025-07-11 23:55:06.034155: Epoch 383 
2025-07-11 23:55:06.035421: Current learning rate: 0.00648 
2025-07-11 23:56:13.884208: train_loss -0.9727 
2025-07-11 23:56:13.885529: val_loss -0.9471 
2025-07-11 23:56:13.886551: Pseudo dice [np.float32(0.9515)] 
2025-07-11 23:56:13.887748: Epoch time: 67.86 s 
2025-07-11 23:56:14.783975:  
2025-07-11 23:56:14.785645: Epoch 384 
2025-07-11 23:56:14.786828: Current learning rate: 0.00647 
2025-07-11 23:57:22.524862: train_loss -0.9735 
2025-07-11 23:57:22.526255: val_loss -0.9472 
2025-07-11 23:57:22.527365: Pseudo dice [np.float32(0.9515)] 
2025-07-11 23:57:22.528537: Epoch time: 67.74 s 
2025-07-11 23:57:23.442101:  
2025-07-11 23:57:23.443542: Epoch 385 
2025-07-11 23:57:23.444673: Current learning rate: 0.00646 
2025-07-11 23:58:31.247357: train_loss -0.9731 
2025-07-11 23:58:31.249001: val_loss -0.9487 
2025-07-11 23:58:31.250198: Pseudo dice [np.float32(0.952)] 
2025-07-11 23:58:31.251410: Epoch time: 67.81 s 
2025-07-11 23:58:32.174744:  
2025-07-11 23:58:32.176563: Epoch 386 
2025-07-11 23:58:32.177851: Current learning rate: 0.00645 
2025-07-11 23:59:39.785109: train_loss -0.9724 
2025-07-11 23:59:39.786298: val_loss -0.9471 
2025-07-11 23:59:39.787434: Pseudo dice [np.float32(0.9506)] 
2025-07-11 23:59:39.788666: Epoch time: 67.61 s 
2025-07-11 23:59:40.713428:  
2025-07-11 23:59:40.715416: Epoch 387 
2025-07-11 23:59:40.716557: Current learning rate: 0.00644 
2025-07-12 00:00:48.668571: train_loss -0.9715 
2025-07-12 00:00:48.669896: val_loss -0.9495 
2025-07-12 00:00:48.671052: Pseudo dice [np.float32(0.9535)] 
2025-07-12 00:00:48.672239: Epoch time: 67.96 s 
2025-07-12 00:00:49.591922:  
2025-07-12 00:00:49.593500: Epoch 388 
2025-07-12 00:00:49.594617: Current learning rate: 0.00643 
2025-07-12 00:01:57.338592: train_loss -0.9726 
2025-07-12 00:01:57.339930: val_loss -0.9483 
2025-07-12 00:01:57.341019: Pseudo dice [np.float32(0.9516)] 
2025-07-12 00:01:57.342172: Epoch time: 67.75 s 
2025-07-12 00:01:58.260317:  
2025-07-12 00:01:58.262010: Epoch 389 
2025-07-12 00:01:58.263113: Current learning rate: 0.00642 
2025-07-12 00:03:05.822345: train_loss -0.9714 
2025-07-12 00:03:05.823752: val_loss -0.9469 
2025-07-12 00:03:05.824999: Pseudo dice [np.float32(0.9513)] 
2025-07-12 00:03:05.826229: Epoch time: 67.57 s 
2025-07-12 00:03:06.781333:  
2025-07-12 00:03:06.783154: Epoch 390 
2025-07-12 00:03:06.784265: Current learning rate: 0.00641 
2025-07-12 00:04:14.795306: train_loss -0.9702 
2025-07-12 00:04:14.796640: val_loss -0.9498 
2025-07-12 00:04:14.797692: Pseudo dice [np.float32(0.9539)] 
2025-07-12 00:04:14.798754: Epoch time: 68.02 s 
2025-07-12 00:04:16.502862:  
2025-07-12 00:04:16.504395: Epoch 391 
2025-07-12 00:04:16.505506: Current learning rate: 0.0064 
2025-07-12 00:05:24.336476: train_loss -0.9719 
2025-07-12 00:05:24.337883: val_loss -0.9454 
2025-07-12 00:05:24.339043: Pseudo dice [np.float32(0.9492)] 
2025-07-12 00:05:24.340259: Epoch time: 67.84 s 
2025-07-12 00:05:25.257954:  
2025-07-12 00:05:25.259701: Epoch 392 
2025-07-12 00:05:25.260771: Current learning rate: 0.00639 
2025-07-12 00:06:33.211319: train_loss -0.9724 
2025-07-12 00:06:33.212686: val_loss -0.9482 
2025-07-12 00:06:33.213836: Pseudo dice [np.float32(0.9528)] 
2025-07-12 00:06:33.214929: Epoch time: 67.96 s 
2025-07-12 00:06:34.130707:  
2025-07-12 00:06:34.132275: Epoch 393 
2025-07-12 00:06:34.133425: Current learning rate: 0.00638 
2025-07-12 00:07:42.222773: train_loss -0.9717 
2025-07-12 00:07:42.224315: val_loss -0.9511 
2025-07-12 00:07:42.225302: Pseudo dice [np.float32(0.9546)] 
2025-07-12 00:07:42.226579: Epoch time: 68.1 s 
2025-07-12 00:07:43.144224:  
2025-07-12 00:07:43.145981: Epoch 394 
2025-07-12 00:07:43.147187: Current learning rate: 0.00637 
2025-07-12 00:08:51.053499: train_loss -0.9728 
2025-07-12 00:08:51.054680: val_loss -0.9497 
2025-07-12 00:08:51.055728: Pseudo dice [np.float32(0.9536)] 
2025-07-12 00:08:51.056673: Epoch time: 67.91 s 
2025-07-12 00:08:51.976398:  
2025-07-12 00:08:51.978608: Epoch 395 
2025-07-12 00:08:51.979908: Current learning rate: 0.00636 
2025-07-12 00:09:59.805263: train_loss -0.972 
2025-07-12 00:09:59.806557: val_loss -0.948 
2025-07-12 00:09:59.807545: Pseudo dice [np.float32(0.9521)] 
2025-07-12 00:09:59.808773: Epoch time: 67.83 s 
2025-07-12 00:10:00.715592:  
2025-07-12 00:10:00.717925: Epoch 396 
2025-07-12 00:10:00.719094: Current learning rate: 0.00635 
2025-07-12 00:11:08.309289: train_loss -0.9721 
2025-07-12 00:11:08.310689: val_loss -0.9503 
2025-07-12 00:11:08.311793: Pseudo dice [np.float32(0.9537)] 
2025-07-12 00:11:08.313020: Epoch time: 67.6 s 
2025-07-12 00:11:08.314225: Yayy! New best EMA pseudo Dice: 0.9523000121116638 
2025-07-12 00:11:10.291025:  
2025-07-12 00:11:10.292678: Epoch 397 
2025-07-12 00:11:10.293762: Current learning rate: 0.00634 
2025-07-12 00:12:17.896469: train_loss -0.9735 
2025-07-12 00:12:17.897772: val_loss -0.9462 
2025-07-12 00:12:17.898891: Pseudo dice [np.float32(0.9498)] 
2025-07-12 00:12:17.899933: Epoch time: 67.61 s 
2025-07-12 00:12:18.831145:  
2025-07-12 00:12:18.832873: Epoch 398 
2025-07-12 00:12:18.834054: Current learning rate: 0.00633 
2025-07-12 00:13:26.321801: train_loss -0.9728 
2025-07-12 00:13:26.323886: val_loss -0.9442 
2025-07-12 00:13:26.324797: Pseudo dice [np.float32(0.9484)] 
2025-07-12 00:13:26.325848: Epoch time: 67.49 s 
2025-07-12 00:13:27.224568:  
2025-07-12 00:13:27.226120: Epoch 399 
2025-07-12 00:13:27.227250: Current learning rate: 0.00632 
2025-07-12 00:14:35.508229: train_loss -0.9726 
2025-07-12 00:14:35.509731: val_loss -0.949 
2025-07-12 00:14:35.511024: Pseudo dice [np.float32(0.9527)] 
2025-07-12 00:14:35.512235: Epoch time: 68.29 s 
2025-07-12 00:14:37.811333:  
2025-07-12 00:14:37.813112: Epoch 400 
2025-07-12 00:14:37.814356: Current learning rate: 0.00631 
2025-07-12 00:15:45.398553: train_loss -0.9721 
2025-07-12 00:15:45.399876: val_loss -0.9465 
2025-07-12 00:15:45.401090: Pseudo dice [np.float32(0.9515)] 
2025-07-12 00:15:45.402149: Epoch time: 67.59 s 
2025-07-12 00:15:46.335412:  
2025-07-12 00:15:46.336825: Epoch 401 
2025-07-12 00:15:46.337880: Current learning rate: 0.0063 
2025-07-12 00:16:53.783994: train_loss -0.9703 
2025-07-12 00:16:53.785107: val_loss -0.9405 
2025-07-12 00:16:53.786329: Pseudo dice [np.float32(0.9446)] 
2025-07-12 00:16:53.787390: Epoch time: 67.45 s 
2025-07-12 00:16:54.709398:  
2025-07-12 00:16:54.710992: Epoch 402 
2025-07-12 00:16:54.712175: Current learning rate: 0.0063 
2025-07-12 00:18:02.256431: train_loss -0.9715 
2025-07-12 00:18:02.257746: val_loss -0.9448 
2025-07-12 00:18:02.258929: Pseudo dice [np.float32(0.9488)] 
2025-07-12 00:18:02.260143: Epoch time: 67.55 s 
2025-07-12 00:18:03.180229:  
2025-07-12 00:18:03.181953: Epoch 403 
2025-07-12 00:18:03.183185: Current learning rate: 0.00629 
2025-07-12 00:19:10.839768: train_loss -0.9727 
2025-07-12 00:19:10.841115: val_loss -0.9505 
2025-07-12 00:19:10.842212: Pseudo dice [np.float32(0.9538)] 
2025-07-12 00:19:10.843300: Epoch time: 67.66 s 
2025-07-12 00:19:11.769339:  
2025-07-12 00:19:11.770848: Epoch 404 
2025-07-12 00:19:11.771974: Current learning rate: 0.00628 
2025-07-12 00:20:19.459121: train_loss -0.9732 
2025-07-12 00:20:19.460448: val_loss -0.9482 
2025-07-12 00:20:19.461660: Pseudo dice [np.float32(0.9516)] 
2025-07-12 00:20:19.462746: Epoch time: 67.69 s 
2025-07-12 00:20:20.384517:  
2025-07-12 00:20:20.386240: Epoch 405 
2025-07-12 00:20:20.387362: Current learning rate: 0.00627 
2025-07-12 00:21:28.092586: train_loss -0.9735 
2025-07-12 00:21:28.093885: val_loss -0.9504 
2025-07-12 00:21:28.095060: Pseudo dice [np.float32(0.9546)] 
2025-07-12 00:21:28.096065: Epoch time: 67.71 s 
2025-07-12 00:21:29.019258:  
2025-07-12 00:21:29.020768: Epoch 406 
2025-07-12 00:21:29.021930: Current learning rate: 0.00626 
2025-07-12 00:22:36.706803: train_loss -0.9737 
2025-07-12 00:22:36.708042: val_loss -0.9461 
2025-07-12 00:22:36.709018: Pseudo dice [np.float32(0.95)] 
2025-07-12 00:22:36.710059: Epoch time: 67.69 s 
2025-07-12 00:22:37.620785:  
2025-07-12 00:22:37.622192: Epoch 407 
2025-07-12 00:22:37.623337: Current learning rate: 0.00625 
2025-07-12 00:23:45.411216: train_loss -0.9734 
2025-07-12 00:23:45.412716: val_loss -0.9465 
2025-07-12 00:23:45.413928: Pseudo dice [np.float32(0.9506)] 
2025-07-12 00:23:45.415145: Epoch time: 67.79 s 
2025-07-12 00:23:46.330117:  
2025-07-12 00:23:46.331986: Epoch 408 
2025-07-12 00:23:46.333055: Current learning rate: 0.00624 
2025-07-12 00:24:54.695098: train_loss -0.9732 
2025-07-12 00:24:54.696395: val_loss -0.9461 
2025-07-12 00:24:54.697405: Pseudo dice [np.float32(0.95)] 
2025-07-12 00:24:54.698428: Epoch time: 68.37 s 
2025-07-12 00:24:55.626786:  
2025-07-12 00:24:55.628855: Epoch 409 
2025-07-12 00:24:55.630228: Current learning rate: 0.00623 
2025-07-12 00:26:03.209158: train_loss -0.974 
2025-07-12 00:26:03.210548: val_loss -0.9479 
2025-07-12 00:26:03.211734: Pseudo dice [np.float32(0.9528)] 
2025-07-12 00:26:03.212842: Epoch time: 67.59 s 
2025-07-12 00:26:04.141246:  
2025-07-12 00:26:04.142986: Epoch 410 
2025-07-12 00:26:04.144302: Current learning rate: 0.00622 
2025-07-12 00:27:11.472817: train_loss -0.9736 
2025-07-12 00:27:11.474052: val_loss -0.9483 
2025-07-12 00:27:11.475356: Pseudo dice [np.float32(0.9524)] 
2025-07-12 00:27:11.476597: Epoch time: 67.33 s 
2025-07-12 00:27:12.363410:  
2025-07-12 00:27:12.364902: Epoch 411 
2025-07-12 00:27:12.366283: Current learning rate: 0.00621 
2025-07-12 00:28:19.990289: train_loss -0.9734 
2025-07-12 00:28:19.991519: val_loss -0.9466 
2025-07-12 00:28:19.992587: Pseudo dice [np.float32(0.9505)] 
2025-07-12 00:28:19.993631: Epoch time: 67.63 s 
2025-07-12 00:28:20.892553:  
2025-07-12 00:28:20.894422: Epoch 412 
2025-07-12 00:28:20.895586: Current learning rate: 0.0062 
2025-07-12 00:29:28.576361: train_loss -0.9735 
2025-07-12 00:29:28.577862: val_loss -0.9454 
2025-07-12 00:29:28.578861: Pseudo dice [np.float32(0.95)] 
2025-07-12 00:29:28.579787: Epoch time: 67.69 s 
2025-07-12 00:29:29.486408:  
2025-07-12 00:29:29.488014: Epoch 413 
2025-07-12 00:29:29.489176: Current learning rate: 0.00619 
2025-07-12 00:30:37.096178: train_loss -0.9745 
2025-07-12 00:30:37.097641: val_loss -0.9521 
2025-07-12 00:30:37.098837: Pseudo dice [np.float32(0.9562)] 
2025-07-12 00:30:37.099821: Epoch time: 67.61 s 
2025-07-12 00:30:37.987048:  
2025-07-12 00:30:37.988901: Epoch 414 
2025-07-12 00:30:37.990235: Current learning rate: 0.00618 
2025-07-12 00:31:45.240606: train_loss -0.975 
2025-07-12 00:31:45.241858: val_loss -0.9516 
2025-07-12 00:31:45.242831: Pseudo dice [np.float32(0.955)] 
2025-07-12 00:31:45.243770: Epoch time: 67.26 s 
2025-07-12 00:31:46.142573:  
2025-07-12 00:31:46.144276: Epoch 415 
2025-07-12 00:31:46.145352: Current learning rate: 0.00617 
2025-07-12 00:32:53.547231: train_loss -0.9741 
2025-07-12 00:32:53.548584: val_loss -0.9475 
2025-07-12 00:32:53.549785: Pseudo dice [np.float32(0.9518)] 
2025-07-12 00:32:53.551184: Epoch time: 67.41 s 
2025-07-12 00:32:54.443430:  
2025-07-12 00:32:54.445129: Epoch 416 
2025-07-12 00:32:54.446817: Current learning rate: 0.00616 
2025-07-12 00:34:01.925173: train_loss -0.9733 
2025-07-12 00:34:01.926546: val_loss -0.9502 
2025-07-12 00:34:01.927665: Pseudo dice [np.float32(0.9543)] 
2025-07-12 00:34:01.928947: Epoch time: 67.49 s 
2025-07-12 00:34:02.826857:  
2025-07-12 00:34:02.828820: Epoch 417 
2025-07-12 00:34:02.830229: Current learning rate: 0.00615 
2025-07-12 00:35:11.154899: train_loss -0.9746 
2025-07-12 00:35:11.156343: val_loss -0.9454 
2025-07-12 00:35:11.157518: Pseudo dice [np.float32(0.9489)] 
2025-07-12 00:35:11.158600: Epoch time: 68.33 s 
2025-07-12 00:35:12.033043:  
2025-07-12 00:35:12.035043: Epoch 418 
2025-07-12 00:35:12.036159: Current learning rate: 0.00614 
2025-07-12 00:36:19.513614: train_loss -0.9748 
2025-07-12 00:36:19.514799: val_loss -0.952 
2025-07-12 00:36:19.515951: Pseudo dice [np.float32(0.9556)] 
2025-07-12 00:36:19.517051: Epoch time: 67.48 s 
2025-07-12 00:36:20.413687:  
2025-07-12 00:36:20.415603: Epoch 419 
2025-07-12 00:36:20.416923: Current learning rate: 0.00613 
2025-07-12 00:37:27.917246: train_loss -0.9742 
2025-07-12 00:37:27.918583: val_loss -0.947 
2025-07-12 00:37:27.919604: Pseudo dice [np.float32(0.9507)] 
2025-07-12 00:37:27.920890: Epoch time: 67.51 s 
2025-07-12 00:37:28.811335:  
2025-07-12 00:37:28.812937: Epoch 420 
2025-07-12 00:37:28.814083: Current learning rate: 0.00612 
2025-07-12 00:38:36.522328: train_loss -0.974 
2025-07-12 00:38:36.523651: val_loss -0.9504 
2025-07-12 00:38:36.524815: Pseudo dice [np.float32(0.9544)] 
2025-07-12 00:38:36.525858: Epoch time: 67.71 s 
2025-07-12 00:38:36.526915: Yayy! New best EMA pseudo Dice: 0.9523000121116638 
2025-07-12 00:38:38.643318:  
2025-07-12 00:38:38.644661: Epoch 421 
2025-07-12 00:38:38.645720: Current learning rate: 0.00612 
2025-07-12 00:39:46.766239: train_loss -0.9743 
2025-07-12 00:39:46.767541: val_loss -0.9466 
2025-07-12 00:39:46.768752: Pseudo dice [np.float32(0.9503)] 
2025-07-12 00:39:46.769805: Epoch time: 68.13 s 
2025-07-12 00:39:47.662522:  
2025-07-12 00:39:47.664236: Epoch 422 
2025-07-12 00:39:47.665416: Current learning rate: 0.00611 
2025-07-12 00:40:55.708183: train_loss -0.9733 
2025-07-12 00:40:55.709663: val_loss -0.9468 
2025-07-12 00:40:55.710831: Pseudo dice [np.float32(0.9511)] 
2025-07-12 00:40:55.711974: Epoch time: 68.05 s 
2025-07-12 00:40:56.598017:  
2025-07-12 00:40:56.599863: Epoch 423 
2025-07-12 00:40:56.601001: Current learning rate: 0.0061 
2025-07-12 00:42:04.522470: train_loss -0.9747 
2025-07-12 00:42:04.524051: val_loss -0.9479 
2025-07-12 00:42:04.525124: Pseudo dice [np.float32(0.9516)] 
2025-07-12 00:42:04.526302: Epoch time: 67.93 s 
2025-07-12 00:42:05.426021:  
2025-07-12 00:42:05.427950: Epoch 424 
2025-07-12 00:42:05.429178: Current learning rate: 0.00609 
2025-07-12 00:43:13.366522: train_loss -0.9733 
2025-07-12 00:43:13.367894: val_loss -0.9411 
2025-07-12 00:43:13.368964: Pseudo dice [np.float32(0.9449)] 
2025-07-12 00:43:13.370072: Epoch time: 67.94 s 
2025-07-12 00:43:14.271835:  
2025-07-12 00:43:14.273301: Epoch 425 
2025-07-12 00:43:14.274359: Current learning rate: 0.00608 
2025-07-12 00:44:22.355089: train_loss -0.9736 
2025-07-12 00:44:22.356335: val_loss -0.9506 
2025-07-12 00:44:22.357672: Pseudo dice [np.float32(0.9547)] 
2025-07-12 00:44:22.358822: Epoch time: 68.09 s 
2025-07-12 00:44:23.250295:  
2025-07-12 00:44:23.251866: Epoch 426 
2025-07-12 00:44:23.253019: Current learning rate: 0.00607 
2025-07-12 00:45:32.016160: train_loss -0.9745 
2025-07-12 00:45:32.017320: val_loss -0.9483 
2025-07-12 00:45:32.018239: Pseudo dice [np.float32(0.9531)] 
2025-07-12 00:45:32.019416: Epoch time: 68.77 s 
2025-07-12 00:45:32.917878:  
2025-07-12 00:45:32.919877: Epoch 427 
2025-07-12 00:45:32.921148: Current learning rate: 0.00606 
2025-07-12 00:46:40.978468: train_loss -0.9739 
2025-07-12 00:46:40.979752: val_loss -0.9485 
2025-07-12 00:46:40.980900: Pseudo dice [np.float32(0.9537)] 
2025-07-12 00:46:40.982160: Epoch time: 68.06 s 
2025-07-12 00:46:41.888314:  
2025-07-12 00:46:41.889764: Epoch 428 
2025-07-12 00:46:41.891004: Current learning rate: 0.00605 
2025-07-12 00:47:49.794629: train_loss -0.9741 
2025-07-12 00:47:49.796079: val_loss -0.9472 
2025-07-12 00:47:49.797200: Pseudo dice [np.float32(0.9519)] 
2025-07-12 00:47:49.798336: Epoch time: 67.91 s 
2025-07-12 00:47:50.692804:  
2025-07-12 00:47:50.694380: Epoch 429 
2025-07-12 00:47:50.695556: Current learning rate: 0.00604 
2025-07-12 00:48:58.357489: train_loss -0.9742 
2025-07-12 00:48:58.358914: val_loss -0.9469 
2025-07-12 00:48:58.360097: Pseudo dice [np.float32(0.9518)] 
2025-07-12 00:48:58.361098: Epoch time: 67.67 s 
2025-07-12 00:48:59.253794:  
2025-07-12 00:48:59.255657: Epoch 430 
2025-07-12 00:48:59.256806: Current learning rate: 0.00603 
2025-07-12 00:50:06.825468: train_loss -0.9747 
2025-07-12 00:50:06.826823: val_loss -0.95 
2025-07-12 00:50:06.827940: Pseudo dice [np.float32(0.9535)] 
2025-07-12 00:50:06.829121: Epoch time: 67.58 s 
2025-07-12 00:50:07.724009:  
2025-07-12 00:50:07.725737: Epoch 431 
2025-07-12 00:50:07.726898: Current learning rate: 0.00602 
2025-07-12 00:51:15.208821: train_loss -0.9744 
2025-07-12 00:51:15.210391: val_loss -0.9534 
2025-07-12 00:51:15.211282: Pseudo dice [np.float32(0.9564)] 
2025-07-12 00:51:15.212316: Epoch time: 67.49 s 
2025-07-12 00:51:15.213470: Yayy! New best EMA pseudo Dice: 0.9524999856948853 
2025-07-12 00:51:17.321635:  
2025-07-12 00:51:17.323439: Epoch 432 
2025-07-12 00:51:17.324534: Current learning rate: 0.00601 
2025-07-12 00:52:24.729738: train_loss -0.9745 
2025-07-12 00:52:24.731298: val_loss -0.9396 
2025-07-12 00:52:24.732539: Pseudo dice [np.float32(0.9436)] 
2025-07-12 00:52:24.733661: Epoch time: 67.41 s 
2025-07-12 00:52:25.620929:  
2025-07-12 00:52:25.622503: Epoch 433 
2025-07-12 00:52:25.623608: Current learning rate: 0.006 
2025-07-12 00:53:33.087875: train_loss -0.9732 
2025-07-12 00:53:33.089126: val_loss -0.9486 
2025-07-12 00:53:33.090118: Pseudo dice [np.float32(0.9525)] 
2025-07-12 00:53:33.091196: Epoch time: 67.47 s 
2025-07-12 00:53:33.988103:  
2025-07-12 00:53:33.989749: Epoch 434 
2025-07-12 00:53:33.990961: Current learning rate: 0.00599 
2025-07-12 00:54:41.459075: train_loss -0.9739 
2025-07-12 00:54:41.460317: val_loss -0.9504 
2025-07-12 00:54:41.461439: Pseudo dice [np.float32(0.954)] 
2025-07-12 00:54:41.462563: Epoch time: 67.47 s 
2025-07-12 00:54:43.112177:  
2025-07-12 00:54:43.113654: Epoch 435 
2025-07-12 00:54:43.114774: Current learning rate: 0.00598 
2025-07-12 00:55:50.469623: train_loss -0.9732 
2025-07-12 00:55:50.470860: val_loss -0.95 
2025-07-12 00:55:50.472258: Pseudo dice [np.float32(0.9544)] 
2025-07-12 00:55:50.473377: Epoch time: 67.36 s 
2025-07-12 00:55:51.361568:  
2025-07-12 00:55:51.363558: Epoch 436 
2025-07-12 00:55:51.364767: Current learning rate: 0.00597 
2025-07-12 00:56:58.698187: train_loss -0.9743 
2025-07-12 00:56:58.699591: val_loss -0.9495 
2025-07-12 00:56:58.700826: Pseudo dice [np.float32(0.9532)] 
2025-07-12 00:56:58.701984: Epoch time: 67.34 s 
2025-07-12 00:56:59.594451:  
2025-07-12 00:56:59.596047: Epoch 437 
2025-07-12 00:56:59.597200: Current learning rate: 0.00596 
2025-07-12 00:58:07.169219: train_loss -0.974 
2025-07-12 00:58:07.170604: val_loss -0.9483 
2025-07-12 00:58:07.171821: Pseudo dice [np.float32(0.9516)] 
2025-07-12 00:58:07.173303: Epoch time: 67.58 s 
2025-07-12 00:58:08.104458:  
2025-07-12 00:58:08.106179: Epoch 438 
2025-07-12 00:58:08.107733: Current learning rate: 0.00595 
2025-07-12 00:59:15.803453: train_loss -0.9734 
2025-07-12 00:59:15.804710: val_loss -0.9485 
2025-07-12 00:59:15.805691: Pseudo dice [np.float32(0.953)] 
2025-07-12 00:59:15.806772: Epoch time: 67.7 s 
2025-07-12 00:59:16.699939:  
2025-07-12 00:59:16.701614: Epoch 439 
2025-07-12 00:59:16.703080: Current learning rate: 0.00594 
2025-07-12 01:00:24.065067: train_loss -0.9731 
2025-07-12 01:00:24.066299: val_loss -0.9483 
2025-07-12 01:00:24.067501: Pseudo dice [np.float32(0.9519)] 
2025-07-12 01:00:24.068682: Epoch time: 67.37 s 
2025-07-12 01:00:24.969371:  
2025-07-12 01:00:24.971107: Epoch 440 
2025-07-12 01:00:24.972239: Current learning rate: 0.00593 
2025-07-12 01:01:32.612527: train_loss -0.9739 
2025-07-12 01:01:32.613891: val_loss -0.9454 
2025-07-12 01:01:32.615030: Pseudo dice [np.float32(0.9498)] 
2025-07-12 01:01:32.616184: Epoch time: 67.65 s 
2025-07-12 01:01:33.511582:  
2025-07-12 01:01:33.512798: Epoch 441 
2025-07-12 01:01:33.514062: Current learning rate: 0.00592 
2025-07-12 01:02:41.093602: train_loss -0.9748 
2025-07-12 01:02:41.095183: val_loss -0.9473 
2025-07-12 01:02:41.096446: Pseudo dice [np.float32(0.9511)] 
2025-07-12 01:02:41.097553: Epoch time: 67.59 s 
2025-07-12 01:02:41.985242:  
2025-07-12 01:02:41.986882: Epoch 442 
2025-07-12 01:02:41.988121: Current learning rate: 0.00592 
2025-07-12 01:03:49.915540: train_loss -0.9748 
2025-07-12 01:03:49.916898: val_loss -0.9459 
2025-07-12 01:03:49.918052: Pseudo dice [np.float32(0.951)] 
2025-07-12 01:03:49.919230: Epoch time: 67.93 s 
2025-07-12 01:03:50.806848:  
2025-07-12 01:03:50.808388: Epoch 443 
2025-07-12 01:03:50.809496: Current learning rate: 0.00591 
2025-07-12 01:04:58.874531: train_loss -0.9747 
2025-07-12 01:04:58.876037: val_loss -0.9459 
2025-07-12 01:04:58.877170: Pseudo dice [np.float32(0.95)] 
2025-07-12 01:04:58.878257: Epoch time: 68.07 s 
2025-07-12 01:04:59.756670:  
2025-07-12 01:04:59.757984: Epoch 444 
2025-07-12 01:04:59.759078: Current learning rate: 0.0059 
2025-07-12 01:06:08.262090: train_loss -0.9735 
2025-07-12 01:06:08.263356: val_loss -0.9494 
2025-07-12 01:06:08.264512: Pseudo dice [np.float32(0.9525)] 
2025-07-12 01:06:08.265586: Epoch time: 68.51 s 
2025-07-12 01:06:09.148427:  
2025-07-12 01:06:09.150109: Epoch 445 
2025-07-12 01:06:09.151493: Current learning rate: 0.00589 
2025-07-12 01:07:16.770895: train_loss -0.9727 
2025-07-12 01:07:16.772200: val_loss -0.9496 
2025-07-12 01:07:16.773464: Pseudo dice [np.float32(0.9544)] 
2025-07-12 01:07:16.774510: Epoch time: 67.63 s 
2025-07-12 01:07:17.651240:  
2025-07-12 01:07:17.653068: Epoch 446 
2025-07-12 01:07:17.654394: Current learning rate: 0.00588 
2025-07-12 01:08:25.307073: train_loss -0.9738 
2025-07-12 01:08:25.308461: val_loss -0.9445 
2025-07-12 01:08:25.309613: Pseudo dice [np.float32(0.9484)] 
2025-07-12 01:08:25.310843: Epoch time: 67.66 s 
2025-07-12 01:08:26.210027:  
2025-07-12 01:08:26.211634: Epoch 447 
2025-07-12 01:08:26.212850: Current learning rate: 0.00587 
2025-07-12 01:09:33.660551: train_loss -0.9732 
2025-07-12 01:09:33.662019: val_loss -0.9409 
2025-07-12 01:09:33.663134: Pseudo dice [np.float32(0.9449)] 
2025-07-12 01:09:33.664340: Epoch time: 67.45 s 
2025-07-12 01:09:34.543293:  
2025-07-12 01:09:34.545035: Epoch 448 
2025-07-12 01:09:34.546155: Current learning rate: 0.00586 
2025-07-12 01:10:41.941901: train_loss -0.9743 
2025-07-12 01:10:41.943471: val_loss -0.9456 
2025-07-12 01:10:41.944474: Pseudo dice [np.float32(0.9498)] 
2025-07-12 01:10:41.945728: Epoch time: 67.4 s 
2025-07-12 01:10:42.828681:  
2025-07-12 01:10:42.830512: Epoch 449 
2025-07-12 01:10:42.831671: Current learning rate: 0.00585 
2025-07-12 01:11:50.475722: train_loss -0.9753 
2025-07-12 01:11:50.477050: val_loss -0.9478 
2025-07-12 01:11:50.478105: Pseudo dice [np.float32(0.9517)] 
2025-07-12 01:11:50.479181: Epoch time: 67.65 s 
2025-07-12 01:11:52.594229:  
2025-07-12 01:11:52.595680: Epoch 450 
2025-07-12 01:11:52.596838: Current learning rate: 0.00584 
2025-07-12 01:13:00.254282: train_loss -0.9746 
2025-07-12 01:13:00.255559: val_loss -0.9449 
2025-07-12 01:13:00.256604: Pseudo dice [np.float32(0.9488)] 
2025-07-12 01:13:00.257867: Epoch time: 67.66 s 
2025-07-12 01:13:01.140380:  
2025-07-12 01:13:01.142119: Epoch 451 
2025-07-12 01:13:01.143247: Current learning rate: 0.00583 
2025-07-12 01:14:08.815729: train_loss -0.9741 
2025-07-12 01:14:08.816969: val_loss -0.9491 
2025-07-12 01:14:08.818047: Pseudo dice [np.float32(0.9528)] 
2025-07-12 01:14:08.819269: Epoch time: 67.68 s 
2025-07-12 01:14:09.701033:  
2025-07-12 01:14:09.703118: Epoch 452 
2025-07-12 01:14:09.704265: Current learning rate: 0.00582 
2025-07-12 01:15:17.553859: train_loss -0.9752 
2025-07-12 01:15:17.555168: val_loss -0.9496 
2025-07-12 01:15:17.556383: Pseudo dice [np.float32(0.9536)] 
2025-07-12 01:15:17.557685: Epoch time: 67.86 s 
2025-07-12 01:15:18.446964:  
2025-07-12 01:15:18.448483: Epoch 453 
2025-07-12 01:15:18.449519: Current learning rate: 0.00581 
2025-07-12 01:16:26.795799: train_loss -0.9744 
2025-07-12 01:16:26.797102: val_loss -0.9485 
2025-07-12 01:16:26.798378: Pseudo dice [np.float32(0.9523)] 
2025-07-12 01:16:26.799617: Epoch time: 68.35 s 
2025-07-12 01:16:27.686010:  
2025-07-12 01:16:27.687902: Epoch 454 
2025-07-12 01:16:27.689289: Current learning rate: 0.0058 
2025-07-12 01:17:35.256636: train_loss -0.9744 
2025-07-12 01:17:35.258579: val_loss -0.9522 
2025-07-12 01:17:35.259752: Pseudo dice [np.float32(0.9556)] 
2025-07-12 01:17:35.260742: Epoch time: 67.57 s 
2025-07-12 01:17:36.139152:  
2025-07-12 01:17:36.140815: Epoch 455 
2025-07-12 01:17:36.141986: Current learning rate: 0.00579 
2025-07-12 01:18:43.667420: train_loss -0.9738 
2025-07-12 01:18:43.669938: val_loss -0.9456 
2025-07-12 01:18:43.670988: Pseudo dice [np.float32(0.9493)] 
2025-07-12 01:18:43.672146: Epoch time: 67.53 s 
2025-07-12 01:18:44.550813:  
2025-07-12 01:18:44.552642: Epoch 456 
2025-07-12 01:18:44.553899: Current learning rate: 0.00578 
2025-07-12 01:19:52.387940: train_loss -0.971 
2025-07-12 01:19:52.389270: val_loss -0.9431 
2025-07-12 01:19:52.390408: Pseudo dice [np.float32(0.9474)] 
2025-07-12 01:19:52.391425: Epoch time: 67.84 s 
2025-07-12 01:19:53.280310:  
2025-07-12 01:19:53.281883: Epoch 457 
2025-07-12 01:19:53.283038: Current learning rate: 0.00577 
2025-07-12 01:21:01.286760: train_loss -0.9709 
2025-07-12 01:21:01.288178: val_loss -0.9458 
2025-07-12 01:21:01.289015: Pseudo dice [np.float32(0.9488)] 
2025-07-12 01:21:01.290251: Epoch time: 68.01 s 
2025-07-12 01:21:02.182480:  
2025-07-12 01:21:02.184081: Epoch 458 
2025-07-12 01:21:02.185250: Current learning rate: 0.00576 
2025-07-12 01:22:10.270591: train_loss -0.9734 
2025-07-12 01:22:10.271934: val_loss -0.9445 
2025-07-12 01:22:10.273269: Pseudo dice [np.float32(0.9483)] 
2025-07-12 01:22:10.274292: Epoch time: 68.09 s 
2025-07-12 01:22:11.155227:  
2025-07-12 01:22:11.156894: Epoch 459 
2025-07-12 01:22:11.157989: Current learning rate: 0.00575 
2025-07-12 01:23:19.525462: train_loss -0.9729 
2025-07-12 01:23:19.526808: val_loss -0.9433 
2025-07-12 01:23:19.527924: Pseudo dice [np.float32(0.9482)] 
2025-07-12 01:23:19.529065: Epoch time: 68.37 s 
2025-07-12 01:23:20.407476:  
2025-07-12 01:23:20.408848: Epoch 460 
2025-07-12 01:23:20.409943: Current learning rate: 0.00574 
2025-07-12 01:24:28.653944: train_loss -0.9736 
2025-07-12 01:24:28.655365: val_loss -0.9504 
2025-07-12 01:24:28.656458: Pseudo dice [np.float32(0.9546)] 
2025-07-12 01:24:28.657595: Epoch time: 68.25 s 
2025-07-12 01:24:29.541412:  
2025-07-12 01:24:29.543179: Epoch 461 
2025-07-12 01:24:29.544241: Current learning rate: 0.00573 
2025-07-12 01:25:37.488113: train_loss -0.9743 
2025-07-12 01:25:37.489519: val_loss -0.9456 
2025-07-12 01:25:37.490687: Pseudo dice [np.float32(0.949)] 
2025-07-12 01:25:37.491618: Epoch time: 67.95 s 
2025-07-12 01:25:38.369374:  
2025-07-12 01:25:38.371043: Epoch 462 
2025-07-12 01:25:38.372190: Current learning rate: 0.00572 
2025-07-12 01:26:47.053796: train_loss -0.9747 
2025-07-12 01:26:47.055044: val_loss -0.948 
2025-07-12 01:26:47.056264: Pseudo dice [np.float32(0.9525)] 
2025-07-12 01:26:47.057307: Epoch time: 68.69 s 
2025-07-12 01:26:47.948967:  
2025-07-12 01:26:47.950729: Epoch 463 
2025-07-12 01:26:47.951945: Current learning rate: 0.00571 
2025-07-12 01:27:55.641894: train_loss -0.9747 
2025-07-12 01:27:55.642969: val_loss -0.9482 
2025-07-12 01:27:55.644212: Pseudo dice [np.float32(0.9521)] 
2025-07-12 01:27:55.645211: Epoch time: 67.7 s 
2025-07-12 01:27:56.530088:  
2025-07-12 01:27:56.531991: Epoch 464 
2025-07-12 01:27:56.533230: Current learning rate: 0.0057 
2025-07-12 01:29:03.925456: train_loss -0.9752 
2025-07-12 01:29:03.926786: val_loss -0.9471 
2025-07-12 01:29:03.927746: Pseudo dice [np.float32(0.9511)] 
2025-07-12 01:29:03.928691: Epoch time: 67.4 s 
2025-07-12 01:29:04.811768:  
2025-07-12 01:29:04.813691: Epoch 465 
2025-07-12 01:29:04.814822: Current learning rate: 0.0057 
2025-07-12 01:30:12.281021: train_loss -0.9756 
2025-07-12 01:30:12.282677: val_loss -0.9463 
2025-07-12 01:30:12.283866: Pseudo dice [np.float32(0.9505)] 
2025-07-12 01:30:12.284967: Epoch time: 67.47 s 
2025-07-12 01:30:13.173803:  
2025-07-12 01:30:13.175384: Epoch 466 
2025-07-12 01:30:13.176490: Current learning rate: 0.00569 
2025-07-12 01:31:20.661961: train_loss -0.9747 
2025-07-12 01:31:20.663243: val_loss -0.9465 
2025-07-12 01:31:20.664285: Pseudo dice [np.float32(0.951)] 
2025-07-12 01:31:20.665271: Epoch time: 67.49 s 
2025-07-12 01:31:21.549351:  
2025-07-12 01:31:21.551013: Epoch 467 
2025-07-12 01:31:21.552209: Current learning rate: 0.00568 
2025-07-12 01:32:29.040884: train_loss -0.9731 
2025-07-12 01:32:29.042279: val_loss -0.9479 
2025-07-12 01:32:29.043451: Pseudo dice [np.float32(0.9524)] 
2025-07-12 01:32:29.044665: Epoch time: 67.5 s 
2025-07-12 01:32:29.937046:  
2025-07-12 01:32:29.939001: Epoch 468 
2025-07-12 01:32:29.940141: Current learning rate: 0.00567 
2025-07-12 01:33:37.416999: train_loss -0.9712 
2025-07-12 01:33:37.418205: val_loss -0.9481 
2025-07-12 01:33:37.419500: Pseudo dice [np.float32(0.9526)] 
2025-07-12 01:33:37.420442: Epoch time: 67.48 s 
2025-07-12 01:33:38.304790:  
2025-07-12 01:33:38.306258: Epoch 469 
2025-07-12 01:33:38.307717: Current learning rate: 0.00566 
2025-07-12 01:34:45.733974: train_loss -0.9745 
2025-07-12 01:34:45.735268: val_loss -0.9471 
2025-07-12 01:34:45.736410: Pseudo dice [np.float32(0.9508)] 
2025-07-12 01:34:45.737458: Epoch time: 67.43 s 
2025-07-12 01:34:46.625221:  
2025-07-12 01:34:46.626555: Epoch 470 
2025-07-12 01:34:46.627750: Current learning rate: 0.00565 
2025-07-12 01:35:54.323292: train_loss -0.9745 
2025-07-12 01:35:54.324707: val_loss -0.9503 
2025-07-12 01:35:54.325612: Pseudo dice [np.float32(0.9541)] 
2025-07-12 01:35:54.326804: Epoch time: 67.7 s 
2025-07-12 01:35:55.195607:  
2025-07-12 01:35:55.197325: Epoch 471 
2025-07-12 01:35:55.198507: Current learning rate: 0.00564 
2025-07-12 01:37:03.479145: train_loss -0.974 
2025-07-12 01:37:03.480456: val_loss -0.9486 
2025-07-12 01:37:03.481761: Pseudo dice [np.float32(0.9528)] 
2025-07-12 01:37:03.483115: Epoch time: 68.29 s 
2025-07-12 01:37:04.356247:  
2025-07-12 01:37:04.357894: Epoch 472 
2025-07-12 01:37:04.358989: Current learning rate: 0.00563 
2025-07-12 01:38:12.397807: train_loss -0.9737 
2025-07-12 01:38:12.399030: val_loss -0.9484 
2025-07-12 01:38:12.400229: Pseudo dice [np.float32(0.9528)] 
2025-07-12 01:38:12.401394: Epoch time: 68.05 s 
2025-07-12 01:38:13.279155:  
2025-07-12 01:38:13.281047: Epoch 473 
2025-07-12 01:38:13.282263: Current learning rate: 0.00562 
2025-07-12 01:39:21.253774: train_loss -0.9738 
2025-07-12 01:39:21.254933: val_loss -0.9425 
2025-07-12 01:39:21.255863: Pseudo dice [np.float32(0.9466)] 
2025-07-12 01:39:21.257005: Epoch time: 67.98 s 
2025-07-12 01:39:22.144220:  
2025-07-12 01:39:22.145672: Epoch 474 
2025-07-12 01:39:22.146857: Current learning rate: 0.00561 
2025-07-12 01:40:30.124535: train_loss -0.9754 
2025-07-12 01:40:30.125937: val_loss -0.9491 
2025-07-12 01:40:30.127100: Pseudo dice [np.float32(0.9534)] 
2025-07-12 01:40:30.128268: Epoch time: 67.98 s 
2025-07-12 01:40:31.003449:  
2025-07-12 01:40:31.005051: Epoch 475 
2025-07-12 01:40:31.006189: Current learning rate: 0.0056 
2025-07-12 01:41:39.026603: train_loss -0.9742 
2025-07-12 01:41:39.027890: val_loss -0.9454 
2025-07-12 01:41:39.029096: Pseudo dice [np.float32(0.9506)] 
2025-07-12 01:41:39.030254: Epoch time: 68.03 s 
2025-07-12 01:41:39.912262:  
2025-07-12 01:41:39.913960: Epoch 476 
2025-07-12 01:41:39.914970: Current learning rate: 0.00559 
2025-07-12 01:42:48.134869: train_loss -0.9742 
2025-07-12 01:42:48.136258: val_loss -0.9432 
2025-07-12 01:42:48.137393: Pseudo dice [np.float32(0.9481)] 
2025-07-12 01:42:48.138426: Epoch time: 68.23 s 
2025-07-12 01:42:49.018140:  
2025-07-12 01:42:49.019698: Epoch 477 
2025-07-12 01:42:49.020869: Current learning rate: 0.00558 
2025-07-12 01:43:56.573643: train_loss -0.9731 
2025-07-12 01:43:56.574923: val_loss -0.9452 
2025-07-12 01:43:56.576037: Pseudo dice [np.float32(0.9497)] 
2025-07-12 01:43:56.577134: Epoch time: 67.56 s 
2025-07-12 01:43:57.460171:  
2025-07-12 01:43:57.461904: Epoch 478 
2025-07-12 01:43:57.463143: Current learning rate: 0.00557 
2025-07-12 01:45:05.138195: train_loss -0.9742 
2025-07-12 01:45:05.139493: val_loss -0.9499 
2025-07-12 01:45:05.140838: Pseudo dice [np.float32(0.9549)] 
2025-07-12 01:45:05.141770: Epoch time: 67.68 s 
2025-07-12 01:45:06.024970:  
2025-07-12 01:45:06.026496: Epoch 479 
2025-07-12 01:45:06.027747: Current learning rate: 0.00556 
2025-07-12 01:46:13.590845: train_loss -0.975 
2025-07-12 01:46:13.592260: val_loss -0.9482 
2025-07-12 01:46:13.593383: Pseudo dice [np.float32(0.9522)] 
2025-07-12 01:46:13.594414: Epoch time: 67.57 s 
2025-07-12 01:46:14.486389:  
2025-07-12 01:46:14.488060: Epoch 480 
2025-07-12 01:46:14.489466: Current learning rate: 0.00555 
2025-07-12 01:47:22.849312: train_loss -0.9742 
2025-07-12 01:47:22.850629: val_loss -0.949 
2025-07-12 01:47:22.851736: Pseudo dice [np.float32(0.9528)] 
2025-07-12 01:47:22.852734: Epoch time: 68.37 s 
2025-07-12 01:47:23.741933:  
2025-07-12 01:47:23.743558: Epoch 481 
2025-07-12 01:47:23.744656: Current learning rate: 0.00554 
2025-07-12 01:48:31.312596: train_loss -0.9747 
2025-07-12 01:48:31.313945: val_loss -0.945 
2025-07-12 01:48:31.315127: Pseudo dice [np.float32(0.9486)] 
2025-07-12 01:48:31.316277: Epoch time: 67.57 s 
2025-07-12 01:48:32.230620:  
2025-07-12 01:48:32.232144: Epoch 482 
2025-07-12 01:48:32.233283: Current learning rate: 0.00553 
2025-07-12 01:49:39.795433: train_loss -0.9753 
2025-07-12 01:49:39.797016: val_loss -0.9458 
2025-07-12 01:49:39.798249: Pseudo dice [np.float32(0.9503)] 
2025-07-12 01:49:39.799451: Epoch time: 67.57 s 
2025-07-12 01:49:40.687585:  
2025-07-12 01:49:40.689165: Epoch 483 
2025-07-12 01:49:40.690341: Current learning rate: 0.00552 
2025-07-12 01:50:48.376340: train_loss -0.9752 
2025-07-12 01:50:48.377708: val_loss -0.95 
2025-07-12 01:50:48.378824: Pseudo dice [np.float32(0.9542)] 
2025-07-12 01:50:48.379947: Epoch time: 67.69 s 
2025-07-12 01:50:49.273053:  
2025-07-12 01:50:49.274780: Epoch 484 
2025-07-12 01:50:49.276019: Current learning rate: 0.00551 
2025-07-12 01:51:57.286505: train_loss -0.974 
2025-07-12 01:51:57.287911: val_loss -0.949 
2025-07-12 01:51:57.289114: Pseudo dice [np.float32(0.9533)] 
2025-07-12 01:51:57.290274: Epoch time: 68.02 s 
2025-07-12 01:51:58.195480:  
2025-07-12 01:51:58.196985: Epoch 485 
2025-07-12 01:51:58.198029: Current learning rate: 0.0055 
2025-07-12 01:53:06.213353: train_loss -0.9746 
2025-07-12 01:53:06.214817: val_loss -0.9522 
2025-07-12 01:53:06.215944: Pseudo dice [np.float32(0.9561)] 
2025-07-12 01:53:06.217150: Epoch time: 68.02 s 
2025-07-12 01:53:07.108575:  
2025-07-12 01:53:07.110341: Epoch 486 
2025-07-12 01:53:07.111524: Current learning rate: 0.00549 
2025-07-12 01:54:15.093743: train_loss -0.9752 
2025-07-12 01:54:15.094945: val_loss -0.9481 
2025-07-12 01:54:15.096137: Pseudo dice [np.float32(0.9522)] 
2025-07-12 01:54:15.097124: Epoch time: 67.99 s 
2025-07-12 01:54:15.984066:  
2025-07-12 01:54:15.985469: Epoch 487 
2025-07-12 01:54:15.986611: Current learning rate: 0.00548 
2025-07-12 01:55:23.997130: train_loss -0.9759 
2025-07-12 01:55:23.998518: val_loss -0.9491 
2025-07-12 01:55:23.999579: Pseudo dice [np.float32(0.953)] 
2025-07-12 01:55:24.000697: Epoch time: 68.02 s 
2025-07-12 01:55:24.880293:  
2025-07-12 01:55:24.882094: Epoch 488 
2025-07-12 01:55:24.883263: Current learning rate: 0.00547 
2025-07-12 01:56:32.831283: train_loss -0.9752 
2025-07-12 01:56:32.832633: val_loss -0.9494 
2025-07-12 01:56:32.833787: Pseudo dice [np.float32(0.9535)] 
2025-07-12 01:56:32.834913: Epoch time: 67.95 s 
2025-07-12 01:56:33.714613:  
2025-07-12 01:56:33.716193: Epoch 489 
2025-07-12 01:56:33.717308: Current learning rate: 0.00546 
2025-07-12 01:57:42.399929: train_loss -0.9753 
2025-07-12 01:57:42.401427: val_loss -0.9476 
2025-07-12 01:57:42.402514: Pseudo dice [np.float32(0.9517)] 
2025-07-12 01:57:42.403866: Epoch time: 68.69 s 
2025-07-12 01:57:43.337311:  
2025-07-12 01:57:43.338951: Epoch 490 
2025-07-12 01:57:43.340103: Current learning rate: 0.00546 
2025-07-12 01:58:50.910054: train_loss -0.9751 
2025-07-12 01:58:50.911450: val_loss -0.9497 
2025-07-12 01:58:50.912602: Pseudo dice [np.float32(0.9539)] 
2025-07-12 01:58:50.913804: Epoch time: 67.58 s 
2025-07-12 01:58:51.799851:  
2025-07-12 01:58:51.801735: Epoch 491 
2025-07-12 01:58:51.803025: Current learning rate: 0.00545 
2025-07-12 01:59:59.317441: train_loss -0.9757 
2025-07-12 01:59:59.318778: val_loss -0.948 
2025-07-12 01:59:59.319767: Pseudo dice [np.float32(0.9523)] 
2025-07-12 01:59:59.320631: Epoch time: 67.52 s 
2025-07-12 02:00:00.215066:  
2025-07-12 02:00:00.216433: Epoch 492 
2025-07-12 02:00:00.217666: Current learning rate: 0.00544 
2025-07-12 02:01:08.091076: train_loss -0.9743 
2025-07-12 02:01:08.092584: val_loss -0.949 
2025-07-12 02:01:08.093770: Pseudo dice [np.float32(0.9542)] 
2025-07-12 02:01:08.094907: Epoch time: 67.88 s 
2025-07-12 02:01:08.095943: Yayy! New best EMA pseudo Dice: 0.9526000022888184 
2025-07-12 02:01:10.277184:  
2025-07-12 02:01:10.278995: Epoch 493 
2025-07-12 02:01:10.280158: Current learning rate: 0.00543 
2025-07-12 02:02:17.849391: train_loss -0.9758 
2025-07-12 02:02:17.850857: val_loss -0.9469 
2025-07-12 02:02:17.852002: Pseudo dice [np.float32(0.9511)] 
2025-07-12 02:02:17.853109: Epoch time: 67.58 s 
2025-07-12 02:02:18.741168:  
2025-07-12 02:02:18.742771: Epoch 494 
2025-07-12 02:02:18.743941: Current learning rate: 0.00542 
2025-07-12 02:03:26.451971: train_loss -0.9759 
2025-07-12 02:03:26.453405: val_loss -0.9473 
2025-07-12 02:03:26.454633: Pseudo dice [np.float32(0.9508)] 
2025-07-12 02:03:26.455692: Epoch time: 67.71 s 
2025-07-12 02:03:27.348040:  
2025-07-12 02:03:27.349776: Epoch 495 
2025-07-12 02:03:27.351024: Current learning rate: 0.00541 
2025-07-12 02:04:35.160810: train_loss -0.9759 
2025-07-12 02:04:35.162209: val_loss -0.945 
2025-07-12 02:04:35.163352: Pseudo dice [np.float32(0.9489)] 
2025-07-12 02:04:35.164388: Epoch time: 67.82 s 
2025-07-12 02:04:36.048570:  
2025-07-12 02:04:36.050155: Epoch 496 
2025-07-12 02:04:36.051314: Current learning rate: 0.0054 
2025-07-12 02:05:43.686694: train_loss -0.9745 
2025-07-12 02:05:43.687826: val_loss -0.9458 
2025-07-12 02:05:43.688857: Pseudo dice [np.float32(0.95)] 
2025-07-12 02:05:43.689754: Epoch time: 67.64 s 
2025-07-12 02:05:44.580353:  
2025-07-12 02:05:44.582085: Epoch 497 
2025-07-12 02:05:44.583274: Current learning rate: 0.00539 
2025-07-12 02:06:52.159971: train_loss -0.9746 
2025-07-12 02:06:52.161541: val_loss -0.9472 
2025-07-12 02:06:52.162585: Pseudo dice [np.float32(0.9508)] 
2025-07-12 02:06:52.163612: Epoch time: 67.58 s 
2025-07-12 02:06:53.050194:  
2025-07-12 02:06:53.051824: Epoch 498 
2025-07-12 02:06:53.052950: Current learning rate: 0.00538 
2025-07-12 02:08:01.369747: train_loss -0.9748 
2025-07-12 02:08:01.371009: val_loss -0.948 
2025-07-12 02:08:01.372027: Pseudo dice [np.float32(0.9525)] 
2025-07-12 02:08:01.372989: Epoch time: 68.32 s 
2025-07-12 02:08:02.259760:  
2025-07-12 02:08:02.261661: Epoch 499 
2025-07-12 02:08:02.262733: Current learning rate: 0.00537 
2025-07-12 02:09:09.955646: train_loss -0.9755 
2025-07-12 02:09:09.956940: val_loss -0.9449 
2025-07-12 02:09:09.957969: Pseudo dice [np.float32(0.949)] 
2025-07-12 02:09:09.959272: Epoch time: 67.7 s 
2025-07-12 02:09:12.278395:  
2025-07-12 02:09:12.280050: Epoch 500 
2025-07-12 02:09:12.281271: Current learning rate: 0.00536 
2025-07-12 02:10:20.189819: train_loss -0.9745 
2025-07-12 02:10:20.191045: val_loss -0.945 
2025-07-12 02:10:20.192328: Pseudo dice [np.float32(0.949)] 
2025-07-12 02:10:20.193286: Epoch time: 67.91 s 
2025-07-12 02:10:21.087637:  
2025-07-12 02:10:21.089422: Epoch 501 
2025-07-12 02:10:21.090672: Current learning rate: 0.00535 
2025-07-12 02:11:29.200997: train_loss -0.9751 
2025-07-12 02:11:29.202444: val_loss -0.9459 
2025-07-12 02:11:29.203638: Pseudo dice [np.float32(0.9508)] 
2025-07-12 02:11:29.204820: Epoch time: 68.12 s 
2025-07-12 02:11:30.104148:  
2025-07-12 02:11:30.105429: Epoch 502 
2025-07-12 02:11:30.106582: Current learning rate: 0.00534 
2025-07-12 02:12:38.061789: train_loss -0.9742 
2025-07-12 02:12:38.063129: val_loss -0.9473 
2025-07-12 02:12:38.064363: Pseudo dice [np.float32(0.9521)] 
2025-07-12 02:12:38.065428: Epoch time: 67.96 s 
2025-07-12 02:12:38.955665:  
2025-07-12 02:12:38.957282: Epoch 503 
2025-07-12 02:12:38.958386: Current learning rate: 0.00533 
2025-07-12 02:13:46.602973: train_loss -0.9743 
2025-07-12 02:13:46.604206: val_loss -0.9483 
2025-07-12 02:13:46.605283: Pseudo dice [np.float32(0.9515)] 
2025-07-12 02:13:46.606516: Epoch time: 67.65 s 
2025-07-12 02:13:47.504209:  
2025-07-12 02:13:47.505826: Epoch 504 
2025-07-12 02:13:47.506993: Current learning rate: 0.00532 
2025-07-12 02:14:55.292687: train_loss -0.9747 
2025-07-12 02:14:55.294075: val_loss -0.9475 
2025-07-12 02:14:55.295234: Pseudo dice [np.float32(0.9519)] 
2025-07-12 02:14:55.296601: Epoch time: 67.79 s 
2025-07-12 02:14:56.180059:  
2025-07-12 02:14:56.181757: Epoch 505 
2025-07-12 02:14:56.182860: Current learning rate: 0.00531 
2025-07-12 02:16:04.001605: train_loss -0.9751 
2025-07-12 02:16:04.003012: val_loss -0.9506 
2025-07-12 02:16:04.003909: Pseudo dice [np.float32(0.954)] 
2025-07-12 02:16:04.004934: Epoch time: 67.83 s 
2025-07-12 02:16:04.903404:  
2025-07-12 02:16:04.905125: Epoch 506 
2025-07-12 02:16:04.906395: Current learning rate: 0.0053 
2025-07-12 02:17:12.603235: train_loss -0.9747 
2025-07-12 02:17:12.604720: val_loss -0.9453 
2025-07-12 02:17:12.605775: Pseudo dice [np.float32(0.9502)] 
2025-07-12 02:17:12.606734: Epoch time: 67.7 s 
2025-07-12 02:17:13.490274:  
2025-07-12 02:17:13.491674: Epoch 507 
2025-07-12 02:17:13.492824: Current learning rate: 0.00529 
2025-07-12 02:18:21.645247: train_loss -0.9754 
2025-07-12 02:18:21.646493: val_loss -0.948 
2025-07-12 02:18:21.647646: Pseudo dice [np.float32(0.9516)] 
2025-07-12 02:18:21.648584: Epoch time: 68.16 s 
2025-07-12 02:18:22.534779:  
2025-07-12 02:18:22.536887: Epoch 508 
2025-07-12 02:18:22.538003: Current learning rate: 0.00528 
2025-07-12 02:19:29.824804: train_loss -0.9763 
2025-07-12 02:19:29.826285: val_loss -0.9475 
2025-07-12 02:19:29.827310: Pseudo dice [np.float32(0.9529)] 
2025-07-12 02:19:29.828341: Epoch time: 67.29 s 
2025-07-12 02:19:30.719378:  
2025-07-12 02:19:30.721348: Epoch 509 
2025-07-12 02:19:30.722688: Current learning rate: 0.00527 
2025-07-12 02:20:38.318104: train_loss -0.9752 
2025-07-12 02:20:38.319511: val_loss -0.9503 
2025-07-12 02:20:38.320755: Pseudo dice [np.float32(0.9528)] 
2025-07-12 02:20:38.321916: Epoch time: 67.6 s 
2025-07-12 02:20:39.221287:  
2025-07-12 02:20:39.223915: Epoch 510 
2025-07-12 02:20:39.225272: Current learning rate: 0.00526 
2025-07-12 02:21:46.784992: train_loss -0.9762 
2025-07-12 02:21:46.786329: val_loss -0.9508 
2025-07-12 02:21:46.787330: Pseudo dice [np.float32(0.9547)] 
2025-07-12 02:21:46.788299: Epoch time: 67.57 s 
2025-07-12 02:21:47.677791:  
2025-07-12 02:21:47.679321: Epoch 511 
2025-07-12 02:21:47.680444: Current learning rate: 0.00525 
2025-07-12 02:22:55.113088: train_loss -0.9755 
2025-07-12 02:22:55.114488: val_loss -0.9501 
2025-07-12 02:22:55.115537: Pseudo dice [np.float32(0.954)] 
2025-07-12 02:22:55.116750: Epoch time: 67.44 s 
2025-07-12 02:22:56.013370:  
2025-07-12 02:22:56.014853: Epoch 512 
2025-07-12 02:22:56.016017: Current learning rate: 0.00524 
2025-07-12 02:24:03.421147: train_loss -0.9755 
2025-07-12 02:24:03.423383: val_loss -0.9513 
2025-07-12 02:24:03.424542: Pseudo dice [np.float32(0.9557)] 
2025-07-12 02:24:03.425558: Epoch time: 67.41 s 
2025-07-12 02:24:04.316219:  
2025-07-12 02:24:04.317736: Epoch 513 
2025-07-12 02:24:04.318853: Current learning rate: 0.00523 
2025-07-12 02:25:12.079051: train_loss -0.976 
2025-07-12 02:25:12.080395: val_loss -0.9488 
2025-07-12 02:25:12.081408: Pseudo dice [np.float32(0.9526)] 
2025-07-12 02:25:12.082432: Epoch time: 67.77 s 
2025-07-12 02:25:12.965884:  
2025-07-12 02:25:12.967689: Epoch 514 
2025-07-12 02:25:12.968800: Current learning rate: 0.00522 
2025-07-12 02:26:21.089653: train_loss -0.9761 
2025-07-12 02:26:21.091091: val_loss -0.9496 
2025-07-12 02:26:21.092297: Pseudo dice [np.float32(0.9533)] 
2025-07-12 02:26:21.093550: Epoch time: 68.13 s 
2025-07-12 02:26:21.094506: Yayy! New best EMA pseudo Dice: 0.9527000188827515 
2025-07-12 02:26:23.424525:  
2025-07-12 02:26:23.426212: Epoch 515 
2025-07-12 02:26:23.427542: Current learning rate: 0.00521 
2025-07-12 02:27:31.408858: train_loss -0.977 
2025-07-12 02:27:31.410221: val_loss -0.95 
2025-07-12 02:27:31.411314: Pseudo dice [np.float32(0.9531)] 
2025-07-12 02:27:31.412343: Epoch time: 67.99 s 
2025-07-12 02:27:31.413397: Yayy! New best EMA pseudo Dice: 0.9527000188827515 
2025-07-12 02:27:34.483982:  
2025-07-12 02:27:34.485588: Epoch 516 
2025-07-12 02:27:34.486712: Current learning rate: 0.0052 
2025-07-12 02:28:42.359992: train_loss -0.9773 
2025-07-12 02:28:42.361488: val_loss -0.9496 
2025-07-12 02:28:42.362675: Pseudo dice [np.float32(0.9533)] 
2025-07-12 02:28:42.363940: Epoch time: 67.88 s 
2025-07-12 02:28:42.365273: Yayy! New best EMA pseudo Dice: 0.9527999758720398 
2025-07-12 02:28:44.674731:  
2025-07-12 02:28:44.675946: Epoch 517 
2025-07-12 02:28:44.677070: Current learning rate: 0.00519 
2025-07-12 02:29:52.594625: train_loss -0.9763 
2025-07-12 02:29:52.595912: val_loss -0.9465 
2025-07-12 02:29:52.597179: Pseudo dice [np.float32(0.9512)] 
2025-07-12 02:29:52.598314: Epoch time: 67.92 s 
2025-07-12 02:29:53.497805:  
2025-07-12 02:29:53.499037: Epoch 518 
2025-07-12 02:29:53.500182: Current learning rate: 0.00518 
2025-07-12 02:31:01.603718: train_loss -0.9758 
2025-07-12 02:31:01.604921: val_loss -0.9415 
2025-07-12 02:31:01.605986: Pseudo dice [np.float32(0.9457)] 
2025-07-12 02:31:01.607151: Epoch time: 68.11 s 
2025-07-12 02:31:02.490585:  
2025-07-12 02:31:02.492150: Epoch 519 
2025-07-12 02:31:02.493270: Current learning rate: 0.00518 
2025-07-12 02:32:10.181765: train_loss -0.9767 
2025-07-12 02:32:10.183180: val_loss -0.9491 
2025-07-12 02:32:10.184387: Pseudo dice [np.float32(0.9522)] 
2025-07-12 02:32:10.185393: Epoch time: 67.69 s 
2025-07-12 02:32:11.084764:  
2025-07-12 02:32:11.086236: Epoch 520 
2025-07-12 02:32:11.087293: Current learning rate: 0.00517 
2025-07-12 02:33:18.545173: train_loss -0.9764 
2025-07-12 02:33:18.546600: val_loss -0.9473 
2025-07-12 02:33:18.547874: Pseudo dice [np.float32(0.952)] 
2025-07-12 02:33:18.549186: Epoch time: 67.46 s 
2025-07-12 02:33:19.428741:  
2025-07-12 02:33:19.430671: Epoch 521 
2025-07-12 02:33:19.431801: Current learning rate: 0.00516 
2025-07-12 02:34:27.256894: train_loss -0.9765 
2025-07-12 02:34:27.258320: val_loss -0.9449 
2025-07-12 02:34:27.259511: Pseudo dice [np.float32(0.9482)] 
2025-07-12 02:34:27.260817: Epoch time: 67.83 s 
2025-07-12 02:34:28.171543:  
2025-07-12 02:34:28.173293: Epoch 522 
2025-07-12 02:34:28.174699: Current learning rate: 0.00515 
2025-07-12 02:35:35.902308: train_loss -0.9768 
2025-07-12 02:35:35.903692: val_loss -0.95 
2025-07-12 02:35:35.904872: Pseudo dice [np.float32(0.9536)] 
2025-07-12 02:35:35.906179: Epoch time: 67.73 s 
2025-07-12 02:35:36.802194:  
2025-07-12 02:35:36.803637: Epoch 523 
2025-07-12 02:35:36.804981: Current learning rate: 0.00514 
2025-07-12 02:36:44.604817: train_loss -0.9768 
2025-07-12 02:36:44.606264: val_loss -0.9454 
2025-07-12 02:36:44.607338: Pseudo dice [np.float32(0.9484)] 
2025-07-12 02:36:44.608513: Epoch time: 67.81 s 
2025-07-12 02:36:45.491466:  
2025-07-12 02:36:45.493138: Epoch 524 
2025-07-12 02:36:45.494269: Current learning rate: 0.00513 
2025-07-12 02:37:53.898812: train_loss -0.9755 
2025-07-12 02:37:53.900084: val_loss -0.9484 
2025-07-12 02:37:53.901272: Pseudo dice [np.float32(0.9527)] 
2025-07-12 02:37:53.902277: Epoch time: 68.41 s 
2025-07-12 02:37:54.791108:  
2025-07-12 02:37:54.792876: Epoch 525 
2025-07-12 02:37:54.794036: Current learning rate: 0.00512 
2025-07-12 02:39:02.467475: train_loss -0.9753 
2025-07-12 02:39:02.468870: val_loss -0.9459 
2025-07-12 02:39:02.469951: Pseudo dice [np.float32(0.9503)] 
2025-07-12 02:39:02.471359: Epoch time: 67.68 s 
2025-07-12 02:39:03.365842:  
2025-07-12 02:39:03.367527: Epoch 526 
2025-07-12 02:39:03.368604: Current learning rate: 0.00511 
2025-07-12 02:40:11.086737: train_loss -0.9757 
2025-07-12 02:40:11.088516: val_loss -0.9503 
2025-07-12 02:40:11.089588: Pseudo dice [np.float32(0.9541)] 
2025-07-12 02:40:11.090961: Epoch time: 67.72 s 
2025-07-12 02:40:11.986177:  
2025-07-12 02:40:11.987818: Epoch 527 
2025-07-12 02:40:11.988986: Current learning rate: 0.0051 
2025-07-12 02:41:19.630253: train_loss -0.9763 
2025-07-12 02:41:19.631404: val_loss -0.9465 
2025-07-12 02:41:19.632487: Pseudo dice [np.float32(0.9499)] 
2025-07-12 02:41:19.633587: Epoch time: 67.65 s 
2025-07-12 02:41:20.526902:  
2025-07-12 02:41:20.528726: Epoch 528 
2025-07-12 02:41:20.529919: Current learning rate: 0.00509 
2025-07-12 02:42:28.185859: train_loss -0.9765 
2025-07-12 02:42:28.187299: val_loss -0.9487 
2025-07-12 02:42:28.188401: Pseudo dice [np.float32(0.9524)] 
2025-07-12 02:42:28.189582: Epoch time: 67.66 s 
2025-07-12 02:42:29.128151:  
2025-07-12 02:42:29.129534: Epoch 529 
2025-07-12 02:42:29.130579: Current learning rate: 0.00508 
2025-07-12 02:43:37.128015: train_loss -0.9763 
2025-07-12 02:43:37.129514: val_loss -0.9519 
2025-07-12 02:43:37.130434: Pseudo dice [np.float32(0.9556)] 
2025-07-12 02:43:37.131589: Epoch time: 68.0 s 
2025-07-12 02:43:38.029654:  
2025-07-12 02:43:38.031232: Epoch 530 
2025-07-12 02:43:38.032392: Current learning rate: 0.00507 
2025-07-12 02:44:46.059793: train_loss -0.9758 
2025-07-12 02:44:46.061191: val_loss -0.9489 
2025-07-12 02:44:46.062380: Pseudo dice [np.float32(0.9524)] 
2025-07-12 02:44:46.063496: Epoch time: 68.03 s 
2025-07-12 02:44:46.959728:  
2025-07-12 02:44:46.961352: Epoch 531 
2025-07-12 02:44:46.962556: Current learning rate: 0.00506 
2025-07-12 02:45:54.823949: train_loss -0.9758 
2025-07-12 02:45:54.825308: val_loss -0.9444 
2025-07-12 02:45:54.826330: Pseudo dice [np.float32(0.9492)] 
2025-07-12 02:45:54.827625: Epoch time: 67.87 s 
2025-07-12 02:45:55.725226:  
2025-07-12 02:45:55.726990: Epoch 532 
2025-07-12 02:45:55.728060: Current learning rate: 0.00505 
2025-07-12 02:47:03.178900: train_loss -0.9753 
2025-07-12 02:47:03.180278: val_loss -0.9479 
2025-07-12 02:47:03.181486: Pseudo dice [np.float32(0.9526)] 
2025-07-12 02:47:03.182710: Epoch time: 67.46 s 
2025-07-12 02:47:04.069089:  
2025-07-12 02:47:04.070779: Epoch 533 
2025-07-12 02:47:04.071873: Current learning rate: 0.00504 
2025-07-12 02:48:12.654163: train_loss -0.9759 
2025-07-12 02:48:12.655357: val_loss -0.9497 
2025-07-12 02:48:12.656437: Pseudo dice [np.float32(0.9531)] 
2025-07-12 02:48:12.657534: Epoch time: 68.59 s 
2025-07-12 02:48:13.546041:  
2025-07-12 02:48:13.547690: Epoch 534 
2025-07-12 02:48:13.548827: Current learning rate: 0.00503 
2025-07-12 02:49:21.414390: train_loss -0.9762 
2025-07-12 02:49:21.415841: val_loss -0.9454 
2025-07-12 02:49:21.417020: Pseudo dice [np.float32(0.9492)] 
2025-07-12 02:49:21.417900: Epoch time: 67.87 s 
2025-07-12 02:49:22.315565:  
2025-07-12 02:49:22.317093: Epoch 535 
2025-07-12 02:49:22.318168: Current learning rate: 0.00502 
2025-07-12 02:50:30.007011: train_loss -0.9752 
2025-07-12 02:50:30.008326: val_loss -0.9467 
2025-07-12 02:50:30.009357: Pseudo dice [np.float32(0.9507)] 
2025-07-12 02:50:30.010425: Epoch time: 67.69 s 
2025-07-12 02:50:30.902386:  
2025-07-12 02:50:30.904135: Epoch 536 
2025-07-12 02:50:30.905390: Current learning rate: 0.00501 
2025-07-12 02:51:38.400362: train_loss -0.9756 
2025-07-12 02:51:38.401609: val_loss -0.9461 
2025-07-12 02:51:38.402775: Pseudo dice [np.float32(0.9499)] 
2025-07-12 02:51:38.404040: Epoch time: 67.5 s 
2025-07-12 02:51:39.305686:  
2025-07-12 02:51:39.307256: Epoch 537 
2025-07-12 02:51:39.308440: Current learning rate: 0.005 
2025-07-12 02:52:46.902447: train_loss -0.9756 
2025-07-12 02:52:46.904035: val_loss -0.9463 
2025-07-12 02:52:46.905272: Pseudo dice [np.float32(0.9503)] 
2025-07-12 02:52:46.906429: Epoch time: 67.6 s 
2025-07-12 02:52:47.802035:  
2025-07-12 02:52:47.803761: Epoch 538 
2025-07-12 02:52:47.804954: Current learning rate: 0.00499 
2025-07-12 02:53:55.186440: train_loss -0.9755 
2025-07-12 02:53:55.187913: val_loss -0.9443 
2025-07-12 02:53:55.189168: Pseudo dice [np.float32(0.9482)] 
2025-07-12 02:53:55.190246: Epoch time: 67.39 s 
2025-07-12 02:53:56.077471:  
2025-07-12 02:53:56.078854: Epoch 539 
2025-07-12 02:53:56.080116: Current learning rate: 0.00498 
2025-07-12 02:55:03.834556: train_loss -0.9756 
2025-07-12 02:55:03.835882: val_loss -0.9486 
2025-07-12 02:55:03.836967: Pseudo dice [np.float32(0.9523)] 
2025-07-12 02:55:03.838749: Epoch time: 67.76 s 
2025-07-12 02:55:04.733372:  
2025-07-12 02:55:04.734924: Epoch 540 
2025-07-12 02:55:04.736106: Current learning rate: 0.00497 
2025-07-12 02:56:12.277337: train_loss -0.9743 
2025-07-12 02:56:12.278799: val_loss -0.9482 
2025-07-12 02:56:12.279797: Pseudo dice [np.float32(0.9522)] 
2025-07-12 02:56:12.280895: Epoch time: 67.55 s 
2025-07-12 02:56:13.176339:  
2025-07-12 02:56:13.178113: Epoch 541 
2025-07-12 02:56:13.179301: Current learning rate: 0.00496 
2025-07-12 02:57:20.819738: train_loss -0.9749 
2025-07-12 02:57:20.821026: val_loss -0.9477 
2025-07-12 02:57:20.822240: Pseudo dice [np.float32(0.9508)] 
2025-07-12 02:57:20.823258: Epoch time: 67.65 s 
2025-07-12 02:57:21.726463:  
2025-07-12 02:57:21.728311: Epoch 542 
2025-07-12 02:57:21.729470: Current learning rate: 0.00495 
2025-07-12 02:58:29.372218: train_loss -0.9758 
2025-07-12 02:58:29.373526: val_loss -0.9487 
2025-07-12 02:58:29.374444: Pseudo dice [np.float32(0.9521)] 
2025-07-12 02:58:29.375728: Epoch time: 67.65 s 
2025-07-12 02:58:31.047937:  
2025-07-12 02:58:31.049818: Epoch 543 
2025-07-12 02:58:31.050955: Current learning rate: 0.00494 
2025-07-12 02:59:38.557299: train_loss -0.9754 
2025-07-12 02:59:38.558552: val_loss -0.947 
2025-07-12 02:59:38.559672: Pseudo dice [np.float32(0.9509)] 
2025-07-12 02:59:38.560729: Epoch time: 67.51 s 
2025-07-12 02:59:39.459202:  
2025-07-12 02:59:39.460965: Epoch 544 
2025-07-12 02:59:39.462204: Current learning rate: 0.00493 
2025-07-12 03:00:47.172110: train_loss -0.976 
2025-07-12 03:00:47.173396: val_loss -0.9445 
2025-07-12 03:00:47.174620: Pseudo dice [np.float32(0.9487)] 
2025-07-12 03:00:47.175771: Epoch time: 67.72 s 
2025-07-12 03:00:48.069126:  
2025-07-12 03:00:48.070764: Epoch 545 
2025-07-12 03:00:48.072050: Current learning rate: 0.00492 
2025-07-12 03:01:56.042467: train_loss -0.976 
2025-07-12 03:01:56.043969: val_loss -0.9476 
2025-07-12 03:01:56.045239: Pseudo dice [np.float32(0.9521)] 
2025-07-12 03:01:56.046331: Epoch time: 67.98 s 
2025-07-12 03:01:56.921008:  
2025-07-12 03:01:56.922548: Epoch 546 
2025-07-12 03:01:56.923712: Current learning rate: 0.00491 
2025-07-12 03:03:04.949507: train_loss -0.9752 
2025-07-12 03:03:04.950905: val_loss -0.9448 
2025-07-12 03:03:04.952098: Pseudo dice [np.float32(0.9483)] 
2025-07-12 03:03:04.953096: Epoch time: 68.03 s 
2025-07-12 03:03:05.840274:  
2025-07-12 03:03:05.841612: Epoch 547 
2025-07-12 03:03:05.842958: Current learning rate: 0.0049 
2025-07-12 03:04:14.061800: train_loss -0.9771 
2025-07-12 03:04:14.063053: val_loss -0.9478 
2025-07-12 03:04:14.064155: Pseudo dice [np.float32(0.9517)] 
2025-07-12 03:04:14.065100: Epoch time: 68.23 s 
2025-07-12 03:04:14.961901:  
2025-07-12 03:04:14.963525: Epoch 548 
2025-07-12 03:04:14.964791: Current learning rate: 0.00489 
2025-07-12 03:05:22.985393: train_loss -0.9762 
2025-07-12 03:05:22.986816: val_loss -0.9523 
2025-07-12 03:05:22.988065: Pseudo dice [np.float32(0.9556)] 
2025-07-12 03:05:22.989216: Epoch time: 68.03 s 
2025-07-12 03:05:23.866405:  
2025-07-12 03:05:23.867989: Epoch 549 
2025-07-12 03:05:23.869128: Current learning rate: 0.00488 
2025-07-12 03:06:31.759165: train_loss -0.9756 
2025-07-12 03:06:31.760444: val_loss -0.9485 
2025-07-12 03:06:31.761569: Pseudo dice [np.float32(0.9518)] 
2025-07-12 03:06:31.762781: Epoch time: 67.9 s 
2025-07-12 03:06:34.106355:  
2025-07-12 03:06:34.108009: Epoch 550 
2025-07-12 03:06:34.109151: Current learning rate: 0.00487 
2025-07-12 03:07:41.886264: train_loss -0.977 
2025-07-12 03:07:41.887570: val_loss -0.9484 
2025-07-12 03:07:41.888723: Pseudo dice [np.float32(0.9509)] 
2025-07-12 03:07:41.889970: Epoch time: 67.78 s 
2025-07-12 03:07:42.783375:  
2025-07-12 03:07:42.785034: Epoch 551 
2025-07-12 03:07:42.786176: Current learning rate: 0.00486 
2025-07-12 03:08:51.157994: train_loss -0.9768 
2025-07-12 03:08:51.159293: val_loss -0.9477 
2025-07-12 03:08:51.160578: Pseudo dice [np.float32(0.9512)] 
2025-07-12 03:08:51.161724: Epoch time: 68.38 s 
2025-07-12 03:08:52.054833:  
2025-07-12 03:08:52.056539: Epoch 552 
2025-07-12 03:08:52.057687: Current learning rate: 0.00485 
2025-07-12 03:09:59.405985: train_loss -0.9765 
2025-07-12 03:09:59.407385: val_loss -0.9465 
2025-07-12 03:09:59.408527: Pseudo dice [np.float32(0.9508)] 
2025-07-12 03:09:59.409745: Epoch time: 67.35 s 
2025-07-12 03:10:00.310614:  
2025-07-12 03:10:00.312413: Epoch 553 
2025-07-12 03:10:00.313586: Current learning rate: 0.00484 
2025-07-12 03:11:07.929249: train_loss -0.9766 
2025-07-12 03:11:07.930600: val_loss -0.9495 
2025-07-12 03:11:07.931623: Pseudo dice [np.float32(0.9535)] 
2025-07-12 03:11:07.932815: Epoch time: 67.62 s 
2025-07-12 03:11:08.837542:  
2025-07-12 03:11:08.839311: Epoch 554 
2025-07-12 03:11:08.840432: Current learning rate: 0.00484 
2025-07-12 03:12:16.300305: train_loss -0.977 
2025-07-12 03:12:16.301705: val_loss -0.9488 
2025-07-12 03:12:16.302835: Pseudo dice [np.float32(0.9522)] 
2025-07-12 03:12:16.304012: Epoch time: 67.47 s 
2025-07-12 03:12:17.192095:  
2025-07-12 03:12:17.193899: Epoch 555 
2025-07-12 03:12:17.195150: Current learning rate: 0.00483 
2025-07-12 03:13:24.744479: train_loss -0.9766 
2025-07-12 03:13:24.745740: val_loss -0.9459 
2025-07-12 03:13:24.746779: Pseudo dice [np.float32(0.9496)] 
2025-07-12 03:13:24.747957: Epoch time: 67.56 s 
2025-07-12 03:13:25.643662:  
2025-07-12 03:13:25.645414: Epoch 556 
2025-07-12 03:13:25.646609: Current learning rate: 0.00482 
2025-07-12 03:14:33.223716: train_loss -0.9716 
2025-07-12 03:14:33.225128: val_loss -0.9462 
2025-07-12 03:14:33.226382: Pseudo dice [np.float32(0.9509)] 
2025-07-12 03:14:33.227437: Epoch time: 67.58 s 
2025-07-12 03:14:34.119568:  
2025-07-12 03:14:34.120983: Epoch 557 
2025-07-12 03:14:34.122266: Current learning rate: 0.00481 
2025-07-12 03:15:41.833853: train_loss -0.9746 
2025-07-12 03:15:41.835263: val_loss -0.9486 
2025-07-12 03:15:41.836455: Pseudo dice [np.float32(0.9529)] 
2025-07-12 03:15:41.837562: Epoch time: 67.72 s 
2025-07-12 03:15:42.726003:  
2025-07-12 03:15:42.727725: Epoch 558 
2025-07-12 03:15:42.728815: Current learning rate: 0.0048 
2025-07-12 03:16:50.802797: train_loss -0.9767 
2025-07-12 03:16:50.804082: val_loss -0.9524 
2025-07-12 03:16:50.805256: Pseudo dice [np.float32(0.9552)] 
2025-07-12 03:16:50.806279: Epoch time: 68.08 s 
2025-07-12 03:16:51.694681:  
2025-07-12 03:16:51.696226: Epoch 559 
2025-07-12 03:16:51.697811: Current learning rate: 0.00479 
2025-07-12 03:17:59.787087: train_loss -0.9755 
2025-07-12 03:17:59.788276: val_loss -0.9468 
2025-07-12 03:17:59.789550: Pseudo dice [np.float32(0.9503)] 
2025-07-12 03:17:59.790710: Epoch time: 68.1 s 
2025-07-12 03:18:00.678221:  
2025-07-12 03:18:00.679677: Epoch 560 
2025-07-12 03:18:00.680859: Current learning rate: 0.00478 
2025-07-12 03:19:09.312468: train_loss -0.9745 
2025-07-12 03:19:09.313764: val_loss -0.9471 
2025-07-12 03:19:09.314987: Pseudo dice [np.float32(0.9506)] 
2025-07-12 03:19:09.315892: Epoch time: 68.64 s 
2025-07-12 03:19:10.205101:  
2025-07-12 03:19:10.206580: Epoch 561 
2025-07-12 03:19:10.207702: Current learning rate: 0.00477 
2025-07-12 03:20:18.029103: train_loss -0.9752 
2025-07-12 03:20:18.030714: val_loss -0.9477 
2025-07-12 03:20:18.031854: Pseudo dice [np.float32(0.9518)] 
2025-07-12 03:20:18.032936: Epoch time: 67.83 s 
2025-07-12 03:20:18.921103:  
2025-07-12 03:20:18.922832: Epoch 562 
2025-07-12 03:20:18.924018: Current learning rate: 0.00476 
2025-07-12 03:21:26.928895: train_loss -0.9748 
2025-07-12 03:21:26.930199: val_loss -0.9492 
2025-07-12 03:21:26.931262: Pseudo dice [np.float32(0.953)] 
2025-07-12 03:21:26.932506: Epoch time: 68.01 s 
2025-07-12 03:21:27.811703:  
2025-07-12 03:21:27.813065: Epoch 563 
2025-07-12 03:21:27.814223: Current learning rate: 0.00475 
2025-07-12 03:22:35.656964: train_loss -0.9751 
2025-07-12 03:22:35.658307: val_loss -0.9494 
2025-07-12 03:22:35.659427: Pseudo dice [np.float32(0.953)] 
2025-07-12 03:22:35.660616: Epoch time: 67.85 s 
2025-07-12 03:22:36.560723:  
2025-07-12 03:22:36.562260: Epoch 564 
2025-07-12 03:22:36.563428: Current learning rate: 0.00474 
2025-07-12 03:23:44.224848: train_loss -0.9768 
2025-07-12 03:23:44.226200: val_loss -0.9496 
2025-07-12 03:23:44.227241: Pseudo dice [np.float32(0.9533)] 
2025-07-12 03:23:44.228464: Epoch time: 67.67 s 
2025-07-12 03:23:45.123432:  
2025-07-12 03:23:45.125283: Epoch 565 
2025-07-12 03:23:45.126782: Current learning rate: 0.00473 
2025-07-12 03:24:52.949118: train_loss -0.976 
2025-07-12 03:24:52.950623: val_loss -0.9463 
2025-07-12 03:24:52.951860: Pseudo dice [np.float32(0.9505)] 
2025-07-12 03:24:52.953017: Epoch time: 67.83 s 
2025-07-12 03:24:53.872322:  
2025-07-12 03:24:53.873945: Epoch 566 
2025-07-12 03:24:53.875251: Current learning rate: 0.00472 
2025-07-12 03:26:01.469658: train_loss -0.9758 
2025-07-12 03:26:01.471190: val_loss -0.9526 
2025-07-12 03:26:01.472192: Pseudo dice [np.float32(0.956)] 
2025-07-12 03:26:01.473250: Epoch time: 67.6 s 
2025-07-12 03:26:02.361690:  
2025-07-12 03:26:02.363925: Epoch 567 
2025-07-12 03:26:02.365097: Current learning rate: 0.00471 
2025-07-12 03:27:09.952563: train_loss -0.9747 
2025-07-12 03:27:09.954064: val_loss -0.9473 
2025-07-12 03:27:09.955699: Pseudo dice [np.float32(0.9513)] 
2025-07-12 03:27:09.957038: Epoch time: 67.59 s 
2025-07-12 03:27:10.850808:  
2025-07-12 03:27:10.852232: Epoch 568 
2025-07-12 03:27:10.853417: Current learning rate: 0.0047 
2025-07-12 03:28:18.444117: train_loss -0.9754 
2025-07-12 03:28:18.445455: val_loss -0.9496 
2025-07-12 03:28:18.446546: Pseudo dice [np.float32(0.9536)] 
2025-07-12 03:28:18.447712: Epoch time: 67.6 s 
2025-07-12 03:28:19.347055:  
2025-07-12 03:28:19.348727: Epoch 569 
2025-07-12 03:28:19.349846: Current learning rate: 0.00469 
2025-07-12 03:29:27.491445: train_loss -0.977 
2025-07-12 03:29:27.493983: val_loss -0.9474 
2025-07-12 03:29:27.495236: Pseudo dice [np.float32(0.9519)] 
2025-07-12 03:29:27.496331: Epoch time: 68.15 s 
2025-07-12 03:29:28.390021:  
2025-07-12 03:29:28.391850: Epoch 570 
2025-07-12 03:29:28.393064: Current learning rate: 0.00468 
2025-07-12 03:30:35.862854: train_loss -0.9758 
2025-07-12 03:30:35.864236: val_loss -0.9464 
2025-07-12 03:30:35.865274: Pseudo dice [np.float32(0.95)] 
2025-07-12 03:30:35.866309: Epoch time: 67.48 s 
2025-07-12 03:30:36.755682:  
2025-07-12 03:30:36.758381: Epoch 571 
2025-07-12 03:30:36.759687: Current learning rate: 0.00467 
2025-07-12 03:31:44.697934: train_loss -0.9756 
2025-07-12 03:31:44.699086: val_loss -0.9496 
2025-07-12 03:31:44.700361: Pseudo dice [np.float32(0.9535)] 
2025-07-12 03:31:44.701404: Epoch time: 67.95 s 
2025-07-12 03:31:45.595138:  
2025-07-12 03:31:45.596532: Epoch 572 
2025-07-12 03:31:45.597714: Current learning rate: 0.00466 
2025-07-12 03:32:53.474021: train_loss -0.9774 
2025-07-12 03:32:53.475235: val_loss -0.9473 
2025-07-12 03:32:53.476364: Pseudo dice [np.float32(0.9509)] 
2025-07-12 03:32:53.477612: Epoch time: 67.88 s 
2025-07-12 03:32:54.385577:  
2025-07-12 03:32:54.387064: Epoch 573 
2025-07-12 03:32:54.388260: Current learning rate: 0.00465 
2025-07-12 03:34:02.362862: train_loss -0.9772 
2025-07-12 03:34:02.364161: val_loss -0.9481 
2025-07-12 03:34:02.365233: Pseudo dice [np.float32(0.9527)] 
2025-07-12 03:34:02.366725: Epoch time: 67.98 s 
2025-07-12 03:34:03.275741:  
2025-07-12 03:34:03.277278: Epoch 574 
2025-07-12 03:34:03.278674: Current learning rate: 0.00464 
2025-07-12 03:35:11.385648: train_loss -0.9762 
2025-07-12 03:35:11.387166: val_loss -0.9498 
2025-07-12 03:35:11.388211: Pseudo dice [np.float32(0.9541)] 
2025-07-12 03:35:11.389395: Epoch time: 68.11 s 
2025-07-12 03:35:12.289064:  
2025-07-12 03:35:12.290714: Epoch 575 
2025-07-12 03:35:12.291797: Current learning rate: 0.00463 
2025-07-12 03:36:20.210106: train_loss -0.9758 
2025-07-12 03:36:20.211443: val_loss -0.9495 
2025-07-12 03:36:20.212695: Pseudo dice [np.float32(0.9544)] 
2025-07-12 03:36:20.213905: Epoch time: 67.92 s 
2025-07-12 03:36:21.114427:  
2025-07-12 03:36:21.116009: Epoch 576 
2025-07-12 03:36:21.117280: Current learning rate: 0.00462 
2025-07-12 03:37:28.779468: train_loss -0.976 
2025-07-12 03:37:28.780747: val_loss -0.9528 
2025-07-12 03:37:28.781852: Pseudo dice [np.float32(0.9561)] 
2025-07-12 03:37:28.782836: Epoch time: 67.67 s 
2025-07-12 03:37:28.783962: Yayy! New best EMA pseudo Dice: 0.9528999924659729 
2025-07-12 03:37:30.762212:  
2025-07-12 03:37:30.763953: Epoch 577 
2025-07-12 03:37:30.765052: Current learning rate: 0.00461 
2025-07-12 03:38:38.342897: train_loss -0.9764 
2025-07-12 03:38:38.344209: val_loss -0.9486 
2025-07-12 03:38:38.345262: Pseudo dice [np.float32(0.9526)] 
2025-07-12 03:38:38.346479: Epoch time: 67.58 s 
2025-07-12 03:38:39.245241:  
2025-07-12 03:38:39.246841: Epoch 578 
2025-07-12 03:38:39.247925: Current learning rate: 0.0046 
2025-07-12 03:39:47.419724: train_loss -0.976 
2025-07-12 03:39:47.421133: val_loss -0.9481 
2025-07-12 03:39:47.422446: Pseudo dice [np.float32(0.9515)] 
2025-07-12 03:39:47.423416: Epoch time: 68.18 s 
2025-07-12 03:39:48.321183:  
2025-07-12 03:39:48.322845: Epoch 579 
2025-07-12 03:39:48.323895: Current learning rate: 0.00459 
2025-07-12 03:40:55.989025: train_loss -0.9763 
2025-07-12 03:40:55.990420: val_loss -0.9524 
2025-07-12 03:40:55.991724: Pseudo dice [np.float32(0.956)] 
2025-07-12 03:40:55.992878: Epoch time: 67.67 s 
2025-07-12 03:40:55.993826: Yayy! New best EMA pseudo Dice: 0.9531000256538391 
2025-07-12 03:40:58.225107:  
2025-07-12 03:40:58.226837: Epoch 580 
2025-07-12 03:40:58.227993: Current learning rate: 0.00458 
2025-07-12 03:42:05.748533: train_loss -0.9764 
2025-07-12 03:42:05.750026: val_loss -0.951 
2025-07-12 03:42:05.751356: Pseudo dice [np.float32(0.9557)] 
2025-07-12 03:42:05.752416: Epoch time: 67.53 s 
2025-07-12 03:42:05.753525: Yayy! New best EMA pseudo Dice: 0.9532999992370605 
2025-07-12 03:42:08.084249:  
2025-07-12 03:42:08.085787: Epoch 581 
2025-07-12 03:42:08.086900: Current learning rate: 0.00457 
2025-07-12 03:43:15.839494: train_loss -0.9772 
2025-07-12 03:43:15.840804: val_loss -0.9437 
2025-07-12 03:43:15.841843: Pseudo dice [np.float32(0.9481)] 
2025-07-12 03:43:15.843074: Epoch time: 67.76 s 
2025-07-12 03:43:16.743627:  
2025-07-12 03:43:16.745343: Epoch 582 
2025-07-12 03:43:16.746575: Current learning rate: 0.00456 
2025-07-12 03:44:24.641291: train_loss -0.9779 
2025-07-12 03:44:24.642790: val_loss -0.9514 
2025-07-12 03:44:24.643816: Pseudo dice [np.float32(0.9552)] 
2025-07-12 03:44:24.644995: Epoch time: 67.9 s 
2025-07-12 03:44:25.543114:  
2025-07-12 03:44:25.545019: Epoch 583 
2025-07-12 03:44:25.546151: Current learning rate: 0.00455 
2025-07-12 03:45:33.564103: train_loss -0.9769 
2025-07-12 03:45:33.565717: val_loss -0.9447 
2025-07-12 03:45:33.566931: Pseudo dice [np.float32(0.9494)] 
2025-07-12 03:45:33.568146: Epoch time: 68.02 s 
2025-07-12 03:45:34.461323:  
2025-07-12 03:45:34.463028: Epoch 584 
2025-07-12 03:45:34.464166: Current learning rate: 0.00454 
2025-07-12 03:46:42.280070: train_loss -0.9769 
2025-07-12 03:46:42.281508: val_loss -0.9479 
2025-07-12 03:46:42.282590: Pseudo dice [np.float32(0.9516)] 
2025-07-12 03:46:42.283568: Epoch time: 67.82 s 
2025-07-12 03:46:43.180134:  
2025-07-12 03:46:43.181697: Epoch 585 
2025-07-12 03:46:43.182824: Current learning rate: 0.00453 
2025-07-12 03:47:51.006852: train_loss -0.9781 
2025-07-12 03:47:51.008340: val_loss -0.9511 
2025-07-12 03:47:51.009498: Pseudo dice [np.float32(0.9548)] 
2025-07-12 03:47:51.010742: Epoch time: 67.83 s 
2025-07-12 03:47:51.902308:  
2025-07-12 03:47:51.903903: Epoch 586 
2025-07-12 03:47:51.905400: Current learning rate: 0.00452 
2025-07-12 03:48:59.622442: train_loss -0.976 
2025-07-12 03:48:59.623598: val_loss -0.9487 
2025-07-12 03:48:59.624868: Pseudo dice [np.float32(0.9524)] 
2025-07-12 03:48:59.626093: Epoch time: 67.72 s 
2025-07-12 03:49:00.577596:  
2025-07-12 03:49:00.579219: Epoch 587 
2025-07-12 03:49:00.580344: Current learning rate: 0.00451 
2025-07-12 03:50:09.154647: train_loss -0.9774 
2025-07-12 03:50:09.155882: val_loss -0.9497 
2025-07-12 03:50:09.157305: Pseudo dice [np.float32(0.9532)] 
2025-07-12 03:50:09.158346: Epoch time: 68.58 s 
2025-07-12 03:50:10.050958:  
2025-07-12 03:50:10.052518: Epoch 588 
2025-07-12 03:50:10.053664: Current learning rate: 0.0045 
2025-07-12 03:51:18.029859: train_loss -0.9782 
2025-07-12 03:51:18.031206: val_loss -0.9453 
2025-07-12 03:51:18.032384: Pseudo dice [np.float32(0.9488)] 
2025-07-12 03:51:18.033562: Epoch time: 67.98 s 
2025-07-12 03:51:18.937825:  
2025-07-12 03:51:18.939727: Epoch 589 
2025-07-12 03:51:18.941033: Current learning rate: 0.00449 
2025-07-12 03:52:26.847507: train_loss -0.978 
2025-07-12 03:52:26.849267: val_loss -0.953 
2025-07-12 03:52:26.850437: Pseudo dice [np.float32(0.9567)] 
2025-07-12 03:52:26.851606: Epoch time: 67.91 s 
2025-07-12 03:52:27.755414:  
2025-07-12 03:52:27.756798: Epoch 590 
2025-07-12 03:52:27.757924: Current learning rate: 0.00448 
2025-07-12 03:53:35.403494: train_loss -0.9786 
2025-07-12 03:53:35.404847: val_loss -0.9504 
2025-07-12 03:53:35.405818: Pseudo dice [np.float32(0.954)] 
2025-07-12 03:53:35.407108: Epoch time: 67.65 s 
2025-07-12 03:53:36.311126:  
2025-07-12 03:53:36.312855: Epoch 591 
2025-07-12 03:53:36.313987: Current learning rate: 0.00447 
2025-07-12 03:54:44.001808: train_loss -0.9776 
2025-07-12 03:54:44.003069: val_loss -0.9527 
2025-07-12 03:54:44.004158: Pseudo dice [np.float32(0.9559)] 
2025-07-12 03:54:44.005197: Epoch time: 67.69 s 
2025-07-12 03:54:44.905625:  
2025-07-12 03:54:44.907330: Epoch 592 
2025-07-12 03:54:44.908520: Current learning rate: 0.00446 
2025-07-12 03:55:52.450607: train_loss -0.9777 
2025-07-12 03:55:52.451994: val_loss -0.9477 
2025-07-12 03:55:52.452963: Pseudo dice [np.float32(0.952)] 
2025-07-12 03:55:52.454138: Epoch time: 67.55 s 
2025-07-12 03:55:53.354240:  
2025-07-12 03:55:53.355861: Epoch 593 
2025-07-12 03:55:53.356986: Current learning rate: 0.00445 
2025-07-12 03:57:01.025405: train_loss -0.9766 
2025-07-12 03:57:01.026778: val_loss -0.9505 
2025-07-12 03:57:01.027918: Pseudo dice [np.float32(0.9529)] 
2025-07-12 03:57:01.029094: Epoch time: 67.67 s 
2025-07-12 03:57:01.920978:  
2025-07-12 03:57:01.922727: Epoch 594 
2025-07-12 03:57:01.923816: Current learning rate: 0.00444 
2025-07-12 03:58:09.675405: train_loss -0.9767 
2025-07-12 03:58:09.676829: val_loss -0.948 
2025-07-12 03:58:09.677979: Pseudo dice [np.float32(0.9515)] 
2025-07-12 03:58:09.679023: Epoch time: 67.76 s 
2025-07-12 03:58:10.575298:  
2025-07-12 03:58:10.576942: Epoch 595 
2025-07-12 03:58:10.578038: Current learning rate: 0.00443 
2025-07-12 03:59:18.241689: train_loss -0.9768 
2025-07-12 03:59:18.242981: val_loss -0.948 
2025-07-12 03:59:18.244111: Pseudo dice [np.float32(0.9519)] 
2025-07-12 03:59:18.245303: Epoch time: 67.67 s 
2025-07-12 03:59:19.146615:  
2025-07-12 03:59:19.148203: Epoch 596 
2025-07-12 03:59:19.149497: Current learning rate: 0.00442 
2025-07-12 04:00:27.567913: train_loss -0.9758 
2025-07-12 04:00:27.569242: val_loss -0.9485 
2025-07-12 04:00:27.570465: Pseudo dice [np.float32(0.9525)] 
2025-07-12 04:00:27.571611: Epoch time: 68.42 s 
2025-07-12 04:00:28.476612:  
2025-07-12 04:00:28.478132: Epoch 597 
2025-07-12 04:00:28.479280: Current learning rate: 0.00441 
2025-07-12 04:01:36.171797: train_loss -0.9757 
2025-07-12 04:01:36.173071: val_loss -0.9466 
2025-07-12 04:01:36.174085: Pseudo dice [np.float32(0.9496)] 
2025-07-12 04:01:36.175384: Epoch time: 67.7 s 
2025-07-12 04:01:37.075282:  
2025-07-12 04:01:37.076975: Epoch 598 
2025-07-12 04:01:37.078184: Current learning rate: 0.0044 
2025-07-12 04:02:44.729925: train_loss -0.9767 
2025-07-12 04:02:44.731147: val_loss -0.9506 
2025-07-12 04:02:44.732378: Pseudo dice [np.float32(0.955)] 
2025-07-12 04:02:44.733595: Epoch time: 67.66 s 
2025-07-12 04:02:45.644091:  
2025-07-12 04:02:45.645551: Epoch 599 
2025-07-12 04:02:45.646650: Current learning rate: 0.00439 
2025-07-12 04:03:53.430135: train_loss -0.9759 
2025-07-12 04:03:53.431541: val_loss -0.9478 
2025-07-12 04:03:53.432731: Pseudo dice [np.float32(0.9517)] 
2025-07-12 04:03:53.433969: Epoch time: 67.79 s 
2025-07-12 04:03:55.646664:  
2025-07-12 04:03:55.648289: Epoch 600 
2025-07-12 04:03:55.649480: Current learning rate: 0.00438 
2025-07-12 04:05:03.370445: train_loss -0.9761 
2025-07-12 04:05:03.371742: val_loss -0.9489 
2025-07-12 04:05:03.373025: Pseudo dice [np.float32(0.9528)] 
2025-07-12 04:05:03.374298: Epoch time: 67.73 s 
2025-07-12 04:05:04.272199:  
2025-07-12 04:05:04.274213: Epoch 601 
2025-07-12 04:05:04.275546: Current learning rate: 0.00437 
2025-07-12 04:06:12.078277: train_loss -0.9766 
2025-07-12 04:06:12.079766: val_loss -0.9474 
2025-07-12 04:06:12.080881: Pseudo dice [np.float32(0.9513)] 
2025-07-12 04:06:12.082304: Epoch time: 67.81 s 
2025-07-12 04:06:12.994668:  
2025-07-12 04:06:12.996295: Epoch 602 
2025-07-12 04:06:12.997467: Current learning rate: 0.00436 
2025-07-12 04:07:20.735862: train_loss -0.9771 
2025-07-12 04:07:20.737318: val_loss -0.9481 
2025-07-12 04:07:20.738422: Pseudo dice [np.float32(0.9522)] 
2025-07-12 04:07:20.739544: Epoch time: 67.74 s 
2025-07-12 04:07:21.639576:  
2025-07-12 04:07:21.641110: Epoch 603 
2025-07-12 04:07:21.642713: Current learning rate: 0.00435 
2025-07-12 04:08:29.635294: train_loss -0.9748 
2025-07-12 04:08:29.636601: val_loss -0.9509 
2025-07-12 04:08:29.637625: Pseudo dice [np.float32(0.9546)] 
2025-07-12 04:08:29.638927: Epoch time: 68.0 s 
2025-07-12 04:08:30.540014:  
2025-07-12 04:08:30.541889: Epoch 604 
2025-07-12 04:08:30.543074: Current learning rate: 0.00434 
2025-07-12 04:09:38.504106: train_loss -0.9766 
2025-07-12 04:09:38.505421: val_loss -0.9477 
2025-07-12 04:09:38.506490: Pseudo dice [np.float32(0.9519)] 
2025-07-12 04:09:38.507654: Epoch time: 67.97 s 
2025-07-12 04:09:39.406003:  
2025-07-12 04:09:39.407609: Epoch 605 
2025-07-12 04:09:39.408707: Current learning rate: 0.00433 
2025-07-12 04:10:47.960118: train_loss -0.9761 
2025-07-12 04:10:47.961503: val_loss -0.9438 
2025-07-12 04:10:47.962615: Pseudo dice [np.float32(0.9489)] 
2025-07-12 04:10:47.963666: Epoch time: 68.56 s 
2025-07-12 04:10:48.857790:  
2025-07-12 04:10:48.859437: Epoch 606 
2025-07-12 04:10:48.860673: Current learning rate: 0.00432 
2025-07-12 04:11:56.709100: train_loss -0.9768 
2025-07-12 04:11:56.710307: val_loss -0.9505 
2025-07-12 04:11:56.711229: Pseudo dice [np.float32(0.9539)] 
2025-07-12 04:11:56.712315: Epoch time: 67.85 s 
2025-07-12 04:11:57.621328:  
2025-07-12 04:11:57.622946: Epoch 607 
2025-07-12 04:11:57.624031: Current learning rate: 0.00431 
2025-07-12 04:13:05.724378: train_loss -0.9751 
2025-07-12 04:13:05.725645: val_loss -0.9461 
2025-07-12 04:13:05.726823: Pseudo dice [np.float32(0.9499)] 
2025-07-12 04:13:05.727870: Epoch time: 68.11 s 
2025-07-12 04:13:06.624693:  
2025-07-12 04:13:06.626516: Epoch 608 
2025-07-12 04:13:06.627771: Current learning rate: 0.0043 
2025-07-12 04:14:14.595232: train_loss -0.9744 
2025-07-12 04:14:14.596615: val_loss -0.9506 
2025-07-12 04:14:14.597671: Pseudo dice [np.float32(0.9539)] 
2025-07-12 04:14:14.598897: Epoch time: 67.97 s 
2025-07-12 04:14:15.504115:  
2025-07-12 04:14:15.506073: Epoch 609 
2025-07-12 04:14:15.507284: Current learning rate: 0.00429 
2025-07-12 04:15:23.040238: train_loss -0.9766 
2025-07-12 04:15:23.041571: val_loss -0.9487 
2025-07-12 04:15:23.042679: Pseudo dice [np.float32(0.9522)] 
2025-07-12 04:15:23.043785: Epoch time: 67.54 s 
2025-07-12 04:15:23.945560:  
2025-07-12 04:15:23.947239: Epoch 610 
2025-07-12 04:15:23.948400: Current learning rate: 0.00429 
2025-07-12 04:16:31.501692: train_loss -0.977 
2025-07-12 04:16:31.503029: val_loss -0.951 
2025-07-12 04:16:31.504313: Pseudo dice [np.float32(0.9559)] 
2025-07-12 04:16:31.505235: Epoch time: 67.56 s 
2025-07-12 04:16:32.414970:  
2025-07-12 04:16:32.416253: Epoch 611 
2025-07-12 04:16:32.417334: Current learning rate: 0.00428 
2025-07-12 04:17:40.228766: train_loss -0.9785 
2025-07-12 04:17:40.230000: val_loss -0.9488 
2025-07-12 04:17:40.231079: Pseudo dice [np.float32(0.9525)] 
2025-07-12 04:17:40.232215: Epoch time: 67.82 s 
2025-07-12 04:17:41.125638:  
2025-07-12 04:17:41.127206: Epoch 612 
2025-07-12 04:17:41.128333: Current learning rate: 0.00427 
2025-07-12 04:18:48.818496: train_loss -0.9773 
2025-07-12 04:18:48.819912: val_loss -0.948 
2025-07-12 04:18:48.820913: Pseudo dice [np.float32(0.9516)] 
2025-07-12 04:18:48.821954: Epoch time: 67.7 s 
2025-07-12 04:18:49.715086:  
2025-07-12 04:18:49.716715: Epoch 613 
2025-07-12 04:18:49.717839: Current learning rate: 0.00426 
2025-07-12 04:19:57.278962: train_loss -0.9768 
2025-07-12 04:19:57.280387: val_loss -0.9497 
2025-07-12 04:19:57.281526: Pseudo dice [np.float32(0.9533)] 
2025-07-12 04:19:57.282643: Epoch time: 67.57 s 
2025-07-12 04:19:58.182239:  
2025-07-12 04:19:58.183911: Epoch 614 
2025-07-12 04:19:58.185014: Current learning rate: 0.00425 
2025-07-12 04:21:06.340447: train_loss -0.976 
2025-07-12 04:21:06.341961: val_loss -0.9478 
2025-07-12 04:21:06.343402: Pseudo dice [np.float32(0.9513)] 
2025-07-12 04:21:06.344609: Epoch time: 68.16 s 
2025-07-12 04:21:07.253192:  
2025-07-12 04:21:07.254893: Epoch 615 
2025-07-12 04:21:07.255855: Current learning rate: 0.00424 
2025-07-12 04:22:15.090930: train_loss -0.9771 
2025-07-12 04:22:15.092316: val_loss -0.9462 
2025-07-12 04:22:15.093314: Pseudo dice [np.float32(0.9495)] 
2025-07-12 04:22:15.094366: Epoch time: 67.84 s 
2025-07-12 04:22:15.991734:  
2025-07-12 04:22:15.993307: Epoch 616 
2025-07-12 04:22:15.994447: Current learning rate: 0.00423 
2025-07-12 04:23:23.607958: train_loss -0.9773 
2025-07-12 04:23:23.609288: val_loss -0.9508 
2025-07-12 04:23:23.610407: Pseudo dice [np.float32(0.954)] 
2025-07-12 04:23:23.611515: Epoch time: 67.62 s 
2025-07-12 04:23:24.504776:  
2025-07-12 04:23:24.506242: Epoch 617 
2025-07-12 04:23:24.507394: Current learning rate: 0.00422 
2025-07-12 04:24:32.200346: train_loss -0.9768 
2025-07-12 04:24:32.201664: val_loss -0.9518 
2025-07-12 04:24:32.202790: Pseudo dice [np.float32(0.9554)] 
2025-07-12 04:24:32.203933: Epoch time: 67.7 s 
2025-07-12 04:24:33.106067:  
2025-07-12 04:24:33.107878: Epoch 618 
2025-07-12 04:24:33.109162: Current learning rate: 0.00421 
2025-07-12 04:25:40.784504: train_loss -0.9758 
2025-07-12 04:25:40.785667: val_loss -0.9449 
2025-07-12 04:25:40.786590: Pseudo dice [np.float32(0.9488)] 
2025-07-12 04:25:40.787498: Epoch time: 67.68 s 
2025-07-12 04:25:41.684659:  
2025-07-12 04:25:41.686273: Epoch 619 
2025-07-12 04:25:41.687399: Current learning rate: 0.0042 
2025-07-12 04:26:49.674087: train_loss -0.9768 
2025-07-12 04:26:49.675510: val_loss -0.9457 
2025-07-12 04:26:49.676618: Pseudo dice [np.float32(0.949)] 
2025-07-12 04:26:49.677723: Epoch time: 67.99 s 
2025-07-12 04:26:50.604581:  
2025-07-12 04:26:50.606165: Epoch 620 
2025-07-12 04:26:50.607432: Current learning rate: 0.00419 
2025-07-12 04:27:58.839132: train_loss -0.978 
2025-07-12 04:27:58.840613: val_loss -0.9502 
2025-07-12 04:27:58.841766: Pseudo dice [np.float32(0.9533)] 
2025-07-12 04:27:58.842888: Epoch time: 68.24 s 
2025-07-12 04:27:59.739072:  
2025-07-12 04:27:59.741001: Epoch 621 
2025-07-12 04:27:59.742132: Current learning rate: 0.00418 
2025-07-12 04:29:07.808344: train_loss -0.9779 
2025-07-12 04:29:07.809690: val_loss -0.9497 
2025-07-12 04:29:07.810816: Pseudo dice [np.float32(0.9531)] 
2025-07-12 04:29:07.811899: Epoch time: 68.07 s 
2025-07-12 04:29:08.711553:  
2025-07-12 04:29:08.713109: Epoch 622 
2025-07-12 04:29:08.714272: Current learning rate: 0.00417 
2025-07-12 04:30:16.979000: train_loss -0.9788 
2025-07-12 04:30:16.980325: val_loss -0.9509 
2025-07-12 04:30:16.981400: Pseudo dice [np.float32(0.9537)] 
2025-07-12 04:30:16.982634: Epoch time: 68.27 s 
2025-07-12 04:30:17.877768:  
2025-07-12 04:30:17.879682: Epoch 623 
2025-07-12 04:30:17.880802: Current learning rate: 0.00416 
2025-07-12 04:31:26.762768: train_loss -0.9783 
2025-07-12 04:31:26.763987: val_loss -0.947 
2025-07-12 04:31:26.765124: Pseudo dice [np.float32(0.951)] 
2025-07-12 04:31:26.766319: Epoch time: 68.89 s 
2025-07-12 04:31:27.678299:  
2025-07-12 04:31:27.680037: Epoch 624 
2025-07-12 04:31:27.681117: Current learning rate: 0.00415 
2025-07-12 04:32:35.990465: train_loss -0.9781 
2025-07-12 04:32:35.991780: val_loss -0.951 
2025-07-12 04:32:35.992797: Pseudo dice [np.float32(0.9542)] 
2025-07-12 04:32:35.993766: Epoch time: 68.32 s 
2025-07-12 04:32:36.944712:  
2025-07-12 04:32:36.946122: Epoch 625 
2025-07-12 04:32:36.947328: Current learning rate: 0.00414 
2025-07-12 04:33:45.418643: train_loss -0.9772 
2025-07-12 04:33:45.420041: val_loss -0.9473 
2025-07-12 04:33:45.421244: Pseudo dice [np.float32(0.9514)] 
2025-07-12 04:33:45.422223: Epoch time: 68.48 s 
2025-07-12 04:33:46.327397:  
2025-07-12 04:33:46.329153: Epoch 626 
2025-07-12 04:33:46.330763: Current learning rate: 0.00413 
2025-07-12 04:34:54.663163: train_loss -0.977 
2025-07-12 04:34:54.665246: val_loss -0.9485 
2025-07-12 04:34:54.666470: Pseudo dice [np.float32(0.9513)] 
2025-07-12 04:34:54.667605: Epoch time: 68.34 s 
2025-07-12 04:34:55.587015:  
2025-07-12 04:34:55.588386: Epoch 627 
2025-07-12 04:34:55.589531: Current learning rate: 0.00412 
2025-07-12 04:36:04.075094: train_loss -0.9774 
2025-07-12 04:36:04.076490: val_loss -0.9513 
2025-07-12 04:36:04.077541: Pseudo dice [np.float32(0.9546)] 
2025-07-12 04:36:04.078732: Epoch time: 68.49 s 
2025-07-12 04:36:04.989443:  
2025-07-12 04:36:04.991081: Epoch 628 
2025-07-12 04:36:04.992271: Current learning rate: 0.00411 
2025-07-12 04:37:13.321151: train_loss -0.9773 
2025-07-12 04:37:13.322631: val_loss -0.951 
2025-07-12 04:37:13.323555: Pseudo dice [np.float32(0.9542)] 
2025-07-12 04:37:13.324590: Epoch time: 68.34 s 
2025-07-12 04:37:14.244199:  
2025-07-12 04:37:14.245808: Epoch 629 
2025-07-12 04:37:14.246938: Current learning rate: 0.0041 
2025-07-12 04:38:22.481558: train_loss -0.9781 
2025-07-12 04:38:22.482953: val_loss -0.9491 
2025-07-12 04:38:22.484155: Pseudo dice [np.float32(0.952)] 
2025-07-12 04:38:22.485054: Epoch time: 68.24 s 
2025-07-12 04:38:23.394381:  
2025-07-12 04:38:23.395868: Epoch 630 
2025-07-12 04:38:23.396932: Current learning rate: 0.00409 
2025-07-12 04:39:31.704905: train_loss -0.9781 
2025-07-12 04:39:31.706246: val_loss -0.9532 
2025-07-12 04:39:31.707348: Pseudo dice [np.float32(0.9562)] 
2025-07-12 04:39:31.708495: Epoch time: 68.31 s 
2025-07-12 04:39:32.600994:  
2025-07-12 04:39:32.602315: Epoch 631 
2025-07-12 04:39:32.603390: Current learning rate: 0.00408 
2025-07-12 04:40:41.047985: train_loss -0.9781 
2025-07-12 04:40:41.049307: val_loss -0.9518 
2025-07-12 04:40:41.050346: Pseudo dice [np.float32(0.9556)] 
2025-07-12 04:40:41.051430: Epoch time: 68.45 s 
2025-07-12 04:40:41.965614:  
2025-07-12 04:40:41.967136: Epoch 632 
2025-07-12 04:40:41.968162: Current learning rate: 0.00407 
2025-07-12 04:41:51.013942: train_loss -0.9779 
2025-07-12 04:41:51.015356: val_loss -0.9502 
2025-07-12 04:41:51.016410: Pseudo dice [np.float32(0.9532)] 
2025-07-12 04:41:51.017515: Epoch time: 69.05 s 
2025-07-12 04:41:51.916638:  
2025-07-12 04:41:51.918156: Epoch 633 
2025-07-12 04:41:51.919320: Current learning rate: 0.00406 
2025-07-12 04:43:00.331648: train_loss -0.9778 
2025-07-12 04:43:00.332922: val_loss -0.9488 
2025-07-12 04:43:00.334002: Pseudo dice [np.float32(0.9515)] 
2025-07-12 04:43:00.335128: Epoch time: 68.42 s 
2025-07-12 04:43:01.236268:  
2025-07-12 04:43:01.237812: Epoch 634 
2025-07-12 04:43:01.238866: Current learning rate: 0.00405 
2025-07-12 04:44:09.512162: train_loss -0.9773 
2025-07-12 04:44:09.513533: val_loss -0.9487 
2025-07-12 04:44:09.514815: Pseudo dice [np.float32(0.9522)] 
2025-07-12 04:44:09.515868: Epoch time: 68.28 s 
2025-07-12 04:44:10.417149:  
2025-07-12 04:44:10.418882: Epoch 635 
2025-07-12 04:44:10.420088: Current learning rate: 0.00404 
2025-07-12 04:45:18.583663: train_loss -0.9782 
2025-07-12 04:45:18.584819: val_loss -0.9451 
2025-07-12 04:45:18.586218: Pseudo dice [np.float32(0.9492)] 
2025-07-12 04:45:18.587303: Epoch time: 68.17 s 
2025-07-12 04:45:19.489688:  
2025-07-12 04:45:19.491328: Epoch 636 
2025-07-12 04:45:19.492410: Current learning rate: 0.00403 
2025-07-12 04:46:27.712579: train_loss -0.9778 
2025-07-12 04:46:27.713850: val_loss -0.947 
2025-07-12 04:46:27.714957: Pseudo dice [np.float32(0.9505)] 
2025-07-12 04:46:27.715961: Epoch time: 68.23 s 
2025-07-12 04:46:28.620442:  
2025-07-12 04:46:28.622064: Epoch 637 
2025-07-12 04:46:28.623337: Current learning rate: 0.00402 
2025-07-12 04:47:36.938442: train_loss -0.9772 
2025-07-12 04:47:36.939782: val_loss -0.945 
2025-07-12 04:47:36.940774: Pseudo dice [np.float32(0.9488)] 
2025-07-12 04:47:36.941722: Epoch time: 68.32 s 
2025-07-12 04:47:37.836377:  
2025-07-12 04:47:37.837953: Epoch 638 
2025-07-12 04:47:37.838999: Current learning rate: 0.00401 
2025-07-12 04:48:46.229258: train_loss -0.9776 
2025-07-12 04:48:46.230663: val_loss -0.9476 
2025-07-12 04:48:46.231817: Pseudo dice [np.float32(0.952)] 
2025-07-12 04:48:46.232982: Epoch time: 68.4 s 
2025-07-12 04:48:47.155257:  
2025-07-12 04:48:47.156568: Epoch 639 
2025-07-12 04:48:47.157615: Current learning rate: 0.004 
2025-07-12 04:49:55.457599: train_loss -0.9783 
2025-07-12 04:49:55.458865: val_loss -0.9462 
2025-07-12 04:49:55.460090: Pseudo dice [np.float32(0.9497)] 
2025-07-12 04:49:55.461248: Epoch time: 68.31 s 
2025-07-12 04:49:56.409034:  
2025-07-12 04:49:56.410612: Epoch 640 
2025-07-12 04:49:56.411717: Current learning rate: 0.00399 
2025-07-12 04:51:04.721343: train_loss -0.9778 
2025-07-12 04:51:04.722968: val_loss -0.9416 
2025-07-12 04:51:04.724366: Pseudo dice [np.float32(0.9467)] 
2025-07-12 04:51:04.725830: Epoch time: 68.32 s 
2025-07-12 04:51:05.629597:  
2025-07-12 04:51:05.631149: Epoch 641 
2025-07-12 04:51:05.632277: Current learning rate: 0.00398 
2025-07-12 04:52:18.179010: train_loss -0.9784 
2025-07-12 04:52:18.180273: val_loss -0.9501 
2025-07-12 04:52:18.181242: Pseudo dice [np.float32(0.9538)] 
2025-07-12 04:52:18.182424: Epoch time: 72.55 s 
2025-07-12 04:52:19.081703:  
2025-07-12 04:52:19.083432: Epoch 642 
2025-07-12 04:52:19.084543: Current learning rate: 0.00397 
2025-07-12 04:53:31.058483: train_loss -0.9787 
2025-07-12 04:53:31.059538: val_loss -0.9473 
2025-07-12 04:53:31.060402: Pseudo dice [np.float32(0.9518)] 
2025-07-12 04:53:31.061460: Epoch time: 71.98 s 
2025-07-12 04:53:31.976257:  
2025-07-12 04:53:31.977844: Epoch 643 
2025-07-12 04:53:31.979220: Current learning rate: 0.00396 
2025-07-12 04:54:39.280121: train_loss -0.9784 
2025-07-12 04:54:39.281530: val_loss -0.9511 
2025-07-12 04:54:39.282736: Pseudo dice [np.float32(0.9549)] 
2025-07-12 04:54:39.283891: Epoch time: 67.31 s 
2025-07-12 04:54:40.192677:  
2025-07-12 04:54:40.194206: Epoch 644 
2025-07-12 04:54:40.195312: Current learning rate: 0.00395 
2025-07-12 04:55:47.386019: train_loss -0.9796 
2025-07-12 04:55:47.387376: val_loss -0.9501 
2025-07-12 04:55:47.388485: Pseudo dice [np.float32(0.9529)] 
2025-07-12 04:55:47.389615: Epoch time: 67.2 s 
2025-07-12 04:55:48.298697:  
2025-07-12 04:55:48.300377: Epoch 645 
2025-07-12 04:55:48.301765: Current learning rate: 0.00394 
2025-07-12 04:56:55.600486: train_loss -0.9782 
2025-07-12 04:56:55.602024: val_loss -0.9459 
2025-07-12 04:56:55.603113: Pseudo dice [np.float32(0.95)] 
2025-07-12 04:56:55.604303: Epoch time: 67.31 s 
2025-07-12 04:56:56.506158:  
2025-07-12 04:56:56.507588: Epoch 646 
2025-07-12 04:56:56.508848: Current learning rate: 0.00393 
2025-07-12 04:58:03.686204: train_loss -0.9785 
2025-07-12 04:58:03.687555: val_loss -0.9505 
2025-07-12 04:58:03.688763: Pseudo dice [np.float32(0.954)] 
2025-07-12 04:58:03.689738: Epoch time: 67.18 s 
2025-07-12 04:58:04.594324:  
2025-07-12 04:58:04.595888: Epoch 647 
2025-07-12 04:58:04.596997: Current learning rate: 0.00392 
2025-07-12 04:59:12.107154: train_loss -0.9772 
2025-07-12 04:59:12.108415: val_loss -0.9438 
2025-07-12 04:59:12.109553: Pseudo dice [np.float32(0.9476)] 
2025-07-12 04:59:12.110541: Epoch time: 67.52 s 
2025-07-12 04:59:13.023322:  
2025-07-12 04:59:13.024843: Epoch 648 
2025-07-12 04:59:13.025955: Current learning rate: 0.00391 
2025-07-12 05:00:20.784739: train_loss -0.9776 
2025-07-12 05:00:20.786077: val_loss -0.9472 
2025-07-12 05:00:20.787246: Pseudo dice [np.float32(0.9508)] 
2025-07-12 05:00:20.788484: Epoch time: 67.76 s 
2025-07-12 05:00:21.687079:  
2025-07-12 05:00:21.688580: Epoch 649 
2025-07-12 05:00:21.689653: Current learning rate: 0.0039 
2025-07-12 05:01:29.451551: train_loss -0.9765 
2025-07-12 05:01:29.452740: val_loss -0.9475 
2025-07-12 05:01:29.454286: Pseudo dice [np.float32(0.9513)] 
2025-07-12 05:01:29.455387: Epoch time: 67.77 s 
2025-07-12 05:01:32.412025:  
2025-07-12 05:01:32.413688: Epoch 650 
2025-07-12 05:01:32.414928: Current learning rate: 0.00389 
2025-07-12 05:02:40.422875: train_loss -0.9767 
2025-07-12 05:02:40.424027: val_loss -0.9498 
2025-07-12 05:02:40.425004: Pseudo dice [np.float32(0.9536)] 
2025-07-12 05:02:40.425894: Epoch time: 68.01 s 
2025-07-12 05:02:41.317179:  
2025-07-12 05:02:41.318683: Epoch 651 
2025-07-12 05:02:41.319781: Current learning rate: 0.00388 
2025-07-12 05:03:49.439778: train_loss -0.9784 
2025-07-12 05:03:49.440978: val_loss -0.9506 
2025-07-12 05:03:49.441938: Pseudo dice [np.float32(0.9536)] 
2025-07-12 05:03:49.443078: Epoch time: 68.13 s 
2025-07-12 05:03:50.340119:  
2025-07-12 05:03:50.341894: Epoch 652 
2025-07-12 05:03:50.343027: Current learning rate: 0.00387 
2025-07-12 05:04:58.476690: train_loss -0.9786 
2025-07-12 05:04:58.478060: val_loss -0.9485 
2025-07-12 05:04:58.479087: Pseudo dice [np.float32(0.9524)] 
2025-07-12 05:04:58.480339: Epoch time: 68.14 s 
2025-07-12 05:04:59.379271:  
2025-07-12 05:04:59.380681: Epoch 653 
2025-07-12 05:04:59.381852: Current learning rate: 0.00386 
2025-07-12 05:06:07.757790: train_loss -0.9785 
2025-07-12 05:06:07.758955: val_loss -0.9533 
2025-07-12 05:06:07.760020: Pseudo dice [np.float32(0.9561)] 
2025-07-12 05:06:07.760986: Epoch time: 68.38 s 
2025-07-12 05:06:08.665254:  
2025-07-12 05:06:08.666759: Epoch 654 
2025-07-12 05:06:08.667897: Current learning rate: 0.00385 
2025-07-12 05:07:17.014522: train_loss -0.9778 
2025-07-12 05:07:17.015810: val_loss -0.9513 
2025-07-12 05:07:17.016875: Pseudo dice [np.float32(0.9544)] 
2025-07-12 05:07:17.018039: Epoch time: 68.35 s 
2025-07-12 05:07:17.915215:  
2025-07-12 05:07:17.916665: Epoch 655 
2025-07-12 05:07:17.917746: Current learning rate: 0.00384 
2025-07-12 05:08:26.328857: train_loss -0.9772 
2025-07-12 05:08:26.330153: val_loss -0.9486 
2025-07-12 05:08:26.331272: Pseudo dice [np.float32(0.9518)] 
2025-07-12 05:08:26.332339: Epoch time: 68.42 s 
2025-07-12 05:08:27.226246:  
2025-07-12 05:08:27.227830: Epoch 656 
2025-07-12 05:08:27.228953: Current learning rate: 0.00383 
2025-07-12 05:09:35.507762: train_loss -0.978 
2025-07-12 05:09:35.509100: val_loss -0.9486 
2025-07-12 05:09:35.510268: Pseudo dice [np.float32(0.9519)] 
2025-07-12 05:09:35.511379: Epoch time: 68.29 s 
2025-07-12 05:09:36.419397:  
2025-07-12 05:09:36.420788: Epoch 657 
2025-07-12 05:09:36.421928: Current learning rate: 0.00382 
2025-07-12 05:10:44.757029: train_loss -0.9781 
2025-07-12 05:10:44.758462: val_loss -0.9502 
2025-07-12 05:10:44.759706: Pseudo dice [np.float32(0.9539)] 
2025-07-12 05:10:44.760688: Epoch time: 68.34 s 
2025-07-12 05:10:45.661601:  
2025-07-12 05:10:45.662975: Epoch 658 
2025-07-12 05:10:45.664091: Current learning rate: 0.00381 
2025-07-12 05:11:53.800516: train_loss -0.9785 
2025-07-12 05:11:53.801904: val_loss -0.949 
2025-07-12 05:11:53.803036: Pseudo dice [np.float32(0.952)] 
2025-07-12 05:11:53.803869: Epoch time: 68.14 s 
2025-07-12 05:11:55.467112:  
2025-07-12 05:11:55.468853: Epoch 659 
2025-07-12 05:11:55.470072: Current learning rate: 0.0038 
2025-07-12 05:13:03.790245: train_loss -0.9746 
2025-07-12 05:13:03.791406: val_loss -0.9458 
2025-07-12 05:13:03.792825: Pseudo dice [np.float32(0.9496)] 
2025-07-12 05:13:03.793927: Epoch time: 68.33 s 
2025-07-12 05:13:04.693182:  
2025-07-12 05:13:04.694974: Epoch 660 
2025-07-12 05:13:04.696023: Current learning rate: 0.00379 
2025-07-12 05:14:12.955163: train_loss -0.9759 
2025-07-12 05:14:12.956493: val_loss -0.9498 
2025-07-12 05:14:12.957661: Pseudo dice [np.float32(0.9531)] 
2025-07-12 05:14:12.958673: Epoch time: 68.27 s 
2025-07-12 05:14:13.864459:  
2025-07-12 05:14:13.865894: Epoch 661 
2025-07-12 05:14:13.867078: Current learning rate: 0.00378 
2025-07-12 05:15:22.168839: train_loss -0.9772 
2025-07-12 05:15:22.170245: val_loss -0.951 
2025-07-12 05:15:22.171366: Pseudo dice [np.float32(0.9544)] 
2025-07-12 05:15:22.172482: Epoch time: 68.31 s 
2025-07-12 05:15:23.075193:  
2025-07-12 05:15:23.076603: Epoch 662 
2025-07-12 05:15:23.077714: Current learning rate: 0.00377 
2025-07-12 05:16:31.404783: train_loss -0.9778 
2025-07-12 05:16:31.406101: val_loss -0.9496 
2025-07-12 05:16:31.407102: Pseudo dice [np.float32(0.9535)] 
2025-07-12 05:16:31.408164: Epoch time: 68.33 s 
2025-07-12 05:16:32.321193:  
2025-07-12 05:16:32.322504: Epoch 663 
2025-07-12 05:16:32.323627: Current learning rate: 0.00376 
2025-07-12 05:17:40.594797: train_loss -0.9776 
2025-07-12 05:17:40.596182: val_loss -0.947 
2025-07-12 05:17:40.597245: Pseudo dice [np.float32(0.9505)] 
2025-07-12 05:17:40.598408: Epoch time: 68.28 s 
2025-07-12 05:17:41.498678:  
2025-07-12 05:17:41.500414: Epoch 664 
2025-07-12 05:17:41.501532: Current learning rate: 0.00375 
2025-07-12 05:18:49.757317: train_loss -0.9778 
2025-07-12 05:18:49.758565: val_loss -0.9525 
2025-07-12 05:18:49.759804: Pseudo dice [np.float32(0.9558)] 
2025-07-12 05:18:49.760951: Epoch time: 68.26 s 
2025-07-12 05:18:50.658680:  
2025-07-12 05:18:50.660344: Epoch 665 
2025-07-12 05:18:50.661445: Current learning rate: 0.00374 
2025-07-12 05:19:58.922291: train_loss -0.9781 
2025-07-12 05:19:58.923563: val_loss -0.9471 
2025-07-12 05:19:58.924697: Pseudo dice [np.float32(0.9502)] 
2025-07-12 05:19:58.925781: Epoch time: 68.27 s 
2025-07-12 05:19:59.821233:  
2025-07-12 05:19:59.822932: Epoch 666 
2025-07-12 05:19:59.824174: Current learning rate: 0.00373 
2025-07-12 05:21:08.062895: train_loss -0.9761 
2025-07-12 05:21:08.064229: val_loss -0.9441 
2025-07-12 05:21:08.065433: Pseudo dice [np.float32(0.9479)] 
2025-07-12 05:21:08.066665: Epoch time: 68.25 s 
2025-07-12 05:21:08.950147:  
2025-07-12 05:21:08.951631: Epoch 667 
2025-07-12 05:21:08.952741: Current learning rate: 0.00372 
2025-07-12 05:22:16.970901: train_loss -0.9774 
2025-07-12 05:22:16.972248: val_loss -0.9494 
2025-07-12 05:22:16.973298: Pseudo dice [np.float32(0.9533)] 
2025-07-12 05:22:16.974526: Epoch time: 68.02 s 
2025-07-12 05:22:18.641361:  
2025-07-12 05:22:18.642804: Epoch 668 
2025-07-12 05:22:18.643866: Current learning rate: 0.00371 
2025-07-12 05:23:31.175377: train_loss -0.9781 
2025-07-12 05:23:31.176622: val_loss -0.9501 
2025-07-12 05:23:31.177738: Pseudo dice [np.float32(0.9533)] 
2025-07-12 05:23:31.178942: Epoch time: 72.54 s 
2025-07-12 05:23:32.080466:  
2025-07-12 05:23:32.081805: Epoch 669 
2025-07-12 05:23:32.082841: Current learning rate: 0.0037 
2025-07-12 05:24:44.102598: train_loss -0.978 
2025-07-12 05:24:44.103895: val_loss -0.9527 
2025-07-12 05:24:44.105241: Pseudo dice [np.float32(0.956)] 
2025-07-12 05:24:44.106221: Epoch time: 72.03 s 
2025-07-12 05:24:45.014277:  
2025-07-12 05:24:45.015791: Epoch 670 
2025-07-12 05:24:45.016869: Current learning rate: 0.00369 
2025-07-12 05:25:52.872575: train_loss -0.9785 
2025-07-12 05:25:52.873826: val_loss -0.9506 
2025-07-12 05:25:52.875218: Pseudo dice [np.float32(0.9537)] 
2025-07-12 05:25:52.876158: Epoch time: 67.86 s 
2025-07-12 05:25:53.783016:  
2025-07-12 05:25:53.784400: Epoch 671 
2025-07-12 05:25:53.785543: Current learning rate: 0.00368 
2025-07-12 05:27:01.851515: train_loss -0.9781 
2025-07-12 05:27:01.852893: val_loss -0.9513 
2025-07-12 05:27:01.853944: Pseudo dice [np.float32(0.9548)] 
2025-07-12 05:27:01.855152: Epoch time: 68.07 s 
2025-07-12 05:27:02.759633:  
2025-07-12 05:27:02.761202: Epoch 672 
2025-07-12 05:27:02.762361: Current learning rate: 0.00367 
2025-07-12 05:28:10.754918: train_loss -0.9785 
2025-07-12 05:28:10.756097: val_loss -0.9516 
2025-07-12 05:28:10.757401: Pseudo dice [np.float32(0.9547)] 
2025-07-12 05:28:10.758265: Epoch time: 68.0 s 
2025-07-12 05:28:11.664758:  
2025-07-12 05:28:11.666356: Epoch 673 
2025-07-12 05:28:11.667537: Current learning rate: 0.00366 
2025-07-12 05:29:19.826358: train_loss -0.9772 
2025-07-12 05:29:19.827557: val_loss -0.9497 
2025-07-12 05:29:19.828855: Pseudo dice [np.float32(0.9538)] 
2025-07-12 05:29:19.829859: Epoch time: 68.17 s 
2025-07-12 05:29:20.742804:  
2025-07-12 05:29:20.744269: Epoch 674 
2025-07-12 05:29:20.745335: Current learning rate: 0.00365 
2025-07-12 05:30:28.974274: train_loss -0.9784 
2025-07-12 05:30:28.975707: val_loss -0.9517 
2025-07-12 05:30:28.976838: Pseudo dice [np.float32(0.9559)] 
2025-07-12 05:30:28.977938: Epoch time: 68.23 s 
2025-07-12 05:30:28.979089: Yayy! New best EMA pseudo Dice: 0.953499972820282 
2025-07-12 05:30:30.979322:  
2025-07-12 05:30:30.980930: Epoch 675 
2025-07-12 05:30:30.982083: Current learning rate: 0.00364 
2025-07-12 05:31:39.006458: train_loss -0.9787 
2025-07-12 05:31:39.007650: val_loss -0.9473 
2025-07-12 05:31:39.008765: Pseudo dice [np.float32(0.9519)] 
2025-07-12 05:31:39.009808: Epoch time: 68.03 s 
2025-07-12 05:31:39.921866:  
2025-07-12 05:31:39.923606: Epoch 676 
2025-07-12 05:31:39.924767: Current learning rate: 0.00363 
2025-07-12 05:32:48.682401: train_loss -0.979 
2025-07-12 05:32:48.683643: val_loss -0.9474 
2025-07-12 05:32:48.684515: Pseudo dice [np.float32(0.9512)] 
2025-07-12 05:32:48.685696: Epoch time: 68.76 s 
2025-07-12 05:32:49.590136:  
2025-07-12 05:32:49.591448: Epoch 677 
2025-07-12 05:32:49.592582: Current learning rate: 0.00362 
2025-07-12 05:33:57.724466: train_loss -0.9798 
2025-07-12 05:33:57.725862: val_loss -0.9485 
2025-07-12 05:33:57.726895: Pseudo dice [np.float32(0.9517)] 
2025-07-12 05:33:57.728295: Epoch time: 68.14 s 
2025-07-12 05:33:58.635043:  
2025-07-12 05:33:58.637057: Epoch 678 
2025-07-12 05:33:58.638169: Current learning rate: 0.00361 
2025-07-12 05:35:07.035002: train_loss -0.9794 
2025-07-12 05:35:07.036434: val_loss -0.9499 
2025-07-12 05:35:07.037509: Pseudo dice [np.float32(0.9537)] 
2025-07-12 05:35:07.038555: Epoch time: 68.4 s 
2025-07-12 05:35:07.950574:  
2025-07-12 05:35:07.952199: Epoch 679 
2025-07-12 05:35:07.953321: Current learning rate: 0.0036 
2025-07-12 05:36:16.145401: train_loss -0.9793 
2025-07-12 05:36:16.146753: val_loss -0.9441 
2025-07-12 05:36:16.147895: Pseudo dice [np.float32(0.9477)] 
2025-07-12 05:36:16.149038: Epoch time: 68.2 s 
2025-07-12 05:36:17.051223:  
2025-07-12 05:36:17.052536: Epoch 680 
2025-07-12 05:36:17.053630: Current learning rate: 0.00359 
2025-07-12 05:37:25.265313: train_loss -0.9784 
2025-07-12 05:37:25.266594: val_loss -0.9466 
2025-07-12 05:37:25.267743: Pseudo dice [np.float32(0.9509)] 
2025-07-12 05:37:25.268991: Epoch time: 68.22 s 
2025-07-12 05:37:26.169386:  
2025-07-12 05:37:26.171010: Epoch 681 
2025-07-12 05:37:26.172174: Current learning rate: 0.00358 
2025-07-12 05:38:34.638008: train_loss -0.9779 
2025-07-12 05:38:34.639336: val_loss -0.9484 
2025-07-12 05:38:34.640519: Pseudo dice [np.float32(0.9515)] 
2025-07-12 05:38:34.641775: Epoch time: 68.47 s 
2025-07-12 05:38:35.611173:  
2025-07-12 05:38:35.612535: Epoch 682 
2025-07-12 05:38:35.613606: Current learning rate: 0.00357 
2025-07-12 05:39:43.742111: train_loss -0.9785 
2025-07-12 05:39:43.743503: val_loss -0.9481 
2025-07-12 05:39:43.744646: Pseudo dice [np.float32(0.9524)] 
2025-07-12 05:39:43.745563: Epoch time: 68.13 s 
2025-07-12 05:39:44.631702:  
2025-07-12 05:39:44.633415: Epoch 683 
2025-07-12 05:39:44.634535: Current learning rate: 0.00356 
2025-07-12 05:40:52.957791: train_loss -0.9787 
2025-07-12 05:40:52.960069: val_loss -0.9458 
2025-07-12 05:40:52.961216: Pseudo dice [np.float32(0.9494)] 
2025-07-12 05:40:52.962200: Epoch time: 68.33 s 
2025-07-12 05:40:53.875975:  
2025-07-12 05:40:53.877794: Epoch 684 
2025-07-12 05:40:53.878994: Current learning rate: 0.00355 
2025-07-12 05:42:02.181829: train_loss -0.9781 
2025-07-12 05:42:02.183022: val_loss -0.9489 
2025-07-12 05:42:02.184074: Pseudo dice [np.float32(0.9529)] 
2025-07-12 05:42:02.185093: Epoch time: 68.31 s 
2025-07-12 05:42:03.089259:  
2025-07-12 05:42:03.090680: Epoch 685 
2025-07-12 05:42:03.091786: Current learning rate: 0.00354 
2025-07-12 05:43:12.165864: train_loss -0.9781 
2025-07-12 05:43:12.167221: val_loss -0.9462 
2025-07-12 05:43:12.168337: Pseudo dice [np.float32(0.9503)] 
2025-07-12 05:43:12.169542: Epoch time: 69.08 s 
2025-07-12 05:43:13.082165:  
2025-07-12 05:43:13.083770: Epoch 686 
2025-07-12 05:43:13.084944: Current learning rate: 0.00353 
2025-07-12 05:44:21.493861: train_loss -0.9781 
2025-07-12 05:44:21.494987: val_loss -0.9468 
2025-07-12 05:44:21.496017: Pseudo dice [np.float32(0.9501)] 
2025-07-12 05:44:21.497018: Epoch time: 68.42 s 
2025-07-12 05:44:22.404879:  
2025-07-12 05:44:22.406270: Epoch 687 
2025-07-12 05:44:22.407322: Current learning rate: 0.00352 
2025-07-12 05:45:32.276903: train_loss -0.9792 
2025-07-12 05:45:32.278203: val_loss -0.9472 
2025-07-12 05:45:32.279299: Pseudo dice [np.float32(0.9505)] 
2025-07-12 05:45:32.280448: Epoch time: 69.88 s 
2025-07-12 05:45:33.192247:  
2025-07-12 05:45:33.193773: Epoch 688 
2025-07-12 05:45:33.194836: Current learning rate: 0.00351 
2025-07-12 05:46:40.700943: train_loss -0.9797 
2025-07-12 05:46:40.702232: val_loss -0.947 
2025-07-12 05:46:40.703418: Pseudo dice [np.float32(0.9498)] 
2025-07-12 05:46:40.704519: Epoch time: 67.51 s 
2025-07-12 05:46:41.614849:  
2025-07-12 05:46:41.616272: Epoch 689 
2025-07-12 05:46:41.617658: Current learning rate: 0.0035 
2025-07-12 05:47:48.634264: train_loss -0.9778 
2025-07-12 05:47:48.635554: val_loss -0.9459 
2025-07-12 05:47:48.636828: Pseudo dice [np.float32(0.9495)] 
2025-07-12 05:47:48.637870: Epoch time: 67.02 s 
2025-07-12 05:47:49.533845:  
2025-07-12 05:47:49.535432: Epoch 690 
2025-07-12 05:47:49.536633: Current learning rate: 0.00349 
2025-07-12 05:48:56.410292: train_loss -0.9787 
2025-07-12 05:48:56.411540: val_loss -0.9503 
2025-07-12 05:48:56.412644: Pseudo dice [np.float32(0.9535)] 
2025-07-12 05:48:56.413756: Epoch time: 66.88 s 
2025-07-12 05:48:57.321579:  
2025-07-12 05:48:57.323036: Epoch 691 
2025-07-12 05:48:57.324185: Current learning rate: 0.00348 
2025-07-12 05:50:04.455786: train_loss -0.9782 
2025-07-12 05:50:04.456969: val_loss -0.9522 
2025-07-12 05:50:04.457884: Pseudo dice [np.float32(0.9561)] 
2025-07-12 05:50:04.459007: Epoch time: 67.14 s 
2025-07-12 05:50:05.363707:  
2025-07-12 05:50:05.364990: Epoch 692 
2025-07-12 05:50:05.366067: Current learning rate: 0.00346 
2025-07-12 05:51:12.623020: train_loss -0.9797 
2025-07-12 05:51:12.624339: val_loss -0.9472 
2025-07-12 05:51:12.625507: Pseudo dice [np.float32(0.9508)] 
2025-07-12 05:51:12.626633: Epoch time: 67.26 s 
2025-07-12 05:51:13.533715:  
2025-07-12 05:51:13.535430: Epoch 693 
2025-07-12 05:51:13.536638: Current learning rate: 0.00345 
2025-07-12 05:52:21.084816: train_loss -0.9795 
2025-07-12 05:52:21.086074: val_loss -0.9488 
2025-07-12 05:52:21.087265: Pseudo dice [np.float32(0.9523)] 
2025-07-12 05:52:21.088494: Epoch time: 67.55 s 
2025-07-12 05:52:21.977861:  
2025-07-12 05:52:21.979638: Epoch 694 
2025-07-12 05:52:21.980790: Current learning rate: 0.00344 
2025-07-12 05:53:30.453173: train_loss -0.9792 
2025-07-12 05:53:30.454463: val_loss -0.9485 
2025-07-12 05:53:30.455547: Pseudo dice [np.float32(0.9521)] 
2025-07-12 05:53:30.456532: Epoch time: 68.48 s 
2025-07-12 05:53:31.358777:  
2025-07-12 05:53:31.360329: Epoch 695 
2025-07-12 05:53:31.361414: Current learning rate: 0.00343 
2025-07-12 05:54:39.413327: train_loss -0.9778 
2025-07-12 05:54:39.414478: val_loss -0.9454 
2025-07-12 05:54:39.415682: Pseudo dice [np.float32(0.9493)] 
2025-07-12 05:54:39.416795: Epoch time: 68.06 s 
2025-07-12 05:54:40.329127:  
2025-07-12 05:54:40.330905: Epoch 696 
2025-07-12 05:54:40.332074: Current learning rate: 0.00342 
2025-07-12 05:55:48.448142: train_loss -0.9777 
2025-07-12 05:55:48.449476: val_loss -0.9488 
2025-07-12 05:55:48.450708: Pseudo dice [np.float32(0.952)] 
2025-07-12 05:55:48.451695: Epoch time: 68.12 s 
2025-07-12 05:55:49.361504:  
2025-07-12 05:55:49.363049: Epoch 697 
2025-07-12 05:55:49.364100: Current learning rate: 0.00341 
2025-07-12 05:57:01.369743: train_loss -0.9789 
2025-07-12 05:57:01.371092: val_loss -0.9538 
2025-07-12 05:57:01.372230: Pseudo dice [np.float32(0.9569)] 
2025-07-12 05:57:01.373496: Epoch time: 72.01 s 
2025-07-12 05:57:02.275903:  
2025-07-12 05:57:02.277728: Epoch 698 
2025-07-12 05:57:02.278805: Current learning rate: 0.0034 
2025-07-12 05:58:13.704655: train_loss -0.9795 
2025-07-12 05:58:13.705995: val_loss -0.9475 
2025-07-12 05:58:13.707181: Pseudo dice [np.float32(0.9509)] 
2025-07-12 05:58:13.708207: Epoch time: 71.43 s 
2025-07-12 05:58:14.610558:  
2025-07-12 05:58:14.612278: Epoch 699 
2025-07-12 05:58:14.613429: Current learning rate: 0.00339 
2025-07-12 05:59:21.639867: train_loss -0.9786 
2025-07-12 05:59:21.641205: val_loss -0.9471 
2025-07-12 05:59:21.642361: Pseudo dice [np.float32(0.9507)] 
2025-07-12 05:59:21.643430: Epoch time: 67.03 s 
2025-07-12 05:59:23.759503:  
2025-07-12 05:59:23.761127: Epoch 700 
2025-07-12 05:59:23.762344: Current learning rate: 0.00338 
2025-07-12 06:00:30.552282: train_loss -0.9785 
2025-07-12 06:00:30.553658: val_loss -0.9493 
2025-07-12 06:00:30.554609: Pseudo dice [np.float32(0.9527)] 
2025-07-12 06:00:30.555647: Epoch time: 66.8 s 
2025-07-12 06:00:31.464990:  
2025-07-12 06:00:31.466445: Epoch 701 
2025-07-12 06:00:31.467587: Current learning rate: 0.00337 
2025-07-12 06:01:38.267250: train_loss -0.9787 
2025-07-12 06:01:38.268599: val_loss -0.9474 
2025-07-12 06:01:38.269880: Pseudo dice [np.float32(0.9511)] 
2025-07-12 06:01:38.270980: Epoch time: 66.81 s 
2025-07-12 06:01:39.176852:  
2025-07-12 06:01:39.178175: Epoch 702 
2025-07-12 06:01:39.179269: Current learning rate: 0.00336 
2025-07-12 06:02:46.230703: train_loss -0.9798 
2025-07-12 06:02:46.232187: val_loss -0.9491 
2025-07-12 06:02:46.233218: Pseudo dice [np.float32(0.9527)] 
2025-07-12 06:02:46.234279: Epoch time: 67.06 s 
2025-07-12 06:02:47.897497:  
2025-07-12 06:02:47.899060: Epoch 703 
2025-07-12 06:02:47.900200: Current learning rate: 0.00335 
2025-07-12 06:03:55.137458: train_loss -0.9791 
2025-07-12 06:03:55.138793: val_loss -0.9532 
2025-07-12 06:03:55.140039: Pseudo dice [np.float32(0.9567)] 
2025-07-12 06:03:55.141255: Epoch time: 67.24 s 
2025-07-12 06:03:56.062674:  
2025-07-12 06:03:56.064191: Epoch 704 
2025-07-12 06:03:56.065245: Current learning rate: 0.00334 
2025-07-12 06:05:03.676623: train_loss -0.9787 
2025-07-12 06:05:03.677955: val_loss -0.9478 
2025-07-12 06:05:03.679022: Pseudo dice [np.float32(0.9512)] 
2025-07-12 06:05:03.679951: Epoch time: 67.62 s 
2025-07-12 06:05:04.590586:  
2025-07-12 06:05:04.591918: Epoch 705 
2025-07-12 06:05:04.593091: Current learning rate: 0.00333 
2025-07-12 06:06:12.464630: train_loss -0.9789 
2025-07-12 06:06:12.466074: val_loss -0.9472 
2025-07-12 06:06:12.467165: Pseudo dice [np.float32(0.9512)] 
2025-07-12 06:06:12.468453: Epoch time: 67.88 s 
2025-07-12 06:06:13.378727:  
2025-07-12 06:06:13.380254: Epoch 706 
2025-07-12 06:06:13.381430: Current learning rate: 0.00332 
2025-07-12 06:07:21.499278: train_loss -0.9793 
2025-07-12 06:07:21.500714: val_loss -0.9533 
2025-07-12 06:07:21.501639: Pseudo dice [np.float32(0.9567)] 
2025-07-12 06:07:21.502702: Epoch time: 68.12 s 
2025-07-12 06:07:22.407121:  
2025-07-12 06:07:22.408696: Epoch 707 
2025-07-12 06:07:22.409816: Current learning rate: 0.00331 
2025-07-12 06:08:30.516948: train_loss -0.9797 
2025-07-12 06:08:30.518231: val_loss -0.9495 
2025-07-12 06:08:30.519305: Pseudo dice [np.float32(0.9531)] 
2025-07-12 06:08:30.520262: Epoch time: 68.11 s 
2025-07-12 06:08:31.427064:  
2025-07-12 06:08:31.428624: Epoch 708 
2025-07-12 06:08:31.429826: Current learning rate: 0.0033 
2025-07-12 06:09:39.744531: train_loss -0.9789 
2025-07-12 06:09:39.745627: val_loss -0.9493 
2025-07-12 06:09:39.746691: Pseudo dice [np.float32(0.9533)] 
2025-07-12 06:09:39.747719: Epoch time: 68.32 s 
2025-07-12 06:09:40.675928:  
2025-07-12 06:09:40.677341: Epoch 709 
2025-07-12 06:09:40.678418: Current learning rate: 0.00329 
2025-07-12 06:10:48.956908: train_loss -0.9792 
2025-07-12 06:10:48.958421: val_loss -0.9474 
2025-07-12 06:10:48.959592: Pseudo dice [np.float32(0.9509)] 
2025-07-12 06:10:48.960793: Epoch time: 68.28 s 
2025-07-12 06:10:49.864852:  
2025-07-12 06:10:49.866413: Epoch 710 
2025-07-12 06:10:49.867515: Current learning rate: 0.00328 
2025-07-12 06:11:58.071099: train_loss -0.9801 
2025-07-12 06:11:58.072769: val_loss -0.9535 
2025-07-12 06:11:58.073954: Pseudo dice [np.float32(0.9561)] 
2025-07-12 06:11:58.074973: Epoch time: 68.21 s 
2025-07-12 06:11:58.987857:  
2025-07-12 06:11:58.989379: Epoch 711 
2025-07-12 06:11:58.990676: Current learning rate: 0.00327 
2025-07-12 06:13:07.276482: train_loss -0.9798 
2025-07-12 06:13:07.277699: val_loss -0.9506 
2025-07-12 06:13:07.279001: Pseudo dice [np.float32(0.9544)] 
2025-07-12 06:13:07.280062: Epoch time: 68.29 s 
2025-07-12 06:13:08.954045:  
2025-07-12 06:13:08.955433: Epoch 712 
2025-07-12 06:13:08.956556: Current learning rate: 0.00326 
2025-07-12 06:14:17.148712: train_loss -0.9787 
2025-07-12 06:14:17.150169: val_loss -0.9501 
2025-07-12 06:14:17.151288: Pseudo dice [np.float32(0.9541)] 
2025-07-12 06:14:17.152371: Epoch time: 68.2 s 
2025-07-12 06:14:18.067220:  
2025-07-12 06:14:18.068663: Epoch 713 
2025-07-12 06:14:18.069731: Current learning rate: 0.00325 
2025-07-12 06:15:26.130872: train_loss -0.9792 
2025-07-12 06:15:26.132165: val_loss -0.9476 
2025-07-12 06:15:26.133327: Pseudo dice [np.float32(0.9514)] 
2025-07-12 06:15:26.134502: Epoch time: 68.07 s 
2025-07-12 06:15:27.026475:  
2025-07-12 06:15:27.027914: Epoch 714 
2025-07-12 06:15:27.029170: Current learning rate: 0.00324 
2025-07-12 06:16:35.181958: train_loss -0.9793 
2025-07-12 06:16:35.183251: val_loss -0.9468 
2025-07-12 06:16:35.184337: Pseudo dice [np.float32(0.951)] 
2025-07-12 06:16:35.185396: Epoch time: 68.16 s 
2025-07-12 06:16:36.100052:  
2025-07-12 06:16:36.101710: Epoch 715 
2025-07-12 06:16:36.102833: Current learning rate: 0.00323 
2025-07-12 06:17:44.089296: train_loss -0.9798 
2025-07-12 06:17:44.090758: val_loss -0.9462 
2025-07-12 06:17:44.091814: Pseudo dice [np.float32(0.9498)] 
2025-07-12 06:17:44.092799: Epoch time: 67.99 s 
2025-07-12 06:17:45.008835:  
2025-07-12 06:17:45.010601: Epoch 716 
2025-07-12 06:17:45.011841: Current learning rate: 0.00322 
2025-07-12 06:18:53.125726: train_loss -0.9795 
2025-07-12 06:18:53.126902: val_loss -0.9492 
2025-07-12 06:18:53.128093: Pseudo dice [np.float32(0.9526)] 
2025-07-12 06:18:53.129336: Epoch time: 68.12 s 
2025-07-12 06:18:54.042904:  
2025-07-12 06:18:54.044405: Epoch 717 
2025-07-12 06:18:54.045557: Current learning rate: 0.00321 
2025-07-12 06:20:02.277992: train_loss -0.9783 
2025-07-12 06:20:02.279267: val_loss -0.9446 
2025-07-12 06:20:02.280472: Pseudo dice [np.float32(0.95)] 
2025-07-12 06:20:02.281579: Epoch time: 68.24 s 
2025-07-12 06:20:03.195068:  
2025-07-12 06:20:03.196492: Epoch 718 
2025-07-12 06:20:03.197595: Current learning rate: 0.0032 
2025-07-12 06:21:11.302361: train_loss -0.9793 
2025-07-12 06:21:11.303505: val_loss -0.9498 
2025-07-12 06:21:11.304667: Pseudo dice [np.float32(0.9534)] 
2025-07-12 06:21:11.305733: Epoch time: 68.11 s 
2025-07-12 06:21:12.206702:  
2025-07-12 06:21:12.208273: Epoch 719 
2025-07-12 06:21:12.209419: Current learning rate: 0.00319 
2025-07-12 06:22:20.489654: train_loss -0.9794 
2025-07-12 06:22:20.490814: val_loss -0.9492 
2025-07-12 06:22:20.492016: Pseudo dice [np.float32(0.9534)] 
2025-07-12 06:22:20.493164: Epoch time: 68.29 s 
2025-07-12 06:22:21.404337:  
2025-07-12 06:22:21.405912: Epoch 720 
2025-07-12 06:22:21.406956: Current learning rate: 0.00318 
2025-07-12 06:23:29.879502: train_loss -0.9794 
2025-07-12 06:23:29.880777: val_loss -0.9444 
2025-07-12 06:23:29.881934: Pseudo dice [np.float32(0.9494)] 
2025-07-12 06:23:29.883083: Epoch time: 68.48 s 
2025-07-12 06:23:31.561383:  
2025-07-12 06:23:31.562901: Epoch 721 
2025-07-12 06:23:31.563993: Current learning rate: 0.00317 
2025-07-12 06:24:39.959619: train_loss -0.9795 
2025-07-12 06:24:39.960866: val_loss -0.9529 
2025-07-12 06:24:39.962078: Pseudo dice [np.float32(0.9558)] 
2025-07-12 06:24:39.963283: Epoch time: 68.4 s 
2025-07-12 06:24:40.878047:  
2025-07-12 06:24:40.879339: Epoch 722 
2025-07-12 06:24:40.880463: Current learning rate: 0.00316 
2025-07-12 06:25:49.649294: train_loss -0.9802 
2025-07-12 06:25:49.650715: val_loss -0.9521 
2025-07-12 06:25:49.651745: Pseudo dice [np.float32(0.9556)] 
2025-07-12 06:25:49.652826: Epoch time: 68.77 s 
2025-07-12 06:25:50.564518:  
2025-07-12 06:25:50.565834: Epoch 723 
2025-07-12 06:25:50.566973: Current learning rate: 0.00315 
2025-07-12 06:26:59.301113: train_loss -0.9797 
2025-07-12 06:26:59.302589: val_loss -0.9467 
2025-07-12 06:26:59.303763: Pseudo dice [np.float32(0.9513)] 
2025-07-12 06:26:59.304959: Epoch time: 68.74 s 
2025-07-12 06:27:00.217276:  
2025-07-12 06:27:00.218719: Epoch 724 
2025-07-12 06:27:00.219785: Current learning rate: 0.00314 
2025-07-12 06:28:07.351866: train_loss -0.9795 
2025-07-12 06:28:07.353108: val_loss -0.9458 
2025-07-12 06:28:07.354459: Pseudo dice [np.float32(0.9499)] 
2025-07-12 06:28:07.355418: Epoch time: 67.14 s 
2025-07-12 06:28:08.273191:  
2025-07-12 06:28:08.274707: Epoch 725 
2025-07-12 06:28:08.275824: Current learning rate: 0.00313 
2025-07-12 06:29:15.068361: train_loss -0.9802 
2025-07-12 06:29:15.073822: val_loss -0.9493 
2025-07-12 06:29:15.074785: Pseudo dice [np.float32(0.9524)] 
2025-07-12 06:29:15.076081: Epoch time: 66.8 s 
2025-07-12 06:29:15.989581:  
2025-07-12 06:29:15.991177: Epoch 726 
2025-07-12 06:29:15.992268: Current learning rate: 0.00312 
2025-07-12 06:30:22.853650: train_loss -0.979 
2025-07-12 06:30:22.855014: val_loss -0.9481 
2025-07-12 06:30:22.856239: Pseudo dice [np.float32(0.9515)] 
2025-07-12 06:30:22.857333: Epoch time: 66.87 s 
2025-07-12 06:30:23.784899:  
2025-07-12 06:30:23.786409: Epoch 727 
2025-07-12 06:30:23.787419: Current learning rate: 0.00311 
2025-07-12 06:31:30.881585: train_loss -0.9801 
2025-07-12 06:31:30.882914: val_loss -0.9494 
2025-07-12 06:31:30.883959: Pseudo dice [np.float32(0.9526)] 
2025-07-12 06:31:30.885071: Epoch time: 67.1 s 
2025-07-12 06:31:31.793298:  
2025-07-12 06:31:31.795027: Epoch 728 
2025-07-12 06:31:31.796142: Current learning rate: 0.0031 
2025-07-12 06:32:39.282691: train_loss -0.9807 
2025-07-12 06:32:39.283871: val_loss -0.9475 
2025-07-12 06:32:39.284930: Pseudo dice [np.float32(0.951)] 
2025-07-12 06:32:39.285975: Epoch time: 67.49 s 
2025-07-12 06:32:40.196778:  
2025-07-12 06:32:40.198099: Epoch 729 
2025-07-12 06:32:40.199319: Current learning rate: 0.00309 
2025-07-12 06:33:47.864194: train_loss -0.9789 
2025-07-12 06:33:47.865463: val_loss -0.9494 
2025-07-12 06:33:47.866572: Pseudo dice [np.float32(0.9528)] 
2025-07-12 06:33:47.867733: Epoch time: 67.67 s 
2025-07-12 06:33:49.551662:  
2025-07-12 06:33:49.553258: Epoch 730 
2025-07-12 06:33:49.554389: Current learning rate: 0.00308 
2025-07-12 06:34:57.227866: train_loss -0.9802 
2025-07-12 06:34:57.229145: val_loss -0.9515 
2025-07-12 06:34:57.230241: Pseudo dice [np.float32(0.9548)] 
2025-07-12 06:34:57.231387: Epoch time: 67.68 s 
2025-07-12 06:34:58.147670:  
2025-07-12 06:34:58.149424: Epoch 731 
2025-07-12 06:34:58.150556: Current learning rate: 0.00307 
2025-07-12 06:36:06.081085: train_loss -0.9798 
2025-07-12 06:36:06.082392: val_loss -0.9517 
2025-07-12 06:36:06.083501: Pseudo dice [np.float32(0.9559)] 
2025-07-12 06:36:06.084629: Epoch time: 67.94 s 
2025-07-12 06:36:07.001022:  
2025-07-12 06:36:07.002538: Epoch 732 
2025-07-12 06:36:07.003635: Current learning rate: 0.00306 
2025-07-12 06:37:15.111755: train_loss -0.9791 
2025-07-12 06:37:15.113064: val_loss -0.9491 
2025-07-12 06:37:15.113999: Pseudo dice [np.float32(0.9525)] 
2025-07-12 06:37:15.115010: Epoch time: 68.11 s 
2025-07-12 06:37:16.028160:  
2025-07-12 06:37:16.029932: Epoch 733 
2025-07-12 06:37:16.031050: Current learning rate: 0.00305 
2025-07-12 06:38:24.246755: train_loss -0.98 
2025-07-12 06:38:24.247943: val_loss -0.9471 
2025-07-12 06:38:24.249073: Pseudo dice [np.float32(0.9516)] 
2025-07-12 06:38:24.250103: Epoch time: 68.22 s 
2025-07-12 06:38:25.145430:  
2025-07-12 06:38:25.147103: Epoch 734 
2025-07-12 06:38:25.148286: Current learning rate: 0.00304 
2025-07-12 06:39:33.531322: train_loss -0.9805 
2025-07-12 06:39:33.532587: val_loss -0.9512 
2025-07-12 06:39:33.533706: Pseudo dice [np.float32(0.954)] 
2025-07-12 06:39:33.534990: Epoch time: 68.39 s 
2025-07-12 06:39:34.449801:  
2025-07-12 06:39:34.451571: Epoch 735 
2025-07-12 06:39:34.452720: Current learning rate: 0.00303 
2025-07-12 06:40:42.680772: train_loss -0.9803 
2025-07-12 06:40:42.682180: val_loss -0.9524 
2025-07-12 06:40:42.683311: Pseudo dice [np.float32(0.956)] 
2025-07-12 06:40:42.684522: Epoch time: 68.23 s 
2025-07-12 06:40:43.593372:  
2025-07-12 06:40:43.595006: Epoch 736 
2025-07-12 06:40:43.596200: Current learning rate: 0.00302 
2025-07-12 06:41:51.981351: train_loss -0.9801 
2025-07-12 06:41:51.982619: val_loss -0.949 
2025-07-12 06:41:51.983784: Pseudo dice [np.float32(0.9533)] 
2025-07-12 06:41:51.984906: Epoch time: 68.39 s 
2025-07-12 06:41:52.897216:  
2025-07-12 06:41:52.898941: Epoch 737 
2025-07-12 06:41:52.900216: Current learning rate: 0.00301 
2025-07-12 06:43:01.128626: train_loss -0.9787 
2025-07-12 06:43:01.130039: val_loss -0.9443 
2025-07-12 06:43:01.131200: Pseudo dice [np.float32(0.9485)] 
2025-07-12 06:43:01.132267: Epoch time: 68.23 s 
2025-07-12 06:43:02.041811:  
2025-07-12 06:43:02.043202: Epoch 738 
2025-07-12 06:43:02.044418: Current learning rate: 0.003 
2025-07-12 06:44:10.281878: train_loss -0.979 
2025-07-12 06:44:10.283005: val_loss -0.9484 
2025-07-12 06:44:10.283918: Pseudo dice [np.float32(0.9518)] 
2025-07-12 06:44:10.284929: Epoch time: 68.24 s 
2025-07-12 06:44:11.971819:  
2025-07-12 06:44:11.973264: Epoch 739 
2025-07-12 06:44:11.974398: Current learning rate: 0.00299 
2025-07-12 06:45:20.200136: train_loss -0.9799 
2025-07-12 06:45:20.201622: val_loss -0.9467 
2025-07-12 06:45:20.202602: Pseudo dice [np.float32(0.95)] 
2025-07-12 06:45:20.203565: Epoch time: 68.23 s 
2025-07-12 06:45:21.200139:  
2025-07-12 06:45:21.201486: Epoch 740 
2025-07-12 06:45:21.202727: Current learning rate: 0.00297 
2025-07-12 06:46:33.842646: train_loss -0.9793 
2025-07-12 06:46:33.845110: val_loss -0.9483 
2025-07-12 06:46:33.846267: Pseudo dice [np.float32(0.9526)] 
2025-07-12 06:46:33.847356: Epoch time: 72.65 s 
2025-07-12 06:46:34.770401:  
2025-07-12 06:46:34.772031: Epoch 741 
2025-07-12 06:46:34.773132: Current learning rate: 0.00296 
2025-07-12 06:47:46.551088: train_loss -0.9801 
2025-07-12 06:47:46.552423: val_loss -0.9464 
2025-07-12 06:47:46.553634: Pseudo dice [np.float32(0.9504)] 
2025-07-12 06:47:46.554774: Epoch time: 71.78 s 
2025-07-12 06:47:47.472654:  
2025-07-12 06:47:47.474341: Epoch 742 
2025-07-12 06:47:47.475557: Current learning rate: 0.00295 
2025-07-12 06:48:54.674941: train_loss -0.9804 
2025-07-12 06:48:54.676198: val_loss -0.9524 
2025-07-12 06:48:54.677349: Pseudo dice [np.float32(0.9556)] 
2025-07-12 06:48:54.678352: Epoch time: 67.21 s 
2025-07-12 06:48:55.596406:  
2025-07-12 06:48:55.597924: Epoch 743 
2025-07-12 06:48:55.599193: Current learning rate: 0.00294 
2025-07-12 06:50:02.765272: train_loss -0.9806 
2025-07-12 06:50:02.766649: val_loss -0.9461 
2025-07-12 06:50:02.767612: Pseudo dice [np.float32(0.9506)] 
2025-07-12 06:50:02.768712: Epoch time: 67.17 s 
2025-07-12 06:50:03.667305:  
2025-07-12 06:50:03.668621: Epoch 744 
2025-07-12 06:50:03.669846: Current learning rate: 0.00293 
2025-07-12 06:51:10.760038: train_loss -0.9799 
2025-07-12 06:51:10.761417: val_loss -0.9515 
2025-07-12 06:51:10.762509: Pseudo dice [np.float32(0.9551)] 
2025-07-12 06:51:10.763732: Epoch time: 67.1 s 
2025-07-12 06:51:11.672599:  
2025-07-12 06:51:11.674067: Epoch 745 
2025-07-12 06:51:11.675183: Current learning rate: 0.00292 
2025-07-12 06:52:18.913630: train_loss -0.9798 
2025-07-12 06:52:18.915157: val_loss -0.9538 
2025-07-12 06:52:18.916343: Pseudo dice [np.float32(0.957)] 
2025-07-12 06:52:18.917403: Epoch time: 67.24 s 
2025-07-12 06:52:19.827490:  
2025-07-12 06:52:19.829180: Epoch 746 
2025-07-12 06:52:19.830920: Current learning rate: 0.00291 
2025-07-12 06:53:27.123360: train_loss -0.98 
2025-07-12 06:53:27.124632: val_loss -0.9498 
2025-07-12 06:53:27.125682: Pseudo dice [np.float32(0.9529)] 
2025-07-12 06:53:27.126732: Epoch time: 67.3 s 
2025-07-12 06:53:28.026008:  
2025-07-12 06:53:28.027339: Epoch 747 
2025-07-12 06:53:28.028394: Current learning rate: 0.0029 
2025-07-12 06:54:35.498622: train_loss -0.9794 
2025-07-12 06:54:35.499885: val_loss -0.9478 
2025-07-12 06:54:35.500924: Pseudo dice [np.float32(0.9517)] 
2025-07-12 06:54:35.501861: Epoch time: 67.48 s 
2025-07-12 06:54:37.181398:  
2025-07-12 06:54:37.182852: Epoch 748 
2025-07-12 06:54:37.184007: Current learning rate: 0.00289 
2025-07-12 06:55:45.011448: train_loss -0.9799 
2025-07-12 06:55:45.012776: val_loss -0.9441 
2025-07-12 06:55:45.013851: Pseudo dice [np.float32(0.9482)] 
2025-07-12 06:55:45.014762: Epoch time: 67.83 s 
2025-07-12 06:55:45.924612:  
2025-07-12 06:55:45.926170: Epoch 749 
2025-07-12 06:55:45.927329: Current learning rate: 0.00288 
2025-07-12 06:56:54.153666: train_loss -0.9795 
2025-07-12 06:56:54.154976: val_loss -0.9501 
2025-07-12 06:56:54.156138: Pseudo dice [np.float32(0.9527)] 
2025-07-12 06:56:54.157152: Epoch time: 68.23 s 
2025-07-12 06:56:56.533635:  
2025-07-12 06:56:56.535132: Epoch 750 
2025-07-12 06:56:56.536253: Current learning rate: 0.00287 
2025-07-12 06:58:04.643912: train_loss -0.9798 
2025-07-12 06:58:04.645218: val_loss -0.9458 
2025-07-12 06:58:04.646320: Pseudo dice [np.float32(0.9488)] 
2025-07-12 06:58:04.647417: Epoch time: 68.11 s 
2025-07-12 06:58:05.563254:  
2025-07-12 06:58:05.564794: Epoch 751 
2025-07-12 06:58:05.565934: Current learning rate: 0.00286 
2025-07-12 06:59:13.716845: train_loss -0.9803 
2025-07-12 06:59:13.718336: val_loss -0.9506 
2025-07-12 06:59:13.719563: Pseudo dice [np.float32(0.9541)] 
2025-07-12 06:59:13.720581: Epoch time: 68.16 s 
2025-07-12 06:59:14.629337:  
2025-07-12 06:59:14.630921: Epoch 752 
2025-07-12 06:59:14.632069: Current learning rate: 0.00285 
2025-07-12 07:00:22.884203: train_loss -0.9799 
2025-07-12 07:00:22.885503: val_loss -0.9475 
2025-07-12 07:00:22.886611: Pseudo dice [np.float32(0.9515)] 
2025-07-12 07:00:22.887813: Epoch time: 68.26 s 
2025-07-12 07:00:23.796449:  
2025-07-12 07:00:23.797909: Epoch 753 
2025-07-12 07:00:23.798963: Current learning rate: 0.00284 
2025-07-12 07:01:31.936804: train_loss -0.9798 
2025-07-12 07:01:31.938052: val_loss -0.9506 
2025-07-12 07:01:31.939075: Pseudo dice [np.float32(0.9545)] 
2025-07-12 07:01:31.940174: Epoch time: 68.14 s 
2025-07-12 07:01:32.840271:  
2025-07-12 07:01:32.841775: Epoch 754 
2025-07-12 07:01:32.842872: Current learning rate: 0.00283 
2025-07-12 07:02:41.101009: train_loss -0.9803 
2025-07-12 07:02:41.102414: val_loss -0.9515 
2025-07-12 07:02:41.103588: Pseudo dice [np.float32(0.9546)] 
2025-07-12 07:02:41.104603: Epoch time: 68.26 s 
2025-07-12 07:02:42.015445:  
2025-07-12 07:02:42.016754: Epoch 755 
2025-07-12 07:02:42.017982: Current learning rate: 0.00282 
2025-07-12 07:03:50.241016: train_loss -0.9808 
2025-07-12 07:03:50.242569: val_loss -0.947 
2025-07-12 07:03:50.243790: Pseudo dice [np.float32(0.9512)] 
2025-07-12 07:03:50.244862: Epoch time: 68.23 s 
2025-07-12 07:03:51.134076:  
2025-07-12 07:03:51.135891: Epoch 756 
2025-07-12 07:03:51.136970: Current learning rate: 0.00281 
2025-07-12 07:04:59.976460: train_loss -0.9803 
2025-07-12 07:04:59.977771: val_loss -0.9465 
2025-07-12 07:04:59.978903: Pseudo dice [np.float32(0.9506)] 
2025-07-12 07:04:59.980026: Epoch time: 68.85 s 
2025-07-12 07:05:00.866838:  
2025-07-12 07:05:00.868350: Epoch 757 
2025-07-12 07:05:00.869385: Current learning rate: 0.0028 
2025-07-12 07:06:09.053449: train_loss -0.9803 
2025-07-12 07:06:09.054713: val_loss -0.9473 
2025-07-12 07:06:09.055857: Pseudo dice [np.float32(0.951)] 
2025-07-12 07:06:09.057072: Epoch time: 68.19 s 
2025-07-12 07:06:09.976170:  
2025-07-12 07:06:09.977899: Epoch 758 
2025-07-12 07:06:09.979158: Current learning rate: 0.00279 
2025-07-12 07:07:18.220084: train_loss -0.9812 
2025-07-12 07:07:18.221428: val_loss -0.9514 
2025-07-12 07:07:18.222450: Pseudo dice [np.float32(0.9557)] 
2025-07-12 07:07:18.223628: Epoch time: 68.25 s 
2025-07-12 07:07:19.128341:  
2025-07-12 07:07:19.129713: Epoch 759 
2025-07-12 07:07:19.130735: Current learning rate: 0.00278 
2025-07-12 07:08:27.352834: train_loss -0.9807 
2025-07-12 07:08:27.354211: val_loss -0.9506 
2025-07-12 07:08:27.355197: Pseudo dice [np.float32(0.9532)] 
2025-07-12 07:08:27.356229: Epoch time: 68.23 s 
2025-07-12 07:08:28.271801:  
2025-07-12 07:08:28.273304: Epoch 760 
2025-07-12 07:08:28.274425: Current learning rate: 0.00277 
2025-07-12 07:09:36.475719: train_loss -0.9805 
2025-07-12 07:09:36.477022: val_loss -0.9488 
2025-07-12 07:09:36.478197: Pseudo dice [np.float32(0.9518)] 
2025-07-12 07:09:36.479274: Epoch time: 68.21 s 
2025-07-12 07:09:37.374310:  
2025-07-12 07:09:37.375786: Epoch 761 
2025-07-12 07:09:37.376873: Current learning rate: 0.00276 
2025-07-12 07:10:45.790814: train_loss -0.9804 
2025-07-12 07:10:45.792401: val_loss -0.9484 
2025-07-12 07:10:45.793684: Pseudo dice [np.float32(0.9516)] 
2025-07-12 07:10:45.794795: Epoch time: 68.42 s 
2025-07-12 07:10:46.698604:  
2025-07-12 07:10:46.700340: Epoch 762 
2025-07-12 07:10:46.701504: Current learning rate: 0.00275 
2025-07-12 07:11:54.927749: train_loss -0.9802 
2025-07-12 07:11:54.929079: val_loss -0.9477 
2025-07-12 07:11:54.930072: Pseudo dice [np.float32(0.9513)] 
2025-07-12 07:11:54.931200: Epoch time: 68.23 s 
2025-07-12 07:11:55.848980:  
2025-07-12 07:11:55.850341: Epoch 763 
2025-07-12 07:11:55.851444: Current learning rate: 0.00274 
2025-07-12 07:13:07.646834: train_loss -0.9803 
2025-07-12 07:13:07.647943: val_loss -0.9467 
2025-07-12 07:13:07.648913: Pseudo dice [np.float32(0.9498)] 
2025-07-12 07:13:07.649991: Epoch time: 71.8 s 
2025-07-12 07:13:08.567173:  
2025-07-12 07:13:08.568382: Epoch 764 
2025-07-12 07:13:08.569424: Current learning rate: 0.00273 
2025-07-12 07:14:19.574008: train_loss -0.9795 
2025-07-12 07:14:19.575417: val_loss -0.9467 
2025-07-12 07:14:19.576517: Pseudo dice [np.float32(0.9511)] 
2025-07-12 07:14:19.577624: Epoch time: 71.01 s 
2025-07-12 07:14:20.510531:  
2025-07-12 07:14:20.512055: Epoch 765 
2025-07-12 07:14:20.513113: Current learning rate: 0.00272 
2025-07-12 07:15:28.591548: train_loss -0.9787 
2025-07-12 07:15:28.592843: val_loss -0.945 
2025-07-12 07:15:28.593989: Pseudo dice [np.float32(0.949)] 
2025-07-12 07:15:28.595258: Epoch time: 68.08 s 
2025-07-12 07:15:29.522298:  
2025-07-12 07:15:29.523920: Epoch 766 
2025-07-12 07:15:29.525000: Current learning rate: 0.00271 
2025-07-12 07:16:36.750635: train_loss -0.9797 
2025-07-12 07:16:36.752213: val_loss -0.9523 
2025-07-12 07:16:36.753311: Pseudo dice [np.float32(0.9558)] 
2025-07-12 07:16:36.754559: Epoch time: 67.23 s 
2025-07-12 07:16:37.665413:  
2025-07-12 07:16:37.666950: Epoch 767 
2025-07-12 07:16:37.667980: Current learning rate: 0.0027 
2025-07-12 07:17:44.765209: train_loss -0.9801 
2025-07-12 07:17:44.766350: val_loss -0.9473 
2025-07-12 07:17:44.767277: Pseudo dice [np.float32(0.9512)] 
2025-07-12 07:17:44.768102: Epoch time: 67.1 s 
2025-07-12 07:17:45.696469:  
2025-07-12 07:17:45.697755: Epoch 768 
2025-07-12 07:17:45.698979: Current learning rate: 0.00268 
2025-07-12 07:18:52.831587: train_loss -0.9801 
2025-07-12 07:18:52.832813: val_loss -0.9538 
2025-07-12 07:18:52.833706: Pseudo dice [np.float32(0.9567)] 
2025-07-12 07:18:52.834787: Epoch time: 67.14 s 
2025-07-12 07:18:53.730961:  
2025-07-12 07:18:53.732719: Epoch 769 
2025-07-12 07:18:53.733883: Current learning rate: 0.00267 
2025-07-12 07:20:01.109761: train_loss -0.9799 
2025-07-12 07:20:01.111138: val_loss -0.947 
2025-07-12 07:20:01.112118: Pseudo dice [np.float32(0.9508)] 
2025-07-12 07:20:01.113111: Epoch time: 67.38 s 
2025-07-12 07:20:02.027905:  
2025-07-12 07:20:02.029273: Epoch 770 
2025-07-12 07:20:02.030418: Current learning rate: 0.00266 
2025-07-12 07:21:09.825237: train_loss -0.9797 
2025-07-12 07:21:09.826581: val_loss -0.9492 
2025-07-12 07:21:09.827739: Pseudo dice [np.float32(0.9526)] 
2025-07-12 07:21:09.828773: Epoch time: 67.8 s 
2025-07-12 07:21:10.756032:  
2025-07-12 07:21:10.757626: Epoch 771 
2025-07-12 07:21:10.758672: Current learning rate: 0.00265 
2025-07-12 07:22:18.698264: train_loss -0.9794 
2025-07-12 07:22:18.699610: val_loss -0.949 
2025-07-12 07:22:18.700859: Pseudo dice [np.float32(0.9524)] 
2025-07-12 07:22:18.701955: Epoch time: 67.95 s 
2025-07-12 07:22:19.593314:  
2025-07-12 07:22:19.594889: Epoch 772 
2025-07-12 07:22:19.595950: Current learning rate: 0.00264 
2025-07-12 07:23:27.771862: train_loss -0.9794 
2025-07-12 07:23:27.773133: val_loss -0.9481 
2025-07-12 07:23:27.774109: Pseudo dice [np.float32(0.9518)] 
2025-07-12 07:23:27.775362: Epoch time: 68.18 s 
2025-07-12 07:23:28.693141:  
2025-07-12 07:23:28.694892: Epoch 773 
2025-07-12 07:23:28.695972: Current learning rate: 0.00263 
2025-07-12 07:24:36.938489: train_loss -0.9788 
2025-07-12 07:24:36.939857: val_loss -0.9472 
2025-07-12 07:24:36.940904: Pseudo dice [np.float32(0.9515)] 
2025-07-12 07:24:36.942065: Epoch time: 68.25 s 
2025-07-12 07:24:37.865787:  
2025-07-12 07:24:37.867696: Epoch 774 
2025-07-12 07:24:37.868837: Current learning rate: 0.00262 
2025-07-12 07:25:46.673956: train_loss -0.9792 
2025-07-12 07:25:46.675171: val_loss -0.9516 
2025-07-12 07:25:46.676260: Pseudo dice [np.float32(0.9555)] 
2025-07-12 07:25:46.677230: Epoch time: 68.81 s 
2025-07-12 07:25:47.589205:  
2025-07-12 07:25:47.590752: Epoch 775 
2025-07-12 07:25:47.591820: Current learning rate: 0.00261 
2025-07-12 07:26:55.867986: train_loss -0.9798 
2025-07-12 07:26:55.869402: val_loss -0.9459 
2025-07-12 07:26:55.870362: Pseudo dice [np.float32(0.9497)] 
2025-07-12 07:26:55.871483: Epoch time: 68.28 s 
2025-07-12 07:26:56.786674:  
2025-07-12 07:26:56.788244: Epoch 776 
2025-07-12 07:26:56.789526: Current learning rate: 0.0026 
2025-07-12 07:28:05.294198: train_loss -0.9789 
2025-07-12 07:28:05.295340: val_loss -0.9447 
2025-07-12 07:28:05.296468: Pseudo dice [np.float32(0.9489)] 
2025-07-12 07:28:05.297622: Epoch time: 68.51 s 
2025-07-12 07:28:06.213435:  
2025-07-12 07:28:06.215073: Epoch 777 
2025-07-12 07:28:06.216178: Current learning rate: 0.00259 
2025-07-12 07:29:14.611193: train_loss -0.9794 
2025-07-12 07:29:14.612427: val_loss -0.9481 
2025-07-12 07:29:14.613363: Pseudo dice [np.float32(0.9517)] 
2025-07-12 07:29:14.614347: Epoch time: 68.4 s 
2025-07-12 07:29:15.540203:  
2025-07-12 07:29:15.541527: Epoch 778 
2025-07-12 07:29:15.542590: Current learning rate: 0.00258 
2025-07-12 07:30:23.962744: train_loss -0.9797 
2025-07-12 07:30:23.964142: val_loss -0.9477 
2025-07-12 07:30:23.965253: Pseudo dice [np.float32(0.9514)] 
2025-07-12 07:30:23.966293: Epoch time: 68.43 s 
2025-07-12 07:30:24.894013:  
2025-07-12 07:30:24.895384: Epoch 779 
2025-07-12 07:30:24.896766: Current learning rate: 0.00257 
2025-07-12 07:31:33.693040: train_loss -0.9803 
2025-07-12 07:31:33.694504: val_loss -0.9504 
2025-07-12 07:31:33.695538: Pseudo dice [np.float32(0.9546)] 
2025-07-12 07:31:33.696686: Epoch time: 68.8 s 
2025-07-12 07:31:34.607319:  
2025-07-12 07:31:34.608937: Epoch 780 
2025-07-12 07:31:34.610073: Current learning rate: 0.00256 
2025-07-12 07:32:42.308675: train_loss -0.9806 
2025-07-12 07:32:42.309978: val_loss -0.951 
2025-07-12 07:32:42.311149: Pseudo dice [np.float32(0.9548)] 
2025-07-12 07:32:42.312041: Epoch time: 67.7 s 
2025-07-12 07:32:43.220824:  
2025-07-12 07:32:43.222380: Epoch 781 
2025-07-12 07:32:43.223481: Current learning rate: 0.00255 
2025-07-12 07:33:51.184549: train_loss -0.9807 
2025-07-12 07:33:51.185879: val_loss -0.9494 
2025-07-12 07:33:51.186973: Pseudo dice [np.float32(0.9533)] 
2025-07-12 07:33:51.188196: Epoch time: 67.97 s 
2025-07-12 07:33:52.110305:  
2025-07-12 07:33:52.111580: Epoch 782 
2025-07-12 07:33:52.112931: Current learning rate: 0.00254 
2025-07-12 07:35:00.247438: train_loss -0.9794 
2025-07-12 07:35:00.248707: val_loss -0.9476 
2025-07-12 07:35:00.249667: Pseudo dice [np.float32(0.9513)] 
2025-07-12 07:35:00.250857: Epoch time: 68.14 s 
2025-07-12 07:35:01.930594:  
2025-07-12 07:35:01.932225: Epoch 783 
2025-07-12 07:35:01.933372: Current learning rate: 0.00253 
2025-07-12 07:36:10.068704: train_loss -0.9773 
2025-07-12 07:36:10.070109: val_loss -0.9462 
2025-07-12 07:36:10.071191: Pseudo dice [np.float32(0.9511)] 
2025-07-12 07:36:10.072356: Epoch time: 68.14 s 
2025-07-12 07:36:10.985042:  
2025-07-12 07:36:10.986373: Epoch 784 
2025-07-12 07:36:10.987416: Current learning rate: 0.00252 
2025-07-12 07:37:18.975202: train_loss -0.9798 
2025-07-12 07:37:18.976447: val_loss -0.9539 
2025-07-12 07:37:18.977309: Pseudo dice [np.float32(0.9566)] 
2025-07-12 07:37:18.978617: Epoch time: 67.99 s 
2025-07-12 07:37:19.899949:  
2025-07-12 07:37:19.901587: Epoch 785 
2025-07-12 07:37:19.902711: Current learning rate: 0.00251 
2025-07-12 07:38:28.065027: train_loss -0.9803 
2025-07-12 07:38:28.066390: val_loss -0.9514 
2025-07-12 07:38:28.067495: Pseudo dice [np.float32(0.9544)] 
2025-07-12 07:38:28.068508: Epoch time: 68.17 s 
2025-07-12 07:38:28.962530:  
2025-07-12 07:38:28.963808: Epoch 786 
2025-07-12 07:38:28.964973: Current learning rate: 0.0025 
2025-07-12 07:39:42.592196: train_loss -0.9803 
2025-07-12 07:39:42.593490: val_loss -0.9493 
2025-07-12 07:39:42.594579: Pseudo dice [np.float32(0.9523)] 
2025-07-12 07:39:42.595561: Epoch time: 73.63 s 
2025-07-12 07:39:43.508327:  
2025-07-12 07:39:43.509768: Epoch 787 
2025-07-12 07:39:43.510841: Current learning rate: 0.00249 
2025-07-12 07:40:54.991341: train_loss -0.9802 
2025-07-12 07:40:54.992786: val_loss -0.9525 
2025-07-12 07:40:54.993818: Pseudo dice [np.float32(0.9561)] 
2025-07-12 07:40:54.994994: Epoch time: 71.49 s 
2025-07-12 07:40:55.918851:  
2025-07-12 07:40:55.920353: Epoch 788 
2025-07-12 07:40:55.921546: Current learning rate: 0.00248 
2025-07-12 07:42:03.061702: train_loss -0.9813 
2025-07-12 07:42:03.063133: val_loss -0.9512 
2025-07-12 07:42:03.064401: Pseudo dice [np.float32(0.9546)] 
2025-07-12 07:42:03.065391: Epoch time: 67.15 s 
2025-07-12 07:42:03.964631:  
2025-07-12 07:42:03.966149: Epoch 789 
2025-07-12 07:42:03.967399: Current learning rate: 0.00247 
2025-07-12 07:43:11.147701: train_loss -0.9807 
2025-07-12 07:43:11.148996: val_loss -0.9515 
2025-07-12 07:43:11.150385: Pseudo dice [np.float32(0.9555)] 
2025-07-12 07:43:11.151389: Epoch time: 67.19 s 
2025-07-12 07:43:11.152711: Yayy! New best EMA pseudo Dice: 0.953499972820282 
2025-07-12 07:43:13.334627:  
2025-07-12 07:43:13.335905: Epoch 790 
2025-07-12 07:43:13.337008: Current learning rate: 0.00245 
2025-07-12 07:44:21.134017: train_loss -0.9805 
2025-07-12 07:44:21.135394: val_loss -0.9503 
2025-07-12 07:44:21.136596: Pseudo dice [np.float32(0.9544)] 
2025-07-12 07:44:21.137625: Epoch time: 67.8 s 
2025-07-12 07:44:21.138784: Yayy! New best EMA pseudo Dice: 0.9535999894142151 
2025-07-12 07:44:23.473885:  
2025-07-12 07:44:23.475747: Epoch 791 
2025-07-12 07:44:23.476886: Current learning rate: 0.00244 
2025-07-12 07:45:32.332210: train_loss -0.98 
2025-07-12 07:45:32.333635: val_loss -0.9471 
2025-07-12 07:45:32.334798: Pseudo dice [np.float32(0.9498)] 
2025-07-12 07:45:32.335919: Epoch time: 68.86 s 
2025-07-12 07:45:33.250950:  
2025-07-12 07:45:33.252934: Epoch 792 
2025-07-12 07:45:33.254156: Current learning rate: 0.00243 
2025-07-12 07:46:41.452707: train_loss -0.9795 
2025-07-12 07:46:41.453922: val_loss -0.9472 
2025-07-12 07:46:41.455054: Pseudo dice [np.float32(0.9508)] 
2025-07-12 07:46:41.456138: Epoch time: 68.21 s 
2025-07-12 07:46:42.379371:  
2025-07-12 07:46:42.381103: Epoch 793 
2025-07-12 07:46:42.382264: Current learning rate: 0.00242 
2025-07-12 07:47:50.575396: train_loss -0.9799 
2025-07-12 07:47:50.576681: val_loss -0.9508 
2025-07-12 07:47:50.577788: Pseudo dice [np.float32(0.9546)] 
2025-07-12 07:47:50.578856: Epoch time: 68.2 s 
2025-07-12 07:47:51.488387:  
2025-07-12 07:47:51.490133: Epoch 794 
2025-07-12 07:47:51.491277: Current learning rate: 0.00241 
2025-07-12 07:48:59.663048: train_loss -0.9806 
2025-07-12 07:48:59.664397: val_loss -0.9455 
2025-07-12 07:48:59.665468: Pseudo dice [np.float32(0.9493)] 
2025-07-12 07:48:59.666594: Epoch time: 68.18 s 
2025-07-12 07:49:00.595707:  
2025-07-12 07:49:00.597426: Epoch 795 
2025-07-12 07:49:00.598520: Current learning rate: 0.0024 
2025-07-12 07:50:09.040683: train_loss -0.9805 
2025-07-12 07:50:09.041981: val_loss -0.9502 
2025-07-12 07:50:09.043171: Pseudo dice [np.float32(0.9543)] 
2025-07-12 07:50:09.044372: Epoch time: 68.45 s 
2025-07-12 07:50:09.975876:  
2025-07-12 07:50:09.977533: Epoch 796 
2025-07-12 07:50:09.978647: Current learning rate: 0.00239 
2025-07-12 07:51:18.207055: train_loss -0.9806 
2025-07-12 07:51:18.208237: val_loss -0.9485 
2025-07-12 07:51:18.209291: Pseudo dice [np.float32(0.9521)] 
2025-07-12 07:51:18.210506: Epoch time: 68.23 s 
2025-07-12 07:51:19.106229:  
2025-07-12 07:51:19.107801: Epoch 797 
2025-07-12 07:51:19.108837: Current learning rate: 0.00238 
2025-07-12 07:52:27.504463: train_loss -0.9805 
2025-07-12 07:52:27.506703: val_loss -0.9454 
2025-07-12 07:52:27.507813: Pseudo dice [np.float32(0.9487)] 
2025-07-12 07:52:27.508947: Epoch time: 68.4 s 
2025-07-12 07:52:28.426690:  
2025-07-12 07:52:28.428393: Epoch 798 
2025-07-12 07:52:28.429510: Current learning rate: 0.00237 
2025-07-12 07:53:36.696412: train_loss -0.981 
2025-07-12 07:53:36.697631: val_loss -0.9472 
2025-07-12 07:53:36.698562: Pseudo dice [np.float32(0.95)] 
2025-07-12 07:53:36.699558: Epoch time: 68.27 s 
2025-07-12 07:53:37.631279:  
2025-07-12 07:53:37.632698: Epoch 799 
2025-07-12 07:53:37.633792: Current learning rate: 0.00236 
2025-07-12 07:54:45.786814: train_loss -0.98 
2025-07-12 07:54:45.788862: val_loss -0.9476 
2025-07-12 07:54:45.789952: Pseudo dice [np.float32(0.9515)] 
2025-07-12 07:54:45.791093: Epoch time: 68.16 s 
2025-07-12 07:54:48.738008:  
2025-07-12 07:54:48.739412: Epoch 800 
2025-07-12 07:54:48.740725: Current learning rate: 0.00235 
2025-07-12 07:55:56.837615: train_loss -0.9801 
2025-07-12 07:55:56.839148: val_loss -0.9495 
2025-07-12 07:55:56.840466: Pseudo dice [np.float32(0.9535)] 
2025-07-12 07:55:56.841646: Epoch time: 68.1 s 
2025-07-12 07:55:57.766242:  
2025-07-12 07:55:57.767917: Epoch 801 
2025-07-12 07:55:57.769032: Current learning rate: 0.00234 
2025-07-12 07:57:05.925236: train_loss -0.9803 
2025-07-12 07:57:05.926494: val_loss -0.9508 
2025-07-12 07:57:05.927652: Pseudo dice [np.float32(0.9544)] 
2025-07-12 07:57:05.928751: Epoch time: 68.16 s 
2025-07-12 07:57:06.849383:  
2025-07-12 07:57:06.850785: Epoch 802 
2025-07-12 07:57:06.851821: Current learning rate: 0.00233 
2025-07-12 07:58:15.134214: train_loss -0.9805 
2025-07-12 07:58:15.135772: val_loss -0.9439 
2025-07-12 07:58:15.136752: Pseudo dice [np.float32(0.9482)] 
2025-07-12 07:58:15.137862: Epoch time: 68.29 s 
2025-07-12 07:58:16.058134:  
2025-07-12 07:58:16.059494: Epoch 803 
2025-07-12 07:58:16.060615: Current learning rate: 0.00232 
2025-07-12 07:59:24.401918: train_loss -0.9803 
2025-07-12 07:59:24.403181: val_loss -0.9491 
2025-07-12 07:59:24.404092: Pseudo dice [np.float32(0.9519)] 
2025-07-12 07:59:24.405104: Epoch time: 68.35 s 
2025-07-12 07:59:25.311406:  
2025-07-12 07:59:25.312746: Epoch 804 
2025-07-12 07:59:25.313874: Current learning rate: 0.00231 
2025-07-12 08:00:33.769628: train_loss -0.9812 
2025-07-12 08:00:33.770957: val_loss -0.9486 
2025-07-12 08:00:33.772029: Pseudo dice [np.float32(0.9514)] 
2025-07-12 08:00:33.773052: Epoch time: 68.46 s 
2025-07-12 08:00:34.697004:  
2025-07-12 08:00:34.698596: Epoch 805 
2025-07-12 08:00:34.699629: Current learning rate: 0.0023 
2025-07-12 08:01:42.857316: train_loss -0.9813 
2025-07-12 08:01:42.858849: val_loss -0.9478 
2025-07-12 08:01:42.859825: Pseudo dice [np.float32(0.9519)] 
2025-07-12 08:01:42.860963: Epoch time: 68.16 s 
2025-07-12 08:01:43.784672:  
2025-07-12 08:01:43.786196: Epoch 806 
2025-07-12 08:01:43.787470: Current learning rate: 0.00229 
2025-07-12 08:02:52.056264: train_loss -0.9804 
2025-07-12 08:02:52.057626: val_loss -0.9507 
2025-07-12 08:02:52.058740: Pseudo dice [np.float32(0.9545)] 
2025-07-12 08:02:52.059642: Epoch time: 68.28 s 
2025-07-12 08:02:52.980445:  
2025-07-12 08:02:52.982157: Epoch 807 
2025-07-12 08:02:52.983298: Current learning rate: 0.00228 
2025-07-12 08:04:01.077526: train_loss -0.9814 
2025-07-12 08:04:01.078808: val_loss -0.9503 
2025-07-12 08:04:01.079967: Pseudo dice [np.float32(0.9542)] 
2025-07-12 08:04:01.081172: Epoch time: 68.1 s 
2025-07-12 08:04:02.003271:  
2025-07-12 08:04:02.004783: Epoch 808 
2025-07-12 08:04:02.005941: Current learning rate: 0.00226 
2025-07-12 08:05:10.843993: train_loss -0.9809 
2025-07-12 08:05:10.845327: val_loss -0.9477 
2025-07-12 08:05:10.846457: Pseudo dice [np.float32(0.9512)] 
2025-07-12 08:05:10.847605: Epoch time: 68.84 s 
2025-07-12 08:05:11.765816:  
2025-07-12 08:05:11.767099: Epoch 809 
2025-07-12 08:05:11.768299: Current learning rate: 0.00225 
2025-07-12 08:06:19.838415: train_loss -0.9804 
2025-07-12 08:06:19.839783: val_loss -0.9489 
2025-07-12 08:06:19.840899: Pseudo dice [np.float32(0.9536)] 
2025-07-12 08:06:19.842461: Epoch time: 68.08 s 
2025-07-12 08:06:20.751705:  
2025-07-12 08:06:20.753237: Epoch 810 
2025-07-12 08:06:20.754462: Current learning rate: 0.00224 
2025-07-12 08:07:28.854059: train_loss -0.9811 
2025-07-12 08:07:28.855353: val_loss -0.9497 
2025-07-12 08:07:28.856545: Pseudo dice [np.float32(0.9528)] 
2025-07-12 08:07:28.857686: Epoch time: 68.11 s 
2025-07-12 08:07:29.779478:  
2025-07-12 08:07:29.781207: Epoch 811 
2025-07-12 08:07:29.782282: Current learning rate: 0.00223 
2025-07-12 08:08:37.958960: train_loss -0.9809 
2025-07-12 08:08:37.960113: val_loss -0.9494 
2025-07-12 08:08:37.961210: Pseudo dice [np.float32(0.9532)] 
2025-07-12 08:08:37.962305: Epoch time: 68.18 s 
2025-07-12 08:08:38.881477:  
2025-07-12 08:08:38.882699: Epoch 812 
2025-07-12 08:08:38.883800: Current learning rate: 0.00222 
2025-07-12 08:09:51.559694: train_loss -0.9807 
2025-07-12 08:09:51.560967: val_loss -0.9491 
2025-07-12 08:09:51.562145: Pseudo dice [np.float32(0.9533)] 
2025-07-12 08:09:51.563253: Epoch time: 72.68 s 
2025-07-12 08:09:52.466323:  
2025-07-12 08:09:52.467743: Epoch 813 
2025-07-12 08:09:52.468906: Current learning rate: 0.00221 
2025-07-12 08:11:04.629647: train_loss -0.9799 
2025-07-12 08:11:04.630949: val_loss -0.9516 
2025-07-12 08:11:04.632157: Pseudo dice [np.float32(0.9545)] 
2025-07-12 08:11:04.633294: Epoch time: 72.17 s 
2025-07-12 08:11:05.555406:  
2025-07-12 08:11:05.557117: Epoch 814 
2025-07-12 08:11:05.558226: Current learning rate: 0.0022 
2025-07-12 08:12:12.643141: train_loss -0.9803 
2025-07-12 08:12:12.644507: val_loss -0.9515 
2025-07-12 08:12:12.645400: Pseudo dice [np.float32(0.9548)] 
2025-07-12 08:12:12.646437: Epoch time: 67.09 s 
2025-07-12 08:12:13.558140:  
2025-07-12 08:12:13.559677: Epoch 815 
2025-07-12 08:12:13.560905: Current learning rate: 0.00219 
2025-07-12 08:13:20.543608: train_loss -0.9808 
2025-07-12 08:13:20.544894: val_loss -0.9476 
2025-07-12 08:13:20.546075: Pseudo dice [np.float32(0.9512)] 
2025-07-12 08:13:20.547139: Epoch time: 66.99 s 
2025-07-12 08:13:21.485267:  
2025-07-12 08:13:21.486511: Epoch 816 
2025-07-12 08:13:21.487681: Current learning rate: 0.00218 
2025-07-12 08:14:28.423855: train_loss -0.9808 
2025-07-12 08:14:28.425290: val_loss -0.952 
2025-07-12 08:14:28.426333: Pseudo dice [np.float32(0.9557)] 
2025-07-12 08:14:28.427422: Epoch time: 66.94 s 
2025-07-12 08:14:29.358318:  
2025-07-12 08:14:29.360029: Epoch 817 
2025-07-12 08:14:29.361220: Current learning rate: 0.00217 
2025-07-12 08:15:37.012637: train_loss -0.981 
2025-07-12 08:15:37.013946: val_loss -0.9483 
2025-07-12 08:15:37.015134: Pseudo dice [np.float32(0.952)] 
2025-07-12 08:15:37.016402: Epoch time: 67.66 s 
2025-07-12 08:15:37.940286:  
2025-07-12 08:15:37.941902: Epoch 818 
2025-07-12 08:15:37.942944: Current learning rate: 0.00216 
2025-07-12 08:16:45.303251: train_loss -0.9801 
2025-07-12 08:16:45.304621: val_loss -0.9458 
2025-07-12 08:16:45.305733: Pseudo dice [np.float32(0.9496)] 
2025-07-12 08:16:45.306865: Epoch time: 67.37 s 
2025-07-12 08:16:46.235199:  
2025-07-12 08:16:46.236738: Epoch 819 
2025-07-12 08:16:46.237952: Current learning rate: 0.00215 
2025-07-12 08:17:53.684901: train_loss -0.9805 
2025-07-12 08:17:53.686391: val_loss -0.9497 
2025-07-12 08:17:53.687721: Pseudo dice [np.float32(0.9534)] 
2025-07-12 08:17:53.688828: Epoch time: 67.45 s 
2025-07-12 08:17:54.582836:  
2025-07-12 08:17:54.584638: Epoch 820 
2025-07-12 08:17:54.585884: Current learning rate: 0.00214 
2025-07-12 08:19:02.291108: train_loss -0.9804 
2025-07-12 08:19:02.292506: val_loss -0.9478 
2025-07-12 08:19:02.293644: Pseudo dice [np.float32(0.9512)] 
2025-07-12 08:19:02.294773: Epoch time: 67.71 s 
2025-07-12 08:19:03.181428:  
2025-07-12 08:19:03.183035: Epoch 821 
2025-07-12 08:19:03.184292: Current learning rate: 0.00213 
2025-07-12 08:20:11.098610: train_loss -0.9813 
2025-07-12 08:20:11.099885: val_loss -0.9493 
2025-07-12 08:20:11.100954: Pseudo dice [np.float32(0.953)] 
2025-07-12 08:20:11.102089: Epoch time: 67.92 s 
2025-07-12 08:20:11.972865:  
2025-07-12 08:20:11.974638: Epoch 822 
2025-07-12 08:20:11.975834: Current learning rate: 0.00212 
2025-07-12 08:21:19.942626: train_loss -0.9816 
2025-07-12 08:21:19.943959: val_loss -0.9502 
2025-07-12 08:21:19.944839: Pseudo dice [np.float32(0.9534)] 
2025-07-12 08:21:19.945932: Epoch time: 67.97 s 
2025-07-12 08:21:20.832195:  
2025-07-12 08:21:20.833354: Epoch 823 
2025-07-12 08:21:20.834450: Current learning rate: 0.0021 
2025-07-12 08:22:28.704593: train_loss -0.9803 
2025-07-12 08:22:28.705891: val_loss -0.9487 
2025-07-12 08:22:28.707225: Pseudo dice [np.float32(0.952)] 
2025-07-12 08:22:28.708479: Epoch time: 67.88 s 
2025-07-12 08:22:29.592506:  
2025-07-12 08:22:29.593781: Epoch 824 
2025-07-12 08:22:29.594916: Current learning rate: 0.00209 
2025-07-12 08:23:37.594823: train_loss -0.9816 
2025-07-12 08:23:37.596257: val_loss -0.9499 
2025-07-12 08:23:37.597480: Pseudo dice [np.float32(0.9527)] 
2025-07-12 08:23:37.598606: Epoch time: 68.01 s 
2025-07-12 08:23:38.487712:  
2025-07-12 08:23:38.489249: Epoch 825 
2025-07-12 08:23:38.490382: Current learning rate: 0.00208 
2025-07-12 08:24:46.476632: train_loss -0.9813 
2025-07-12 08:24:46.477965: val_loss -0.9449 
2025-07-12 08:24:46.479128: Pseudo dice [np.float32(0.9487)] 
2025-07-12 08:24:46.480782: Epoch time: 67.99 s 
2025-07-12 08:24:47.379469:  
2025-07-12 08:24:47.380917: Epoch 826 
2025-07-12 08:24:47.382013: Current learning rate: 0.00207 
2025-07-12 08:25:56.193208: train_loss -0.9812 
2025-07-12 08:25:56.194422: val_loss -0.9515 
2025-07-12 08:25:56.195590: Pseudo dice [np.float32(0.9548)] 
2025-07-12 08:25:56.196743: Epoch time: 68.82 s 
2025-07-12 08:25:57.091865:  
2025-07-12 08:25:57.093400: Epoch 827 
2025-07-12 08:25:57.094681: Current learning rate: 0.00206 
2025-07-12 08:27:05.194847: train_loss -0.9809 
2025-07-12 08:27:05.195987: val_loss -0.9514 
2025-07-12 08:27:05.196998: Pseudo dice [np.float32(0.9556)] 
2025-07-12 08:27:05.198351: Epoch time: 68.11 s 
2025-07-12 08:27:06.086915:  
2025-07-12 08:27:06.088210: Epoch 828 
2025-07-12 08:27:06.089350: Current learning rate: 0.00205 
2025-07-12 08:28:14.193735: train_loss -0.9813 
2025-07-12 08:28:14.194983: val_loss -0.9472 
2025-07-12 08:28:14.196165: Pseudo dice [np.float32(0.9509)] 
2025-07-12 08:28:14.197202: Epoch time: 68.11 s 
2025-07-12 08:28:15.096027:  
2025-07-12 08:28:15.097680: Epoch 829 
2025-07-12 08:28:15.098845: Current learning rate: 0.00204 
2025-07-12 08:29:23.172190: train_loss -0.9815 
2025-07-12 08:29:23.173825: val_loss -0.9487 
2025-07-12 08:29:23.174831: Pseudo dice [np.float32(0.9527)] 
2025-07-12 08:29:23.175953: Epoch time: 68.08 s 
2025-07-12 08:29:24.066763:  
2025-07-12 08:29:24.068299: Epoch 830 
2025-07-12 08:29:24.069450: Current learning rate: 0.00203 
2025-07-12 08:30:32.063001: train_loss -0.9821 
2025-07-12 08:30:32.064452: val_loss -0.948 
2025-07-12 08:30:32.065701: Pseudo dice [np.float32(0.9522)] 
2025-07-12 08:30:32.066832: Epoch time: 68.0 s 
2025-07-12 08:30:32.958393:  
2025-07-12 08:30:32.959875: Epoch 831 
2025-07-12 08:30:32.960901: Current learning rate: 0.00202 
2025-07-12 08:31:40.969009: train_loss -0.9825 
2025-07-12 08:31:40.970356: val_loss -0.9503 
2025-07-12 08:31:40.971605: Pseudo dice [np.float32(0.9538)] 
2025-07-12 08:31:40.972725: Epoch time: 68.01 s 
2025-07-12 08:31:41.875352:  
2025-07-12 08:31:41.876973: Epoch 832 
2025-07-12 08:31:41.878063: Current learning rate: 0.00201 
2025-07-12 08:32:49.917273: train_loss -0.9821 
2025-07-12 08:32:49.918591: val_loss -0.9456 
2025-07-12 08:32:49.919718: Pseudo dice [np.float32(0.9489)] 
2025-07-12 08:32:49.920721: Epoch time: 68.05 s 
2025-07-12 08:32:50.811828:  
2025-07-12 08:32:50.813153: Epoch 833 
2025-07-12 08:32:50.814245: Current learning rate: 0.002 
2025-07-12 08:33:58.982273: train_loss -0.9809 
2025-07-12 08:33:58.983701: val_loss -0.9484 
2025-07-12 08:33:58.984922: Pseudo dice [np.float32(0.9517)] 
2025-07-12 08:33:58.986058: Epoch time: 68.17 s 
2025-07-12 08:33:59.872997:  
2025-07-12 08:33:59.874547: Epoch 834 
2025-07-12 08:33:59.875728: Current learning rate: 0.00199 
2025-07-12 08:35:08.313307: train_loss -0.9806 
2025-07-12 08:35:08.314563: val_loss -0.9475 
2025-07-12 08:35:08.315791: Pseudo dice [np.float32(0.9507)] 
2025-07-12 08:35:08.316788: Epoch time: 68.44 s 
2025-07-12 08:35:09.207191:  
2025-07-12 08:35:09.208513: Epoch 835 
2025-07-12 08:35:09.209686: Current learning rate: 0.00198 
2025-07-12 08:36:18.160471: train_loss -0.9817 
2025-07-12 08:36:18.161830: val_loss -0.9524 
2025-07-12 08:36:18.163000: Pseudo dice [np.float32(0.9554)] 
2025-07-12 08:36:18.164242: Epoch time: 68.96 s 
2025-07-12 08:36:19.056235:  
2025-07-12 08:36:19.057660: Epoch 836 
2025-07-12 08:36:19.058776: Current learning rate: 0.00196 
2025-07-12 08:37:27.248358: train_loss -0.9811 
2025-07-12 08:37:27.249641: val_loss -0.9445 
2025-07-12 08:37:27.250689: Pseudo dice [np.float32(0.9476)] 
2025-07-12 08:37:27.251782: Epoch time: 68.2 s 
2025-07-12 08:37:28.141471:  
2025-07-12 08:37:28.143198: Epoch 837 
2025-07-12 08:37:28.144670: Current learning rate: 0.00195 
2025-07-12 08:38:36.355447: train_loss -0.9814 
2025-07-12 08:38:36.356850: val_loss -0.9484 
2025-07-12 08:38:36.357874: Pseudo dice [np.float32(0.9519)] 
2025-07-12 08:38:36.359086: Epoch time: 68.22 s 
2025-07-12 08:38:37.246944:  
2025-07-12 08:38:37.248322: Epoch 838 
2025-07-12 08:38:37.249407: Current learning rate: 0.00194 
2025-07-12 08:39:45.560135: train_loss -0.981 
2025-07-12 08:39:45.561788: val_loss -0.9466 
2025-07-12 08:39:45.562919: Pseudo dice [np.float32(0.9504)] 
2025-07-12 08:39:45.563938: Epoch time: 68.32 s 
2025-07-12 08:39:46.460548:  
2025-07-12 08:39:46.462033: Epoch 839 
2025-07-12 08:39:46.463178: Current learning rate: 0.00193 
2025-07-12 08:40:54.683790: train_loss -0.9814 
2025-07-12 08:40:54.685123: val_loss -0.9508 
2025-07-12 08:40:54.686274: Pseudo dice [np.float32(0.9545)] 
2025-07-12 08:40:54.687387: Epoch time: 68.23 s 
2025-07-12 08:40:55.584936:  
2025-07-12 08:40:55.586411: Epoch 840 
2025-07-12 08:40:55.587490: Current learning rate: 0.00192 
2025-07-12 08:42:03.730130: train_loss -0.982 
2025-07-12 08:42:03.731551: val_loss -0.9508 
2025-07-12 08:42:03.732735: Pseudo dice [np.float32(0.9547)] 
2025-07-12 08:42:03.733766: Epoch time: 68.15 s 
2025-07-12 08:42:04.624663:  
2025-07-12 08:42:04.626625: Epoch 841 
2025-07-12 08:42:04.627755: Current learning rate: 0.00191 
2025-07-12 08:43:13.184116: train_loss -0.9815 
2025-07-12 08:43:13.185411: val_loss -0.9494 
2025-07-12 08:43:13.186408: Pseudo dice [np.float32(0.9524)] 
2025-07-12 08:43:13.187558: Epoch time: 68.56 s 
2025-07-12 08:43:14.077444:  
2025-07-12 08:43:14.079080: Epoch 842 
2025-07-12 08:43:14.080341: Current learning rate: 0.0019 
2025-07-12 08:44:22.072582: train_loss -0.9811 
2025-07-12 08:44:22.073761: val_loss -0.9443 
2025-07-12 08:44:22.074828: Pseudo dice [np.float32(0.9483)] 
2025-07-12 08:44:22.076010: Epoch time: 68.0 s 
2025-07-12 08:44:22.963646:  
2025-07-12 08:44:22.965055: Epoch 843 
2025-07-12 08:44:22.966166: Current learning rate: 0.00189 
2025-07-12 08:45:30.605815: train_loss -0.9814 
2025-07-12 08:45:30.607234: val_loss -0.9467 
2025-07-12 08:45:30.608677: Pseudo dice [np.float32(0.9512)] 
2025-07-12 08:45:30.609914: Epoch time: 67.65 s 
2025-07-12 08:45:31.507861:  
2025-07-12 08:45:31.509114: Epoch 844 
2025-07-12 08:45:31.510650: Current learning rate: 0.00188 
2025-07-12 08:46:40.159135: train_loss -0.9819 
2025-07-12 08:46:40.160786: val_loss -0.9467 
2025-07-12 08:46:40.161873: Pseudo dice [np.float32(0.9507)] 
2025-07-12 08:46:40.162894: Epoch time: 68.65 s 
2025-07-12 08:46:41.031519:  
2025-07-12 08:46:41.032970: Epoch 845 
2025-07-12 08:46:41.034104: Current learning rate: 0.00187 
2025-07-12 08:47:49.088074: train_loss -0.9822 
2025-07-12 08:47:49.089467: val_loss -0.9468 
2025-07-12 08:47:49.090707: Pseudo dice [np.float32(0.9511)] 
2025-07-12 08:47:49.091907: Epoch time: 68.06 s 
2025-07-12 08:47:49.985866:  
2025-07-12 08:47:49.987678: Epoch 846 
2025-07-12 08:47:49.988816: Current learning rate: 0.00186 
2025-07-12 08:48:58.318449: train_loss -0.9815 
2025-07-12 08:48:58.319772: val_loss -0.9519 
2025-07-12 08:48:58.320824: Pseudo dice [np.float32(0.9549)] 
2025-07-12 08:48:58.321785: Epoch time: 68.34 s 
2025-07-12 08:48:59.211513:  
2025-07-12 08:48:59.213131: Epoch 847 
2025-07-12 08:48:59.214277: Current learning rate: 0.00185 
2025-07-12 08:50:07.630584: train_loss -0.982 
2025-07-12 08:50:07.631896: val_loss -0.947 
2025-07-12 08:50:07.633065: Pseudo dice [np.float32(0.9509)] 
2025-07-12 08:50:07.634169: Epoch time: 68.42 s 
2025-07-12 08:50:08.529355:  
2025-07-12 08:50:08.530880: Epoch 848 
2025-07-12 08:50:08.532252: Current learning rate: 0.00184 
2025-07-12 08:51:16.750405: train_loss -0.9824 
2025-07-12 08:51:16.751725: val_loss -0.9495 
2025-07-12 08:51:16.752735: Pseudo dice [np.float32(0.9532)] 
2025-07-12 08:51:16.753759: Epoch time: 68.22 s 
2025-07-12 08:51:17.635917:  
2025-07-12 08:51:17.637902: Epoch 849 
2025-07-12 08:51:17.639014: Current learning rate: 0.00182 
2025-07-12 08:52:25.737464: train_loss -0.9823 
2025-07-12 08:52:25.738802: val_loss -0.9532 
2025-07-12 08:52:25.739951: Pseudo dice [np.float32(0.9561)] 
2025-07-12 08:52:25.741039: Epoch time: 68.1 s 
2025-07-12 08:52:27.720015:  
2025-07-12 08:52:27.721883: Epoch 850 
2025-07-12 08:52:27.723018: Current learning rate: 0.00181 
2025-07-12 08:53:35.916880: train_loss -0.9816 
2025-07-12 08:53:35.918143: val_loss -0.9538 
2025-07-12 08:53:35.919257: Pseudo dice [np.float32(0.9562)] 
2025-07-12 08:53:35.920398: Epoch time: 68.2 s 
2025-07-12 08:53:36.802644:  
2025-07-12 08:53:36.804248: Epoch 851 
2025-07-12 08:53:36.805339: Current learning rate: 0.0018 
2025-07-12 08:54:45.099398: train_loss -0.9822 
2025-07-12 08:54:45.100789: val_loss -0.9515 
2025-07-12 08:54:45.101790: Pseudo dice [np.float32(0.954)] 
2025-07-12 08:54:45.102939: Epoch time: 68.3 s 
2025-07-12 08:54:45.988946:  
2025-07-12 08:54:45.990277: Epoch 852 
2025-07-12 08:54:45.991494: Current learning rate: 0.00179 
2025-07-12 08:55:54.310411: train_loss -0.9817 
2025-07-12 08:55:54.311684: val_loss -0.944 
2025-07-12 08:55:54.312706: Pseudo dice [np.float32(0.9483)] 
2025-07-12 08:55:54.313871: Epoch time: 68.32 s 
2025-07-12 08:55:55.204282:  
2025-07-12 08:55:55.205969: Epoch 853 
2025-07-12 08:55:55.207121: Current learning rate: 0.00178 
2025-07-12 08:57:04.002048: train_loss -0.9813 
2025-07-12 08:57:04.003822: val_loss -0.9459 
2025-07-12 08:57:04.004977: Pseudo dice [np.float32(0.9501)] 
2025-07-12 08:57:04.006040: Epoch time: 68.8 s 
2025-07-12 08:57:04.893801:  
2025-07-12 08:57:04.895294: Epoch 854 
2025-07-12 08:57:04.896518: Current learning rate: 0.00177 
2025-07-12 08:58:13.384166: train_loss -0.982 
2025-07-12 08:58:13.386348: val_loss -0.9463 
2025-07-12 08:58:13.387399: Pseudo dice [np.float32(0.9506)] 
2025-07-12 08:58:13.388509: Epoch time: 68.49 s 
2025-07-12 08:58:14.254581:  
2025-07-12 08:58:14.256248: Epoch 855 
2025-07-12 08:58:14.257357: Current learning rate: 0.00176 
2025-07-12 08:59:22.170847: train_loss -0.9818 
2025-07-12 08:59:22.172333: val_loss -0.9477 
2025-07-12 08:59:22.173409: Pseudo dice [np.float32(0.9511)] 
2025-07-12 08:59:22.174546: Epoch time: 67.92 s 
2025-07-12 08:59:23.033731:  
2025-07-12 08:59:23.035332: Epoch 856 
2025-07-12 08:59:23.036493: Current learning rate: 0.00175 
2025-07-12 09:00:30.219920: train_loss -0.982 
2025-07-12 09:00:30.221207: val_loss -0.9445 
2025-07-12 09:00:30.222273: Pseudo dice [np.float32(0.9485)] 
2025-07-12 09:00:30.223389: Epoch time: 67.19 s 
2025-07-12 09:00:31.087869:  
2025-07-12 09:00:31.089419: Epoch 857 
2025-07-12 09:00:31.090584: Current learning rate: 0.00174 
2025-07-12 09:01:38.825992: train_loss -0.9824 
2025-07-12 09:01:38.827108: val_loss -0.9466 
2025-07-12 09:01:38.828214: Pseudo dice [np.float32(0.9498)] 
2025-07-12 09:01:38.829135: Epoch time: 67.74 s 
2025-07-12 09:01:39.712662:  
2025-07-12 09:01:39.714237: Epoch 858 
2025-07-12 09:01:39.715348: Current learning rate: 0.00173 
2025-07-12 09:02:47.592735: train_loss -0.982 
2025-07-12 09:02:47.593895: val_loss -0.9475 
2025-07-12 09:02:47.594905: Pseudo dice [np.float32(0.9516)] 
2025-07-12 09:02:47.595879: Epoch time: 67.88 s 
2025-07-12 09:02:48.476491:  
2025-07-12 09:02:48.478000: Epoch 859 
2025-07-12 09:02:48.479160: Current learning rate: 0.00172 
2025-07-12 09:03:56.586634: train_loss -0.9821 
2025-07-12 09:03:56.587886: val_loss -0.9512 
2025-07-12 09:03:56.589083: Pseudo dice [np.float32(0.9555)] 
2025-07-12 09:03:56.590443: Epoch time: 68.11 s 
2025-07-12 09:03:57.467599:  
2025-07-12 09:03:57.468990: Epoch 860 
2025-07-12 09:03:57.470252: Current learning rate: 0.0017 
2025-07-12 09:05:05.545640: train_loss -0.9819 
2025-07-12 09:05:05.546924: val_loss -0.9491 
2025-07-12 09:05:05.547956: Pseudo dice [np.float32(0.9523)] 
2025-07-12 09:05:05.548953: Epoch time: 68.08 s 
2025-07-12 09:05:06.430299:  
2025-07-12 09:05:06.431906: Epoch 861 
2025-07-12 09:05:06.433062: Current learning rate: 0.00169 
2025-07-12 09:06:14.747746: train_loss -0.9824 
2025-07-12 09:06:14.749397: val_loss -0.9492 
2025-07-12 09:06:14.750497: Pseudo dice [np.float32(0.9529)] 
2025-07-12 09:06:14.751471: Epoch time: 68.32 s 
2025-07-12 09:06:15.636637:  
2025-07-12 09:06:15.637844: Epoch 862 
2025-07-12 09:06:15.638985: Current learning rate: 0.00168 
2025-07-12 09:07:24.546152: train_loss -0.982 
2025-07-12 09:07:24.547480: val_loss -0.9486 
2025-07-12 09:07:24.548695: Pseudo dice [np.float32(0.9518)] 
2025-07-12 09:07:24.549965: Epoch time: 68.91 s 
2025-07-12 09:07:25.438473:  
2025-07-12 09:07:25.440069: Epoch 863 
2025-07-12 09:07:25.441308: Current learning rate: 0.00167 
2025-07-12 09:08:33.599406: train_loss -0.9818 
2025-07-12 09:08:33.600629: val_loss -0.947 
2025-07-12 09:08:33.601700: Pseudo dice [np.float32(0.9503)] 
2025-07-12 09:08:33.602839: Epoch time: 68.16 s 
2025-07-12 09:08:34.480663:  
2025-07-12 09:08:34.482376: Epoch 864 
2025-07-12 09:08:34.483672: Current learning rate: 0.00166 
2025-07-12 09:09:42.691969: train_loss -0.9824 
2025-07-12 09:09:42.693235: val_loss -0.9508 
2025-07-12 09:09:42.694347: Pseudo dice [np.float32(0.954)] 
2025-07-12 09:09:42.695325: Epoch time: 68.21 s 
2025-07-12 09:09:43.578493:  
2025-07-12 09:09:43.579999: Epoch 865 
2025-07-12 09:09:43.581201: Current learning rate: 0.00165 
2025-07-12 09:10:51.837093: train_loss -0.9823 
2025-07-12 09:10:51.838288: val_loss -0.9502 
2025-07-12 09:10:51.839536: Pseudo dice [np.float32(0.9535)] 
2025-07-12 09:10:51.840846: Epoch time: 68.26 s 
2025-07-12 09:10:52.716491:  
2025-07-12 09:10:52.718088: Epoch 866 
2025-07-12 09:10:52.719281: Current learning rate: 0.00164 
2025-07-12 09:12:01.129644: train_loss -0.9815 
2025-07-12 09:12:01.130889: val_loss -0.9483 
2025-07-12 09:12:01.132059: Pseudo dice [np.float32(0.9514)] 
2025-07-12 09:12:01.133068: Epoch time: 68.42 s 
2025-07-12 09:12:02.015716:  
2025-07-12 09:12:02.017380: Epoch 867 
2025-07-12 09:12:02.018458: Current learning rate: 0.00163 
2025-07-12 09:13:10.367742: train_loss -0.9816 
2025-07-12 09:13:10.368928: val_loss -0.9495 
2025-07-12 09:13:10.369847: Pseudo dice [np.float32(0.9531)] 
2025-07-12 09:13:10.370958: Epoch time: 68.36 s 
2025-07-12 09:13:11.252089:  
2025-07-12 09:13:11.253720: Epoch 868 
2025-07-12 09:13:11.254840: Current learning rate: 0.00162 
2025-07-12 09:14:19.363714: train_loss -0.9823 
2025-07-12 09:14:19.365080: val_loss -0.9508 
2025-07-12 09:14:19.366302: Pseudo dice [np.float32(0.9541)] 
2025-07-12 09:14:19.367421: Epoch time: 68.12 s 
2025-07-12 09:14:20.241247:  
2025-07-12 09:14:20.242963: Epoch 869 
2025-07-12 09:14:20.244096: Current learning rate: 0.00161 
2025-07-12 09:15:28.459781: train_loss -0.9823 
2025-07-12 09:15:28.461028: val_loss -0.9498 
2025-07-12 09:15:28.462204: Pseudo dice [np.float32(0.9533)] 
2025-07-12 09:15:28.463306: Epoch time: 68.22 s 
2025-07-12 09:15:29.324593:  
2025-07-12 09:15:29.326225: Epoch 870 
2025-07-12 09:15:29.327338: Current learning rate: 0.00159 
2025-07-12 09:16:37.524083: train_loss -0.982 
2025-07-12 09:16:37.525540: val_loss -0.9483 
2025-07-12 09:16:37.526758: Pseudo dice [np.float32(0.9519)] 
2025-07-12 09:16:37.527804: Epoch time: 68.2 s 
2025-07-12 09:16:38.416512:  
2025-07-12 09:16:38.417984: Epoch 871 
2025-07-12 09:16:38.419119: Current learning rate: 0.00158 
2025-07-12 09:17:46.662610: train_loss -0.9822 
2025-07-12 09:17:46.663919: val_loss -0.9513 
2025-07-12 09:17:46.665038: Pseudo dice [np.float32(0.9547)] 
2025-07-12 09:17:46.666032: Epoch time: 68.25 s 
2025-07-12 09:17:48.309463:  
2025-07-12 09:17:48.310917: Epoch 872 
2025-07-12 09:17:48.312100: Current learning rate: 0.00157 
2025-07-12 09:18:56.624041: train_loss -0.9822 
2025-07-12 09:18:56.625333: val_loss -0.947 
2025-07-12 09:18:56.626179: Pseudo dice [np.float32(0.951)] 
2025-07-12 09:18:56.627127: Epoch time: 68.32 s 
2025-07-12 09:18:57.507608:  
2025-07-12 09:18:57.509043: Epoch 873 
2025-07-12 09:18:57.510126: Current learning rate: 0.00156 
2025-07-12 09:20:05.903039: train_loss -0.9822 
2025-07-12 09:20:05.904382: val_loss -0.9477 
2025-07-12 09:20:05.905411: Pseudo dice [np.float32(0.9515)] 
2025-07-12 09:20:05.906420: Epoch time: 68.4 s 
2025-07-12 09:20:06.787654:  
2025-07-12 09:20:06.789182: Epoch 874 
2025-07-12 09:20:06.790261: Current learning rate: 0.00155 
2025-07-12 09:21:15.089856: train_loss -0.9823 
2025-07-12 09:21:15.091289: val_loss -0.9469 
2025-07-12 09:21:15.092321: Pseudo dice [np.float32(0.9509)] 
2025-07-12 09:21:15.093501: Epoch time: 68.31 s 
2025-07-12 09:21:15.972205:  
2025-07-12 09:21:15.973940: Epoch 875 
2025-07-12 09:21:15.975123: Current learning rate: 0.00154 
2025-07-12 09:22:24.351099: train_loss -0.9828 
2025-07-12 09:22:24.352439: val_loss -0.9485 
2025-07-12 09:22:24.353366: Pseudo dice [np.float32(0.9519)] 
2025-07-12 09:22:24.354313: Epoch time: 68.38 s 
2025-07-12 09:22:25.236594:  
2025-07-12 09:22:25.238209: Epoch 876 
2025-07-12 09:22:25.239323: Current learning rate: 0.00153 
2025-07-12 09:23:33.386127: train_loss -0.9825 
2025-07-12 09:23:33.387460: val_loss -0.9466 
2025-07-12 09:23:33.388535: Pseudo dice [np.float32(0.9506)] 
2025-07-12 09:23:33.389601: Epoch time: 68.15 s 
2025-07-12 09:23:34.270404:  
2025-07-12 09:23:34.272022: Epoch 877 
2025-07-12 09:23:34.273191: Current learning rate: 0.00152 
2025-07-12 09:24:42.666250: train_loss -0.9824 
2025-07-12 09:24:42.667508: val_loss -0.9495 
2025-07-12 09:24:42.668687: Pseudo dice [np.float32(0.953)] 
2025-07-12 09:24:42.669753: Epoch time: 68.4 s 
2025-07-12 09:24:43.556318:  
2025-07-12 09:24:43.557871: Epoch 878 
2025-07-12 09:24:43.559064: Current learning rate: 0.00151 
2025-07-12 09:25:53.391613: train_loss -0.9824 
2025-07-12 09:25:53.392889: val_loss -0.9521 
2025-07-12 09:25:53.394041: Pseudo dice [np.float32(0.9555)] 
2025-07-12 09:25:53.395170: Epoch time: 69.84 s 
2025-07-12 09:25:54.271158:  
2025-07-12 09:25:54.272949: Epoch 879 
2025-07-12 09:25:54.274103: Current learning rate: 0.00149 
2025-07-12 09:27:05.097806: train_loss -0.9824 
2025-07-12 09:27:05.098984: val_loss -0.9513 
2025-07-12 09:27:05.100204: Pseudo dice [np.float32(0.9543)] 
2025-07-12 09:27:05.101403: Epoch time: 70.83 s 
2025-07-12 09:27:05.983045:  
2025-07-12 09:27:05.984313: Epoch 880 
2025-07-12 09:27:05.985281: Current learning rate: 0.00148 
2025-07-12 09:28:13.850337: train_loss -0.9823 
2025-07-12 09:28:13.851713: val_loss -0.9525 
2025-07-12 09:28:13.852748: Pseudo dice [np.float32(0.9554)] 
2025-07-12 09:28:13.853867: Epoch time: 67.87 s 
2025-07-12 09:28:14.741179:  
2025-07-12 09:28:14.742812: Epoch 881 
2025-07-12 09:28:14.743997: Current learning rate: 0.00147 
2025-07-12 09:29:23.347147: train_loss -0.9822 
2025-07-12 09:29:23.348518: val_loss -0.9523 
2025-07-12 09:29:23.349618: Pseudo dice [np.float32(0.9554)] 
2025-07-12 09:29:23.350733: Epoch time: 68.61 s 
2025-07-12 09:29:24.208691:  
2025-07-12 09:29:24.210424: Epoch 882 
2025-07-12 09:29:24.211582: Current learning rate: 0.00146 
2025-07-12 09:30:32.233026: train_loss -0.9831 
2025-07-12 09:30:32.234438: val_loss -0.9484 
2025-07-12 09:30:32.235713: Pseudo dice [np.float32(0.9521)] 
2025-07-12 09:30:32.236842: Epoch time: 68.03 s 
2025-07-12 09:30:33.118269:  
2025-07-12 09:30:33.119574: Epoch 883 
2025-07-12 09:30:33.120671: Current learning rate: 0.00145 
2025-07-12 09:31:41.077937: train_loss -0.9828 
2025-07-12 09:31:41.079289: val_loss -0.9481 
2025-07-12 09:31:41.080353: Pseudo dice [np.float32(0.9509)] 
2025-07-12 09:31:41.081539: Epoch time: 67.96 s 
2025-07-12 09:31:41.965651:  
2025-07-12 09:31:41.967276: Epoch 884 
2025-07-12 09:31:41.968385: Current learning rate: 0.00144 
2025-07-12 09:32:50.208236: train_loss -0.9821 
2025-07-12 09:32:50.209420: val_loss -0.9519 
2025-07-12 09:32:50.210295: Pseudo dice [np.float32(0.9547)] 
2025-07-12 09:32:50.211279: Epoch time: 68.25 s 
2025-07-12 09:32:51.101075:  
2025-07-12 09:32:51.102664: Epoch 885 
2025-07-12 09:32:51.103856: Current learning rate: 0.00143 
2025-07-12 09:33:59.495409: train_loss -0.983 
2025-07-12 09:33:59.496687: val_loss -0.9499 
2025-07-12 09:33:59.497691: Pseudo dice [np.float32(0.9531)] 
2025-07-12 09:33:59.498844: Epoch time: 68.4 s 
2025-07-12 09:34:00.371365:  
2025-07-12 09:34:00.373152: Epoch 886 
2025-07-12 09:34:00.374314: Current learning rate: 0.00142 
2025-07-12 09:35:11.863142: train_loss -0.9828 
2025-07-12 09:35:11.864389: val_loss -0.9475 
2025-07-12 09:35:11.865474: Pseudo dice [np.float32(0.9512)] 
2025-07-12 09:35:11.866490: Epoch time: 71.5 s 
2025-07-12 09:35:12.759024:  
2025-07-12 09:35:12.760684: Epoch 887 
2025-07-12 09:35:12.761873: Current learning rate: 0.00141 
2025-07-12 09:36:24.289484: train_loss -0.9826 
2025-07-12 09:36:24.290893: val_loss -0.95 
2025-07-12 09:36:24.292050: Pseudo dice [np.float32(0.9534)] 
2025-07-12 09:36:24.293224: Epoch time: 71.53 s 
2025-07-12 09:36:25.179246:  
2025-07-12 09:36:25.180802: Epoch 888 
2025-07-12 09:36:25.181957: Current learning rate: 0.00139 
2025-07-12 09:37:32.542930: train_loss -0.9826 
2025-07-12 09:37:32.544383: val_loss -0.9488 
2025-07-12 09:37:32.545412: Pseudo dice [np.float32(0.9521)] 
2025-07-12 09:37:32.546522: Epoch time: 67.37 s 
2025-07-12 09:37:33.421539:  
2025-07-12 09:37:33.423058: Epoch 889 
2025-07-12 09:37:33.424151: Current learning rate: 0.00138 
2025-07-12 09:38:40.483077: train_loss -0.9828 
2025-07-12 09:38:40.484412: val_loss -0.947 
2025-07-12 09:38:40.485519: Pseudo dice [np.float32(0.95)] 
2025-07-12 09:38:40.486753: Epoch time: 67.07 s 
2025-07-12 09:38:41.373417:  
2025-07-12 09:38:41.375140: Epoch 890 
2025-07-12 09:38:41.376259: Current learning rate: 0.00137 
2025-07-12 09:39:49.095295: train_loss -0.9827 
2025-07-12 09:39:49.096660: val_loss -0.9468 
2025-07-12 09:39:49.097793: Pseudo dice [np.float32(0.9504)] 
2025-07-12 09:39:49.099138: Epoch time: 67.73 s 
2025-07-12 09:39:49.977774:  
2025-07-12 09:39:49.979539: Epoch 891 
2025-07-12 09:39:49.980812: Current learning rate: 0.00136 
2025-07-12 09:40:57.201383: train_loss -0.9821 
2025-07-12 09:40:57.202735: val_loss -0.9494 
2025-07-12 09:40:57.203944: Pseudo dice [np.float32(0.9523)] 
2025-07-12 09:40:57.205086: Epoch time: 67.23 s 
2025-07-12 09:40:58.083369:  
2025-07-12 09:40:58.084809: Epoch 892 
2025-07-12 09:40:58.085905: Current learning rate: 0.00135 
2025-07-12 09:42:05.669781: train_loss -0.9829 
2025-07-12 09:42:05.670934: val_loss -0.9493 
2025-07-12 09:42:05.672110: Pseudo dice [np.float32(0.953)] 
2025-07-12 09:42:05.673066: Epoch time: 67.59 s 
2025-07-12 09:42:06.553499:  
2025-07-12 09:42:06.555013: Epoch 893 
2025-07-12 09:42:06.556134: Current learning rate: 0.00134 
2025-07-12 09:43:14.177899: train_loss -0.9826 
2025-07-12 09:43:14.179065: val_loss -0.9485 
2025-07-12 09:43:14.180081: Pseudo dice [np.float32(0.952)] 
2025-07-12 09:43:14.181183: Epoch time: 67.63 s 
2025-07-12 09:43:15.059314:  
2025-07-12 09:43:15.060895: Epoch 894 
2025-07-12 09:43:15.062029: Current learning rate: 0.00133 
2025-07-12 09:44:22.905291: train_loss -0.9823 
2025-07-12 09:44:22.906712: val_loss -0.9442 
2025-07-12 09:44:22.907876: Pseudo dice [np.float32(0.9479)] 
2025-07-12 09:44:22.909233: Epoch time: 67.85 s 
2025-07-12 09:44:23.793330:  
2025-07-12 09:44:23.794726: Epoch 895 
2025-07-12 09:44:23.795972: Current learning rate: 0.00132 
2025-07-12 09:45:31.926155: train_loss -0.9825 
2025-07-12 09:45:31.927560: val_loss -0.948 
2025-07-12 09:45:31.928683: Pseudo dice [np.float32(0.9513)] 
2025-07-12 09:45:31.929770: Epoch time: 68.14 s 
2025-07-12 09:45:32.812156:  
2025-07-12 09:45:32.813678: Epoch 896 
2025-07-12 09:45:32.814723: Current learning rate: 0.0013 
2025-07-12 09:46:41.122831: train_loss -0.9826 
2025-07-12 09:46:41.124118: val_loss -0.9512 
2025-07-12 09:46:41.125225: Pseudo dice [np.float32(0.9544)] 
2025-07-12 09:46:41.126282: Epoch time: 68.31 s 
2025-07-12 09:46:42.006255:  
2025-07-12 09:46:42.007737: Epoch 897 
2025-07-12 09:46:42.008825: Current learning rate: 0.00129 
2025-07-12 09:47:50.448543: train_loss -0.9823 
2025-07-12 09:47:50.449814: val_loss -0.9491 
2025-07-12 09:47:50.450883: Pseudo dice [np.float32(0.952)] 
2025-07-12 09:47:50.451880: Epoch time: 68.45 s 
2025-07-12 09:47:51.326113:  
2025-07-12 09:47:51.327753: Epoch 898 
2025-07-12 09:47:51.328990: Current learning rate: 0.00128 
2025-07-12 09:48:59.609866: train_loss -0.9823 
2025-07-12 09:48:59.611361: val_loss -0.9475 
2025-07-12 09:48:59.612674: Pseudo dice [np.float32(0.9503)] 
2025-07-12 09:48:59.613711: Epoch time: 68.29 s 
2025-07-12 09:49:00.486425:  
2025-07-12 09:49:00.488165: Epoch 899 
2025-07-12 09:49:00.489302: Current learning rate: 0.00127 
2025-07-12 09:50:09.348537: train_loss -0.9823 
2025-07-12 09:50:09.349765: val_loss -0.9491 
2025-07-12 09:50:09.350774: Pseudo dice [np.float32(0.9525)] 
2025-07-12 09:50:09.351836: Epoch time: 68.87 s 
2025-07-12 09:50:11.469469:  
2025-07-12 09:50:11.471082: Epoch 900 
2025-07-12 09:50:11.472212: Current learning rate: 0.00126 
2025-07-12 09:51:19.555215: train_loss -0.9831 
2025-07-12 09:51:19.556647: val_loss -0.9499 
2025-07-12 09:51:19.557577: Pseudo dice [np.float32(0.9533)] 
2025-07-12 09:51:19.558459: Epoch time: 68.09 s 
2025-07-12 09:51:20.434817:  
2025-07-12 09:51:20.436646: Epoch 901 
2025-07-12 09:51:20.437813: Current learning rate: 0.00125 
2025-07-12 09:52:28.558496: train_loss -0.9825 
2025-07-12 09:52:28.559756: val_loss -0.9511 
2025-07-12 09:52:28.560909: Pseudo dice [np.float32(0.9539)] 
2025-07-12 09:52:28.562214: Epoch time: 68.13 s 
2025-07-12 09:52:29.437164:  
2025-07-12 09:52:29.438867: Epoch 902 
2025-07-12 09:52:29.439989: Current learning rate: 0.00124 
2025-07-12 09:53:37.566602: train_loss -0.983 
2025-07-12 09:53:37.567852: val_loss -0.9493 
2025-07-12 09:53:37.568956: Pseudo dice [np.float32(0.9527)] 
2025-07-12 09:53:37.570272: Epoch time: 68.13 s 
2025-07-12 09:53:38.446401:  
2025-07-12 09:53:38.448029: Epoch 903 
2025-07-12 09:53:38.449155: Current learning rate: 0.00122 
2025-07-12 09:54:46.637053: train_loss -0.9825 
2025-07-12 09:54:46.638386: val_loss -0.9482 
2025-07-12 09:54:46.639489: Pseudo dice [np.float32(0.9512)] 
2025-07-12 09:54:46.640612: Epoch time: 68.19 s 
2025-07-12 09:54:47.523434:  
2025-07-12 09:54:47.524775: Epoch 904 
2025-07-12 09:54:47.525883: Current learning rate: 0.00121 
2025-07-12 09:55:56.700669: train_loss -0.9832 
2025-07-12 09:55:56.702035: val_loss -0.9496 
2025-07-12 09:55:56.702980: Pseudo dice [np.float32(0.9525)] 
2025-07-12 09:55:56.704143: Epoch time: 69.18 s 
2025-07-12 09:55:57.579683:  
2025-07-12 09:55:57.581291: Epoch 905 
2025-07-12 09:55:57.582405: Current learning rate: 0.0012 
2025-07-12 09:57:05.867344: train_loss -0.9828 
2025-07-12 09:57:05.868577: val_loss -0.9472 
2025-07-12 09:57:05.869753: Pseudo dice [np.float32(0.9492)] 
2025-07-12 09:57:05.870855: Epoch time: 68.29 s 
2025-07-12 09:57:06.756870:  
2025-07-12 09:57:06.758454: Epoch 906 
2025-07-12 09:57:06.759604: Current learning rate: 0.00119 
2025-07-12 09:58:13.892507: train_loss -0.9827 
2025-07-12 09:58:13.893834: val_loss -0.9461 
2025-07-12 09:58:13.894685: Pseudo dice [np.float32(0.9493)] 
2025-07-12 09:58:13.895626: Epoch time: 67.14 s 
2025-07-12 09:58:14.782578:  
2025-07-12 09:58:14.784349: Epoch 907 
2025-07-12 09:58:14.785517: Current learning rate: 0.00118 
2025-07-12 09:59:21.951248: train_loss -0.9826 
2025-07-12 09:59:21.952727: val_loss -0.9505 
2025-07-12 09:59:21.953796: Pseudo dice [np.float32(0.9536)] 
2025-07-12 09:59:21.954914: Epoch time: 67.17 s 
2025-07-12 09:59:22.831137:  
2025-07-12 09:59:22.832739: Epoch 908 
2025-07-12 09:59:22.833751: Current learning rate: 0.00117 
2025-07-12 10:00:30.637158: train_loss -0.9832 
2025-07-12 10:00:30.638638: val_loss -0.9477 
2025-07-12 10:00:30.639647: Pseudo dice [np.float32(0.9518)] 
2025-07-12 10:00:30.640734: Epoch time: 67.81 s 
2025-07-12 10:00:31.525120:  
2025-07-12 10:00:31.526263: Epoch 909 
2025-07-12 10:00:31.527404: Current learning rate: 0.00116 
2025-07-12 10:01:38.911139: train_loss -0.9826 
2025-07-12 10:01:38.912489: val_loss -0.9499 
2025-07-12 10:01:38.913534: Pseudo dice [np.float32(0.9531)] 
2025-07-12 10:01:38.914652: Epoch time: 67.39 s 
2025-07-12 10:01:39.808369:  
2025-07-12 10:01:39.810000: Epoch 910 
2025-07-12 10:01:39.811096: Current learning rate: 0.00115 
2025-07-12 10:02:47.320076: train_loss -0.9829 
2025-07-12 10:02:47.321360: val_loss -0.951 
2025-07-12 10:02:47.322627: Pseudo dice [np.float32(0.9545)] 
2025-07-12 10:02:47.323826: Epoch time: 67.52 s 
2025-07-12 10:02:48.199025:  
2025-07-12 10:02:48.200316: Epoch 911 
2025-07-12 10:02:48.201430: Current learning rate: 0.00113 
2025-07-12 10:03:55.929965: train_loss -0.9826 
2025-07-12 10:03:55.932319: val_loss -0.9536 
2025-07-12 10:03:55.933775: Pseudo dice [np.float32(0.9575)] 
2025-07-12 10:03:55.934715: Epoch time: 67.73 s 
2025-07-12 10:03:56.811014:  
2025-07-12 10:03:56.812356: Epoch 912 
2025-07-12 10:03:56.814036: Current learning rate: 0.00112 
2025-07-12 10:05:04.823958: train_loss -0.9825 
2025-07-12 10:05:04.825325: val_loss -0.9488 
2025-07-12 10:05:04.826479: Pseudo dice [np.float32(0.9524)] 
2025-07-12 10:05:04.827578: Epoch time: 68.02 s 
2025-07-12 10:05:05.690239:  
2025-07-12 10:05:05.691809: Epoch 913 
2025-07-12 10:05:05.692917: Current learning rate: 0.00111 
2025-07-12 10:06:13.836969: train_loss -0.9829 
2025-07-12 10:06:13.838363: val_loss -0.9464 
2025-07-12 10:06:13.839467: Pseudo dice [np.float32(0.9489)] 
2025-07-12 10:06:13.840687: Epoch time: 68.15 s 
2025-07-12 10:06:14.726501:  
2025-07-12 10:06:14.728142: Epoch 914 
2025-07-12 10:06:14.729238: Current learning rate: 0.0011 
2025-07-12 10:07:28.478627: train_loss -0.9839 
2025-07-12 10:07:28.479902: val_loss -0.9507 
2025-07-12 10:07:28.481025: Pseudo dice [np.float32(0.954)] 
2025-07-12 10:07:28.482178: Epoch time: 73.76 s 
2025-07-12 10:07:29.357671:  
2025-07-12 10:07:29.359411: Epoch 915 
2025-07-12 10:07:29.360520: Current learning rate: 0.00109 
2025-07-12 10:08:41.202132: train_loss -0.9831 
2025-07-12 10:08:41.203253: val_loss -0.9488 
2025-07-12 10:08:41.204536: Pseudo dice [np.float32(0.9518)] 
2025-07-12 10:08:41.205659: Epoch time: 71.85 s 
2025-07-12 10:08:42.076322:  
2025-07-12 10:08:42.077932: Epoch 916 
2025-07-12 10:08:42.079089: Current learning rate: 0.00108 
2025-07-12 10:09:49.225974: train_loss -0.983 
2025-07-12 10:09:49.227433: val_loss -0.9501 
2025-07-12 10:09:49.228555: Pseudo dice [np.float32(0.953)] 
2025-07-12 10:09:49.229669: Epoch time: 67.15 s 
2025-07-12 10:09:50.090744:  
2025-07-12 10:09:50.092378: Epoch 917 
2025-07-12 10:09:50.093644: Current learning rate: 0.00106 
2025-07-12 10:10:57.855366: train_loss -0.9833 
2025-07-12 10:10:57.856694: val_loss -0.9503 
2025-07-12 10:10:57.857749: Pseudo dice [np.float32(0.9533)] 
2025-07-12 10:10:57.858751: Epoch time: 67.77 s 
2025-07-12 10:10:58.739173:  
2025-07-12 10:10:58.740743: Epoch 918 
2025-07-12 10:10:58.741886: Current learning rate: 0.00105 
2025-07-12 10:12:05.788944: train_loss -0.9836 
2025-07-12 10:12:05.790148: val_loss -0.9525 
2025-07-12 10:12:05.791158: Pseudo dice [np.float32(0.9553)] 
2025-07-12 10:12:05.792108: Epoch time: 67.05 s 
2025-07-12 10:12:06.673579:  
2025-07-12 10:12:06.675135: Epoch 919 
2025-07-12 10:12:06.676228: Current learning rate: 0.00104 
2025-07-12 10:13:13.836684: train_loss -0.983 
2025-07-12 10:13:13.838098: val_loss -0.9506 
2025-07-12 10:13:13.839035: Pseudo dice [np.float32(0.9531)] 
2025-07-12 10:13:13.840219: Epoch time: 67.17 s 
2025-07-12 10:13:14.729458:  
2025-07-12 10:13:14.731001: Epoch 920 
2025-07-12 10:13:14.732044: Current learning rate: 0.00103 
2025-07-12 10:14:22.129001: train_loss -0.9839 
2025-07-12 10:14:22.130373: val_loss -0.9461 
2025-07-12 10:14:22.131548: Pseudo dice [np.float32(0.9495)] 
2025-07-12 10:14:22.132440: Epoch time: 67.4 s 
2025-07-12 10:14:23.007871:  
2025-07-12 10:14:23.009280: Epoch 921 
2025-07-12 10:14:23.010395: Current learning rate: 0.00102 
2025-07-12 10:15:30.457897: train_loss -0.9833 
2025-07-12 10:15:30.459128: val_loss -0.9501 
2025-07-12 10:15:30.460395: Pseudo dice [np.float32(0.9531)] 
2025-07-12 10:15:30.461445: Epoch time: 67.45 s 
2025-07-12 10:15:31.342900:  
2025-07-12 10:15:31.344233: Epoch 922 
2025-07-12 10:15:31.345365: Current learning rate: 0.00101 
2025-07-12 10:16:39.096442: train_loss -0.9836 
2025-07-12 10:16:39.097654: val_loss -0.9478 
2025-07-12 10:16:39.098631: Pseudo dice [np.float32(0.9515)] 
2025-07-12 10:16:39.099750: Epoch time: 67.76 s 
2025-07-12 10:16:39.982822:  
2025-07-12 10:16:39.984814: Epoch 923 
2025-07-12 10:16:39.985937: Current learning rate: 0.001 
2025-07-12 10:17:47.999740: train_loss -0.9838 
2025-07-12 10:17:48.001200: val_loss -0.9524 
2025-07-12 10:17:48.002378: Pseudo dice [np.float32(0.9553)] 
2025-07-12 10:17:48.003624: Epoch time: 68.02 s 
2025-07-12 10:17:48.888928:  
2025-07-12 10:17:48.890521: Epoch 924 
2025-07-12 10:17:48.891667: Current learning rate: 0.00098 
2025-07-12 10:18:56.948358: train_loss -0.9832 
2025-07-12 10:18:56.949678: val_loss -0.9498 
2025-07-12 10:18:56.950879: Pseudo dice [np.float32(0.9531)] 
2025-07-12 10:18:56.952009: Epoch time: 68.06 s 
2025-07-12 10:18:57.828929:  
2025-07-12 10:18:57.830311: Epoch 925 
2025-07-12 10:18:57.831400: Current learning rate: 0.00097 
2025-07-12 10:20:05.922195: train_loss -0.9833 
2025-07-12 10:20:05.923717: val_loss -0.953 
2025-07-12 10:20:05.924889: Pseudo dice [np.float32(0.9563)] 
2025-07-12 10:20:05.925957: Epoch time: 68.1 s 
2025-07-12 10:20:06.803412:  
2025-07-12 10:20:06.805685: Epoch 926 
2025-07-12 10:20:06.806830: Current learning rate: 0.00096 
2025-07-12 10:21:15.817533: train_loss -0.9835 
2025-07-12 10:21:15.819114: val_loss -0.9473 
2025-07-12 10:21:15.820334: Pseudo dice [np.float32(0.9507)] 
2025-07-12 10:21:15.821487: Epoch time: 69.02 s 
2025-07-12 10:21:16.683017:  
2025-07-12 10:21:16.684764: Epoch 927 
2025-07-12 10:21:16.685816: Current learning rate: 0.00095 
2025-07-12 10:22:24.854425: train_loss -0.9831 
2025-07-12 10:22:24.855744: val_loss -0.949 
2025-07-12 10:22:24.856739: Pseudo dice [np.float32(0.952)] 
2025-07-12 10:22:24.857835: Epoch time: 68.17 s 
2025-07-12 10:22:25.741692:  
2025-07-12 10:22:25.743629: Epoch 928 
2025-07-12 10:22:25.744858: Current learning rate: 0.00094 
2025-07-12 10:23:34.125005: train_loss -0.9832 
2025-07-12 10:23:34.126477: val_loss -0.9501 
2025-07-12 10:23:34.127689: Pseudo dice [np.float32(0.953)] 
2025-07-12 10:23:34.128808: Epoch time: 68.39 s 
2025-07-12 10:23:35.016391:  
2025-07-12 10:23:35.018129: Epoch 929 
2025-07-12 10:23:35.019372: Current learning rate: 0.00092 
2025-07-12 10:24:43.300864: train_loss -0.9834 
2025-07-12 10:24:43.302131: val_loss -0.9509 
2025-07-12 10:24:43.303239: Pseudo dice [np.float32(0.9537)] 
2025-07-12 10:24:43.304226: Epoch time: 68.29 s 
2025-07-12 10:24:44.183624:  
2025-07-12 10:24:44.185239: Epoch 930 
2025-07-12 10:24:44.186347: Current learning rate: 0.00091 
2025-07-12 10:25:52.447668: train_loss -0.9829 
2025-07-12 10:25:52.449141: val_loss -0.9491 
2025-07-12 10:25:52.450141: Pseudo dice [np.float32(0.9524)] 
2025-07-12 10:25:52.451347: Epoch time: 68.27 s 
2025-07-12 10:25:53.316734:  
2025-07-12 10:25:53.318496: Epoch 931 
2025-07-12 10:25:53.319720: Current learning rate: 0.0009 
2025-07-12 10:27:01.531116: train_loss -0.9834 
2025-07-12 10:27:01.532458: val_loss -0.9497 
2025-07-12 10:27:01.533511: Pseudo dice [np.float32(0.9518)] 
2025-07-12 10:27:01.534527: Epoch time: 68.22 s 
2025-07-12 10:27:02.419661:  
2025-07-12 10:27:02.421237: Epoch 932 
2025-07-12 10:27:02.422379: Current learning rate: 0.00089 
2025-07-12 10:28:10.601253: train_loss -0.9834 
2025-07-12 10:28:10.602628: val_loss -0.9511 
2025-07-12 10:28:10.603766: Pseudo dice [np.float32(0.954)] 
2025-07-12 10:28:10.604869: Epoch time: 68.19 s 
2025-07-12 10:28:11.487244:  
2025-07-12 10:28:11.488938: Epoch 933 
2025-07-12 10:28:11.489991: Current learning rate: 0.00088 
2025-07-12 10:29:19.628006: train_loss -0.9833 
2025-07-12 10:29:19.629268: val_loss -0.9511 
2025-07-12 10:29:19.630326: Pseudo dice [np.float32(0.9542)] 
2025-07-12 10:29:19.631212: Epoch time: 68.14 s 
2025-07-12 10:29:20.510148:  
2025-07-12 10:29:20.511570: Epoch 934 
2025-07-12 10:29:20.512676: Current learning rate: 0.00087 
2025-07-12 10:30:28.852846: train_loss -0.983 
2025-07-12 10:30:28.853986: val_loss -0.9493 
2025-07-12 10:30:28.855000: Pseudo dice [np.float32(0.9524)] 
2025-07-12 10:30:28.855812: Epoch time: 68.35 s 
2025-07-12 10:30:29.739238:  
2025-07-12 10:30:29.740758: Epoch 935 
2025-07-12 10:30:29.741841: Current learning rate: 0.00085 
2025-07-12 10:31:38.644106: train_loss -0.983 
2025-07-12 10:31:38.645304: val_loss -0.9458 
2025-07-12 10:31:38.646389: Pseudo dice [np.float32(0.9497)] 
2025-07-12 10:31:38.647357: Epoch time: 68.91 s 
2025-07-12 10:31:39.530279:  
2025-07-12 10:31:39.532009: Epoch 936 
2025-07-12 10:31:39.533304: Current learning rate: 0.00084 
2025-07-12 10:32:47.640456: train_loss -0.9837 
2025-07-12 10:32:47.641720: val_loss -0.9523 
2025-07-12 10:32:47.642765: Pseudo dice [np.float32(0.9553)] 
2025-07-12 10:32:47.643720: Epoch time: 68.11 s 
2025-07-12 10:32:48.524364:  
2025-07-12 10:32:48.525934: Epoch 937 
2025-07-12 10:32:48.527216: Current learning rate: 0.00083 
2025-07-12 10:33:56.589719: train_loss -0.9834 
2025-07-12 10:33:56.591211: val_loss -0.9469 
2025-07-12 10:33:56.592160: Pseudo dice [np.float32(0.9502)] 
2025-07-12 10:33:56.593127: Epoch time: 68.07 s 
2025-07-12 10:33:57.471624:  
2025-07-12 10:33:57.473162: Epoch 938 
2025-07-12 10:33:57.474481: Current learning rate: 0.00082 
2025-07-12 10:35:05.713110: train_loss -0.9839 
2025-07-12 10:35:05.714586: val_loss -0.9515 
2025-07-12 10:35:05.715658: Pseudo dice [np.float32(0.9542)] 
2025-07-12 10:35:05.716828: Epoch time: 68.24 s 
2025-07-12 10:35:06.595796:  
2025-07-12 10:35:06.597266: Epoch 939 
2025-07-12 10:35:06.598434: Current learning rate: 0.00081 
2025-07-12 10:36:14.763491: train_loss -0.9834 
2025-07-12 10:36:14.764821: val_loss -0.948 
2025-07-12 10:36:14.765774: Pseudo dice [np.float32(0.951)] 
2025-07-12 10:36:14.766867: Epoch time: 68.17 s 
2025-07-12 10:36:15.649145:  
2025-07-12 10:36:15.650817: Epoch 940 
2025-07-12 10:36:15.652007: Current learning rate: 0.00079 
2025-07-12 10:37:23.960177: train_loss -0.9837 
2025-07-12 10:37:23.961388: val_loss -0.9476 
2025-07-12 10:37:23.962499: Pseudo dice [np.float32(0.9505)] 
2025-07-12 10:37:23.963567: Epoch time: 68.31 s 
2025-07-12 10:37:24.836320:  
2025-07-12 10:37:24.837952: Epoch 941 
2025-07-12 10:37:24.839016: Current learning rate: 0.00078 
2025-07-12 10:38:33.188476: train_loss -0.9829 
2025-07-12 10:38:33.189936: val_loss -0.949 
2025-07-12 10:38:33.191139: Pseudo dice [np.float32(0.9525)] 
2025-07-12 10:38:33.192240: Epoch time: 68.36 s 
2025-07-12 10:38:34.057016:  
2025-07-12 10:38:34.058739: Epoch 942 
2025-07-12 10:38:34.059955: Current learning rate: 0.00077 
2025-07-12 10:39:42.401970: train_loss -0.9836 
2025-07-12 10:39:42.403461: val_loss -0.9509 
2025-07-12 10:39:42.404733: Pseudo dice [np.float32(0.9537)] 
2025-07-12 10:39:42.405690: Epoch time: 68.35 s 
2025-07-12 10:39:43.283957:  
2025-07-12 10:39:43.285256: Epoch 943 
2025-07-12 10:39:43.286334: Current learning rate: 0.00076 
2025-07-12 10:40:51.607890: train_loss -0.983 
2025-07-12 10:40:51.609341: val_loss -0.95 
2025-07-12 10:40:51.610457: Pseudo dice [np.float32(0.9538)] 
2025-07-12 10:40:51.611651: Epoch time: 68.33 s 
2025-07-12 10:40:52.510821:  
2025-07-12 10:40:52.512320: Epoch 944 
2025-07-12 10:40:52.513372: Current learning rate: 0.00075 
2025-07-12 10:42:01.529731: train_loss -0.9837 
2025-07-12 10:42:01.530917: val_loss -0.9443 
2025-07-12 10:42:01.532221: Pseudo dice [np.float32(0.9481)] 
2025-07-12 10:42:01.533379: Epoch time: 69.02 s 
2025-07-12 10:42:02.413599:  
2025-07-12 10:42:02.415182: Epoch 945 
2025-07-12 10:42:02.416806: Current learning rate: 0.00074 
2025-07-12 10:43:10.651291: train_loss -0.983 
2025-07-12 10:43:10.652530: val_loss -0.9504 
2025-07-12 10:43:10.653597: Pseudo dice [np.float32(0.953)] 
2025-07-12 10:43:10.654714: Epoch time: 68.24 s 
2025-07-12 10:43:11.533708:  
2025-07-12 10:43:11.535146: Epoch 946 
2025-07-12 10:43:11.536335: Current learning rate: 0.00072 
2025-07-12 10:44:19.561449: train_loss -0.9832 
2025-07-12 10:44:19.562730: val_loss -0.9515 
2025-07-12 10:44:19.563815: Pseudo dice [np.float32(0.9545)] 
2025-07-12 10:44:19.564881: Epoch time: 68.03 s 
2025-07-12 10:44:20.442342:  
2025-07-12 10:44:20.443916: Epoch 947 
2025-07-12 10:44:20.445071: Current learning rate: 0.00071 
2025-07-12 10:45:29.000200: train_loss -0.9841 
2025-07-12 10:45:29.001616: val_loss -0.9501 
2025-07-12 10:45:29.002480: Pseudo dice [np.float32(0.9525)] 
2025-07-12 10:45:29.003469: Epoch time: 68.56 s 
2025-07-12 10:45:29.884378:  
2025-07-12 10:45:29.886167: Epoch 948 
2025-07-12 10:45:29.887295: Current learning rate: 0.0007 
2025-07-12 10:46:38.110744: train_loss -0.9838 
2025-07-12 10:46:38.112032: val_loss -0.9508 
2025-07-12 10:46:38.113099: Pseudo dice [np.float32(0.9535)] 
2025-07-12 10:46:38.114353: Epoch time: 68.23 s 
2025-07-12 10:46:39.003412:  
2025-07-12 10:46:39.004919: Epoch 949 
2025-07-12 10:46:39.005970: Current learning rate: 0.00069 
2025-07-12 10:47:48.564209: train_loss -0.9839 
2025-07-12 10:47:48.565599: val_loss -0.9497 
2025-07-12 10:47:48.566714: Pseudo dice [np.float32(0.9529)] 
2025-07-12 10:47:48.567798: Epoch time: 69.56 s 
2025-07-12 10:47:50.495740:  
2025-07-12 10:47:50.497179: Epoch 950 
2025-07-12 10:47:50.498315: Current learning rate: 0.00067 
2025-07-12 10:49:01.772079: train_loss -0.9842 
2025-07-12 10:49:01.773386: val_loss -0.9491 
2025-07-12 10:49:01.774536: Pseudo dice [np.float32(0.9522)] 
2025-07-12 10:49:01.775557: Epoch time: 71.28 s 
2025-07-12 10:49:02.646649:  
2025-07-12 10:49:02.648118: Epoch 951 
2025-07-12 10:49:02.649413: Current learning rate: 0.00066 
2025-07-12 10:50:10.714833: train_loss -0.9835 
2025-07-12 10:50:10.716131: val_loss -0.9507 
2025-07-12 10:50:10.717279: Pseudo dice [np.float32(0.9541)] 
2025-07-12 10:50:10.718425: Epoch time: 68.07 s 
2025-07-12 10:50:11.600699:  
2025-07-12 10:50:11.602349: Epoch 952 
2025-07-12 10:50:11.603628: Current learning rate: 0.00065 
2025-07-12 10:51:19.666441: train_loss -0.9838 
2025-07-12 10:51:19.667702: val_loss -0.9489 
2025-07-12 10:51:19.668799: Pseudo dice [np.float32(0.9513)] 
2025-07-12 10:51:19.670048: Epoch time: 68.07 s 
2025-07-12 10:51:20.541950:  
2025-07-12 10:51:20.543792: Epoch 953 
2025-07-12 10:51:20.544932: Current learning rate: 0.00064 
2025-07-12 10:52:29.304093: train_loss -0.9841 
2025-07-12 10:52:29.305277: val_loss -0.9492 
2025-07-12 10:52:29.306484: Pseudo dice [np.float32(0.9522)] 
2025-07-12 10:52:29.307641: Epoch time: 68.77 s 
2025-07-12 10:52:30.190681:  
2025-07-12 10:52:30.192321: Epoch 954 
2025-07-12 10:52:30.193433: Current learning rate: 0.00063 
2025-07-12 10:53:38.512805: train_loss -0.9842 
2025-07-12 10:53:38.514155: val_loss -0.9526 
2025-07-12 10:53:38.515337: Pseudo dice [np.float32(0.9561)] 
2025-07-12 10:53:38.516394: Epoch time: 68.33 s 
2025-07-12 10:53:39.406899:  
2025-07-12 10:53:39.408675: Epoch 955 
2025-07-12 10:53:39.410788: Current learning rate: 0.00061 
2025-07-12 10:54:47.747727: train_loss -0.9837 
2025-07-12 10:54:47.749064: val_loss -0.9495 
2025-07-12 10:54:47.750232: Pseudo dice [np.float32(0.9529)] 
2025-07-12 10:54:47.751519: Epoch time: 68.34 s 
2025-07-12 10:54:48.661448:  
2025-07-12 10:54:48.662908: Epoch 956 
2025-07-12 10:54:48.664074: Current learning rate: 0.0006 
2025-07-12 10:55:56.887777: train_loss -0.9843 
2025-07-12 10:55:56.889118: val_loss -0.9539 
2025-07-12 10:55:56.890228: Pseudo dice [np.float32(0.9563)] 
2025-07-12 10:55:56.891251: Epoch time: 68.23 s 
2025-07-12 10:55:57.795213:  
2025-07-12 10:55:57.797007: Epoch 957 
2025-07-12 10:55:57.798204: Current learning rate: 0.00059 
2025-07-12 10:57:05.836963: train_loss -0.9832 
2025-07-12 10:57:05.838204: val_loss -0.9495 
2025-07-12 10:57:05.839295: Pseudo dice [np.float32(0.9524)] 
2025-07-12 10:57:05.840478: Epoch time: 68.05 s 
2025-07-12 10:57:06.743356:  
2025-07-12 10:57:06.745193: Epoch 958 
2025-07-12 10:57:06.746344: Current learning rate: 0.00058 
2025-07-12 10:58:14.692677: train_loss -0.9839 
2025-07-12 10:58:14.694204: val_loss -0.9465 
2025-07-12 10:58:14.695189: Pseudo dice [np.float32(0.9497)] 
2025-07-12 10:58:14.696402: Epoch time: 67.95 s 
2025-07-12 10:58:15.576975:  
2025-07-12 10:58:15.578786: Epoch 959 
2025-07-12 10:58:15.580012: Current learning rate: 0.00056 
2025-07-12 10:59:23.445332: train_loss -0.984 
2025-07-12 10:59:23.446656: val_loss -0.9504 
2025-07-12 10:59:23.447870: Pseudo dice [np.float32(0.9532)] 
2025-07-12 10:59:23.449186: Epoch time: 67.87 s 
2025-07-12 10:59:24.344611:  
2025-07-12 10:59:24.346219: Epoch 960 
2025-07-12 10:59:24.347564: Current learning rate: 0.00055 
2025-07-12 11:00:32.310168: train_loss -0.9839 
2025-07-12 11:00:32.311862: val_loss -0.9501 
2025-07-12 11:00:32.313166: Pseudo dice [np.float32(0.9532)] 
2025-07-12 11:00:32.314161: Epoch time: 67.97 s 
2025-07-12 11:00:33.202642:  
2025-07-12 11:00:33.204359: Epoch 961 
2025-07-12 11:00:33.205577: Current learning rate: 0.00054 
2025-07-12 11:01:40.713506: train_loss -0.9836 
2025-07-12 11:01:40.714987: val_loss -0.9517 
2025-07-12 11:01:40.716268: Pseudo dice [np.float32(0.9547)] 
2025-07-12 11:01:40.717534: Epoch time: 67.51 s 
2025-07-12 11:01:41.600061:  
2025-07-12 11:01:41.601793: Epoch 962 
2025-07-12 11:01:41.602969: Current learning rate: 0.00053 
2025-07-12 11:02:49.773930: train_loss -0.9842 
2025-07-12 11:02:49.775172: val_loss -0.9519 
2025-07-12 11:02:49.776088: Pseudo dice [np.float32(0.9546)] 
2025-07-12 11:02:49.777210: Epoch time: 68.18 s 
2025-07-12 11:02:50.667176:  
2025-07-12 11:02:50.668495: Epoch 963 
2025-07-12 11:02:50.669528: Current learning rate: 0.00051 
2025-07-12 11:03:58.070183: train_loss -0.9842 
2025-07-12 11:03:58.071525: val_loss -0.9489 
2025-07-12 11:03:58.072534: Pseudo dice [np.float32(0.9519)] 
2025-07-12 11:03:58.073471: Epoch time: 67.41 s 
2025-07-12 11:03:58.968277:  
2025-07-12 11:03:58.970022: Epoch 964 
2025-07-12 11:03:58.971280: Current learning rate: 0.0005 
2025-07-12 11:05:06.233312: train_loss -0.9831 
2025-07-12 11:05:06.234673: val_loss -0.9489 
2025-07-12 11:05:06.235849: Pseudo dice [np.float32(0.9514)] 
2025-07-12 11:05:06.236991: Epoch time: 67.27 s 
2025-07-12 11:05:07.127916:  
2025-07-12 11:05:07.129681: Epoch 965 
2025-07-12 11:05:07.130842: Current learning rate: 0.00049 
2025-07-12 11:06:14.508442: train_loss -0.9832 
2025-07-12 11:06:14.509645: val_loss -0.9466 
2025-07-12 11:06:14.510810: Pseudo dice [np.float32(0.9505)] 
2025-07-12 11:06:14.511775: Epoch time: 67.38 s 
2025-07-12 11:06:15.406281:  
2025-07-12 11:06:15.408058: Epoch 966 
2025-07-12 11:06:15.409142: Current learning rate: 0.00048 
2025-07-12 11:07:22.924738: train_loss -0.9839 
2025-07-12 11:07:22.926000: val_loss -0.949 
2025-07-12 11:07:22.926922: Pseudo dice [np.float32(0.9524)] 
2025-07-12 11:07:22.928224: Epoch time: 67.52 s 
2025-07-12 11:07:23.818782:  
2025-07-12 11:07:23.820496: Epoch 967 
2025-07-12 11:07:23.821936: Current learning rate: 0.00046 
2025-07-12 11:08:31.045213: train_loss -0.9842 
2025-07-12 11:08:31.046580: val_loss -0.9479 
2025-07-12 11:08:31.047559: Pseudo dice [np.float32(0.9518)] 
2025-07-12 11:08:31.048802: Epoch time: 67.23 s 
2025-07-12 11:08:31.952017:  
2025-07-12 11:08:31.953906: Epoch 968 
2025-07-12 11:08:31.955235: Current learning rate: 0.00045 
2025-07-12 11:09:39.338081: train_loss -0.9841 
2025-07-12 11:09:39.340523: val_loss -0.9492 
2025-07-12 11:09:39.341782: Pseudo dice [np.float32(0.953)] 
2025-07-12 11:09:39.343010: Epoch time: 67.39 s 
2025-07-12 11:09:40.238304:  
2025-07-12 11:09:40.240100: Epoch 969 
2025-07-12 11:09:40.241188: Current learning rate: 0.00044 
2025-07-12 11:10:47.634387: train_loss -0.9841 
2025-07-12 11:10:47.635785: val_loss -0.95 
2025-07-12 11:10:47.637083: Pseudo dice [np.float32(0.9532)] 
2025-07-12 11:10:47.638183: Epoch time: 67.4 s 
2025-07-12 11:10:48.531330:  
2025-07-12 11:10:48.533026: Epoch 970 
2025-07-12 11:10:48.534092: Current learning rate: 0.00043 
2025-07-12 11:11:56.032344: train_loss -0.9844 
2025-07-12 11:11:56.033675: val_loss -0.9493 
2025-07-12 11:11:56.034611: Pseudo dice [np.float32(0.9525)] 
2025-07-12 11:11:56.035754: Epoch time: 67.5 s 
2025-07-12 11:11:56.941056:  
2025-07-12 11:11:56.942843: Epoch 971 
2025-07-12 11:11:56.944040: Current learning rate: 0.00041 
2025-07-12 11:13:05.094165: train_loss -0.984 
2025-07-12 11:13:05.095551: val_loss -0.9465 
2025-07-12 11:13:05.096434: Pseudo dice [np.float32(0.9494)] 
2025-07-12 11:13:05.097716: Epoch time: 68.16 s 
2025-07-12 11:13:05.991539:  
2025-07-12 11:13:05.993334: Epoch 972 
2025-07-12 11:13:05.994408: Current learning rate: 0.0004 
2025-07-12 11:14:13.574784: train_loss -0.9845 
2025-07-12 11:14:13.576324: val_loss -0.9511 
2025-07-12 11:14:13.577669: Pseudo dice [np.float32(0.954)] 
2025-07-12 11:14:13.578749: Epoch time: 67.59 s 
2025-07-12 11:14:14.483834:  
2025-07-12 11:14:14.485944: Epoch 973 
2025-07-12 11:14:14.487154: Current learning rate: 0.00039 
2025-07-12 11:15:22.360022: train_loss -0.9839 
2025-07-12 11:15:22.361245: val_loss -0.9511 
2025-07-12 11:15:22.362346: Pseudo dice [np.float32(0.9543)] 
2025-07-12 11:15:22.363410: Epoch time: 67.88 s 
2025-07-12 11:15:23.262471:  
2025-07-12 11:15:23.263853: Epoch 974 
2025-07-12 11:15:23.264978: Current learning rate: 0.00037 
2025-07-12 11:16:31.015034: train_loss -0.9841 
2025-07-12 11:16:31.016234: val_loss -0.9502 
2025-07-12 11:16:31.017426: Pseudo dice [np.float32(0.9532)] 
2025-07-12 11:16:31.018430: Epoch time: 67.76 s 
2025-07-12 11:16:31.913725:  
2025-07-12 11:16:31.915326: Epoch 975 
2025-07-12 11:16:31.916443: Current learning rate: 0.00036 
2025-07-12 11:17:39.538665: train_loss -0.9842 
2025-07-12 11:17:39.540159: val_loss -0.9498 
2025-07-12 11:17:39.541394: Pseudo dice [np.float32(0.9529)] 
2025-07-12 11:17:39.542734: Epoch time: 67.63 s 
2025-07-12 11:17:40.441558:  
2025-07-12 11:17:40.443125: Epoch 976 
2025-07-12 11:17:40.444522: Current learning rate: 0.00035 
2025-07-12 11:18:48.047675: train_loss -0.984 
2025-07-12 11:18:48.048944: val_loss -0.9505 
2025-07-12 11:18:48.050237: Pseudo dice [np.float32(0.9534)] 
2025-07-12 11:18:48.051312: Epoch time: 67.61 s 
2025-07-12 11:18:48.950827:  
2025-07-12 11:18:48.952412: Epoch 977 
2025-07-12 11:18:48.953568: Current learning rate: 0.00034 
2025-07-12 11:19:56.310292: train_loss -0.9841 
2025-07-12 11:19:56.311632: val_loss -0.9512 
2025-07-12 11:19:56.312988: Pseudo dice [np.float32(0.9538)] 
2025-07-12 11:19:56.314209: Epoch time: 67.36 s 
2025-07-12 11:19:57.215908:  
2025-07-12 11:19:57.217517: Epoch 978 
2025-07-12 11:19:57.218748: Current learning rate: 0.00032 
2025-07-12 11:21:04.594168: train_loss -0.9842 
2025-07-12 11:21:04.595658: val_loss -0.9495 
2025-07-12 11:21:04.596814: Pseudo dice [np.float32(0.9522)] 
2025-07-12 11:21:04.597955: Epoch time: 67.38 s 
2025-07-12 11:21:05.490865:  
2025-07-12 11:21:05.492742: Epoch 979 
2025-07-12 11:21:05.493798: Current learning rate: 0.00031 
2025-07-12 11:22:12.811241: train_loss -0.9841 
2025-07-12 11:22:12.812754: val_loss -0.9488 
2025-07-12 11:22:12.813938: Pseudo dice [np.float32(0.9521)] 
2025-07-12 11:22:12.815040: Epoch time: 67.32 s 
2025-07-12 11:22:13.711451:  
2025-07-12 11:22:13.713047: Epoch 980 
2025-07-12 11:22:13.714061: Current learning rate: 0.0003 
2025-07-12 11:23:21.666377: train_loss -0.9838 
2025-07-12 11:23:21.667768: val_loss -0.9518 
2025-07-12 11:23:21.668868: Pseudo dice [np.float32(0.9551)] 
2025-07-12 11:23:21.670062: Epoch time: 67.96 s 
2025-07-12 11:23:22.562740:  
2025-07-12 11:23:22.564581: Epoch 981 
2025-07-12 11:23:22.565802: Current learning rate: 0.00028 
2025-07-12 11:24:29.804172: train_loss -0.9842 
2025-07-12 11:24:29.805448: val_loss -0.9513 
2025-07-12 11:24:29.806862: Pseudo dice [np.float32(0.9543)] 
2025-07-12 11:24:29.808007: Epoch time: 67.24 s 
2025-07-12 11:24:30.697475:  
2025-07-12 11:24:30.699202: Epoch 982 
2025-07-12 11:24:30.700356: Current learning rate: 0.00027 
2025-07-12 11:25:38.077721: train_loss -0.9841 
2025-07-12 11:25:38.078938: val_loss -0.952 
2025-07-12 11:25:38.080081: Pseudo dice [np.float32(0.9546)] 
2025-07-12 11:25:38.081287: Epoch time: 67.38 s 
2025-07-12 11:25:38.975628:  
2025-07-12 11:25:38.977178: Epoch 983 
2025-07-12 11:25:38.978545: Current learning rate: 0.00026 
2025-07-12 11:26:46.570305: train_loss -0.9847 
2025-07-12 11:26:46.571654: val_loss -0.9518 
2025-07-12 11:26:46.572820: Pseudo dice [np.float32(0.9551)] 
2025-07-12 11:26:46.573950: Epoch time: 67.6 s 
2025-07-12 11:26:47.478846:  
2025-07-12 11:26:47.480551: Epoch 984 
2025-07-12 11:26:47.481713: Current learning rate: 0.00024 
2025-07-12 11:27:54.854004: train_loss -0.9847 
2025-07-12 11:27:54.855114: val_loss -0.9533 
2025-07-12 11:27:54.856437: Pseudo dice [np.float32(0.9562)] 
2025-07-12 11:27:54.857308: Epoch time: 67.38 s 
2025-07-12 11:27:54.858629: Yayy! New best EMA pseudo Dice: 0.9537000060081482 
2025-07-12 11:27:56.833261:  
2025-07-12 11:27:56.835002: Epoch 985 
2025-07-12 11:27:56.836196: Current learning rate: 0.00023 
2025-07-12 11:29:04.042366: train_loss -0.9843 
2025-07-12 11:29:04.043761: val_loss -0.9514 
2025-07-12 11:29:04.044876: Pseudo dice [np.float32(0.9547)] 
2025-07-12 11:29:04.046167: Epoch time: 67.21 s 
2025-07-12 11:29:04.047292: Yayy! New best EMA pseudo Dice: 0.9538000226020813 
2025-07-12 11:29:06.174903:  
2025-07-12 11:29:06.176917: Epoch 986 
2025-07-12 11:29:06.178013: Current learning rate: 0.00021 
2025-07-12 11:30:13.609142: train_loss -0.9843 
2025-07-12 11:30:13.610539: val_loss -0.9485 
2025-07-12 11:30:13.611712: Pseudo dice [np.float32(0.9517)] 
2025-07-12 11:30:13.612906: Epoch time: 67.44 s 
2025-07-12 11:30:14.504808:  
2025-07-12 11:30:14.506669: Epoch 987 
2025-07-12 11:30:14.507961: Current learning rate: 0.0002 
2025-07-12 11:31:21.841725: train_loss -0.9839 
2025-07-12 11:31:21.843002: val_loss -0.9515 
2025-07-12 11:31:21.844072: Pseudo dice [np.float32(0.9548)] 
2025-07-12 11:31:21.845248: Epoch time: 67.34 s 
2025-07-12 11:31:22.735185:  
2025-07-12 11:31:22.736386: Epoch 988 
2025-07-12 11:31:22.737516: Current learning rate: 0.00019 
2025-07-12 11:32:30.400352: train_loss -0.9844 
2025-07-12 11:32:30.401769: val_loss -0.9503 
2025-07-12 11:32:30.402870: Pseudo dice [np.float32(0.9539)] 
2025-07-12 11:32:30.403931: Epoch time: 67.67 s 
2025-07-12 11:32:31.298949:  
2025-07-12 11:32:31.300521: Epoch 989 
2025-07-12 11:32:31.301672: Current learning rate: 0.00017 
2025-07-12 11:33:40.009103: train_loss -0.9842 
2025-07-12 11:33:40.010308: val_loss -0.9504 
2025-07-12 11:33:40.011482: Pseudo dice [np.float32(0.9535)] 
2025-07-12 11:33:40.012590: Epoch time: 68.71 s 
2025-07-12 11:33:40.895514:  
2025-07-12 11:33:40.897234: Epoch 990 
2025-07-12 11:33:40.898353: Current learning rate: 0.00016 
2025-07-12 11:34:48.862749: train_loss -0.9844 
2025-07-12 11:34:48.863937: val_loss -0.9499 
2025-07-12 11:34:48.865088: Pseudo dice [np.float32(0.953)] 
2025-07-12 11:34:48.866192: Epoch time: 67.97 s 
2025-07-12 11:34:49.756447:  
2025-07-12 11:34:49.758160: Epoch 991 
2025-07-12 11:34:49.759333: Current learning rate: 0.00014 
2025-07-12 11:35:57.935451: train_loss -0.9841 
2025-07-12 11:35:57.936799: val_loss -0.9536 
2025-07-12 11:35:57.938029: Pseudo dice [np.float32(0.9559)] 
2025-07-12 11:35:57.939179: Epoch time: 68.18 s 
2025-07-12 11:35:57.940101: Yayy! New best EMA pseudo Dice: 0.9538999795913696 
2025-07-12 11:36:00.051311:  
2025-07-12 11:36:00.053122: Epoch 992 
2025-07-12 11:36:00.054704: Current learning rate: 0.00013 
2025-07-12 11:37:08.525944: train_loss -0.9841 
2025-07-12 11:37:08.527273: val_loss -0.953 
2025-07-12 11:37:08.528329: Pseudo dice [np.float32(0.9561)] 
2025-07-12 11:37:08.529446: Epoch time: 68.48 s 
2025-07-12 11:37:08.530494: Yayy! New best EMA pseudo Dice: 0.9541000127792358 
2025-07-12 11:37:10.666935:  
2025-07-12 11:37:10.668684: Epoch 993 
2025-07-12 11:37:10.669832: Current learning rate: 0.00011 
2025-07-12 11:38:18.757635: train_loss -0.9844 
2025-07-12 11:38:18.758876: val_loss -0.9463 
2025-07-12 11:38:18.760041: Pseudo dice [np.float32(0.9491)] 
2025-07-12 11:38:18.761230: Epoch time: 68.09 s 
2025-07-12 11:38:19.657015:  
2025-07-12 11:38:19.658532: Epoch 994 
2025-07-12 11:38:19.659644: Current learning rate: 0.0001 
2025-07-12 11:39:28.024754: train_loss -0.9841 
2025-07-12 11:39:28.026042: val_loss -0.9539 
2025-07-12 11:39:28.027225: Pseudo dice [np.float32(0.9574)] 
2025-07-12 11:39:28.028276: Epoch time: 68.37 s 
2025-07-12 11:39:28.908595:  
2025-07-12 11:39:28.910042: Epoch 995 
2025-07-12 11:39:28.911177: Current learning rate: 8e-05 
2025-07-12 11:40:37.125047: train_loss -0.9841 
2025-07-12 11:40:37.126240: val_loss -0.9527 
2025-07-12 11:40:37.127250: Pseudo dice [np.float32(0.9557)] 
2025-07-12 11:40:37.128182: Epoch time: 68.22 s 
2025-07-12 11:40:37.129235: Yayy! New best EMA pseudo Dice: 0.9541000127792358 
2025-07-12 11:40:39.269211:  
2025-07-12 11:40:39.270455: Epoch 996 
2025-07-12 11:40:39.271605: Current learning rate: 7e-05 
2025-07-12 11:41:47.765259: train_loss -0.9843 
2025-07-12 11:41:47.766574: val_loss -0.9499 
2025-07-12 11:41:47.767657: Pseudo dice [np.float32(0.9526)] 
2025-07-12 11:41:47.768973: Epoch time: 68.5 s 
2025-07-12 11:41:48.691425:  
2025-07-12 11:41:48.693050: Epoch 997 
2025-07-12 11:41:48.694286: Current learning rate: 5e-05 
2025-07-12 11:42:58.318933: train_loss -0.9842 
2025-07-12 11:42:58.320284: val_loss -0.949 
2025-07-12 11:42:58.321299: Pseudo dice [np.float32(0.9525)] 
2025-07-12 11:42:58.322157: Epoch time: 69.63 s 
2025-07-12 11:42:59.224572:  
2025-07-12 11:42:59.226254: Epoch 998 
2025-07-12 11:42:59.227421: Current learning rate: 4e-05 
2025-07-12 11:44:06.375902: train_loss -0.9848 
2025-07-12 11:44:06.377192: val_loss -0.9489 
2025-07-12 11:44:06.378074: Pseudo dice [np.float32(0.9523)] 
2025-07-12 11:44:06.379071: Epoch time: 67.15 s 
2025-07-12 11:44:07.323991:  
2025-07-12 11:44:07.325768: Epoch 999 
2025-07-12 11:44:07.326871: Current learning rate: 2e-05 
2025-07-12 11:45:14.169900: train_loss -0.9848 
2025-07-12 11:45:14.171326: val_loss -0.9473 
2025-07-12 11:45:14.172656: Pseudo dice [np.float32(0.9501)] 
2025-07-12 11:45:14.173749: Epoch time: 66.85 s 
2025-07-12 11:45:16.153937: Training done. 
2025-07-12 11:45:16.201537: Using splits from existing split file: /data/nnUNet_preprocessed/Dataset010_PTB_all_energies_1mm_no_background_alldata/splits_final.json 
2025-07-12 11:45:16.208133: The split file contains 5 splits. 
2025-07-12 11:45:16.209705: Desired fold for training: 2 
2025-07-12 11:45:16.210803: This split has 1440 training and 360 validation cases. 
2025-07-12 11:45:16.216746: predicting PTB_all_energies_1mm_no_background_0005 
2025-07-12 11:45:16.224070: PTB_all_energies_1mm_no_background_0005, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.573763: predicting PTB_all_energies_1mm_no_background_0010 
2025-07-12 11:45:52.580840: PTB_all_energies_1mm_no_background_0010, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.642056: predicting PTB_all_energies_1mm_no_background_0015 
2025-07-12 11:45:52.649073: PTB_all_energies_1mm_no_background_0015, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.698559: predicting PTB_all_energies_1mm_no_background_0027 
2025-07-12 11:45:52.705283: PTB_all_energies_1mm_no_background_0027, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.750652: predicting PTB_all_energies_1mm_no_background_0036 
2025-07-12 11:45:52.758660: PTB_all_energies_1mm_no_background_0036, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.809966: predicting PTB_all_energies_1mm_no_background_0038 
2025-07-12 11:45:52.817245: PTB_all_energies_1mm_no_background_0038, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.868087: predicting PTB_all_energies_1mm_no_background_0052 
2025-07-12 11:45:52.874596: PTB_all_energies_1mm_no_background_0052, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.930640: predicting PTB_all_energies_1mm_no_background_0054 
2025-07-12 11:45:52.937855: PTB_all_energies_1mm_no_background_0054, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:52.986061: predicting PTB_all_energies_1mm_no_background_0055 
2025-07-12 11:45:52.992997: PTB_all_energies_1mm_no_background_0055, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.041945: predicting PTB_all_energies_1mm_no_background_0059 
2025-07-12 11:45:53.048620: PTB_all_energies_1mm_no_background_0059, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.097298: predicting PTB_all_energies_1mm_no_background_0060 
2025-07-12 11:45:53.104641: PTB_all_energies_1mm_no_background_0060, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.152858: predicting PTB_all_energies_1mm_no_background_0061 
2025-07-12 11:45:53.159948: PTB_all_energies_1mm_no_background_0061, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.210304: predicting PTB_all_energies_1mm_no_background_0064 
2025-07-12 11:45:53.216782: PTB_all_energies_1mm_no_background_0064, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.267465: predicting PTB_all_energies_1mm_no_background_0076 
2025-07-12 11:45:53.275057: PTB_all_energies_1mm_no_background_0076, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.323330: predicting PTB_all_energies_1mm_no_background_0090 
2025-07-12 11:45:53.331764: PTB_all_energies_1mm_no_background_0090, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.399700: predicting PTB_all_energies_1mm_no_background_0092 
2025-07-12 11:45:53.407398: PTB_all_energies_1mm_no_background_0092, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.458465: predicting PTB_all_energies_1mm_no_background_0096 
2025-07-12 11:45:53.465387: PTB_all_energies_1mm_no_background_0096, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.513103: predicting PTB_all_energies_1mm_no_background_0104 
2025-07-12 11:45:53.520635: PTB_all_energies_1mm_no_background_0104, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.588272: predicting PTB_all_energies_1mm_no_background_0107 
2025-07-12 11:45:53.595712: PTB_all_energies_1mm_no_background_0107, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.653417: predicting PTB_all_energies_1mm_no_background_0118 
2025-07-12 11:45:53.660643: PTB_all_energies_1mm_no_background_0118, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.728683: predicting PTB_all_energies_1mm_no_background_0120 
2025-07-12 11:45:53.735905: PTB_all_energies_1mm_no_background_0120, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.792797: predicting PTB_all_energies_1mm_no_background_0125 
2025-07-12 11:45:53.799709: PTB_all_energies_1mm_no_background_0125, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.847704: predicting PTB_all_energies_1mm_no_background_0127 
2025-07-12 11:45:53.855602: PTB_all_energies_1mm_no_background_0127, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.923160: predicting PTB_all_energies_1mm_no_background_0131 
2025-07-12 11:45:53.930317: PTB_all_energies_1mm_no_background_0131, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:53.985125: predicting PTB_all_energies_1mm_no_background_0134 
2025-07-12 11:45:53.991641: PTB_all_energies_1mm_no_background_0134, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.040699: predicting PTB_all_energies_1mm_no_background_0135 
2025-07-12 11:45:54.048270: PTB_all_energies_1mm_no_background_0135, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.115999: predicting PTB_all_energies_1mm_no_background_0136 
2025-07-12 11:45:54.123339: PTB_all_energies_1mm_no_background_0136, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.181610: predicting PTB_all_energies_1mm_no_background_0147 
2025-07-12 11:45:54.187982: PTB_all_energies_1mm_no_background_0147, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.233253: predicting PTB_all_energies_1mm_no_background_0157 
2025-07-12 11:45:54.239459: PTB_all_energies_1mm_no_background_0157, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.285594: predicting PTB_all_energies_1mm_no_background_0159 
2025-07-12 11:45:54.292487: PTB_all_energies_1mm_no_background_0159, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.339628: predicting PTB_all_energies_1mm_no_background_0161 
2025-07-12 11:45:54.347297: PTB_all_energies_1mm_no_background_0161, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.415152: predicting PTB_all_energies_1mm_no_background_0164 
2025-07-12 11:45:54.422403: PTB_all_energies_1mm_no_background_0164, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.476244: predicting PTB_all_energies_1mm_no_background_0169 
2025-07-12 11:45:54.482514: PTB_all_energies_1mm_no_background_0169, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.528792: predicting PTB_all_energies_1mm_no_background_0170 
2025-07-12 11:45:54.536158: PTB_all_energies_1mm_no_background_0170, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.603877: predicting PTB_all_energies_1mm_no_background_0182 
2025-07-12 11:45:54.611600: PTB_all_energies_1mm_no_background_0182, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.666887: predicting PTB_all_energies_1mm_no_background_0184 
2025-07-12 11:45:54.673672: PTB_all_energies_1mm_no_background_0184, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.720609: predicting PTB_all_energies_1mm_no_background_0185 
2025-07-12 11:45:54.726839: PTB_all_energies_1mm_no_background_0185, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.772819: predicting PTB_all_energies_1mm_no_background_0186 
2025-07-12 11:45:54.780043: PTB_all_energies_1mm_no_background_0186, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.827245: predicting PTB_all_energies_1mm_no_background_0187 
2025-07-12 11:45:54.834365: PTB_all_energies_1mm_no_background_0187, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.902597: predicting PTB_all_energies_1mm_no_background_0196 
2025-07-12 11:45:54.909786: PTB_all_energies_1mm_no_background_0196, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:54.964873: predicting PTB_all_energies_1mm_no_background_0197 
2025-07-12 11:45:54.971808: PTB_all_energies_1mm_no_background_0197, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.018120: predicting PTB_all_energies_1mm_no_background_0198 
2025-07-12 11:45:55.026415: PTB_all_energies_1mm_no_background_0198, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.096640: predicting PTB_all_energies_1mm_no_background_0204 
2025-07-12 11:45:55.104054: PTB_all_energies_1mm_no_background_0204, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.166467: predicting PTB_all_energies_1mm_no_background_0205 
2025-07-12 11:45:55.172998: PTB_all_energies_1mm_no_background_0205, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.218520: predicting PTB_all_energies_1mm_no_background_0217 
2025-07-12 11:45:55.225044: PTB_all_energies_1mm_no_background_0217, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.271010: predicting PTB_all_energies_1mm_no_background_0223 
2025-07-12 11:45:55.277705: PTB_all_energies_1mm_no_background_0223, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.325839: predicting PTB_all_energies_1mm_no_background_0237 
2025-07-12 11:45:55.332909: PTB_all_energies_1mm_no_background_0237, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.401261: predicting PTB_all_energies_1mm_no_background_0242 
2025-07-12 11:45:55.408903: PTB_all_energies_1mm_no_background_0242, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.464682: predicting PTB_all_energies_1mm_no_background_0243 
2025-07-12 11:45:55.471323: PTB_all_energies_1mm_no_background_0243, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.517503: predicting PTB_all_energies_1mm_no_background_0245 
2025-07-12 11:45:55.526325: PTB_all_energies_1mm_no_background_0245, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.593951: predicting PTB_all_energies_1mm_no_background_0246 
2025-07-12 11:45:55.601414: PTB_all_energies_1mm_no_background_0246, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.656281: predicting PTB_all_energies_1mm_no_background_0247 
2025-07-12 11:45:55.662876: PTB_all_energies_1mm_no_background_0247, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.708107: predicting PTB_all_energies_1mm_no_background_0250 
2025-07-12 11:45:55.714606: PTB_all_energies_1mm_no_background_0250, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.760733: predicting PTB_all_energies_1mm_no_background_0257 
2025-07-12 11:45:55.767425: PTB_all_energies_1mm_no_background_0257, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.817027: predicting PTB_all_energies_1mm_no_background_0258 
2025-07-12 11:45:55.824095: PTB_all_energies_1mm_no_background_0258, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.892743: predicting PTB_all_energies_1mm_no_background_0259 
2025-07-12 11:45:55.900416: PTB_all_energies_1mm_no_background_0259, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:55.959074: predicting PTB_all_energies_1mm_no_background_0273 
2025-07-12 11:45:55.966074: PTB_all_energies_1mm_no_background_0273, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.012022: predicting PTB_all_energies_1mm_no_background_0277 
2025-07-12 11:45:56.019732: PTB_all_energies_1mm_no_background_0277, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.087583: predicting PTB_all_energies_1mm_no_background_0281 
2025-07-12 11:45:56.095083: PTB_all_energies_1mm_no_background_0281, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.146562: predicting PTB_all_energies_1mm_no_background_0287 
2025-07-12 11:45:56.152840: PTB_all_energies_1mm_no_background_0287, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.197679: predicting PTB_all_energies_1mm_no_background_0297 
2025-07-12 11:45:56.204148: PTB_all_energies_1mm_no_background_0297, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.250462: predicting PTB_all_energies_1mm_no_background_0308 
2025-07-12 11:45:56.257230: PTB_all_energies_1mm_no_background_0308, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.305790: predicting PTB_all_energies_1mm_no_background_0314 
2025-07-12 11:45:56.312972: PTB_all_energies_1mm_no_background_0314, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.380599: predicting PTB_all_energies_1mm_no_background_0321 
2025-07-12 11:45:56.387903: PTB_all_energies_1mm_no_background_0321, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.441791: predicting PTB_all_energies_1mm_no_background_0323 
2025-07-12 11:45:56.448621: PTB_all_energies_1mm_no_background_0323, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.494712: predicting PTB_all_energies_1mm_no_background_0327 
2025-07-12 11:45:56.501781: PTB_all_energies_1mm_no_background_0327, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.570201: predicting PTB_all_energies_1mm_no_background_0328 
2025-07-12 11:45:56.578063: PTB_all_energies_1mm_no_background_0328, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.639366: predicting PTB_all_energies_1mm_no_background_0333 
2025-07-12 11:45:56.645704: PTB_all_energies_1mm_no_background_0333, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.690304: predicting PTB_all_energies_1mm_no_background_0341 
2025-07-12 11:45:56.696519: PTB_all_energies_1mm_no_background_0341, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.742303: predicting PTB_all_energies_1mm_no_background_0344 
2025-07-12 11:45:56.750081: PTB_all_energies_1mm_no_background_0344, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.798027: predicting PTB_all_energies_1mm_no_background_0347 
2025-07-12 11:45:56.805764: PTB_all_energies_1mm_no_background_0347, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.874456: predicting PTB_all_energies_1mm_no_background_0350 
2025-07-12 11:45:56.882049: PTB_all_energies_1mm_no_background_0350, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.937324: predicting PTB_all_energies_1mm_no_background_0353 
2025-07-12 11:45:56.943607: PTB_all_energies_1mm_no_background_0353, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:56.989047: predicting PTB_all_energies_1mm_no_background_0360 
2025-07-12 11:45:56.996399: PTB_all_energies_1mm_no_background_0360, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.064592: predicting PTB_all_energies_1mm_no_background_0367 
2025-07-12 11:45:57.071972: PTB_all_energies_1mm_no_background_0367, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.133759: predicting PTB_all_energies_1mm_no_background_0369 
2025-07-12 11:45:57.140674: PTB_all_energies_1mm_no_background_0369, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.185847: predicting PTB_all_energies_1mm_no_background_0377 
2025-07-12 11:45:57.192328: PTB_all_energies_1mm_no_background_0377, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.238859: predicting PTB_all_energies_1mm_no_background_0380 
2025-07-12 11:45:57.245697: PTB_all_energies_1mm_no_background_0380, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.293846: predicting PTB_all_energies_1mm_no_background_0382 
2025-07-12 11:45:57.301652: PTB_all_energies_1mm_no_background_0382, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.368478: predicting PTB_all_energies_1mm_no_background_0387 
2025-07-12 11:45:57.374891: PTB_all_energies_1mm_no_background_0387, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.420712: predicting PTB_all_energies_1mm_no_background_0405 
2025-07-12 11:45:57.427423: PTB_all_energies_1mm_no_background_0405, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.475920: predicting PTB_all_energies_1mm_no_background_0409 
2025-07-12 11:45:57.482709: PTB_all_energies_1mm_no_background_0409, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.550856: predicting PTB_all_energies_1mm_no_background_0413 
2025-07-12 11:45:57.558330: PTB_all_energies_1mm_no_background_0413, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.611780: predicting PTB_all_energies_1mm_no_background_0416 
2025-07-12 11:45:57.618329: PTB_all_energies_1mm_no_background_0416, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.664975: predicting PTB_all_energies_1mm_no_background_0417 
2025-07-12 11:45:57.672509: PTB_all_energies_1mm_no_background_0417, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.719958: predicting PTB_all_energies_1mm_no_background_0425 
2025-07-12 11:45:57.727128: PTB_all_energies_1mm_no_background_0425, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.776122: predicting PTB_all_energies_1mm_no_background_0431 
2025-07-12 11:45:57.783977: PTB_all_energies_1mm_no_background_0431, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.852511: predicting PTB_all_energies_1mm_no_background_0432 
2025-07-12 11:45:57.859860: PTB_all_energies_1mm_no_background_0432, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.913254: predicting PTB_all_energies_1mm_no_background_0435 
2025-07-12 11:45:57.920160: PTB_all_energies_1mm_no_background_0435, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:57.968726: predicting PTB_all_energies_1mm_no_background_0438 
2025-07-12 11:45:57.975864: PTB_all_energies_1mm_no_background_0438, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.043675: predicting PTB_all_energies_1mm_no_background_0446 
2025-07-12 11:45:58.051075: PTB_all_energies_1mm_no_background_0446, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.111842: predicting PTB_all_energies_1mm_no_background_0453 
2025-07-12 11:45:58.118224: PTB_all_energies_1mm_no_background_0453, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.164634: predicting PTB_all_energies_1mm_no_background_0455 
2025-07-12 11:45:58.171339: PTB_all_energies_1mm_no_background_0455, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.219228: predicting PTB_all_energies_1mm_no_background_0461 
2025-07-12 11:45:58.225358: PTB_all_energies_1mm_no_background_0461, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.274023: predicting PTB_all_energies_1mm_no_background_0467 
2025-07-12 11:45:58.281608: PTB_all_energies_1mm_no_background_0467, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.351157: predicting PTB_all_energies_1mm_no_background_0470 
2025-07-12 11:45:58.358596: PTB_all_energies_1mm_no_background_0470, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.412625: predicting PTB_all_energies_1mm_no_background_0474 
2025-07-12 11:45:58.419221: PTB_all_energies_1mm_no_background_0474, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.467553: predicting PTB_all_energies_1mm_no_background_0475 
2025-07-12 11:45:58.474926: PTB_all_energies_1mm_no_background_0475, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.542948: predicting PTB_all_energies_1mm_no_background_0477 
2025-07-12 11:45:58.550168: PTB_all_energies_1mm_no_background_0477, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.612797: predicting PTB_all_energies_1mm_no_background_0478 
2025-07-12 11:45:58.619673: PTB_all_energies_1mm_no_background_0478, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.665397: predicting PTB_all_energies_1mm_no_background_0485 
2025-07-12 11:45:58.671749: PTB_all_energies_1mm_no_background_0485, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.717040: predicting PTB_all_energies_1mm_no_background_0491 
2025-07-12 11:45:58.724480: PTB_all_energies_1mm_no_background_0491, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.772435: predicting PTB_all_energies_1mm_no_background_0492 
2025-07-12 11:45:58.779470: PTB_all_energies_1mm_no_background_0492, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.825533: predicting PTB_all_energies_1mm_no_background_0502 
2025-07-12 11:45:58.833688: PTB_all_energies_1mm_no_background_0502, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.902623: predicting PTB_all_energies_1mm_no_background_0503 
2025-07-12 11:45:58.910022: PTB_all_energies_1mm_no_background_0503, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:58.971218: predicting PTB_all_energies_1mm_no_background_0504 
2025-07-12 11:45:58.978431: PTB_all_energies_1mm_no_background_0504, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.028888: predicting PTB_all_energies_1mm_no_background_0508 
2025-07-12 11:45:59.035872: PTB_all_energies_1mm_no_background_0508, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.083129: predicting PTB_all_energies_1mm_no_background_0516 
2025-07-12 11:45:59.090384: PTB_all_energies_1mm_no_background_0516, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.137289: predicting PTB_all_energies_1mm_no_background_0517 
2025-07-12 11:45:59.143637: PTB_all_energies_1mm_no_background_0517, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.189979: predicting PTB_all_energies_1mm_no_background_0521 
2025-07-12 11:45:59.197263: PTB_all_energies_1mm_no_background_0521, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.245003: predicting PTB_all_energies_1mm_no_background_0531 
2025-07-12 11:45:59.251300: PTB_all_energies_1mm_no_background_0531, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.297736: predicting PTB_all_energies_1mm_no_background_0540 
2025-07-12 11:45:59.304831: PTB_all_energies_1mm_no_background_0540, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.372884: predicting PTB_all_energies_1mm_no_background_0548 
2025-07-12 11:45:59.380268: PTB_all_energies_1mm_no_background_0548, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.441831: predicting PTB_all_energies_1mm_no_background_0549 
2025-07-12 11:45:59.448805: PTB_all_energies_1mm_no_background_0549, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.512015: predicting PTB_all_energies_1mm_no_background_0556 
2025-07-12 11:45:59.518767: PTB_all_energies_1mm_no_background_0556, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.566209: predicting PTB_all_energies_1mm_no_background_0558 
2025-07-12 11:45:59.572310: PTB_all_energies_1mm_no_background_0558, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.616805: predicting PTB_all_energies_1mm_no_background_0567 
2025-07-12 11:45:59.624705: PTB_all_energies_1mm_no_background_0567, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.692162: predicting PTB_all_energies_1mm_no_background_0580 
2025-07-12 11:45:59.699614: PTB_all_energies_1mm_no_background_0580, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.752096: predicting PTB_all_energies_1mm_no_background_0592 
2025-07-12 11:45:59.758878: PTB_all_energies_1mm_no_background_0592, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.806032: predicting PTB_all_energies_1mm_no_background_0596 
2025-07-12 11:45:59.813849: PTB_all_energies_1mm_no_background_0596, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.882294: predicting PTB_all_energies_1mm_no_background_0612 
2025-07-12 11:45:59.888914: PTB_all_energies_1mm_no_background_0612, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.936938: predicting PTB_all_energies_1mm_no_background_0628 
2025-07-12 11:45:59.943550: PTB_all_energies_1mm_no_background_0628, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:45:59.988839: predicting PTB_all_energies_1mm_no_background_0630 
2025-07-12 11:45:59.995236: PTB_all_energies_1mm_no_background_0630, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.042238: predicting PTB_all_energies_1mm_no_background_0637 
2025-07-12 11:46:00.049264: PTB_all_energies_1mm_no_background_0637, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.094940: predicting PTB_all_energies_1mm_no_background_0643 
2025-07-12 11:46:00.102281: PTB_all_energies_1mm_no_background_0643, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.170109: predicting PTB_all_energies_1mm_no_background_0646 
2025-07-12 11:46:00.177402: PTB_all_energies_1mm_no_background_0646, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.238946: predicting PTB_all_energies_1mm_no_background_0650 
2025-07-12 11:46:00.245818: PTB_all_energies_1mm_no_background_0650, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.292962: predicting PTB_all_energies_1mm_no_background_0651 
2025-07-12 11:46:00.299729: PTB_all_energies_1mm_no_background_0651, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.348011: predicting PTB_all_energies_1mm_no_background_0657 
2025-07-12 11:46:00.355195: PTB_all_energies_1mm_no_background_0657, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.402633: predicting PTB_all_energies_1mm_no_background_0671 
2025-07-12 11:46:00.409787: PTB_all_energies_1mm_no_background_0671, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.456494: predicting PTB_all_energies_1mm_no_background_0677 
2025-07-12 11:46:00.463209: PTB_all_energies_1mm_no_background_0677, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.509501: predicting PTB_all_energies_1mm_no_background_0688 
2025-07-12 11:46:00.515942: PTB_all_energies_1mm_no_background_0688, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.561661: predicting PTB_all_energies_1mm_no_background_0698 
2025-07-12 11:46:00.567928: PTB_all_energies_1mm_no_background_0698, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.613807: predicting PTB_all_energies_1mm_no_background_0701 
2025-07-12 11:46:00.620764: PTB_all_energies_1mm_no_background_0701, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.667357: predicting PTB_all_energies_1mm_no_background_0704 
2025-07-12 11:46:00.674141: PTB_all_energies_1mm_no_background_0704, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.720527: predicting PTB_all_energies_1mm_no_background_0708 
2025-07-12 11:46:00.728199: PTB_all_energies_1mm_no_background_0708, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.796170: predicting PTB_all_energies_1mm_no_background_0725 
2025-07-12 11:46:00.803674: PTB_all_energies_1mm_no_background_0725, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.864815: predicting PTB_all_energies_1mm_no_background_0726 
2025-07-12 11:46:00.871263: PTB_all_energies_1mm_no_background_0726, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.917971: predicting PTB_all_energies_1mm_no_background_0731 
2025-07-12 11:46:00.925338: PTB_all_energies_1mm_no_background_0731, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:00.988516: predicting PTB_all_energies_1mm_no_background_0733 
2025-07-12 11:46:00.994768: PTB_all_energies_1mm_no_background_0733, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.040174: predicting PTB_all_energies_1mm_no_background_0735 
2025-07-12 11:46:01.046584: PTB_all_energies_1mm_no_background_0735, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.092456: predicting PTB_all_energies_1mm_no_background_0740 
2025-07-12 11:46:01.099874: PTB_all_energies_1mm_no_background_0740, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.167946: predicting PTB_all_energies_1mm_no_background_0749 
2025-07-12 11:46:01.175530: PTB_all_energies_1mm_no_background_0749, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.237083: predicting PTB_all_energies_1mm_no_background_0750 
2025-07-12 11:46:01.243700: PTB_all_energies_1mm_no_background_0750, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.289609: predicting PTB_all_energies_1mm_no_background_0762 
2025-07-12 11:46:01.297091: PTB_all_energies_1mm_no_background_0762, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.363969: predicting PTB_all_energies_1mm_no_background_0767 
2025-07-12 11:46:01.370784: PTB_all_energies_1mm_no_background_0767, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.417583: predicting PTB_all_energies_1mm_no_background_0773 
2025-07-12 11:46:01.424047: PTB_all_energies_1mm_no_background_0773, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.469583: predicting PTB_all_energies_1mm_no_background_0779 
2025-07-12 11:46:01.476591: PTB_all_energies_1mm_no_background_0779, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.521504: predicting PTB_all_energies_1mm_no_background_0784 
2025-07-12 11:46:01.528938: PTB_all_energies_1mm_no_background_0784, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.574682: predicting PTB_all_energies_1mm_no_background_0791 
2025-07-12 11:46:01.583503: PTB_all_energies_1mm_no_background_0791, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.652562: predicting PTB_all_energies_1mm_no_background_0796 
2025-07-12 11:46:01.660125: PTB_all_energies_1mm_no_background_0796, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.718351: predicting PTB_all_energies_1mm_no_background_0804 
2025-07-12 11:46:01.724570: PTB_all_energies_1mm_no_background_0804, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.770692: predicting PTB_all_energies_1mm_no_background_0809 
2025-07-12 11:46:01.777582: PTB_all_energies_1mm_no_background_0809, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.826180: predicting PTB_all_energies_1mm_no_background_0822 
2025-07-12 11:46:01.833210: PTB_all_energies_1mm_no_background_0822, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.901311: predicting PTB_all_energies_1mm_no_background_0823 
2025-07-12 11:46:01.908736: PTB_all_energies_1mm_no_background_0823, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:01.972005: predicting PTB_all_energies_1mm_no_background_0827 
2025-07-12 11:46:01.978801: PTB_all_energies_1mm_no_background_0827, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.024336: predicting PTB_all_energies_1mm_no_background_0839 
2025-07-12 11:46:02.030936: PTB_all_energies_1mm_no_background_0839, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.076735: predicting PTB_all_energies_1mm_no_background_0840 
2025-07-12 11:46:02.083776: PTB_all_energies_1mm_no_background_0840, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.129853: predicting PTB_all_energies_1mm_no_background_0843 
2025-07-12 11:46:02.137169: PTB_all_energies_1mm_no_background_0843, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.185740: predicting PTB_all_energies_1mm_no_background_0861 
2025-07-12 11:46:02.193479: PTB_all_energies_1mm_no_background_0861, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.261711: predicting PTB_all_energies_1mm_no_background_0867 
2025-07-12 11:46:02.268710: PTB_all_energies_1mm_no_background_0867, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.321631: predicting PTB_all_energies_1mm_no_background_0868 
2025-07-12 11:46:02.327959: PTB_all_energies_1mm_no_background_0868, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.374531: predicting PTB_all_energies_1mm_no_background_0873 
2025-07-12 11:46:02.381130: PTB_all_energies_1mm_no_background_0873, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.426559: predicting PTB_all_energies_1mm_no_background_0874 
2025-07-12 11:46:02.433392: PTB_all_energies_1mm_no_background_0874, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.478737: predicting PTB_all_energies_1mm_no_background_0882 
2025-07-12 11:46:02.485731: PTB_all_energies_1mm_no_background_0882, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.531969: predicting PTB_all_energies_1mm_no_background_0888 
2025-07-12 11:46:02.538666: PTB_all_energies_1mm_no_background_0888, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.584695: predicting PTB_all_energies_1mm_no_background_0890 
2025-07-12 11:46:02.591589: PTB_all_energies_1mm_no_background_0890, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.641039: predicting PTB_all_energies_1mm_no_background_0896 
2025-07-12 11:46:02.649132: PTB_all_energies_1mm_no_background_0896, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.717726: predicting PTB_all_energies_1mm_no_background_0900 
2025-07-12 11:46:02.725013: PTB_all_energies_1mm_no_background_0900, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.785909: predicting PTB_all_energies_1mm_no_background_0901 
2025-07-12 11:46:02.792230: PTB_all_energies_1mm_no_background_0901, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.839219: predicting PTB_all_energies_1mm_no_background_0912 
2025-07-12 11:46:02.845699: PTB_all_energies_1mm_no_background_0912, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.893632: predicting PTB_all_energies_1mm_no_background_0913 
2025-07-12 11:46:02.900052: PTB_all_energies_1mm_no_background_0913, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.945323: predicting PTB_all_energies_1mm_no_background_0917 
2025-07-12 11:46:02.951599: PTB_all_energies_1mm_no_background_0917, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:02.997697: predicting PTB_all_energies_1mm_no_background_0919 
2025-07-12 11:46:03.004233: PTB_all_energies_1mm_no_background_0919, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.050235: predicting PTB_all_energies_1mm_no_background_0922 
2025-07-12 11:46:03.057002: PTB_all_energies_1mm_no_background_0922, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.105636: predicting PTB_all_energies_1mm_no_background_0928 
2025-07-12 11:46:03.113743: PTB_all_energies_1mm_no_background_0928, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.182254: predicting PTB_all_energies_1mm_no_background_0931 
2025-07-12 11:46:03.189545: PTB_all_energies_1mm_no_background_0931, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.249819: predicting PTB_all_energies_1mm_no_background_0932 
2025-07-12 11:46:03.256209: PTB_all_energies_1mm_no_background_0932, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.302364: predicting PTB_all_energies_1mm_no_background_0934 
2025-07-12 11:46:03.308853: PTB_all_energies_1mm_no_background_0934, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.356533: predicting PTB_all_energies_1mm_no_background_0936 
2025-07-12 11:46:03.363040: PTB_all_energies_1mm_no_background_0936, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.408479: predicting PTB_all_energies_1mm_no_background_0942 
2025-07-12 11:46:03.414791: PTB_all_energies_1mm_no_background_0942, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.460676: predicting PTB_all_energies_1mm_no_background_0944 
2025-07-12 11:46:03.467272: PTB_all_energies_1mm_no_background_0944, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.513148: predicting PTB_all_energies_1mm_no_background_0949 
2025-07-12 11:46:03.520323: PTB_all_energies_1mm_no_background_0949, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.583957: predicting PTB_all_energies_1mm_no_background_0951 
2025-07-12 11:46:03.590211: PTB_all_energies_1mm_no_background_0951, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.636563: predicting PTB_all_energies_1mm_no_background_0955 
2025-07-12 11:46:03.643159: PTB_all_energies_1mm_no_background_0955, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.691598: predicting PTB_all_energies_1mm_no_background_0958 
2025-07-12 11:46:03.699132: PTB_all_energies_1mm_no_background_0958, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.767697: predicting PTB_all_energies_1mm_no_background_0960 
2025-07-12 11:46:03.775420: PTB_all_energies_1mm_no_background_0960, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.837651: predicting PTB_all_energies_1mm_no_background_0966 
2025-07-12 11:46:03.844025: PTB_all_energies_1mm_no_background_0966, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.890258: predicting PTB_all_energies_1mm_no_background_0970 
2025-07-12 11:46:03.896523: PTB_all_energies_1mm_no_background_0970, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.943026: predicting PTB_all_energies_1mm_no_background_0972 
2025-07-12 11:46:03.949512: PTB_all_energies_1mm_no_background_0972, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:03.995255: predicting PTB_all_energies_1mm_no_background_0973 
2025-07-12 11:46:04.001612: PTB_all_energies_1mm_no_background_0973, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.047902: predicting PTB_all_energies_1mm_no_background_0974 
2025-07-12 11:46:04.055257: PTB_all_energies_1mm_no_background_0974, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.103296: predicting PTB_all_energies_1mm_no_background_0978 
2025-07-12 11:46:04.109923: PTB_all_energies_1mm_no_background_0978, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.158823: predicting PTB_all_energies_1mm_no_background_0986 
2025-07-12 11:46:04.165325: PTB_all_energies_1mm_no_background_0986, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.211672: predicting PTB_all_energies_1mm_no_background_0987 
2025-07-12 11:46:04.218677: PTB_all_energies_1mm_no_background_0987, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.264612: predicting PTB_all_energies_1mm_no_background_0989 
2025-07-12 11:46:04.271618: PTB_all_energies_1mm_no_background_0989, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.316940: predicting PTB_all_energies_1mm_no_background_0990 
2025-07-12 11:46:04.323569: PTB_all_energies_1mm_no_background_0990, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.369745: predicting PTB_all_energies_1mm_no_background_0991 
2025-07-12 11:46:04.376387: PTB_all_energies_1mm_no_background_0991, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.422163: predicting PTB_all_energies_1mm_no_background_0994 
2025-07-12 11:46:04.429860: PTB_all_energies_1mm_no_background_0994, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.476156: predicting PTB_all_energies_1mm_no_background_1002 
2025-07-12 11:46:04.483679: PTB_all_energies_1mm_no_background_1002, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.532596: predicting PTB_all_energies_1mm_no_background_1008 
2025-07-12 11:46:04.540035: PTB_all_energies_1mm_no_background_1008, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.588889: predicting PTB_all_energies_1mm_no_background_1012 
2025-07-12 11:46:04.596182: PTB_all_energies_1mm_no_background_1012, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.664428: predicting PTB_all_energies_1mm_no_background_1013 
2025-07-12 11:46:04.671962: PTB_all_energies_1mm_no_background_1013, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.727325: predicting PTB_all_energies_1mm_no_background_1016 
2025-07-12 11:46:04.733801: PTB_all_energies_1mm_no_background_1016, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.779867: predicting PTB_all_energies_1mm_no_background_1028 
2025-07-12 11:46:04.786220: PTB_all_energies_1mm_no_background_1028, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.832417: predicting PTB_all_energies_1mm_no_background_1032 
2025-07-12 11:46:04.838676: PTB_all_energies_1mm_no_background_1032, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.884483: predicting PTB_all_energies_1mm_no_background_1038 
2025-07-12 11:46:04.891838: PTB_all_energies_1mm_no_background_1038, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.938328: predicting PTB_all_energies_1mm_no_background_1052 
2025-07-12 11:46:04.945295: PTB_all_energies_1mm_no_background_1052, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:04.992542: predicting PTB_all_energies_1mm_no_background_1058 
2025-07-12 11:46:04.998876: PTB_all_energies_1mm_no_background_1058, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.047872: predicting PTB_all_energies_1mm_no_background_1070 
2025-07-12 11:46:05.055675: PTB_all_energies_1mm_no_background_1070, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.103011: predicting PTB_all_energies_1mm_no_background_1071 
2025-07-12 11:46:05.109989: PTB_all_energies_1mm_no_background_1071, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.155859: predicting PTB_all_energies_1mm_no_background_1081 
2025-07-12 11:46:05.162274: PTB_all_energies_1mm_no_background_1081, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.207495: predicting PTB_all_energies_1mm_no_background_1095 
2025-07-12 11:46:05.214219: PTB_all_energies_1mm_no_background_1095, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.260098: predicting PTB_all_energies_1mm_no_background_1109 
2025-07-12 11:46:05.267709: PTB_all_energies_1mm_no_background_1109, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.335644: predicting PTB_all_energies_1mm_no_background_1113 
2025-07-12 11:46:05.343220: PTB_all_energies_1mm_no_background_1113, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.399431: predicting PTB_all_energies_1mm_no_background_1122 
2025-07-12 11:46:05.406272: PTB_all_energies_1mm_no_background_1122, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.452971: predicting PTB_all_energies_1mm_no_background_1126 
2025-07-12 11:46:05.459841: PTB_all_energies_1mm_no_background_1126, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.509584: predicting PTB_all_energies_1mm_no_background_1127 
2025-07-12 11:46:05.516535: PTB_all_energies_1mm_no_background_1127, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.564831: predicting PTB_all_energies_1mm_no_background_1131 
2025-07-12 11:46:05.571526: PTB_all_energies_1mm_no_background_1131, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.617263: predicting PTB_all_energies_1mm_no_background_1134 
2025-07-12 11:46:05.623823: PTB_all_energies_1mm_no_background_1134, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.668962: predicting PTB_all_energies_1mm_no_background_1137 
2025-07-12 11:46:05.675908: PTB_all_energies_1mm_no_background_1137, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.722749: predicting PTB_all_energies_1mm_no_background_1152 
2025-07-12 11:46:05.730629: PTB_all_energies_1mm_no_background_1152, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.799073: predicting PTB_all_energies_1mm_no_background_1157 
2025-07-12 11:46:05.806471: PTB_all_energies_1mm_no_background_1157, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.868474: predicting PTB_all_energies_1mm_no_background_1159 
2025-07-12 11:46:05.875227: PTB_all_energies_1mm_no_background_1159, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.921560: predicting PTB_all_energies_1mm_no_background_1170 
2025-07-12 11:46:05.928777: PTB_all_energies_1mm_no_background_1170, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:05.976990: predicting PTB_all_energies_1mm_no_background_1174 
2025-07-12 11:46:05.984037: PTB_all_energies_1mm_no_background_1174, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.031997: predicting PTB_all_energies_1mm_no_background_1180 
2025-07-12 11:46:06.038609: PTB_all_energies_1mm_no_background_1180, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.084619: predicting PTB_all_energies_1mm_no_background_1182 
2025-07-12 11:46:06.091398: PTB_all_energies_1mm_no_background_1182, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.136792: predicting PTB_all_energies_1mm_no_background_1184 
2025-07-12 11:46:06.143844: PTB_all_energies_1mm_no_background_1184, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.189770: predicting PTB_all_energies_1mm_no_background_1187 
2025-07-12 11:46:06.197338: PTB_all_energies_1mm_no_background_1187, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.265683: predicting PTB_all_energies_1mm_no_background_1193 
2025-07-12 11:46:06.273197: PTB_all_energies_1mm_no_background_1193, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.335501: predicting PTB_all_energies_1mm_no_background_1203 
2025-07-12 11:46:06.342006: PTB_all_energies_1mm_no_background_1203, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.388237: predicting PTB_all_energies_1mm_no_background_1209 
2025-07-12 11:46:06.395157: PTB_all_energies_1mm_no_background_1209, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.443723: predicting PTB_all_energies_1mm_no_background_1212 
2025-07-12 11:46:06.450607: PTB_all_energies_1mm_no_background_1212, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.498527: predicting PTB_all_energies_1mm_no_background_1216 
2025-07-12 11:46:06.505227: PTB_all_energies_1mm_no_background_1216, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.550912: predicting PTB_all_energies_1mm_no_background_1220 
2025-07-12 11:46:06.557595: PTB_all_energies_1mm_no_background_1220, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.602683: predicting PTB_all_energies_1mm_no_background_1222 
2025-07-12 11:46:06.609536: PTB_all_energies_1mm_no_background_1222, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.655380: predicting PTB_all_energies_1mm_no_background_1224 
2025-07-12 11:46:06.663852: PTB_all_energies_1mm_no_background_1224, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.731648: predicting PTB_all_energies_1mm_no_background_1228 
2025-07-12 11:46:06.739172: PTB_all_energies_1mm_no_background_1228, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.791913: predicting PTB_all_energies_1mm_no_background_1236 
2025-07-12 11:46:06.798461: PTB_all_energies_1mm_no_background_1236, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.845022: predicting PTB_all_energies_1mm_no_background_1246 
2025-07-12 11:46:06.853250: PTB_all_energies_1mm_no_background_1246, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.900506: predicting PTB_all_energies_1mm_no_background_1247 
2025-07-12 11:46:06.907351: PTB_all_energies_1mm_no_background_1247, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:06.956749: predicting PTB_all_energies_1mm_no_background_1253 
2025-07-12 11:46:06.963522: PTB_all_energies_1mm_no_background_1253, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.010476: predicting PTB_all_energies_1mm_no_background_1255 
2025-07-12 11:46:07.016994: PTB_all_energies_1mm_no_background_1255, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.062034: predicting PTB_all_energies_1mm_no_background_1266 
2025-07-12 11:46:07.069133: PTB_all_energies_1mm_no_background_1266, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.115201: predicting PTB_all_energies_1mm_no_background_1275 
2025-07-12 11:46:07.123025: PTB_all_energies_1mm_no_background_1275, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.191536: predicting PTB_all_energies_1mm_no_background_1278 
2025-07-12 11:46:07.199064: PTB_all_energies_1mm_no_background_1278, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.261167: predicting PTB_all_energies_1mm_no_background_1280 
2025-07-12 11:46:07.267855: PTB_all_energies_1mm_no_background_1280, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.314799: predicting PTB_all_energies_1mm_no_background_1282 
2025-07-12 11:46:07.321613: PTB_all_energies_1mm_no_background_1282, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.370228: predicting PTB_all_energies_1mm_no_background_1295 
2025-07-12 11:46:07.377172: PTB_all_energies_1mm_no_background_1295, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.424783: predicting PTB_all_energies_1mm_no_background_1308 
2025-07-12 11:46:07.431719: PTB_all_energies_1mm_no_background_1308, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.477452: predicting PTB_all_energies_1mm_no_background_1309 
2025-07-12 11:46:07.483936: PTB_all_energies_1mm_no_background_1309, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.529182: predicting PTB_all_energies_1mm_no_background_1314 
2025-07-12 11:46:07.535957: PTB_all_energies_1mm_no_background_1314, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.581587: predicting PTB_all_energies_1mm_no_background_1322 
2025-07-12 11:46:07.589493: PTB_all_energies_1mm_no_background_1322, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.657924: predicting PTB_all_energies_1mm_no_background_1323 
2025-07-12 11:46:07.665152: PTB_all_energies_1mm_no_background_1323, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.725394: predicting PTB_all_energies_1mm_no_background_1324 
2025-07-12 11:46:07.731737: PTB_all_energies_1mm_no_background_1324, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.777891: predicting PTB_all_energies_1mm_no_background_1330 
2025-07-12 11:46:07.784545: PTB_all_energies_1mm_no_background_1330, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.832673: predicting PTB_all_energies_1mm_no_background_1331 
2025-07-12 11:46:07.839103: PTB_all_energies_1mm_no_background_1331, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.885616: predicting PTB_all_energies_1mm_no_background_1350 
2025-07-12 11:46:07.892702: PTB_all_energies_1mm_no_background_1350, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.938517: predicting PTB_all_energies_1mm_no_background_1355 
2025-07-12 11:46:07.945121: PTB_all_energies_1mm_no_background_1355, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:07.990890: predicting PTB_all_energies_1mm_no_background_1357 
2025-07-12 11:46:07.997796: PTB_all_energies_1mm_no_background_1357, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.044219: predicting PTB_all_energies_1mm_no_background_1360 
2025-07-12 11:46:08.051912: PTB_all_energies_1mm_no_background_1360, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.119632: predicting PTB_all_energies_1mm_no_background_1363 
2025-07-12 11:46:08.126992: PTB_all_energies_1mm_no_background_1363, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.185611: predicting PTB_all_energies_1mm_no_background_1364 
2025-07-12 11:46:08.192116: PTB_all_energies_1mm_no_background_1364, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.238621: predicting PTB_all_energies_1mm_no_background_1367 
2025-07-12 11:46:08.245267: PTB_all_energies_1mm_no_background_1367, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.293935: predicting PTB_all_energies_1mm_no_background_1375 
2025-07-12 11:46:08.300618: PTB_all_energies_1mm_no_background_1375, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.346509: predicting PTB_all_energies_1mm_no_background_1376 
2025-07-12 11:46:08.353146: PTB_all_energies_1mm_no_background_1376, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.400582: predicting PTB_all_energies_1mm_no_background_1379 
2025-07-12 11:46:08.407181: PTB_all_energies_1mm_no_background_1379, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.453651: predicting PTB_all_energies_1mm_no_background_1384 
2025-07-12 11:46:08.460122: PTB_all_energies_1mm_no_background_1384, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.506348: predicting PTB_all_energies_1mm_no_background_1388 
2025-07-12 11:46:08.514713: PTB_all_energies_1mm_no_background_1388, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.584159: predicting PTB_all_energies_1mm_no_background_1390 
2025-07-12 11:46:08.591630: PTB_all_energies_1mm_no_background_1390, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.651612: predicting PTB_all_energies_1mm_no_background_1401 
2025-07-12 11:46:08.658017: PTB_all_energies_1mm_no_background_1401, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.704092: predicting PTB_all_energies_1mm_no_background_1404 
2025-07-12 11:46:08.710412: PTB_all_energies_1mm_no_background_1404, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.760513: predicting PTB_all_energies_1mm_no_background_1409 
2025-07-12 11:46:08.767134: PTB_all_energies_1mm_no_background_1409, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.813076: predicting PTB_all_energies_1mm_no_background_1411 
2025-07-12 11:46:08.819802: PTB_all_energies_1mm_no_background_1411, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.865110: predicting PTB_all_energies_1mm_no_background_1418 
2025-07-12 11:46:08.871810: PTB_all_energies_1mm_no_background_1418, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.916874: predicting PTB_all_energies_1mm_no_background_1424 
2025-07-12 11:46:08.923958: PTB_all_energies_1mm_no_background_1424, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:08.970179: predicting PTB_all_energies_1mm_no_background_1425 
2025-07-12 11:46:08.977699: PTB_all_energies_1mm_no_background_1425, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.045529: predicting PTB_all_energies_1mm_no_background_1426 
2025-07-12 11:46:09.053076: PTB_all_energies_1mm_no_background_1426, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.114565: predicting PTB_all_energies_1mm_no_background_1427 
2025-07-12 11:46:09.120968: PTB_all_energies_1mm_no_background_1427, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.167247: predicting PTB_all_energies_1mm_no_background_1429 
2025-07-12 11:46:09.174082: PTB_all_energies_1mm_no_background_1429, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.222502: predicting PTB_all_energies_1mm_no_background_1431 
2025-07-12 11:46:09.229347: PTB_all_energies_1mm_no_background_1431, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.275813: predicting PTB_all_energies_1mm_no_background_1449 
2025-07-12 11:46:09.283123: PTB_all_energies_1mm_no_background_1449, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.328890: predicting PTB_all_energies_1mm_no_background_1453 
2025-07-12 11:46:09.335761: PTB_all_energies_1mm_no_background_1453, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.380802: predicting PTB_all_energies_1mm_no_background_1454 
2025-07-12 11:46:09.387077: PTB_all_energies_1mm_no_background_1454, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.433192: predicting PTB_all_energies_1mm_no_background_1456 
2025-07-12 11:46:09.441338: PTB_all_energies_1mm_no_background_1456, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.509266: predicting PTB_all_energies_1mm_no_background_1466 
2025-07-12 11:46:09.516744: PTB_all_energies_1mm_no_background_1466, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.578470: predicting PTB_all_energies_1mm_no_background_1475 
2025-07-12 11:46:09.584651: PTB_all_energies_1mm_no_background_1475, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.630962: predicting PTB_all_energies_1mm_no_background_1480 
2025-07-12 11:46:09.637978: PTB_all_energies_1mm_no_background_1480, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.686456: predicting PTB_all_energies_1mm_no_background_1486 
2025-07-12 11:46:09.692791: PTB_all_energies_1mm_no_background_1486, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.738661: predicting PTB_all_energies_1mm_no_background_1488 
2025-07-12 11:46:09.745785: PTB_all_energies_1mm_no_background_1488, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.791474: predicting PTB_all_energies_1mm_no_background_1493 
2025-07-12 11:46:09.798854: PTB_all_energies_1mm_no_background_1493, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.845516: predicting PTB_all_energies_1mm_no_background_1496 
2025-07-12 11:46:09.851849: PTB_all_energies_1mm_no_background_1496, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.898145: predicting PTB_all_energies_1mm_no_background_1499 
2025-07-12 11:46:09.905783: PTB_all_energies_1mm_no_background_1499, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:09.975215: predicting PTB_all_energies_1mm_no_background_1503 
2025-07-12 11:46:09.982712: PTB_all_energies_1mm_no_background_1503, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.045106: predicting PTB_all_energies_1mm_no_background_1512 
2025-07-12 11:46:10.051674: PTB_all_energies_1mm_no_background_1512, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.098079: predicting PTB_all_energies_1mm_no_background_1513 
2025-07-12 11:46:10.104789: PTB_all_energies_1mm_no_background_1513, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.154653: predicting PTB_all_energies_1mm_no_background_1527 
2025-07-12 11:46:10.161264: PTB_all_energies_1mm_no_background_1527, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.207415: predicting PTB_all_energies_1mm_no_background_1530 
2025-07-12 11:46:10.214041: PTB_all_energies_1mm_no_background_1530, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.259521: predicting PTB_all_energies_1mm_no_background_1534 
2025-07-12 11:46:10.266434: PTB_all_energies_1mm_no_background_1534, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.314786: predicting PTB_all_energies_1mm_no_background_1536 
2025-07-12 11:46:10.322007: PTB_all_energies_1mm_no_background_1536, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.370761: predicting PTB_all_energies_1mm_no_background_1542 
2025-07-12 11:46:10.378434: PTB_all_energies_1mm_no_background_1542, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.446646: predicting PTB_all_energies_1mm_no_background_1544 
2025-07-12 11:46:10.454060: PTB_all_energies_1mm_no_background_1544, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.516068: predicting PTB_all_energies_1mm_no_background_1555 
2025-07-12 11:46:10.522486: PTB_all_energies_1mm_no_background_1555, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.568914: predicting PTB_all_energies_1mm_no_background_1559 
2025-07-12 11:46:10.575455: PTB_all_energies_1mm_no_background_1559, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.621186: predicting PTB_all_energies_1mm_no_background_1560 
2025-07-12 11:46:10.627720: PTB_all_energies_1mm_no_background_1560, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.673296: predicting PTB_all_energies_1mm_no_background_1572 
2025-07-12 11:46:10.680594: PTB_all_energies_1mm_no_background_1572, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.726385: predicting PTB_all_energies_1mm_no_background_1575 
2025-07-12 11:46:10.732786: PTB_all_energies_1mm_no_background_1575, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.783250: predicting PTB_all_energies_1mm_no_background_1579 
2025-07-12 11:46:10.789660: PTB_all_energies_1mm_no_background_1579, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.835941: predicting PTB_all_energies_1mm_no_background_1582 
2025-07-12 11:46:10.843566: PTB_all_energies_1mm_no_background_1582, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.912280: predicting PTB_all_energies_1mm_no_background_1584 
2025-07-12 11:46:10.919676: PTB_all_energies_1mm_no_background_1584, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:10.981292: predicting PTB_all_energies_1mm_no_background_1593 
2025-07-12 11:46:10.987518: PTB_all_energies_1mm_no_background_1593, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.034085: predicting PTB_all_energies_1mm_no_background_1597 
2025-07-12 11:46:11.040896: PTB_all_energies_1mm_no_background_1597, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.087009: predicting PTB_all_energies_1mm_no_background_1598 
2025-07-12 11:46:11.093891: PTB_all_energies_1mm_no_background_1598, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.140771: predicting PTB_all_energies_1mm_no_background_1605 
2025-07-12 11:46:11.147765: PTB_all_energies_1mm_no_background_1605, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.193069: predicting PTB_all_energies_1mm_no_background_1606 
2025-07-12 11:46:11.199870: PTB_all_energies_1mm_no_background_1606, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.248508: predicting PTB_all_energies_1mm_no_background_1612 
2025-07-12 11:46:11.255633: PTB_all_energies_1mm_no_background_1612, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.302519: predicting PTB_all_energies_1mm_no_background_1614 
2025-07-12 11:46:11.311156: PTB_all_energies_1mm_no_background_1614, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.379759: predicting PTB_all_energies_1mm_no_background_1625 
2025-07-12 11:46:11.387055: PTB_all_energies_1mm_no_background_1625, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.448191: predicting PTB_all_energies_1mm_no_background_1629 
2025-07-12 11:46:11.454875: PTB_all_energies_1mm_no_background_1629, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.501289: predicting PTB_all_energies_1mm_no_background_1632 
2025-07-12 11:46:11.507904: PTB_all_energies_1mm_no_background_1632, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.553486: predicting PTB_all_energies_1mm_no_background_1634 
2025-07-12 11:46:11.560168: PTB_all_energies_1mm_no_background_1634, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.606309: predicting PTB_all_energies_1mm_no_background_1638 
2025-07-12 11:46:11.613127: PTB_all_energies_1mm_no_background_1638, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.662087: predicting PTB_all_energies_1mm_no_background_1642 
2025-07-12 11:46:11.668496: PTB_all_energies_1mm_no_background_1642, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.714606: predicting PTB_all_energies_1mm_no_background_1653 
2025-07-12 11:46:11.721622: PTB_all_energies_1mm_no_background_1653, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.768227: predicting PTB_all_energies_1mm_no_background_1654 
2025-07-12 11:46:11.774758: PTB_all_energies_1mm_no_background_1654, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.821147: predicting PTB_all_energies_1mm_no_background_1658 
2025-07-12 11:46:11.827762: PTB_all_energies_1mm_no_background_1658, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.874120: predicting PTB_all_energies_1mm_no_background_1662 
2025-07-12 11:46:11.880667: PTB_all_energies_1mm_no_background_1662, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.927596: predicting PTB_all_energies_1mm_no_background_1663 
2025-07-12 11:46:11.934266: PTB_all_energies_1mm_no_background_1663, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:11.979671: predicting PTB_all_energies_1mm_no_background_1665 
2025-07-12 11:46:11.986009: PTB_all_energies_1mm_no_background_1665, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.033201: predicting PTB_all_energies_1mm_no_background_1669 
2025-07-12 11:46:12.039562: PTB_all_energies_1mm_no_background_1669, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.088539: predicting PTB_all_energies_1mm_no_background_1676 
2025-07-12 11:46:12.094996: PTB_all_energies_1mm_no_background_1676, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.141904: predicting PTB_all_energies_1mm_no_background_1687 
2025-07-12 11:46:12.148589: PTB_all_energies_1mm_no_background_1687, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.194727: predicting PTB_all_energies_1mm_no_background_1689 
2025-07-12 11:46:12.201257: PTB_all_energies_1mm_no_background_1689, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.247425: predicting PTB_all_energies_1mm_no_background_1701 
2025-07-12 11:46:12.254704: PTB_all_energies_1mm_no_background_1701, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.301054: predicting PTB_all_energies_1mm_no_background_1706 
2025-07-12 11:46:12.307714: PTB_all_energies_1mm_no_background_1706, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.354077: predicting PTB_all_energies_1mm_no_background_1722 
2025-07-12 11:46:12.360459: PTB_all_energies_1mm_no_background_1722, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.406020: predicting PTB_all_energies_1mm_no_background_1730 
2025-07-12 11:46:12.412696: PTB_all_energies_1mm_no_background_1730, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.459613: predicting PTB_all_energies_1mm_no_background_1731 
2025-07-12 11:46:12.466257: PTB_all_energies_1mm_no_background_1731, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.513943: predicting PTB_all_energies_1mm_no_background_1737 
2025-07-12 11:46:12.520985: PTB_all_energies_1mm_no_background_1737, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.569572: predicting PTB_all_energies_1mm_no_background_1741 
2025-07-12 11:46:12.576242: PTB_all_energies_1mm_no_background_1741, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.623123: predicting PTB_all_energies_1mm_no_background_1742 
2025-07-12 11:46:12.629624: PTB_all_energies_1mm_no_background_1742, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.675989: predicting PTB_all_energies_1mm_no_background_1745 
2025-07-12 11:46:12.682449: PTB_all_energies_1mm_no_background_1745, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.730978: predicting PTB_all_energies_1mm_no_background_1748 
2025-07-12 11:46:12.737725: PTB_all_energies_1mm_no_background_1748, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.784048: predicting PTB_all_energies_1mm_no_background_1751 
2025-07-12 11:46:12.790460: PTB_all_energies_1mm_no_background_1751, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.835996: predicting PTB_all_energies_1mm_no_background_1757 
2025-07-12 11:46:12.842441: PTB_all_energies_1mm_no_background_1757, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.888421: predicting PTB_all_energies_1mm_no_background_1758 
2025-07-12 11:46:12.895509: PTB_all_energies_1mm_no_background_1758, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.943485: predicting PTB_all_energies_1mm_no_background_1764 
2025-07-12 11:46:12.950336: PTB_all_energies_1mm_no_background_1764, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:12.998944: predicting PTB_all_energies_1mm_no_background_1766 
2025-07-12 11:46:13.005512: PTB_all_energies_1mm_no_background_1766, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.052203: predicting PTB_all_energies_1mm_no_background_1770 
2025-07-12 11:46:13.058767: PTB_all_energies_1mm_no_background_1770, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.105408: predicting PTB_all_energies_1mm_no_background_1771 
2025-07-12 11:46:13.111779: PTB_all_energies_1mm_no_background_1771, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.158547: predicting PTB_all_energies_1mm_no_background_1777 
2025-07-12 11:46:13.165044: PTB_all_energies_1mm_no_background_1777, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.211323: predicting PTB_all_energies_1mm_no_background_1778 
2025-07-12 11:46:13.217776: PTB_all_energies_1mm_no_background_1778, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.263914: predicting PTB_all_energies_1mm_no_background_1782 
2025-07-12 11:46:13.270791: PTB_all_energies_1mm_no_background_1782, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.316771: predicting PTB_all_energies_1mm_no_background_1783 
2025-07-12 11:46:13.323950: PTB_all_energies_1mm_no_background_1783, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.371211: predicting PTB_all_energies_1mm_no_background_1788 
2025-07-12 11:46:13.377989: PTB_all_energies_1mm_no_background_1788, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.427611: predicting PTB_all_energies_1mm_no_background_1789 
2025-07-12 11:46:13.434218: PTB_all_energies_1mm_no_background_1789, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.480763: predicting PTB_all_energies_1mm_no_background_1792 
2025-07-12 11:46:13.487834: PTB_all_energies_1mm_no_background_1792, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.533911: predicting PTB_all_energies_1mm_no_background_1798 
2025-07-12 11:46:13.540558: PTB_all_energies_1mm_no_background_1798, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:13.586359: predicting PTB_all_energies_1mm_no_background_1800 
2025-07-12 11:46:13.593024: PTB_all_energies_1mm_no_background_1800, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 11:46:19.059090: Validation complete 
2025-07-12 11:46:19.060667: Mean Validation Dice:  0.9318611317160446 
