
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-11 16:28:59.394963: Using torch.compile... 
2025-07-11 16:29:00.636511: do_dummy_2d_data_aug: False 
2025-07-11 16:29:00.641647: Creating new 5-fold cross-validation split... 
2025-07-11 16:29:00.658453: Desired fold for training: 0 
2025-07-11 16:29:00.660427: This split has 1440 training and 360 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 35, 'patch_size': [512, 512], 'median_image_size_in_voxels': [504.0, 504.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_PTB_all_energies_1mm_no_background_alldata', 'plans_name': 'nnUNetResEncUNetPlans_24G', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 504, 504], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 4282.0, 'mean': 1593.7022300557526, 'median': 1568.0, 'min': 0.0, 'percentile_00_5': 982.0, 'percentile_99_5': 2808.0, 'std': 337.91142407822184}}} 
 
2025-07-11 16:29:07.180511: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-11 16:29:07.254046:  
2025-07-11 16:29:07.255309: Epoch 0 
2025-07-11 16:29:07.256633: Current learning rate: 0.01 
2025-07-11 16:32:14.298012: train_loss -0.149 
2025-07-11 16:32:14.299179: val_loss -0.6214 
2025-07-11 16:32:14.300403: Pseudo dice [np.float32(0.6474)] 
2025-07-11 16:32:14.301498: Epoch time: 187.05 s 
2025-07-11 16:32:14.302598: Yayy! New best EMA pseudo Dice: 0.6474000215530396 
2025-07-11 16:32:16.198289:  
2025-07-11 16:32:16.199883: Epoch 1 
2025-07-11 16:32:16.201072: Current learning rate: 0.00999 
2025-07-11 16:33:24.357984: train_loss -0.7592 
2025-07-11 16:33:24.359676: val_loss -0.8278 
2025-07-11 16:33:24.362071: Pseudo dice [np.float32(0.8662)] 
2025-07-11 16:33:24.363103: Epoch time: 68.16 s 
2025-07-11 16:33:24.364150: Yayy! New best EMA pseudo Dice: 0.6693000197410583 
2025-07-11 16:33:26.534479:  
2025-07-11 16:33:26.536730: Epoch 2 
2025-07-11 16:33:26.538288: Current learning rate: 0.00998 
2025-07-11 16:34:35.508223: train_loss -0.8458 
2025-07-11 16:34:35.509718: val_loss -0.8709 
2025-07-11 16:34:35.511571: Pseudo dice [np.float32(0.9031)] 
2025-07-11 16:34:35.512830: Epoch time: 68.98 s 
2025-07-11 16:34:35.514305: Yayy! New best EMA pseudo Dice: 0.6927000284194946 
2025-07-11 16:34:37.715205:  
2025-07-11 16:34:37.717318: Epoch 3 
2025-07-11 16:34:37.718387: Current learning rate: 0.00997 
2025-07-11 16:35:46.102561: train_loss -0.8713 
2025-07-11 16:35:46.104411: val_loss -0.8812 
2025-07-11 16:35:46.105513: Pseudo dice [np.float32(0.9031)] 
2025-07-11 16:35:46.106853: Epoch time: 68.39 s 
2025-07-11 16:35:46.108257: Yayy! New best EMA pseudo Dice: 0.713699996471405 
2025-07-11 16:35:48.311452:  
2025-07-11 16:35:48.313814: Epoch 4 
2025-07-11 16:35:48.315025: Current learning rate: 0.00996 
2025-07-11 16:36:56.486093: train_loss -0.891 
2025-07-11 16:36:56.487580: val_loss -0.8929 
2025-07-11 16:36:56.488612: Pseudo dice [np.float32(0.9169)] 
2025-07-11 16:36:56.489626: Epoch time: 68.18 s 
2025-07-11 16:36:56.490886: Yayy! New best EMA pseudo Dice: 0.734000027179718 
2025-07-11 16:36:58.722940:  
2025-07-11 16:36:58.724968: Epoch 5 
2025-07-11 16:36:58.726392: Current learning rate: 0.00995 
2025-07-11 16:38:06.950740: train_loss -0.8989 
2025-07-11 16:38:06.952528: val_loss -0.9034 
2025-07-11 16:38:06.953627: Pseudo dice [np.float32(0.9247)] 
2025-07-11 16:38:06.955064: Epoch time: 68.23 s 
2025-07-11 16:38:06.956417: Yayy! New best EMA pseudo Dice: 0.7530999779701233 
2025-07-11 16:38:09.346828:  
2025-07-11 16:38:09.349028: Epoch 6 
2025-07-11 16:38:09.350446: Current learning rate: 0.00995 
2025-07-11 16:39:17.408844: train_loss -0.9072 
2025-07-11 16:39:17.410288: val_loss -0.9065 
2025-07-11 16:39:17.411334: Pseudo dice [np.float32(0.9251)] 
2025-07-11 16:39:17.412702: Epoch time: 68.07 s 
2025-07-11 16:39:17.413935: Yayy! New best EMA pseudo Dice: 0.7702999711036682 
2025-07-11 16:39:19.836899:  
2025-07-11 16:39:19.838635: Epoch 7 
2025-07-11 16:39:19.839713: Current learning rate: 0.00994 
2025-07-11 16:40:27.880222: train_loss -0.9141 
2025-07-11 16:40:27.881889: val_loss -0.9116 
2025-07-11 16:40:27.882997: Pseudo dice [np.float32(0.9286)] 
2025-07-11 16:40:27.883941: Epoch time: 68.05 s 
2025-07-11 16:40:27.885407: Yayy! New best EMA pseudo Dice: 0.7860999703407288 
2025-07-11 16:40:31.083543:  
2025-07-11 16:40:31.085249: Epoch 8 
2025-07-11 16:40:31.086397: Current learning rate: 0.00993 
2025-07-11 16:41:39.277086: train_loss -0.9177 
2025-07-11 16:41:39.278537: val_loss -0.9161 
2025-07-11 16:41:39.280011: Pseudo dice [np.float32(0.9323)] 
2025-07-11 16:41:39.281215: Epoch time: 68.2 s 
2025-07-11 16:41:39.282229: Yayy! New best EMA pseudo Dice: 0.8007000088691711 
2025-07-11 16:41:41.465198:  
2025-07-11 16:41:41.467202: Epoch 9 
2025-07-11 16:41:41.468329: Current learning rate: 0.00992 
2025-07-11 16:42:49.761434: train_loss -0.921 
2025-07-11 16:42:49.762928: val_loss -0.9138 
2025-07-11 16:42:49.764389: Pseudo dice [np.float32(0.9286)] 
2025-07-11 16:42:49.765852: Epoch time: 68.3 s 
2025-07-11 16:42:49.767297: Yayy! New best EMA pseudo Dice: 0.8134999871253967 
2025-07-11 16:42:51.965238:  
2025-07-11 16:42:51.967142: Epoch 10 
2025-07-11 16:42:51.968205: Current learning rate: 0.00991 
2025-07-11 16:43:59.955040: train_loss -0.9214 
2025-07-11 16:43:59.956454: val_loss -0.9185 
2025-07-11 16:43:59.957956: Pseudo dice [np.float32(0.9338)] 
2025-07-11 16:43:59.959717: Epoch time: 67.99 s 
2025-07-11 16:43:59.960946: Yayy! New best EMA pseudo Dice: 0.8256000280380249 
2025-07-11 16:44:02.096518:  
2025-07-11 16:44:02.098534: Epoch 11 
2025-07-11 16:44:02.099798: Current learning rate: 0.0099 
2025-07-11 16:45:10.437565: train_loss -0.9243 
2025-07-11 16:45:10.438811: val_loss -0.9225 
2025-07-11 16:45:10.439817: Pseudo dice [np.float32(0.937)] 
2025-07-11 16:45:10.440951: Epoch time: 68.34 s 
2025-07-11 16:45:10.442741: Yayy! New best EMA pseudo Dice: 0.8367000222206116 
2025-07-11 16:45:12.685956:  
2025-07-11 16:45:12.688062: Epoch 12 
2025-07-11 16:45:12.689144: Current learning rate: 0.00989 
2025-07-11 16:46:21.001236: train_loss -0.9272 
2025-07-11 16:46:21.002409: val_loss -0.9204 
2025-07-11 16:46:21.003488: Pseudo dice [np.float32(0.9348)] 
2025-07-11 16:46:21.004795: Epoch time: 68.32 s 
2025-07-11 16:46:21.005818: Yayy! New best EMA pseudo Dice: 0.8464999794960022 
2025-07-11 16:46:23.205999:  
2025-07-11 16:46:23.208143: Epoch 13 
2025-07-11 16:46:23.209634: Current learning rate: 0.00988 
2025-07-11 16:47:31.460542: train_loss -0.9282 
2025-07-11 16:47:31.461900: val_loss -0.9247 
2025-07-11 16:47:31.463349: Pseudo dice [np.float32(0.9367)] 
2025-07-11 16:47:31.464509: Epoch time: 68.26 s 
2025-07-11 16:47:31.465690: Yayy! New best EMA pseudo Dice: 0.8554999828338623 
2025-07-11 16:47:33.617466:  
2025-07-11 16:47:33.619481: Epoch 14 
2025-07-11 16:47:33.620671: Current learning rate: 0.00987 
2025-07-11 16:48:41.700199: train_loss -0.9308 
2025-07-11 16:48:41.701498: val_loss -0.9251 
2025-07-11 16:48:41.702737: Pseudo dice [np.float32(0.9372)] 
2025-07-11 16:48:41.704023: Epoch time: 68.09 s 
2025-07-11 16:48:41.705719: Yayy! New best EMA pseudo Dice: 0.8636999726295471 
2025-07-11 16:48:43.915748:  
2025-07-11 16:48:43.917835: Epoch 15 
2025-07-11 16:48:43.919278: Current learning rate: 0.00986 
2025-07-11 16:49:53.086352: train_loss -0.9319 
2025-07-11 16:49:53.087815: val_loss -0.9272 
2025-07-11 16:49:53.088935: Pseudo dice [np.float32(0.938)] 
2025-07-11 16:49:53.089842: Epoch time: 69.17 s 
2025-07-11 16:49:53.091072: Yayy! New best EMA pseudo Dice: 0.8711000084877014 
2025-07-11 16:49:55.302123:  
2025-07-11 16:49:55.304419: Epoch 16 
2025-07-11 16:49:55.305614: Current learning rate: 0.00986 
2025-07-11 16:51:03.674384: train_loss -0.9338 
2025-07-11 16:51:03.675814: val_loss -0.9269 
2025-07-11 16:51:03.676830: Pseudo dice [np.float32(0.9381)] 
2025-07-11 16:51:03.677886: Epoch time: 68.38 s 
2025-07-11 16:51:03.679180: Yayy! New best EMA pseudo Dice: 0.8777999877929688 
2025-07-11 16:51:05.974762:  
2025-07-11 16:51:05.977126: Epoch 17 
2025-07-11 16:51:05.978652: Current learning rate: 0.00985 
2025-07-11 16:52:14.257976: train_loss -0.935 
2025-07-11 16:52:14.259521: val_loss -0.9311 
2025-07-11 16:52:14.261440: Pseudo dice [np.float32(0.94)] 
2025-07-11 16:52:14.262820: Epoch time: 68.29 s 
2025-07-11 16:52:14.263934: Yayy! New best EMA pseudo Dice: 0.8841000199317932 
2025-07-11 16:52:16.487845:  
2025-07-11 16:52:16.490019: Epoch 18 
2025-07-11 16:52:16.491369: Current learning rate: 0.00984 
2025-07-11 16:53:24.778401: train_loss -0.9377 
2025-07-11 16:53:24.779570: val_loss -0.9257 
2025-07-11 16:53:24.780885: Pseudo dice [np.float32(0.9368)] 
2025-07-11 16:53:24.782109: Epoch time: 68.29 s 
2025-07-11 16:53:24.783345: Yayy! New best EMA pseudo Dice: 0.8892999887466431 
2025-07-11 16:53:27.007548:  
2025-07-11 16:53:27.009873: Epoch 19 
2025-07-11 16:53:27.010865: Current learning rate: 0.00983 
2025-07-11 16:54:35.246467: train_loss -0.9387 
2025-07-11 16:54:35.247849: val_loss -0.9284 
2025-07-11 16:54:35.249276: Pseudo dice [np.float32(0.9385)] 
2025-07-11 16:54:35.250453: Epoch time: 68.24 s 
2025-07-11 16:54:35.251587: Yayy! New best EMA pseudo Dice: 0.8942999839782715 
2025-07-11 16:54:37.478536:  
2025-07-11 16:54:37.480744: Epoch 20 
2025-07-11 16:54:37.482265: Current learning rate: 0.00982 
2025-07-11 16:55:45.754293: train_loss -0.9383 
2025-07-11 16:55:45.756145: val_loss -0.9289 
2025-07-11 16:55:45.757354: Pseudo dice [np.float32(0.9388)] 
2025-07-11 16:55:45.758499: Epoch time: 68.28 s 
2025-07-11 16:55:45.759374: Yayy! New best EMA pseudo Dice: 0.8986999988555908 
2025-07-11 16:55:48.050025:  
2025-07-11 16:55:48.051716: Epoch 21 
2025-07-11 16:55:48.052757: Current learning rate: 0.00981 
2025-07-11 16:56:56.335478: train_loss -0.9401 
2025-07-11 16:56:56.336774: val_loss -0.9328 
2025-07-11 16:56:56.338193: Pseudo dice [np.float32(0.9421)] 
2025-07-11 16:56:56.339555: Epoch time: 68.29 s 
2025-07-11 16:56:56.340746: Yayy! New best EMA pseudo Dice: 0.902999997138977 
2025-07-11 16:56:58.555226:  
2025-07-11 16:56:58.557370: Epoch 22 
2025-07-11 16:56:58.558703: Current learning rate: 0.0098 
2025-07-11 16:58:06.779921: train_loss -0.942 
2025-07-11 16:58:06.781594: val_loss -0.9312 
2025-07-11 16:58:06.782764: Pseudo dice [np.float32(0.9396)] 
2025-07-11 16:58:06.784075: Epoch time: 68.23 s 
2025-07-11 16:58:06.785308: Yayy! New best EMA pseudo Dice: 0.9067000150680542 
2025-07-11 16:58:09.004270:  
2025-07-11 16:58:09.006321: Epoch 23 
2025-07-11 16:58:09.007319: Current learning rate: 0.00979 
2025-07-11 16:59:18.073092: train_loss -0.9416 
2025-07-11 16:59:18.074441: val_loss -0.9289 
2025-07-11 16:59:18.075407: Pseudo dice [np.float32(0.939)] 
2025-07-11 16:59:18.076557: Epoch time: 69.07 s 
2025-07-11 16:59:18.077990: Yayy! New best EMA pseudo Dice: 0.9099000096321106 
2025-07-11 16:59:20.307767:  
2025-07-11 16:59:20.309733: Epoch 24 
2025-07-11 16:59:20.310818: Current learning rate: 0.00978 
2025-07-11 17:00:28.876701: train_loss -0.9431 
2025-07-11 17:00:28.878157: val_loss -0.9347 
2025-07-11 17:00:28.879232: Pseudo dice [np.float32(0.9433)] 
2025-07-11 17:00:28.880221: Epoch time: 68.57 s 
2025-07-11 17:00:28.881053: Yayy! New best EMA pseudo Dice: 0.9132999777793884 
2025-07-11 17:00:31.094203:  
2025-07-11 17:00:31.095968: Epoch 25 
2025-07-11 17:00:31.096949: Current learning rate: 0.00977 
2025-07-11 17:01:39.595924: train_loss -0.9434 
2025-07-11 17:01:39.597662: val_loss -0.9318 
2025-07-11 17:01:39.598856: Pseudo dice [np.float32(0.9405)] 
2025-07-11 17:01:39.599767: Epoch time: 68.51 s 
2025-07-11 17:01:39.600970: Yayy! New best EMA pseudo Dice: 0.9160000085830688 
2025-07-11 17:01:41.801343:  
2025-07-11 17:01:41.803489: Epoch 26 
2025-07-11 17:01:41.804741: Current learning rate: 0.00977 
2025-07-11 17:02:50.069771: train_loss -0.9446 
2025-07-11 17:02:50.071907: val_loss -0.9338 
2025-07-11 17:02:50.073716: Pseudo dice [np.float32(0.94)] 
2025-07-11 17:02:50.074896: Epoch time: 68.27 s 
2025-07-11 17:02:50.076001: Yayy! New best EMA pseudo Dice: 0.91839998960495 
2025-07-11 17:02:52.299807:  
2025-07-11 17:02:52.302021: Epoch 27 
2025-07-11 17:02:52.303253: Current learning rate: 0.00976 
2025-07-11 17:04:00.664326: train_loss -0.9449 
2025-07-11 17:04:00.665755: val_loss -0.9324 
2025-07-11 17:04:00.666670: Pseudo dice [np.float32(0.9402)] 
2025-07-11 17:04:00.667919: Epoch time: 68.37 s 
2025-07-11 17:04:00.669219: Yayy! New best EMA pseudo Dice: 0.9205999970436096 
2025-07-11 17:04:02.897030:  
2025-07-11 17:04:02.898927: Epoch 28 
2025-07-11 17:04:02.900364: Current learning rate: 0.00975 
2025-07-11 17:05:11.692639: train_loss -0.9457 
2025-07-11 17:05:11.694238: val_loss -0.9369 
2025-07-11 17:05:11.695550: Pseudo dice [np.float32(0.9454)] 
2025-07-11 17:05:11.696675: Epoch time: 68.8 s 
2025-07-11 17:05:11.697719: Yayy! New best EMA pseudo Dice: 0.9230999946594238 
2025-07-11 17:05:13.886519:  
2025-07-11 17:05:13.888471: Epoch 29 
2025-07-11 17:05:13.889831: Current learning rate: 0.00974 
2025-07-11 17:06:22.320013: train_loss -0.9472 
2025-07-11 17:06:22.321829: val_loss -0.9345 
2025-07-11 17:06:22.322850: Pseudo dice [np.float32(0.9417)] 
2025-07-11 17:06:22.323985: Epoch time: 68.44 s 
2025-07-11 17:06:22.325510: Yayy! New best EMA pseudo Dice: 0.9248999953269958 
2025-07-11 17:06:24.548371:  
2025-07-11 17:06:24.550515: Epoch 30 
2025-07-11 17:06:24.551888: Current learning rate: 0.00973 
2025-07-11 17:07:32.957227: train_loss -0.9483 
2025-07-11 17:07:32.958789: val_loss -0.9316 
2025-07-11 17:07:32.959836: Pseudo dice [np.float32(0.9402)] 
2025-07-11 17:07:32.960962: Epoch time: 68.41 s 
2025-07-11 17:07:32.962430: Yayy! New best EMA pseudo Dice: 0.9265000224113464 
2025-07-11 17:07:35.172150:  
2025-07-11 17:07:35.174356: Epoch 31 
2025-07-11 17:07:35.175494: Current learning rate: 0.00972 
2025-07-11 17:08:43.914536: train_loss -0.9503 
2025-07-11 17:08:43.915956: val_loss -0.9353 
2025-07-11 17:08:43.917068: Pseudo dice [np.float32(0.9414)] 
2025-07-11 17:08:43.918661: Epoch time: 68.75 s 
2025-07-11 17:08:43.920253: Yayy! New best EMA pseudo Dice: 0.9279999732971191 
2025-07-11 17:08:46.145389:  
2025-07-11 17:08:46.147333: Epoch 32 
2025-07-11 17:08:46.148428: Current learning rate: 0.00971 
2025-07-11 17:09:54.297761: train_loss -0.949 
2025-07-11 17:09:54.299026: val_loss -0.9328 
2025-07-11 17:09:54.300254: Pseudo dice [np.float32(0.9402)] 
2025-07-11 17:09:54.301243: Epoch time: 68.16 s 
2025-07-11 17:09:54.302978: Yayy! New best EMA pseudo Dice: 0.9291999936103821 
2025-07-11 17:09:56.513932:  
2025-07-11 17:09:56.516262: Epoch 33 
2025-07-11 17:09:56.517654: Current learning rate: 0.0097 
2025-07-11 17:11:05.043701: train_loss -0.9489 
2025-07-11 17:11:05.045228: val_loss -0.9367 
2025-07-11 17:11:05.046164: Pseudo dice [np.float32(0.944)] 
2025-07-11 17:11:05.047186: Epoch time: 68.53 s 
2025-07-11 17:11:05.048511: Yayy! New best EMA pseudo Dice: 0.9307000041007996 
2025-07-11 17:11:07.259174:  
2025-07-11 17:11:07.261182: Epoch 34 
2025-07-11 17:11:07.262287: Current learning rate: 0.00969 
2025-07-11 17:12:15.830982: train_loss -0.95 
2025-07-11 17:12:15.832426: val_loss -0.9368 
2025-07-11 17:12:15.833678: Pseudo dice [np.float32(0.9443)] 
2025-07-11 17:12:15.834914: Epoch time: 68.58 s 
2025-07-11 17:12:15.836201: Yayy! New best EMA pseudo Dice: 0.9319999814033508 
2025-07-11 17:12:18.114085:  
2025-07-11 17:12:18.116309: Epoch 35 
2025-07-11 17:12:18.117461: Current learning rate: 0.00968 
2025-07-11 17:13:26.661842: train_loss -0.9509 
2025-07-11 17:13:26.663188: val_loss -0.9374 
2025-07-11 17:13:26.664575: Pseudo dice [np.float32(0.9433)] 
2025-07-11 17:13:26.666286: Epoch time: 68.55 s 
2025-07-11 17:13:26.667609: Yayy! New best EMA pseudo Dice: 0.9330999851226807 
2025-07-11 17:13:28.903926:  
2025-07-11 17:13:28.906609: Epoch 36 
2025-07-11 17:13:28.908158: Current learning rate: 0.00968 
2025-07-11 17:14:37.426350: train_loss -0.9522 
2025-07-11 17:14:37.427829: val_loss -0.9381 
2025-07-11 17:14:37.429241: Pseudo dice [np.float32(0.9445)] 
2025-07-11 17:14:37.430286: Epoch time: 68.53 s 
2025-07-11 17:14:37.431352: Yayy! New best EMA pseudo Dice: 0.9343000054359436 
2025-07-11 17:14:39.688729:  
2025-07-11 17:14:39.690886: Epoch 37 
2025-07-11 17:14:39.692293: Current learning rate: 0.00967 
2025-07-11 17:15:48.083657: train_loss -0.9509 
2025-07-11 17:15:48.085151: val_loss -0.9356 
2025-07-11 17:15:48.086361: Pseudo dice [np.float32(0.9424)] 
2025-07-11 17:15:48.087508: Epoch time: 68.4 s 
2025-07-11 17:15:48.089530: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2025-07-11 17:15:50.275695:  
2025-07-11 17:15:50.277505: Epoch 38 
2025-07-11 17:15:50.278811: Current learning rate: 0.00966 
2025-07-11 17:16:58.630329: train_loss -0.9518 
2025-07-11 17:16:58.631747: val_loss -0.9369 
2025-07-11 17:16:58.632792: Pseudo dice [np.float32(0.9441)] 
2025-07-11 17:16:58.634295: Epoch time: 68.36 s 
2025-07-11 17:16:58.635282: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-07-11 17:17:00.837055:  
2025-07-11 17:17:00.839322: Epoch 39 
2025-07-11 17:17:00.841190: Current learning rate: 0.00965 
2025-07-11 17:18:10.028862: train_loss -0.9526 
2025-07-11 17:18:10.031210: val_loss -0.9312 
2025-07-11 17:18:10.032530: Pseudo dice [np.float32(0.9374)] 
2025-07-11 17:18:10.033570: Epoch time: 69.2 s 
2025-07-11 17:18:10.035184: Yayy! New best EMA pseudo Dice: 0.9361000061035156 
2025-07-11 17:18:12.247062:  
2025-07-11 17:18:12.248914: Epoch 40 
2025-07-11 17:18:12.250069: Current learning rate: 0.00964 
2025-07-11 17:19:20.609241: train_loss -0.952 
2025-07-11 17:19:20.610762: val_loss -0.9411 
2025-07-11 17:19:20.612591: Pseudo dice [np.float32(0.947)] 
2025-07-11 17:19:20.614094: Epoch time: 68.37 s 
2025-07-11 17:19:20.615216: Yayy! New best EMA pseudo Dice: 0.9372000098228455 
2025-07-11 17:19:22.877050:  
2025-07-11 17:19:22.879621: Epoch 41 
2025-07-11 17:19:22.880610: Current learning rate: 0.00963 
2025-07-11 17:20:31.528402: train_loss -0.9542 
2025-07-11 17:20:31.529624: val_loss -0.9377 
2025-07-11 17:20:31.531198: Pseudo dice [np.float32(0.9431)] 
2025-07-11 17:20:31.532820: Epoch time: 68.66 s 
2025-07-11 17:20:31.534368: Yayy! New best EMA pseudo Dice: 0.9377999901771545 
2025-07-11 17:20:33.748604:  
2025-07-11 17:20:33.750687: Epoch 42 
2025-07-11 17:20:33.752249: Current learning rate: 0.00962 
2025-07-11 17:21:42.221587: train_loss -0.9543 
2025-07-11 17:21:42.222796: val_loss -0.9372 
2025-07-11 17:21:42.223951: Pseudo dice [np.float32(0.9429)] 
2025-07-11 17:21:42.225121: Epoch time: 68.48 s 
2025-07-11 17:21:42.226630: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-07-11 17:21:44.458312:  
2025-07-11 17:21:44.460568: Epoch 43 
2025-07-11 17:21:44.462389: Current learning rate: 0.00961 
2025-07-11 17:22:52.938355: train_loss -0.9547 
2025-07-11 17:22:52.939703: val_loss -0.937 
2025-07-11 17:22:52.940789: Pseudo dice [np.float32(0.9435)] 
2025-07-11 17:22:52.942631: Epoch time: 68.48 s 
2025-07-11 17:22:52.945232: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-07-11 17:22:55.208986:  
2025-07-11 17:22:55.210904: Epoch 44 
2025-07-11 17:22:55.212070: Current learning rate: 0.0096 
2025-07-11 17:24:03.496039: train_loss -0.9531 
2025-07-11 17:24:03.497796: val_loss -0.9383 
2025-07-11 17:24:03.499349: Pseudo dice [np.float32(0.9444)] 
2025-07-11 17:24:03.501742: Epoch time: 68.29 s 
2025-07-11 17:24:03.504158: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-07-11 17:24:05.751381:  
2025-07-11 17:24:05.753820: Epoch 45 
2025-07-11 17:24:05.754943: Current learning rate: 0.00959 
2025-07-11 17:25:14.028436: train_loss -0.954 
2025-07-11 17:25:14.030709: val_loss -0.938 
2025-07-11 17:25:14.032834: Pseudo dice [np.float32(0.9443)] 
2025-07-11 17:25:14.034776: Epoch time: 68.28 s 
2025-07-11 17:25:14.038175: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-07-11 17:25:16.314456:  
2025-07-11 17:25:16.316628: Epoch 46 
2025-07-11 17:25:16.318115: Current learning rate: 0.00959 
2025-07-11 17:26:24.422652: train_loss -0.9552 
2025-07-11 17:26:24.424522: val_loss -0.9372 
2025-07-11 17:26:24.426113: Pseudo dice [np.float32(0.9443)] 
2025-07-11 17:26:24.428863: Epoch time: 68.11 s 
2025-07-11 17:26:24.430760: Yayy! New best EMA pseudo Dice: 0.9402999877929688 
2025-07-11 17:26:26.685854:  
2025-07-11 17:26:26.688024: Epoch 47 
2025-07-11 17:26:26.689227: Current learning rate: 0.00958 
2025-07-11 17:27:35.704094: train_loss -0.9553 
2025-07-11 17:27:35.705974: val_loss -0.9354 
2025-07-11 17:27:35.707952: Pseudo dice [np.float32(0.9423)] 
2025-07-11 17:27:35.710194: Epoch time: 69.02 s 
2025-07-11 17:27:35.712711: Yayy! New best EMA pseudo Dice: 0.940500020980835 
2025-07-11 17:27:37.983060:  
2025-07-11 17:27:37.985143: Epoch 48 
2025-07-11 17:27:37.986229: Current learning rate: 0.00957 
2025-07-11 17:28:46.233765: train_loss -0.9551 
2025-07-11 17:28:46.236178: val_loss -0.9383 
2025-07-11 17:28:46.238593: Pseudo dice [np.float32(0.944)] 
2025-07-11 17:28:46.241513: Epoch time: 68.25 s 
2025-07-11 17:28:46.244748: Yayy! New best EMA pseudo Dice: 0.9409000277519226 
2025-07-11 17:28:48.491198:  
2025-07-11 17:28:48.493099: Epoch 49 
2025-07-11 17:28:48.494397: Current learning rate: 0.00956 
2025-07-11 17:29:56.890880: train_loss -0.9553 
2025-07-11 17:29:56.893575: val_loss -0.9381 
2025-07-11 17:29:56.894982: Pseudo dice [np.float32(0.9432)] 
2025-07-11 17:29:56.896225: Epoch time: 68.4 s 
2025-07-11 17:29:58.048088: Yayy! New best EMA pseudo Dice: 0.941100001335144 
2025-07-11 17:30:00.273023:  
2025-07-11 17:30:00.274692: Epoch 50 
2025-07-11 17:30:00.275829: Current learning rate: 0.00955 
2025-07-11 17:31:08.581569: train_loss -0.9562 
2025-07-11 17:31:08.583272: val_loss -0.9407 
2025-07-11 17:31:08.585187: Pseudo dice [np.float32(0.9464)] 
2025-07-11 17:31:08.587734: Epoch time: 68.31 s 
2025-07-11 17:31:08.591181: Yayy! New best EMA pseudo Dice: 0.9416000247001648 
2025-07-11 17:31:10.822345:  
2025-07-11 17:31:10.824081: Epoch 51 
2025-07-11 17:31:10.825388: Current learning rate: 0.00954 
2025-07-11 17:32:18.981590: train_loss -0.956 
2025-07-11 17:32:18.984413: val_loss -0.9425 
2025-07-11 17:32:18.986286: Pseudo dice [np.float32(0.9479)] 
2025-07-11 17:32:18.987606: Epoch time: 68.16 s 
2025-07-11 17:32:18.989320: Yayy! New best EMA pseudo Dice: 0.942300021648407 
2025-07-11 17:32:21.227087:  
2025-07-11 17:32:21.228994: Epoch 52 
2025-07-11 17:32:21.230110: Current learning rate: 0.00953 
2025-07-11 17:33:29.835631: train_loss -0.9587 
2025-07-11 17:33:29.837391: val_loss -0.9393 
2025-07-11 17:33:29.838816: Pseudo dice [np.float32(0.9448)] 
2025-07-11 17:33:29.840481: Epoch time: 68.61 s 
2025-07-11 17:33:29.842768: Yayy! New best EMA pseudo Dice: 0.9424999952316284 
2025-07-11 17:33:32.092041:  
2025-07-11 17:33:32.094229: Epoch 53 
2025-07-11 17:33:32.095333: Current learning rate: 0.00952 
2025-07-11 17:34:40.655959: train_loss -0.9587 
2025-07-11 17:34:40.661211: val_loss -0.9459 
2025-07-11 17:34:40.663354: Pseudo dice [np.float32(0.9521)] 
2025-07-11 17:34:40.665368: Epoch time: 68.57 s 
2025-07-11 17:34:40.668595: Yayy! New best EMA pseudo Dice: 0.9434999823570251 
2025-07-11 17:34:42.900985:  
2025-07-11 17:34:42.902975: Epoch 54 
2025-07-11 17:34:42.904323: Current learning rate: 0.00951 
2025-07-11 17:35:51.176828: train_loss -0.9572 
2025-07-11 17:35:51.178818: val_loss -0.9413 
2025-07-11 17:35:51.180397: Pseudo dice [np.float32(0.9467)] 
2025-07-11 17:35:51.182172: Epoch time: 68.28 s 
2025-07-11 17:35:51.184031: Yayy! New best EMA pseudo Dice: 0.9437999725341797 
2025-07-11 17:35:54.239840:  
2025-07-11 17:35:54.241761: Epoch 55 
2025-07-11 17:35:54.243093: Current learning rate: 0.0095 
2025-07-11 17:37:02.526918: train_loss -0.9573 
2025-07-11 17:37:02.529295: val_loss -0.943 
2025-07-11 17:37:02.530608: Pseudo dice [np.float32(0.9488)] 
2025-07-11 17:37:02.532006: Epoch time: 68.29 s 
2025-07-11 17:37:02.534088: Yayy! New best EMA pseudo Dice: 0.9442999958992004 
2025-07-11 17:37:04.808687:  
2025-07-11 17:37:04.810498: Epoch 56 
2025-07-11 17:37:04.811485: Current learning rate: 0.00949 
2025-07-11 17:38:13.106480: train_loss -0.957 
2025-07-11 17:38:13.107750: val_loss -0.9426 
2025-07-11 17:38:13.109547: Pseudo dice [np.float32(0.9493)] 
2025-07-11 17:38:13.111950: Epoch time: 68.3 s 
2025-07-11 17:38:13.115320: Yayy! New best EMA pseudo Dice: 0.9448000192642212 
2025-07-11 17:38:15.335804:  
2025-07-11 17:38:15.337557: Epoch 57 
2025-07-11 17:38:15.338696: Current learning rate: 0.00949 
2025-07-11 17:39:23.626978: train_loss -0.9572 
2025-07-11 17:39:23.629266: val_loss -0.9419 
2025-07-11 17:39:23.631720: Pseudo dice [np.float32(0.9482)] 
2025-07-11 17:39:23.634590: Epoch time: 68.29 s 
2025-07-11 17:39:23.636122: Yayy! New best EMA pseudo Dice: 0.9451000094413757 
2025-07-11 17:39:25.864393:  
2025-07-11 17:39:25.866171: Epoch 58 
2025-07-11 17:39:25.867615: Current learning rate: 0.00948 
2025-07-11 17:40:34.393625: train_loss -0.9597 
2025-07-11 17:40:34.396152: val_loss -0.9394 
2025-07-11 17:40:34.398870: Pseudo dice [np.float32(0.9443)] 
2025-07-11 17:40:34.402161: Epoch time: 68.53 s 
2025-07-11 17:40:35.335971:  
2025-07-11 17:40:35.338487: Epoch 59 
2025-07-11 17:40:35.339791: Current learning rate: 0.00947 
2025-07-11 17:41:43.924003: train_loss -0.9594 
2025-07-11 17:41:43.926516: val_loss -0.94 
2025-07-11 17:41:43.928593: Pseudo dice [np.float32(0.946)] 
2025-07-11 17:41:43.931611: Epoch time: 68.59 s 
2025-07-11 17:41:43.933941: Yayy! New best EMA pseudo Dice: 0.9451000094413757 
2025-07-11 17:41:46.187337:  
2025-07-11 17:41:46.188964: Epoch 60 
2025-07-11 17:41:46.190231: Current learning rate: 0.00946 
2025-07-11 17:42:54.698089: train_loss -0.958 
2025-07-11 17:42:54.700197: val_loss -0.9395 
2025-07-11 17:42:54.702262: Pseudo dice [np.float32(0.9454)] 
2025-07-11 17:42:54.704258: Epoch time: 68.51 s 
2025-07-11 17:42:54.706094: Yayy! New best EMA pseudo Dice: 0.9452000260353088 
2025-07-11 17:42:56.981476:  
2025-07-11 17:42:56.983159: Epoch 61 
2025-07-11 17:42:56.984315: Current learning rate: 0.00945 
2025-07-11 17:44:05.506913: train_loss -0.957 
2025-07-11 17:44:05.508807: val_loss -0.9426 
2025-07-11 17:44:05.512028: Pseudo dice [np.float32(0.9487)] 
2025-07-11 17:44:05.514191: Epoch time: 68.53 s 
2025-07-11 17:44:05.516212: Yayy! New best EMA pseudo Dice: 0.9455000162124634 
2025-07-11 17:44:07.793425:  
2025-07-11 17:44:07.795475: Epoch 62 
2025-07-11 17:44:07.796694: Current learning rate: 0.00944 
2025-07-11 17:45:16.278151: train_loss -0.9596 
2025-07-11 17:45:16.280122: val_loss -0.9393 
2025-07-11 17:45:16.282705: Pseudo dice [np.float32(0.9437)] 
2025-07-11 17:45:16.285507: Epoch time: 68.49 s 
2025-07-11 17:45:17.239061:  
2025-07-11 17:45:17.241687: Epoch 63 
2025-07-11 17:45:17.243562: Current learning rate: 0.00943 
2025-07-11 17:46:26.404570: train_loss -0.9597 
2025-07-11 17:46:26.406132: val_loss -0.944 
2025-07-11 17:46:26.408232: Pseudo dice [np.float32(0.9487)] 
2025-07-11 17:46:26.411144: Epoch time: 69.17 s 
2025-07-11 17:46:26.412823: Yayy! New best EMA pseudo Dice: 0.9456999897956848 
2025-07-11 17:46:28.694245:  
2025-07-11 17:46:28.696159: Epoch 64 
2025-07-11 17:46:28.697423: Current learning rate: 0.00942 
2025-07-11 17:47:37.439609: train_loss -0.959 
2025-07-11 17:47:37.442022: val_loss -0.937 
2025-07-11 17:47:37.445169: Pseudo dice [np.float32(0.9434)] 
2025-07-11 17:47:37.448257: Epoch time: 68.75 s 
2025-07-11 17:47:38.410881:  
2025-07-11 17:47:38.412628: Epoch 65 
2025-07-11 17:47:38.414332: Current learning rate: 0.00941 
2025-07-11 17:48:47.398093: train_loss -0.9594 
2025-07-11 17:48:47.400299: val_loss -0.941 
2025-07-11 17:48:47.402126: Pseudo dice [np.float32(0.9459)] 
2025-07-11 17:48:47.404234: Epoch time: 68.99 s 
2025-07-11 17:48:48.357099:  
2025-07-11 17:48:48.359422: Epoch 66 
2025-07-11 17:48:48.360703: Current learning rate: 0.0094 
2025-07-11 17:49:57.250320: train_loss -0.9601 
2025-07-11 17:49:57.253351: val_loss -0.9392 
2025-07-11 17:49:57.256155: Pseudo dice [np.float32(0.9442)] 
2025-07-11 17:49:57.257569: Epoch time: 68.9 s 
2025-07-11 17:49:58.211984:  
2025-07-11 17:49:58.214488: Epoch 67 
2025-07-11 17:49:58.215843: Current learning rate: 0.00939 
2025-07-11 17:51:07.055302: train_loss -0.961 
2025-07-11 17:51:07.057329: val_loss -0.9421 
2025-07-11 17:51:07.059531: Pseudo dice [np.float32(0.9473)] 
2025-07-11 17:51:07.061926: Epoch time: 68.85 s 
2025-07-11 17:51:08.021876:  
2025-07-11 17:51:08.023835: Epoch 68 
2025-07-11 17:51:08.024977: Current learning rate: 0.00939 
2025-07-11 17:52:17.098237: train_loss -0.9584 
2025-07-11 17:52:17.100899: val_loss -0.9362 
2025-07-11 17:52:17.102487: Pseudo dice [np.float32(0.9431)] 
2025-07-11 17:52:17.104794: Epoch time: 69.08 s 
2025-07-11 17:52:18.084851:  
2025-07-11 17:52:18.087174: Epoch 69 
2025-07-11 17:52:18.089057: Current learning rate: 0.00938 
2025-07-11 17:53:27.134192: train_loss -0.9601 
2025-07-11 17:53:27.137274: val_loss -0.9427 
2025-07-11 17:53:27.139992: Pseudo dice [np.float32(0.9478)] 
2025-07-11 17:53:27.143162: Epoch time: 69.05 s 
2025-07-11 17:53:28.092079:  
2025-07-11 17:53:28.094419: Epoch 70 
2025-07-11 17:53:28.095776: Current learning rate: 0.00937 
2025-07-11 17:54:36.828701: train_loss -0.9584 
2025-07-11 17:54:36.830329: val_loss -0.9403 
2025-07-11 17:54:36.831753: Pseudo dice [np.float32(0.9454)] 
2025-07-11 17:54:36.833233: Epoch time: 68.74 s 
2025-07-11 17:54:37.800471:  
2025-07-11 17:54:37.802638: Epoch 71 
2025-07-11 17:54:37.803873: Current learning rate: 0.00936 
2025-07-11 17:55:46.501444: train_loss -0.9608 
2025-07-11 17:55:46.502568: val_loss -0.9415 
2025-07-11 17:55:46.504613: Pseudo dice [np.float32(0.9466)] 
2025-07-11 17:55:46.506849: Epoch time: 68.7 s 
2025-07-11 17:55:48.275826:  
2025-07-11 17:55:48.278224: Epoch 72 
2025-07-11 17:55:48.279649: Current learning rate: 0.00935 
2025-07-11 17:56:56.878241: train_loss -0.9613 
2025-07-11 17:56:56.879984: val_loss -0.9383 
2025-07-11 17:56:56.881716: Pseudo dice [np.float32(0.9437)] 
2025-07-11 17:56:56.884188: Epoch time: 68.61 s 
2025-07-11 17:56:57.855035:  
2025-07-11 17:56:57.857260: Epoch 73 
2025-07-11 17:56:57.858870: Current learning rate: 0.00934 
2025-07-11 17:58:06.508689: train_loss -0.9605 
2025-07-11 17:58:06.510395: val_loss -0.94 
2025-07-11 17:58:06.511791: Pseudo dice [np.float32(0.9453)] 
2025-07-11 17:58:06.513431: Epoch time: 68.66 s 
2025-07-11 17:58:07.483685:  
2025-07-11 17:58:07.485723: Epoch 74 
2025-07-11 17:58:07.487227: Current learning rate: 0.00933 
2025-07-11 17:59:16.406917: train_loss -0.9604 
2025-07-11 17:59:16.408311: val_loss -0.9396 
2025-07-11 17:59:16.409472: Pseudo dice [np.float32(0.9448)] 
2025-07-11 17:59:16.410971: Epoch time: 68.93 s 
2025-07-11 17:59:17.382391:  
2025-07-11 17:59:17.384576: Epoch 75 
2025-07-11 17:59:17.386410: Current learning rate: 0.00932 
2025-07-11 18:00:26.153751: train_loss -0.9612 
2025-07-11 18:00:26.154982: val_loss -0.9473 
2025-07-11 18:00:26.156498: Pseudo dice [np.float32(0.9524)] 
2025-07-11 18:00:26.158168: Epoch time: 68.77 s 
2025-07-11 18:00:26.159952: Yayy! New best EMA pseudo Dice: 0.9460999965667725 
2025-07-11 18:00:28.432490:  
2025-07-11 18:00:28.434498: Epoch 76 
2025-07-11 18:00:28.435563: Current learning rate: 0.00931 
2025-07-11 18:01:37.041048: train_loss -0.9613 
2025-07-11 18:01:37.042318: val_loss -0.9402 
2025-07-11 18:01:37.043408: Pseudo dice [np.float32(0.9446)] 
2025-07-11 18:01:37.044644: Epoch time: 68.61 s 
2025-07-11 18:01:38.009408:  
2025-07-11 18:01:38.012137: Epoch 77 
2025-07-11 18:01:38.013473: Current learning rate: 0.0093 
2025-07-11 18:02:46.605261: train_loss -0.9631 
2025-07-11 18:02:46.606621: val_loss -0.9428 
2025-07-11 18:02:46.607858: Pseudo dice [np.float32(0.9479)] 
2025-07-11 18:02:46.609219: Epoch time: 68.6 s 
2025-07-11 18:02:46.610286: Yayy! New best EMA pseudo Dice: 0.9460999965667725 
2025-07-11 18:02:48.860293:  
2025-07-11 18:02:48.862557: Epoch 78 
2025-07-11 18:02:48.863872: Current learning rate: 0.0093 
2025-07-11 18:03:57.428777: train_loss -0.9603 
2025-07-11 18:03:57.430410: val_loss -0.9464 
2025-07-11 18:03:57.431508: Pseudo dice [np.float32(0.9513)] 
2025-07-11 18:03:57.432714: Epoch time: 68.57 s 
2025-07-11 18:03:57.433558: Yayy! New best EMA pseudo Dice: 0.9466000199317932 
2025-07-11 18:03:59.682271:  
2025-07-11 18:03:59.684413: Epoch 79 
2025-07-11 18:03:59.686253: Current learning rate: 0.00929 
2025-07-11 18:05:08.445859: train_loss -0.9615 
2025-07-11 18:05:08.448461: val_loss -0.9437 
2025-07-11 18:05:08.449765: Pseudo dice [np.float32(0.9485)] 
2025-07-11 18:05:08.451143: Epoch time: 68.77 s 
2025-07-11 18:05:08.452527: Yayy! New best EMA pseudo Dice: 0.9467999935150146 
2025-07-11 18:05:10.734512:  
2025-07-11 18:05:10.737136: Epoch 80 
2025-07-11 18:05:10.738424: Current learning rate: 0.00928 
2025-07-11 18:06:20.487158: train_loss -0.9606 
2025-07-11 18:06:20.488408: val_loss -0.9416 
2025-07-11 18:06:20.489304: Pseudo dice [np.float32(0.9474)] 
2025-07-11 18:06:20.490485: Epoch time: 69.76 s 
2025-07-11 18:06:20.491988: Yayy! New best EMA pseudo Dice: 0.9469000101089478 
2025-07-11 18:06:22.811994:  
2025-07-11 18:06:22.814611: Epoch 81 
2025-07-11 18:06:22.816269: Current learning rate: 0.00927 
2025-07-11 18:07:31.862414: train_loss -0.9616 
2025-07-11 18:07:31.864735: val_loss -0.9463 
2025-07-11 18:07:31.866851: Pseudo dice [np.float32(0.9508)] 
2025-07-11 18:07:31.869323: Epoch time: 69.05 s 
2025-07-11 18:07:31.870464: Yayy! New best EMA pseudo Dice: 0.9473000168800354 
2025-07-11 18:07:34.173341:  
2025-07-11 18:07:34.175916: Epoch 82 
2025-07-11 18:07:34.177510: Current learning rate: 0.00926 
2025-07-11 18:08:42.852093: train_loss -0.9616 
2025-07-11 18:08:42.854283: val_loss -0.9417 
2025-07-11 18:08:42.856349: Pseudo dice [np.float32(0.9478)] 
2025-07-11 18:08:42.858706: Epoch time: 68.68 s 
2025-07-11 18:08:42.861748: Yayy! New best EMA pseudo Dice: 0.9473000168800354 
2025-07-11 18:08:45.124955:  
2025-07-11 18:08:45.127378: Epoch 83 
2025-07-11 18:08:45.128664: Current learning rate: 0.00925 
2025-07-11 18:09:53.942038: train_loss -0.9616 
2025-07-11 18:09:53.945193: val_loss -0.9406 
2025-07-11 18:09:53.948305: Pseudo dice [np.float32(0.9469)] 
2025-07-11 18:09:53.950184: Epoch time: 68.82 s 
2025-07-11 18:09:54.893353:  
2025-07-11 18:09:54.895265: Epoch 84 
2025-07-11 18:09:54.896307: Current learning rate: 0.00924 
2025-07-11 18:11:04.006732: train_loss -0.963 
2025-07-11 18:11:04.007874: val_loss -0.942 
2025-07-11 18:11:04.008927: Pseudo dice [np.float32(0.9471)] 
2025-07-11 18:11:04.009997: Epoch time: 69.12 s 
2025-07-11 18:11:04.952034:  
2025-07-11 18:11:04.954031: Epoch 85 
2025-07-11 18:11:04.955141: Current learning rate: 0.00923 
2025-07-11 18:12:13.903233: train_loss -0.9627 
2025-07-11 18:12:13.904582: val_loss -0.9422 
2025-07-11 18:12:13.906281: Pseudo dice [np.float32(0.9477)] 
2025-07-11 18:12:13.907876: Epoch time: 68.95 s 
2025-07-11 18:12:14.850001:  
2025-07-11 18:12:14.852584: Epoch 86 
2025-07-11 18:12:14.854184: Current learning rate: 0.00922 
2025-07-11 18:13:23.649957: train_loss -0.9625 
2025-07-11 18:13:23.651343: val_loss -0.9414 
2025-07-11 18:13:23.652269: Pseudo dice [np.float32(0.9466)] 
2025-07-11 18:13:23.653349: Epoch time: 68.8 s 
2025-07-11 18:13:24.590955:  
2025-07-11 18:13:24.593265: Epoch 87 
2025-07-11 18:13:24.594611: Current learning rate: 0.00921 
2025-07-11 18:14:33.097784: train_loss -0.9627 
2025-07-11 18:14:33.099164: val_loss -0.9401 
2025-07-11 18:14:33.100416: Pseudo dice [np.float32(0.9442)] 
2025-07-11 18:14:33.101688: Epoch time: 68.51 s 
2025-07-11 18:14:34.048936:  
2025-07-11 18:14:34.050949: Epoch 88 
2025-07-11 18:14:34.052489: Current learning rate: 0.0092 
2025-07-11 18:15:42.526811: train_loss -0.9617 
2025-07-11 18:15:42.528562: val_loss -0.9431 
2025-07-11 18:15:42.529587: Pseudo dice [np.float32(0.9477)] 
2025-07-11 18:15:42.530643: Epoch time: 68.48 s 
2025-07-11 18:15:44.317114:  
2025-07-11 18:15:44.319159: Epoch 89 
2025-07-11 18:15:44.320268: Current learning rate: 0.0092 
2025-07-11 18:16:52.847448: train_loss -0.9628 
2025-07-11 18:16:52.849460: val_loss -0.9397 
2025-07-11 18:16:52.850758: Pseudo dice [np.float32(0.9441)] 
2025-07-11 18:16:52.851980: Epoch time: 68.53 s 
2025-07-11 18:16:53.795864:  
2025-07-11 18:16:53.798115: Epoch 90 
2025-07-11 18:16:53.799339: Current learning rate: 0.00919 
2025-07-11 18:18:02.295796: train_loss -0.9632 
2025-07-11 18:18:02.297561: val_loss -0.9444 
2025-07-11 18:18:02.298817: Pseudo dice [np.float32(0.9493)] 
2025-07-11 18:18:02.299984: Epoch time: 68.5 s 
2025-07-11 18:18:03.226134:  
2025-07-11 18:18:03.228015: Epoch 91 
2025-07-11 18:18:03.229117: Current learning rate: 0.00918 
2025-07-11 18:19:12.093006: train_loss -0.9618 
2025-07-11 18:19:12.094470: val_loss -0.942 
2025-07-11 18:19:12.095627: Pseudo dice [np.float32(0.9467)] 
2025-07-11 18:19:12.096630: Epoch time: 68.87 s 
2025-07-11 18:19:13.041971:  
2025-07-11 18:19:13.044591: Epoch 92 
2025-07-11 18:19:13.045858: Current learning rate: 0.00917 
2025-07-11 18:20:22.007081: train_loss -0.9624 
2025-07-11 18:20:22.008368: val_loss -0.9419 
2025-07-11 18:20:22.009346: Pseudo dice [np.float32(0.9466)] 
2025-07-11 18:20:22.010506: Epoch time: 68.97 s 
2025-07-11 18:20:22.940028:  
2025-07-11 18:20:22.942385: Epoch 93 
2025-07-11 18:20:22.943366: Current learning rate: 0.00916 
2025-07-11 18:21:31.666455: train_loss -0.962 
2025-07-11 18:21:31.668025: val_loss -0.9428 
2025-07-11 18:21:31.670102: Pseudo dice [np.float32(0.9475)] 
2025-07-11 18:21:31.671941: Epoch time: 68.73 s 
2025-07-11 18:21:32.622582:  
2025-07-11 18:21:32.625149: Epoch 94 
2025-07-11 18:21:32.626418: Current learning rate: 0.00915 
2025-07-11 18:22:41.327852: train_loss -0.963 
2025-07-11 18:22:41.328992: val_loss -0.9422 
2025-07-11 18:22:41.330225: Pseudo dice [np.float32(0.9481)] 
2025-07-11 18:22:41.331914: Epoch time: 68.71 s 
2025-07-11 18:22:42.248922:  
2025-07-11 18:22:42.251371: Epoch 95 
2025-07-11 18:22:42.252833: Current learning rate: 0.00914 
2025-07-11 18:23:50.958264: train_loss -0.9641 
2025-07-11 18:23:50.959538: val_loss -0.946 
2025-07-11 18:23:50.960679: Pseudo dice [np.float32(0.951)] 
2025-07-11 18:23:50.962147: Epoch time: 68.71 s 
2025-07-11 18:23:50.964256: Yayy! New best EMA pseudo Dice: 0.9474999904632568 
2025-07-11 18:23:53.208859:  
2025-07-11 18:23:53.211167: Epoch 96 
2025-07-11 18:23:53.212447: Current learning rate: 0.00913 
2025-07-11 18:25:01.704340: train_loss -0.9637 
2025-07-11 18:25:01.705817: val_loss -0.9423 
2025-07-11 18:25:01.707417: Pseudo dice [np.float32(0.9479)] 
2025-07-11 18:25:01.708992: Epoch time: 68.5 s 
2025-07-11 18:25:01.710222: Yayy! New best EMA pseudo Dice: 0.9474999904632568 
2025-07-11 18:25:03.961155:  
2025-07-11 18:25:03.962861: Epoch 97 
2025-07-11 18:25:03.963832: Current learning rate: 0.00912 
2025-07-11 18:26:13.289542: train_loss -0.9649 
2025-07-11 18:26:13.290876: val_loss -0.9432 
2025-07-11 18:26:13.292262: Pseudo dice [np.float32(0.9478)] 
2025-07-11 18:26:13.293324: Epoch time: 69.33 s 
2025-07-11 18:26:13.294734: Yayy! New best EMA pseudo Dice: 0.9474999904632568 
2025-07-11 18:26:15.540092:  
2025-07-11 18:26:15.542049: Epoch 98 
2025-07-11 18:26:15.543307: Current learning rate: 0.00911 
2025-07-11 18:27:24.302677: train_loss -0.964 
2025-07-11 18:27:24.304727: val_loss -0.9476 
2025-07-11 18:27:24.307073: Pseudo dice [np.float32(0.9526)] 
2025-07-11 18:27:24.308603: Epoch time: 68.77 s 
2025-07-11 18:27:24.309731: Yayy! New best EMA pseudo Dice: 0.9480999708175659 
2025-07-11 18:27:26.580590:  
2025-07-11 18:27:26.583075: Epoch 99 
2025-07-11 18:27:26.584232: Current learning rate: 0.0091 
2025-07-11 18:28:35.523623: train_loss -0.9646 
2025-07-11 18:28:35.525330: val_loss -0.944 
2025-07-11 18:28:35.527081: Pseudo dice [np.float32(0.9484)] 
2025-07-11 18:28:35.528927: Epoch time: 68.95 s 
2025-07-11 18:28:36.822704: Yayy! New best EMA pseudo Dice: 0.9480999708175659 
2025-07-11 18:28:39.180703:  
2025-07-11 18:28:39.183049: Epoch 100 
2025-07-11 18:28:39.184237: Current learning rate: 0.0091 
2025-07-11 18:29:47.949699: train_loss -0.9637 
2025-07-11 18:29:47.951882: val_loss -0.941 
2025-07-11 18:29:47.953648: Pseudo dice [np.float32(0.9452)] 
2025-07-11 18:29:47.955376: Epoch time: 68.77 s 
2025-07-11 18:29:48.879206:  
2025-07-11 18:29:48.881454: Epoch 101 
2025-07-11 18:29:48.883178: Current learning rate: 0.00909 
2025-07-11 18:30:57.554543: train_loss -0.9624 
2025-07-11 18:30:57.556067: val_loss -0.9417 
2025-07-11 18:30:57.557977: Pseudo dice [np.float32(0.9469)] 
2025-07-11 18:30:57.560192: Epoch time: 68.68 s 
2025-07-11 18:30:58.492114:  
2025-07-11 18:30:58.494227: Epoch 102 
2025-07-11 18:30:58.495689: Current learning rate: 0.00908 
2025-07-11 18:32:07.121456: train_loss -0.9636 
2025-07-11 18:32:07.124338: val_loss -0.9427 
2025-07-11 18:32:07.126592: Pseudo dice [np.float32(0.9472)] 
2025-07-11 18:32:07.128452: Epoch time: 68.63 s 
2025-07-11 18:32:08.079365:  
2025-07-11 18:32:08.081760: Epoch 103 
2025-07-11 18:32:08.083258: Current learning rate: 0.00907 
2025-07-11 18:33:16.677129: train_loss -0.9637 
2025-07-11 18:33:16.679405: val_loss -0.9425 
2025-07-11 18:33:16.681580: Pseudo dice [np.float32(0.9469)] 
2025-07-11 18:33:16.683477: Epoch time: 68.6 s 
2025-07-11 18:33:17.609774:  
2025-07-11 18:33:17.611469: Epoch 104 
2025-07-11 18:33:17.612523: Current learning rate: 0.00906 
2025-07-11 18:34:26.344194: train_loss -0.9627 
2025-07-11 18:34:26.345492: val_loss -0.9411 
2025-07-11 18:34:26.347707: Pseudo dice [np.float32(0.9457)] 
2025-07-11 18:34:26.350816: Epoch time: 68.74 s 
2025-07-11 18:34:27.310958:  
2025-07-11 18:34:27.313274: Epoch 105 
2025-07-11 18:34:27.314468: Current learning rate: 0.00905 
2025-07-11 18:35:35.851822: train_loss -0.9637 
2025-07-11 18:35:35.855065: val_loss -0.9409 
2025-07-11 18:35:35.857970: Pseudo dice [np.float32(0.9456)] 
2025-07-11 18:35:35.860373: Epoch time: 68.54 s 
2025-07-11 18:35:37.678025:  
2025-07-11 18:35:37.680400: Epoch 106 
2025-07-11 18:35:37.681635: Current learning rate: 0.00904 
2025-07-11 18:36:46.313929: train_loss -0.9607 
2025-07-11 18:36:46.316734: val_loss -0.9408 
2025-07-11 18:36:46.319289: Pseudo dice [np.float32(0.9453)] 
2025-07-11 18:36:46.321246: Epoch time: 68.64 s 
2025-07-11 18:36:47.291164:  
2025-07-11 18:36:47.293206: Epoch 107 
2025-07-11 18:36:47.294771: Current learning rate: 0.00903 
2025-07-11 18:37:56.047199: train_loss -0.9637 
2025-07-11 18:37:56.048545: val_loss -0.9444 
2025-07-11 18:37:56.050506: Pseudo dice [np.float32(0.9489)] 
2025-07-11 18:37:56.053537: Epoch time: 68.76 s 
2025-07-11 18:37:56.997340:  
2025-07-11 18:37:56.999763: Epoch 108 
2025-07-11 18:37:57.001451: Current learning rate: 0.00902 
2025-07-11 18:39:05.904365: train_loss -0.9631 
2025-07-11 18:39:05.905623: val_loss -0.9475 
2025-07-11 18:39:05.906917: Pseudo dice [np.float32(0.9517)] 
2025-07-11 18:39:05.909513: Epoch time: 68.91 s 
2025-07-11 18:39:06.863251:  
2025-07-11 18:39:06.865280: Epoch 109 
2025-07-11 18:39:06.866447: Current learning rate: 0.00901 
2025-07-11 18:40:15.622943: train_loss -0.9639 
2025-07-11 18:40:15.630439: val_loss -0.9454 
2025-07-11 18:40:15.633986: Pseudo dice [np.float32(0.9507)] 
2025-07-11 18:40:15.636665: Epoch time: 68.76 s 
2025-07-11 18:40:16.591349:  
2025-07-11 18:40:16.593292: Epoch 110 
2025-07-11 18:40:16.595463: Current learning rate: 0.009 
2025-07-11 18:41:25.241827: train_loss -0.9638 
2025-07-11 18:41:25.244720: val_loss -0.9403 
2025-07-11 18:41:25.247585: Pseudo dice [np.float32(0.9447)] 
2025-07-11 18:41:25.250513: Epoch time: 68.65 s 
2025-07-11 18:41:26.207010:  
2025-07-11 18:41:26.208830: Epoch 111 
2025-07-11 18:41:26.210073: Current learning rate: 0.009 
2025-07-11 18:42:34.977931: train_loss -0.9639 
2025-07-11 18:42:34.980268: val_loss -0.9386 
2025-07-11 18:42:34.981855: Pseudo dice [np.float32(0.9432)] 
2025-07-11 18:42:34.983664: Epoch time: 68.77 s 
2025-07-11 18:42:35.932595:  
2025-07-11 18:42:35.934480: Epoch 112 
2025-07-11 18:42:35.935867: Current learning rate: 0.00899 
2025-07-11 18:43:44.686789: train_loss -0.964 
2025-07-11 18:43:44.689311: val_loss -0.9463 
2025-07-11 18:43:44.691404: Pseudo dice [np.float32(0.9517)] 
2025-07-11 18:43:44.694034: Epoch time: 68.76 s 
2025-07-11 18:43:45.658285:  
2025-07-11 18:43:45.660451: Epoch 113 
2025-07-11 18:43:45.661547: Current learning rate: 0.00898 
2025-07-11 18:44:54.452303: train_loss -0.964 
2025-07-11 18:44:54.454494: val_loss -0.9444 
2025-07-11 18:44:54.456479: Pseudo dice [np.float32(0.9493)] 
2025-07-11 18:44:54.457787: Epoch time: 68.8 s 
2025-07-11 18:44:55.398574:  
2025-07-11 18:44:55.400827: Epoch 114 
2025-07-11 18:44:55.402179: Current learning rate: 0.00897 
2025-07-11 18:46:04.267181: train_loss -0.9639 
2025-07-11 18:46:04.269618: val_loss -0.9467 
2025-07-11 18:46:04.270839: Pseudo dice [np.float32(0.9506)] 
2025-07-11 18:46:04.271842: Epoch time: 68.87 s 
2025-07-11 18:46:06.062662:  
2025-07-11 18:46:06.064652: Epoch 115 
2025-07-11 18:46:06.065992: Current learning rate: 0.00896 
2025-07-11 18:47:14.861688: train_loss -0.9647 
2025-07-11 18:47:14.864235: val_loss -0.9398 
2025-07-11 18:47:14.866220: Pseudo dice [np.float32(0.9454)] 
2025-07-11 18:47:14.868560: Epoch time: 68.8 s 
2025-07-11 18:47:15.834412:  
2025-07-11 18:47:15.836809: Epoch 116 
2025-07-11 18:47:15.838106: Current learning rate: 0.00895 
2025-07-11 18:48:24.823289: train_loss -0.9653 
2025-07-11 18:48:24.824602: val_loss -0.9468 
2025-07-11 18:48:24.825959: Pseudo dice [np.float32(0.9511)] 
2025-07-11 18:48:24.827070: Epoch time: 68.99 s 
2025-07-11 18:48:24.828075: Yayy! New best EMA pseudo Dice: 0.9480999708175659 
2025-07-11 18:48:27.260696:  
2025-07-11 18:48:27.262539: Epoch 117 
2025-07-11 18:48:27.264000: Current learning rate: 0.00894 
2025-07-11 18:49:36.096543: train_loss -0.9629 
2025-07-11 18:49:36.097829: val_loss -0.9436 
2025-07-11 18:49:36.099026: Pseudo dice [np.float32(0.9496)] 
2025-07-11 18:49:36.100110: Epoch time: 68.84 s 
2025-07-11 18:49:36.101265: Yayy! New best EMA pseudo Dice: 0.9483000040054321 
2025-07-11 18:49:38.359131:  
2025-07-11 18:49:38.360827: Epoch 118 
2025-07-11 18:49:38.361843: Current learning rate: 0.00893 
2025-07-11 18:50:47.000008: train_loss -0.9633 
2025-07-11 18:50:47.001558: val_loss -0.946 
2025-07-11 18:50:47.003464: Pseudo dice [np.float32(0.9512)] 
2025-07-11 18:50:47.004512: Epoch time: 68.64 s 
2025-07-11 18:50:47.005797: Yayy! New best EMA pseudo Dice: 0.9485999941825867 
2025-07-11 18:50:49.360580:  
2025-07-11 18:50:49.362823: Epoch 119 
2025-07-11 18:50:49.364095: Current learning rate: 0.00892 
2025-07-11 18:51:58.134221: train_loss -0.9648 
2025-07-11 18:51:58.136057: val_loss -0.9443 
2025-07-11 18:51:58.137101: Pseudo dice [np.float32(0.9482)] 
2025-07-11 18:51:58.138033: Epoch time: 68.78 s 
2025-07-11 18:51:59.077879:  
2025-07-11 18:51:59.079801: Epoch 120 
2025-07-11 18:51:59.081185: Current learning rate: 0.00891 
2025-07-11 18:53:08.069687: train_loss -0.9646 
2025-07-11 18:53:08.071195: val_loss -0.9442 
2025-07-11 18:53:08.072377: Pseudo dice [np.float32(0.9492)] 
2025-07-11 18:53:08.073528: Epoch time: 69.0 s 
2025-07-11 18:53:08.074632: Yayy! New best EMA pseudo Dice: 0.9485999941825867 
2025-07-11 18:53:10.445361:  
2025-07-11 18:53:10.447900: Epoch 121 
2025-07-11 18:53:10.449094: Current learning rate: 0.0089 
2025-07-11 18:54:19.411437: train_loss -0.965 
2025-07-11 18:54:19.413451: val_loss -0.9436 
2025-07-11 18:54:19.414458: Pseudo dice [np.float32(0.9478)] 
2025-07-11 18:54:19.415701: Epoch time: 68.97 s 
2025-07-11 18:54:20.340773:  
2025-07-11 18:54:20.342973: Epoch 122 
2025-07-11 18:54:20.344212: Current learning rate: 0.00889 
2025-07-11 18:55:28.991271: train_loss -0.9636 
2025-07-11 18:55:28.992714: val_loss -0.9422 
2025-07-11 18:55:28.993706: Pseudo dice [np.float32(0.947)] 
2025-07-11 18:55:28.995948: Epoch time: 68.65 s 
2025-07-11 18:55:29.983760:  
2025-07-11 18:55:29.986171: Epoch 123 
2025-07-11 18:55:29.987314: Current learning rate: 0.00889 
2025-07-11 18:56:39.782746: train_loss -0.9646 
2025-07-11 18:56:39.784288: val_loss -0.9459 
2025-07-11 18:56:39.785867: Pseudo dice [np.float32(0.9511)] 
2025-07-11 18:56:39.786866: Epoch time: 69.8 s 
2025-07-11 18:56:39.788122: Yayy! New best EMA pseudo Dice: 0.9487000107765198 
2025-07-11 18:56:42.083736:  
2025-07-11 18:56:42.085785: Epoch 124 
2025-07-11 18:56:42.086947: Current learning rate: 0.00888 
2025-07-11 18:57:50.957563: train_loss -0.9648 
2025-07-11 18:57:50.959297: val_loss -0.9439 
2025-07-11 18:57:50.960411: Pseudo dice [np.float32(0.9484)] 
2025-07-11 18:57:50.961517: Epoch time: 68.88 s 
2025-07-11 18:57:51.907529:  
2025-07-11 18:57:51.909530: Epoch 125 
2025-07-11 18:57:51.910650: Current learning rate: 0.00887 
2025-07-11 18:59:00.905957: train_loss -0.9641 
2025-07-11 18:59:00.907444: val_loss -0.9451 
2025-07-11 18:59:00.908740: Pseudo dice [np.float32(0.9495)] 
2025-07-11 18:59:00.910007: Epoch time: 69.0 s 
2025-07-11 18:59:00.911316: Yayy! New best EMA pseudo Dice: 0.9487000107765198 
2025-07-11 18:59:03.162219:  
2025-07-11 18:59:03.163889: Epoch 126 
2025-07-11 18:59:03.165021: Current learning rate: 0.00886 
2025-07-11 19:00:11.807524: train_loss -0.9647 
2025-07-11 19:00:11.808967: val_loss -0.9438 
2025-07-11 19:00:11.810139: Pseudo dice [np.float32(0.9479)] 
2025-07-11 19:00:11.811733: Epoch time: 68.65 s 
2025-07-11 19:00:12.775649:  
2025-07-11 19:00:12.777697: Epoch 127 
2025-07-11 19:00:12.779013: Current learning rate: 0.00885 
2025-07-11 19:01:21.431179: train_loss -0.9658 
2025-07-11 19:01:21.432515: val_loss -0.9464 
2025-07-11 19:01:21.434054: Pseudo dice [np.float32(0.9503)] 
2025-07-11 19:01:21.435188: Epoch time: 68.66 s 
2025-07-11 19:01:21.436338: Yayy! New best EMA pseudo Dice: 0.9488000273704529 
2025-07-11 19:01:23.937216:  
2025-07-11 19:01:23.939398: Epoch 128 
2025-07-11 19:01:23.940649: Current learning rate: 0.00884 
2025-07-11 19:02:32.834546: train_loss -0.9663 
2025-07-11 19:02:32.835915: val_loss -0.9465 
2025-07-11 19:02:32.837131: Pseudo dice [np.float32(0.9511)] 
2025-07-11 19:02:32.838275: Epoch time: 68.9 s 
2025-07-11 19:02:32.839587: Yayy! New best EMA pseudo Dice: 0.9490000009536743 
2025-07-11 19:02:35.080123:  
2025-07-11 19:02:35.082314: Epoch 129 
2025-07-11 19:02:35.083708: Current learning rate: 0.00883 
2025-07-11 19:03:44.030595: train_loss -0.9658 
2025-07-11 19:03:44.031885: val_loss -0.9421 
2025-07-11 19:03:44.033135: Pseudo dice [np.float32(0.9468)] 
2025-07-11 19:03:44.034409: Epoch time: 68.95 s 
2025-07-11 19:03:44.992547:  
2025-07-11 19:03:44.994497: Epoch 130 
2025-07-11 19:03:44.995553: Current learning rate: 0.00882 
2025-07-11 19:04:53.838272: train_loss -0.966 
2025-07-11 19:04:53.839823: val_loss -0.9487 
2025-07-11 19:04:53.841258: Pseudo dice [np.float32(0.9532)] 
2025-07-11 19:04:53.842560: Epoch time: 68.85 s 
2025-07-11 19:04:53.844047: Yayy! New best EMA pseudo Dice: 0.9491999745368958 
2025-07-11 19:04:56.086082:  
2025-07-11 19:04:56.088554: Epoch 131 
2025-07-11 19:04:56.089728: Current learning rate: 0.00881 
2025-07-11 19:06:04.962714: train_loss -0.9648 
2025-07-11 19:06:04.964122: val_loss -0.9414 
2025-07-11 19:06:04.965261: Pseudo dice [np.float32(0.9468)] 
2025-07-11 19:06:04.966516: Epoch time: 68.88 s 
2025-07-11 19:06:06.685326:  
2025-07-11 19:06:06.687486: Epoch 132 
2025-07-11 19:06:06.688714: Current learning rate: 0.0088 
2025-07-11 19:07:15.339519: train_loss -0.9663 
2025-07-11 19:07:15.341196: val_loss -0.9444 
2025-07-11 19:07:15.342244: Pseudo dice [np.float32(0.9481)] 
2025-07-11 19:07:15.343540: Epoch time: 68.66 s 
2025-07-11 19:07:16.298305:  
2025-07-11 19:07:16.300514: Epoch 133 
2025-07-11 19:07:16.302177: Current learning rate: 0.00879 
2025-07-11 19:08:25.020310: train_loss -0.9659 
2025-07-11 19:08:25.022058: val_loss -0.9456 
2025-07-11 19:08:25.023506: Pseudo dice [np.float32(0.9504)] 
2025-07-11 19:08:25.024480: Epoch time: 68.73 s 
2025-07-11 19:08:25.987493:  
2025-07-11 19:08:25.989588: Epoch 134 
2025-07-11 19:08:25.991444: Current learning rate: 0.00879 
2025-07-11 19:09:34.763808: train_loss -0.9657 
2025-07-11 19:09:34.765384: val_loss -0.9409 
2025-07-11 19:09:34.766532: Pseudo dice [np.float32(0.9468)] 
2025-07-11 19:09:34.767634: Epoch time: 68.78 s 
2025-07-11 19:09:35.736191:  
2025-07-11 19:09:35.738219: Epoch 135 
2025-07-11 19:09:35.739921: Current learning rate: 0.00878 
2025-07-11 19:10:44.467683: train_loss -0.9657 
2025-07-11 19:10:44.469975: val_loss -0.9446 
2025-07-11 19:10:44.471185: Pseudo dice [np.float32(0.9503)] 
2025-07-11 19:10:44.472807: Epoch time: 68.74 s 
2025-07-11 19:10:45.428607:  
2025-07-11 19:10:45.431224: Epoch 136 
2025-07-11 19:10:45.432698: Current learning rate: 0.00877 
2025-07-11 19:11:54.220434: train_loss -0.9661 
2025-07-11 19:11:54.222697: val_loss -0.9475 
2025-07-11 19:11:54.224373: Pseudo dice [np.float32(0.9524)] 
2025-07-11 19:11:54.225453: Epoch time: 68.8 s 
2025-07-11 19:11:54.227439: Yayy! New best EMA pseudo Dice: 0.9492999911308289 
2025-07-11 19:11:56.590226:  
2025-07-11 19:11:56.592537: Epoch 137 
2025-07-11 19:11:56.594004: Current learning rate: 0.00876 
2025-07-11 19:13:05.658946: train_loss -0.9666 
2025-07-11 19:13:05.660226: val_loss -0.9442 
2025-07-11 19:13:05.661429: Pseudo dice [np.float32(0.9498)] 
2025-07-11 19:13:05.662934: Epoch time: 69.07 s 
2025-07-11 19:13:05.664094: Yayy! New best EMA pseudo Dice: 0.949400007724762 
2025-07-11 19:13:08.017450:  
2025-07-11 19:13:08.019976: Epoch 138 
2025-07-11 19:13:08.020949: Current learning rate: 0.00875 
2025-07-11 19:14:16.879954: train_loss -0.9656 
2025-07-11 19:14:16.881338: val_loss -0.9434 
2025-07-11 19:14:16.882720: Pseudo dice [np.float32(0.9472)] 
2025-07-11 19:14:16.883899: Epoch time: 68.87 s 
2025-07-11 19:14:17.860622:  
2025-07-11 19:14:17.863000: Epoch 139 
2025-07-11 19:14:17.864363: Current learning rate: 0.00874 
2025-07-11 19:15:27.113666: train_loss -0.9653 
2025-07-11 19:15:27.115341: val_loss -0.9465 
2025-07-11 19:15:27.116374: Pseudo dice [np.float32(0.9515)] 
2025-07-11 19:15:27.117603: Epoch time: 69.26 s 
2025-07-11 19:15:27.118658: Yayy! New best EMA pseudo Dice: 0.949400007724762 
2025-07-11 19:15:29.410254:  
2025-07-11 19:15:29.412553: Epoch 140 
2025-07-11 19:15:29.413730: Current learning rate: 0.00873 
2025-07-11 19:16:39.027712: train_loss -0.9668 
2025-07-11 19:16:39.029413: val_loss -0.9447 
2025-07-11 19:16:39.030624: Pseudo dice [np.float32(0.949)] 
2025-07-11 19:16:39.032068: Epoch time: 69.62 s 
2025-07-11 19:16:39.986029:  
2025-07-11 19:16:39.988138: Epoch 141 
2025-07-11 19:16:39.989333: Current learning rate: 0.00872 
2025-07-11 19:17:48.804321: train_loss -0.9636 
2025-07-11 19:17:48.806559: val_loss -0.9359 
2025-07-11 19:17:48.807911: Pseudo dice [np.float32(0.9411)] 
2025-07-11 19:17:48.809769: Epoch time: 68.82 s 
2025-07-11 19:17:49.723277:  
2025-07-11 19:17:49.725238: Epoch 142 
2025-07-11 19:17:49.726247: Current learning rate: 0.00871 
2025-07-11 19:18:58.661939: train_loss -0.9651 
2025-07-11 19:18:58.663397: val_loss -0.9453 
2025-07-11 19:18:58.664973: Pseudo dice [np.float32(0.9494)] 
2025-07-11 19:18:58.666177: Epoch time: 68.94 s 
2025-07-11 19:18:59.635712:  
2025-07-11 19:18:59.637484: Epoch 143 
2025-07-11 19:18:59.638630: Current learning rate: 0.0087 
2025-07-11 19:20:08.873325: train_loss -0.9662 
2025-07-11 19:20:08.875083: val_loss -0.9458 
2025-07-11 19:20:08.876466: Pseudo dice [np.float32(0.9504)] 
2025-07-11 19:20:08.877660: Epoch time: 69.24 s 
2025-07-11 19:20:09.859539:  
2025-07-11 19:20:09.861745: Epoch 144 
2025-07-11 19:20:09.863502: Current learning rate: 0.00869 
2025-07-11 19:21:18.573053: train_loss -0.9657 
2025-07-11 19:21:18.574258: val_loss -0.9416 
2025-07-11 19:21:18.575502: Pseudo dice [np.float32(0.9453)] 
2025-07-11 19:21:18.576792: Epoch time: 68.72 s 
2025-07-11 19:21:19.525382:  
2025-07-11 19:21:19.527339: Epoch 145 
2025-07-11 19:21:19.528789: Current learning rate: 0.00868 
2025-07-11 19:22:28.156796: train_loss -0.9654 
2025-07-11 19:22:28.158185: val_loss -0.9415 
2025-07-11 19:22:28.159302: Pseudo dice [np.float32(0.947)] 
2025-07-11 19:22:28.160644: Epoch time: 68.63 s 
2025-07-11 19:22:29.124017:  
2025-07-11 19:22:29.126369: Epoch 146 
2025-07-11 19:22:29.127803: Current learning rate: 0.00868 
2025-07-11 19:23:37.663295: train_loss -0.9644 
2025-07-11 19:23:37.664743: val_loss -0.94 
2025-07-11 19:23:37.665673: Pseudo dice [np.float32(0.9444)] 
2025-07-11 19:23:37.666670: Epoch time: 68.54 s 
2025-07-11 19:23:38.630399:  
2025-07-11 19:23:38.632586: Epoch 147 
2025-07-11 19:23:38.634255: Current learning rate: 0.00867 
2025-07-11 19:24:47.082373: train_loss -0.967 
2025-07-11 19:24:47.083956: val_loss -0.9417 
2025-07-11 19:24:47.085190: Pseudo dice [np.float32(0.9469)] 
2025-07-11 19:24:47.086565: Epoch time: 68.46 s 
2025-07-11 19:24:48.076358:  
2025-07-11 19:24:48.078411: Epoch 148 
2025-07-11 19:24:48.080043: Current learning rate: 0.00866 
2025-07-11 19:25:56.705447: train_loss -0.9657 
2025-07-11 19:25:56.706763: val_loss -0.9419 
2025-07-11 19:25:56.708631: Pseudo dice [np.float32(0.947)] 
2025-07-11 19:25:56.709992: Epoch time: 68.63 s 
2025-07-11 19:25:57.662518:  
2025-07-11 19:25:57.664703: Epoch 149 
2025-07-11 19:25:57.666199: Current learning rate: 0.00865 
2025-07-11 19:27:06.934404: train_loss -0.9661 
2025-07-11 19:27:06.936682: val_loss -0.9473 
2025-07-11 19:27:06.938696: Pseudo dice [np.float32(0.9522)] 
2025-07-11 19:27:06.940499: Epoch time: 69.28 s 
2025-07-11 19:27:09.225224:  
2025-07-11 19:27:09.227628: Epoch 150 
2025-07-11 19:27:09.228706: Current learning rate: 0.00864 
2025-07-11 19:28:17.872504: train_loss -0.9654 
2025-07-11 19:28:17.874151: val_loss -0.9444 
2025-07-11 19:28:17.875340: Pseudo dice [np.float32(0.9493)] 
2025-07-11 19:28:17.877034: Epoch time: 68.65 s 
2025-07-11 19:28:18.847213:  
2025-07-11 19:28:18.849534: Epoch 151 
2025-07-11 19:28:18.851255: Current learning rate: 0.00863 
2025-07-11 19:29:27.296684: train_loss -0.9659 
2025-07-11 19:29:27.298606: val_loss -0.95 
2025-07-11 19:29:27.300234: Pseudo dice [np.float32(0.9541)] 
2025-07-11 19:29:27.301556: Epoch time: 68.45 s 
2025-07-11 19:29:28.282545:  
2025-07-11 19:29:28.284850: Epoch 152 
2025-07-11 19:29:28.285933: Current learning rate: 0.00862 
2025-07-11 19:30:36.871351: train_loss -0.9661 
2025-07-11 19:30:36.873278: val_loss -0.9446 
2025-07-11 19:30:36.876144: Pseudo dice [np.float32(0.9479)] 
2025-07-11 19:30:36.878228: Epoch time: 68.59 s 
2025-07-11 19:30:37.861622:  
2025-07-11 19:30:37.864295: Epoch 153 
2025-07-11 19:30:37.866268: Current learning rate: 0.00861 
2025-07-11 19:31:46.550668: train_loss -0.9672 
2025-07-11 19:31:46.551813: val_loss -0.9469 
2025-07-11 19:31:46.553257: Pseudo dice [np.float32(0.9513)] 
2025-07-11 19:31:46.555328: Epoch time: 68.69 s 
2025-07-11 19:31:47.512184:  
2025-07-11 19:31:47.514551: Epoch 154 
2025-07-11 19:31:47.516136: Current learning rate: 0.0086 
2025-07-11 19:32:56.310837: train_loss -0.9657 
2025-07-11 19:32:56.312567: val_loss -0.9456 
2025-07-11 19:32:56.313500: Pseudo dice [np.float32(0.95)] 
2025-07-11 19:32:56.315321: Epoch time: 68.8 s 
2025-07-11 19:32:57.291831:  
2025-07-11 19:32:57.294543: Epoch 155 
2025-07-11 19:32:57.296373: Current learning rate: 0.00859 
2025-07-11 19:34:05.788289: train_loss -0.9653 
2025-07-11 19:34:05.791309: val_loss -0.943 
2025-07-11 19:34:05.793581: Pseudo dice [np.float32(0.9486)] 
2025-07-11 19:34:05.797188: Epoch time: 68.5 s 
2025-07-11 19:34:06.788530:  
2025-07-11 19:34:06.791392: Epoch 156 
2025-07-11 19:34:06.792435: Current learning rate: 0.00858 
2025-07-11 19:35:15.172810: train_loss -0.9664 
2025-07-11 19:35:15.174743: val_loss -0.9428 
2025-07-11 19:35:15.176235: Pseudo dice [np.float32(0.9474)] 
2025-07-11 19:35:15.178146: Epoch time: 68.39 s 
2025-07-11 19:35:16.175540:  
2025-07-11 19:35:16.177622: Epoch 157 
2025-07-11 19:35:16.179250: Current learning rate: 0.00858 
2025-07-11 19:36:25.302203: train_loss -0.9672 
2025-07-11 19:36:25.303710: val_loss -0.9435 
2025-07-11 19:36:25.305153: Pseudo dice [np.float32(0.9467)] 
2025-07-11 19:36:25.307136: Epoch time: 69.13 s 
2025-07-11 19:36:26.260341:  
2025-07-11 19:36:26.262104: Epoch 158 
2025-07-11 19:36:26.263139: Current learning rate: 0.00857 
2025-07-11 19:37:34.719012: train_loss -0.9668 
2025-07-11 19:37:34.720540: val_loss -0.9502 
2025-07-11 19:37:34.721766: Pseudo dice [np.float32(0.955)] 
2025-07-11 19:37:34.722744: Epoch time: 68.46 s 
2025-07-11 19:37:35.677578:  
2025-07-11 19:37:35.680340: Epoch 159 
2025-07-11 19:37:35.682122: Current learning rate: 0.00856 
2025-07-11 19:38:44.261787: train_loss -0.963 
2025-07-11 19:38:44.263601: val_loss -0.9443 
2025-07-11 19:38:44.264983: Pseudo dice [np.float32(0.9488)] 
2025-07-11 19:38:44.266002: Epoch time: 68.59 s 
2025-07-11 19:38:45.223872:  
2025-07-11 19:38:45.226443: Epoch 160 
2025-07-11 19:38:45.227686: Current learning rate: 0.00855 
2025-07-11 19:39:53.808769: train_loss -0.9649 
2025-07-11 19:39:53.810084: val_loss -0.9474 
2025-07-11 19:39:53.811222: Pseudo dice [np.float32(0.9522)] 
2025-07-11 19:39:53.812383: Epoch time: 68.59 s 
2025-07-11 19:39:53.813401: Yayy! New best EMA pseudo Dice: 0.9495999813079834 
2025-07-11 19:39:56.317617:  
2025-07-11 19:39:56.319677: Epoch 161 
2025-07-11 19:39:56.321031: Current learning rate: 0.00854 
2025-07-11 19:41:05.002758: train_loss -0.9661 
2025-07-11 19:41:05.004348: val_loss -0.9423 
2025-07-11 19:41:05.005630: Pseudo dice [np.float32(0.9469)] 
2025-07-11 19:41:05.006860: Epoch time: 68.69 s 
2025-07-11 19:41:05.947104:  
2025-07-11 19:41:05.949063: Epoch 162 
2025-07-11 19:41:05.950470: Current learning rate: 0.00853 
2025-07-11 19:42:14.561981: train_loss -0.9648 
2025-07-11 19:42:14.563991: val_loss -0.934 
2025-07-11 19:42:14.565095: Pseudo dice [np.float32(0.9387)] 
2025-07-11 19:42:14.566100: Epoch time: 68.62 s 
2025-07-11 19:42:15.525607:  
2025-07-11 19:42:15.527905: Epoch 163 
2025-07-11 19:42:15.529690: Current learning rate: 0.00852 
2025-07-11 19:43:24.180382: train_loss -0.9628 
2025-07-11 19:43:24.181609: val_loss -0.9441 
2025-07-11 19:43:24.182962: Pseudo dice [np.float32(0.9488)] 
2025-07-11 19:43:24.184165: Epoch time: 68.66 s 
2025-07-11 19:43:25.127492:  
2025-07-11 19:43:25.130171: Epoch 164 
2025-07-11 19:43:25.131395: Current learning rate: 0.00851 
2025-07-11 19:44:33.835412: train_loss -0.9662 
2025-07-11 19:44:33.836728: val_loss -0.9431 
2025-07-11 19:44:33.838394: Pseudo dice [np.float32(0.9473)] 
2025-07-11 19:44:33.840273: Epoch time: 68.71 s 
2025-07-11 19:44:34.778796:  
2025-07-11 19:44:34.780697: Epoch 165 
2025-07-11 19:44:34.782027: Current learning rate: 0.0085 
2025-07-11 19:45:43.617097: train_loss -0.9658 
2025-07-11 19:45:43.619272: val_loss -0.9413 
2025-07-11 19:45:43.620599: Pseudo dice [np.float32(0.9468)] 
2025-07-11 19:45:43.621619: Epoch time: 68.84 s 
2025-07-11 19:45:44.566444:  
2025-07-11 19:45:44.568523: Epoch 166 
2025-07-11 19:45:44.570171: Current learning rate: 0.00849 
2025-07-11 19:46:54.050491: train_loss -0.9674 
2025-07-11 19:46:54.051798: val_loss -0.9453 
2025-07-11 19:46:54.052936: Pseudo dice [np.float32(0.9506)] 
2025-07-11 19:46:54.054362: Epoch time: 69.49 s 
2025-07-11 19:46:54.968793:  
2025-07-11 19:46:54.970992: Epoch 167 
2025-07-11 19:46:54.972045: Current learning rate: 0.00848 
2025-07-11 19:48:03.686353: train_loss -0.967 
2025-07-11 19:48:03.688215: val_loss -0.9438 
2025-07-11 19:48:03.689209: Pseudo dice [np.float32(0.9488)] 
2025-07-11 19:48:03.690367: Epoch time: 68.72 s 
2025-07-11 19:48:04.645370:  
2025-07-11 19:48:04.647660: Epoch 168 
2025-07-11 19:48:04.648699: Current learning rate: 0.00847 
2025-07-11 19:49:13.543869: train_loss -0.9679 
2025-07-11 19:49:13.545638: val_loss -0.9466 
2025-07-11 19:49:13.546874: Pseudo dice [np.float32(0.951)] 
2025-07-11 19:49:13.548292: Epoch time: 68.9 s 
2025-07-11 19:49:14.503985:  
2025-07-11 19:49:14.505976: Epoch 169 
2025-07-11 19:49:14.507163: Current learning rate: 0.00847 
2025-07-11 19:50:23.308706: train_loss -0.9679 
2025-07-11 19:50:23.310177: val_loss -0.9453 
2025-07-11 19:50:23.311266: Pseudo dice [np.float32(0.9503)] 
2025-07-11 19:50:23.312469: Epoch time: 68.81 s 
2025-07-11 19:50:24.284489:  
2025-07-11 19:50:24.286605: Epoch 170 
2025-07-11 19:50:24.287638: Current learning rate: 0.00846 
2025-07-11 19:51:32.957572: train_loss -0.9675 
2025-07-11 19:51:32.959085: val_loss -0.9469 
2025-07-11 19:51:32.960649: Pseudo dice [np.float32(0.952)] 
2025-07-11 19:51:32.962412: Epoch time: 68.68 s 
2025-07-11 19:51:33.958951:  
2025-07-11 19:51:33.960951: Epoch 171 
2025-07-11 19:51:33.962377: Current learning rate: 0.00845 
2025-07-11 19:52:42.707919: train_loss -0.9671 
2025-07-11 19:52:42.709081: val_loss -0.9465 
2025-07-11 19:52:42.710334: Pseudo dice [np.float32(0.952)] 
2025-07-11 19:52:42.711607: Epoch time: 68.75 s 
2025-07-11 19:52:43.671592:  
2025-07-11 19:52:43.674031: Epoch 172 
2025-07-11 19:52:43.675204: Current learning rate: 0.00844 
2025-07-11 19:53:52.385313: train_loss -0.9652 
2025-07-11 19:53:52.386874: val_loss -0.9456 
2025-07-11 19:53:52.388079: Pseudo dice [np.float32(0.9502)] 
2025-07-11 19:53:52.389376: Epoch time: 68.72 s 
2025-07-11 19:53:53.370093:  
2025-07-11 19:53:53.371739: Epoch 173 
2025-07-11 19:53:53.372967: Current learning rate: 0.00843 
2025-07-11 19:55:02.100845: train_loss -0.9687 
2025-07-11 19:55:02.102178: val_loss -0.9482 
2025-07-11 19:55:02.103710: Pseudo dice [np.float32(0.9526)] 
2025-07-11 19:55:02.104677: Epoch time: 68.73 s 
2025-07-11 19:55:02.106177: Yayy! New best EMA pseudo Dice: 0.9498000144958496 
2025-07-11 19:55:04.623133:  
2025-07-11 19:55:04.625354: Epoch 174 
2025-07-11 19:55:04.626808: Current learning rate: 0.00842 
2025-07-11 19:56:13.608708: train_loss -0.968 
2025-07-11 19:56:13.610541: val_loss -0.9411 
2025-07-11 19:56:13.612016: Pseudo dice [np.float32(0.9462)] 
2025-07-11 19:56:13.613086: Epoch time: 68.99 s 
2025-07-11 19:56:14.567875:  
2025-07-11 19:56:14.570329: Epoch 175 
2025-07-11 19:56:14.572022: Current learning rate: 0.00841 
2025-07-11 19:57:24.089581: train_loss -0.9687 
2025-07-11 19:57:24.091183: val_loss -0.9472 
2025-07-11 19:57:24.093195: Pseudo dice [np.float32(0.9513)] 
2025-07-11 19:57:24.094568: Epoch time: 69.53 s 
2025-07-11 19:57:25.056559:  
2025-07-11 19:57:25.058637: Epoch 176 
2025-07-11 19:57:25.060175: Current learning rate: 0.0084 
2025-07-11 19:58:34.106250: train_loss -0.9679 
2025-07-11 19:58:34.107509: val_loss -0.9457 
2025-07-11 19:58:34.108657: Pseudo dice [np.float32(0.9499)] 
2025-07-11 19:58:34.110115: Epoch time: 69.05 s 
2025-07-11 19:58:35.072262:  
2025-07-11 19:58:35.074328: Epoch 177 
2025-07-11 19:58:35.075755: Current learning rate: 0.00839 
2025-07-11 19:59:44.080682: train_loss -0.9678 
2025-07-11 19:59:44.081880: val_loss -0.9483 
2025-07-11 19:59:44.083110: Pseudo dice [np.float32(0.9527)] 
2025-07-11 19:59:44.084605: Epoch time: 69.01 s 
2025-07-11 19:59:44.086531: Yayy! New best EMA pseudo Dice: 0.949999988079071 
2025-07-11 19:59:46.342196:  
2025-07-11 19:59:46.344664: Epoch 178 
2025-07-11 19:59:46.346388: Current learning rate: 0.00838 
2025-07-11 20:00:55.251863: train_loss -0.9673 
2025-07-11 20:00:55.254451: val_loss -0.9434 
2025-07-11 20:00:55.255978: Pseudo dice [np.float32(0.9481)] 
2025-07-11 20:00:55.257319: Epoch time: 68.91 s 
2025-07-11 20:00:56.212301:  
2025-07-11 20:00:56.214505: Epoch 179 
2025-07-11 20:00:56.215571: Current learning rate: 0.00837 
2025-07-11 20:02:04.886239: train_loss -0.9661 
2025-07-11 20:02:04.887648: val_loss -0.947 
2025-07-11 20:02:04.888806: Pseudo dice [np.float32(0.9515)] 
2025-07-11 20:02:04.890414: Epoch time: 68.68 s 
2025-07-11 20:02:05.811892:  
2025-07-11 20:02:05.814383: Epoch 180 
2025-07-11 20:02:05.815598: Current learning rate: 0.00836 
2025-07-11 20:03:14.407504: train_loss -0.967 
2025-07-11 20:03:14.408825: val_loss -0.9488 
2025-07-11 20:03:14.409916: Pseudo dice [np.float32(0.9524)] 
2025-07-11 20:03:14.410924: Epoch time: 68.6 s 
2025-07-11 20:03:14.412381: Yayy! New best EMA pseudo Dice: 0.9502000212669373 
2025-07-11 20:03:16.651988:  
2025-07-11 20:03:16.654018: Epoch 181 
2025-07-11 20:03:16.655273: Current learning rate: 0.00836 
2025-07-11 20:04:25.302105: train_loss -0.9678 
2025-07-11 20:04:25.303305: val_loss -0.9426 
2025-07-11 20:04:25.304977: Pseudo dice [np.float32(0.9478)] 
2025-07-11 20:04:25.306758: Epoch time: 68.65 s 
2025-07-11 20:04:26.254765:  
2025-07-11 20:04:26.256521: Epoch 182 
2025-07-11 20:04:26.257950: Current learning rate: 0.00835 
2025-07-11 20:05:34.909344: train_loss -0.9678 
2025-07-11 20:05:34.910821: val_loss -0.9448 
2025-07-11 20:05:34.912298: Pseudo dice [np.float32(0.9499)] 
2025-07-11 20:05:34.913636: Epoch time: 68.66 s 
2025-07-11 20:05:35.857090:  
2025-07-11 20:05:35.859454: Epoch 183 
2025-07-11 20:05:35.860708: Current learning rate: 0.00834 
2025-07-11 20:06:45.205070: train_loss -0.9667 
2025-07-11 20:06:45.207097: val_loss -0.9397 
2025-07-11 20:06:45.208451: Pseudo dice [np.float32(0.9435)] 
2025-07-11 20:06:45.209567: Epoch time: 69.35 s 
2025-07-11 20:06:46.165930:  
2025-07-11 20:06:46.168166: Epoch 184 
2025-07-11 20:06:46.169476: Current learning rate: 0.00833 
2025-07-11 20:07:54.862291: train_loss -0.9671 
2025-07-11 20:07:54.864274: val_loss -0.9442 
2025-07-11 20:07:54.866620: Pseudo dice [np.float32(0.9498)] 
2025-07-11 20:07:54.868436: Epoch time: 68.7 s 
2025-07-11 20:07:55.833903:  
2025-07-11 20:07:55.836215: Epoch 185 
2025-07-11 20:07:55.837343: Current learning rate: 0.00832 
2025-07-11 20:09:04.514398: train_loss -0.9674 
2025-07-11 20:09:04.515758: val_loss -0.9472 
2025-07-11 20:09:04.517618: Pseudo dice [np.float32(0.9519)] 
2025-07-11 20:09:04.518763: Epoch time: 68.68 s 
2025-07-11 20:09:05.473535:  
2025-07-11 20:09:05.475658: Epoch 186 
2025-07-11 20:09:05.477203: Current learning rate: 0.00831 
2025-07-11 20:10:14.107547: train_loss -0.9669 
2025-07-11 20:10:14.108947: val_loss -0.949 
2025-07-11 20:10:14.110022: Pseudo dice [np.float32(0.9533)] 
2025-07-11 20:10:14.111145: Epoch time: 68.64 s 
2025-07-11 20:10:15.085501:  
2025-07-11 20:10:15.088196: Epoch 187 
2025-07-11 20:10:15.089409: Current learning rate: 0.0083 
2025-07-11 20:11:23.629571: train_loss -0.9678 
2025-07-11 20:11:23.631021: val_loss -0.9449 
2025-07-11 20:11:23.632212: Pseudo dice [np.float32(0.949)] 
2025-07-11 20:11:23.633345: Epoch time: 68.55 s 
2025-07-11 20:11:24.583320:  
2025-07-11 20:11:24.585198: Epoch 188 
2025-07-11 20:11:24.586232: Current learning rate: 0.00829 
2025-07-11 20:12:33.043965: train_loss -0.9665 
2025-07-11 20:12:33.045613: val_loss -0.9445 
2025-07-11 20:12:33.046735: Pseudo dice [np.float32(0.9485)] 
2025-07-11 20:12:33.047721: Epoch time: 68.46 s 
2025-07-11 20:12:34.012146:  
2025-07-11 20:12:34.014663: Epoch 189 
2025-07-11 20:12:34.016242: Current learning rate: 0.00828 
2025-07-11 20:13:42.617768: train_loss -0.967 
2025-07-11 20:13:42.619447: val_loss -0.9481 
2025-07-11 20:13:42.620426: Pseudo dice [np.float32(0.9517)] 
2025-07-11 20:13:42.621409: Epoch time: 68.61 s 
2025-07-11 20:13:43.589467:  
2025-07-11 20:13:43.591844: Epoch 190 
2025-07-11 20:13:43.593804: Current learning rate: 0.00827 
2025-07-11 20:14:52.126994: train_loss -0.9674 
2025-07-11 20:14:52.128431: val_loss -0.9458 
2025-07-11 20:14:52.129525: Pseudo dice [np.float32(0.951)] 
2025-07-11 20:14:52.131059: Epoch time: 68.54 s 
2025-07-11 20:14:53.090310:  
2025-07-11 20:14:53.093441: Epoch 191 
2025-07-11 20:14:53.095238: Current learning rate: 0.00826 
2025-07-11 20:16:02.065638: train_loss -0.9667 
2025-07-11 20:16:02.067086: val_loss -0.9456 
2025-07-11 20:16:02.068355: Pseudo dice [np.float32(0.9511)] 
2025-07-11 20:16:02.069400: Epoch time: 68.98 s 
2025-07-11 20:16:03.085492:  
2025-07-11 20:16:03.088117: Epoch 192 
2025-07-11 20:16:03.089420: Current learning rate: 0.00825 
2025-07-11 20:17:12.666368: train_loss -0.9661 
2025-07-11 20:17:12.668659: val_loss -0.9458 
2025-07-11 20:17:12.670795: Pseudo dice [np.float32(0.9504)] 
2025-07-11 20:17:12.672260: Epoch time: 69.58 s 
2025-07-11 20:17:13.664091:  
2025-07-11 20:17:13.667172: Epoch 193 
2025-07-11 20:17:13.669256: Current learning rate: 0.00824 
2025-07-11 20:18:22.321309: train_loss -0.9664 
2025-07-11 20:18:22.323269: val_loss -0.9475 
2025-07-11 20:18:22.324560: Pseudo dice [np.float32(0.9517)] 
2025-07-11 20:18:22.325881: Epoch time: 68.66 s 
2025-07-11 20:18:22.326989: Yayy! New best EMA pseudo Dice: 0.9502999782562256 
2025-07-11 20:18:24.793634:  
2025-07-11 20:18:24.795943: Epoch 194 
2025-07-11 20:18:24.797166: Current learning rate: 0.00824 
2025-07-11 20:19:33.533640: train_loss -0.9679 
2025-07-11 20:19:33.535396: val_loss -0.9473 
2025-07-11 20:19:33.537195: Pseudo dice [np.float32(0.9514)] 
2025-07-11 20:19:33.538942: Epoch time: 68.74 s 
2025-07-11 20:19:33.540520: Yayy! New best EMA pseudo Dice: 0.9503999948501587 
2025-07-11 20:19:36.082088:  
2025-07-11 20:19:36.084384: Epoch 195 
2025-07-11 20:19:36.086013: Current learning rate: 0.00823 
2025-07-11 20:20:44.631150: train_loss -0.9687 
2025-07-11 20:20:44.632930: val_loss -0.9475 
2025-07-11 20:20:44.634806: Pseudo dice [np.float32(0.9524)] 
2025-07-11 20:20:44.636355: Epoch time: 68.55 s 
2025-07-11 20:20:44.637654: Yayy! New best EMA pseudo Dice: 0.9506000280380249 
2025-07-11 20:20:47.095457:  
2025-07-11 20:20:47.097284: Epoch 196 
2025-07-11 20:20:47.098394: Current learning rate: 0.00822 
2025-07-11 20:21:55.428030: train_loss -0.9691 
2025-07-11 20:21:55.429224: val_loss -0.949 
2025-07-11 20:21:55.430795: Pseudo dice [np.float32(0.9531)] 
2025-07-11 20:21:55.433443: Epoch time: 68.34 s 
2025-07-11 20:21:55.434922: Yayy! New best EMA pseudo Dice: 0.9509000182151794 
2025-07-11 20:21:57.947181:  
2025-07-11 20:21:57.948956: Epoch 197 
2025-07-11 20:21:57.950266: Current learning rate: 0.00821 
2025-07-11 20:23:06.209730: train_loss -0.9681 
2025-07-11 20:23:06.211617: val_loss -0.9467 
2025-07-11 20:23:06.212836: Pseudo dice [np.float32(0.9517)] 
2025-07-11 20:23:06.214485: Epoch time: 68.27 s 
2025-07-11 20:23:06.215793: Yayy! New best EMA pseudo Dice: 0.9509999752044678 
2025-07-11 20:23:08.532130:  
2025-07-11 20:23:08.533904: Epoch 198 
2025-07-11 20:23:08.535432: Current learning rate: 0.0082 
2025-07-11 20:24:17.024037: train_loss -0.9679 
2025-07-11 20:24:17.025776: val_loss -0.9422 
2025-07-11 20:24:17.027511: Pseudo dice [np.float32(0.9471)] 
2025-07-11 20:24:17.028914: Epoch time: 68.5 s 
2025-07-11 20:24:17.998238:  
2025-07-11 20:24:18.000613: Epoch 199 
2025-07-11 20:24:18.001824: Current learning rate: 0.00819 
2025-07-11 20:25:26.602319: train_loss -0.9684 
2025-07-11 20:25:26.603868: val_loss -0.949 
2025-07-11 20:25:26.604910: Pseudo dice [np.float32(0.9537)] 
2025-07-11 20:25:26.606434: Epoch time: 68.61 s 
2025-07-11 20:25:28.875047:  
2025-07-11 20:25:28.877708: Epoch 200 
2025-07-11 20:25:28.879307: Current learning rate: 0.00818 
2025-07-11 20:26:38.299596: train_loss -0.9681 
2025-07-11 20:26:38.301041: val_loss -0.943 
2025-07-11 20:26:38.302704: Pseudo dice [np.float32(0.9467)] 
2025-07-11 20:26:38.304767: Epoch time: 69.43 s 
2025-07-11 20:26:39.269076:  
2025-07-11 20:26:39.271230: Epoch 201 
2025-07-11 20:26:39.272667: Current learning rate: 0.00817 
2025-07-11 20:27:47.848588: train_loss -0.9679 
2025-07-11 20:27:47.850103: val_loss -0.9352 
2025-07-11 20:27:47.851257: Pseudo dice [np.float32(0.9404)] 
2025-07-11 20:27:47.852502: Epoch time: 68.58 s 
2025-07-11 20:27:48.824093:  
2025-07-11 20:27:48.826180: Epoch 202 
2025-07-11 20:27:48.827425: Current learning rate: 0.00816 
2025-07-11 20:28:57.449815: train_loss -0.9668 
2025-07-11 20:28:57.451202: val_loss -0.9453 
2025-07-11 20:28:57.452309: Pseudo dice [np.float32(0.9497)] 
2025-07-11 20:28:57.454223: Epoch time: 68.63 s 
2025-07-11 20:28:58.440222:  
2025-07-11 20:28:58.442102: Epoch 203 
2025-07-11 20:28:58.443521: Current learning rate: 0.00815 
2025-07-11 20:30:07.047752: train_loss -0.9672 
2025-07-11 20:30:07.049843: val_loss -0.946 
2025-07-11 20:30:07.051053: Pseudo dice [np.float32(0.9501)] 
2025-07-11 20:30:07.052420: Epoch time: 68.61 s 
2025-07-11 20:30:08.005715:  
2025-07-11 20:30:08.007804: Epoch 204 
2025-07-11 20:30:08.008821: Current learning rate: 0.00814 
2025-07-11 20:31:16.781254: train_loss -0.9701 
2025-07-11 20:31:16.782857: val_loss -0.9462 
2025-07-11 20:31:16.784443: Pseudo dice [np.float32(0.9501)] 
2025-07-11 20:31:16.785771: Epoch time: 68.78 s 
2025-07-11 20:31:17.756542:  
2025-07-11 20:31:17.758604: Epoch 205 
2025-07-11 20:31:17.760342: Current learning rate: 0.00813 
2025-07-11 20:32:26.603525: train_loss -0.9681 
2025-07-11 20:32:26.604719: val_loss -0.9491 
2025-07-11 20:32:26.606394: Pseudo dice [np.float32(0.9534)] 
2025-07-11 20:32:26.608019: Epoch time: 68.85 s 
2025-07-11 20:32:27.527265:  
2025-07-11 20:32:27.529551: Epoch 206 
2025-07-11 20:32:27.530836: Current learning rate: 0.00813 
2025-07-11 20:33:36.292039: train_loss -0.9681 
2025-07-11 20:33:36.293796: val_loss -0.9444 
2025-07-11 20:33:36.295599: Pseudo dice [np.float32(0.9491)] 
2025-07-11 20:33:36.297323: Epoch time: 68.77 s 
2025-07-11 20:33:37.241895:  
2025-07-11 20:33:37.244128: Epoch 207 
2025-07-11 20:33:37.245223: Current learning rate: 0.00812 
2025-07-11 20:34:46.145526: train_loss -0.9691 
2025-07-11 20:34:46.146706: val_loss -0.9432 
2025-07-11 20:34:46.147911: Pseudo dice [np.float32(0.9483)] 
2025-07-11 20:34:46.148839: Epoch time: 68.91 s 
2025-07-11 20:34:47.072107:  
2025-07-11 20:34:47.074365: Epoch 208 
2025-07-11 20:34:47.075656: Current learning rate: 0.00811 
2025-07-11 20:35:56.308239: train_loss -0.969 
2025-07-11 20:35:56.309576: val_loss -0.9464 
2025-07-11 20:35:56.310464: Pseudo dice [np.float32(0.9496)] 
2025-07-11 20:35:56.311754: Epoch time: 69.24 s 
2025-07-11 20:35:57.238127:  
2025-07-11 20:35:57.240659: Epoch 209 
2025-07-11 20:35:57.242396: Current learning rate: 0.0081 
2025-07-11 20:37:07.130064: train_loss -0.9688 
2025-07-11 20:37:07.131396: val_loss -0.9489 
2025-07-11 20:37:07.133297: Pseudo dice [np.float32(0.9535)] 
2025-07-11 20:37:07.134488: Epoch time: 69.9 s 
2025-07-11 20:37:08.071151:  
2025-07-11 20:37:08.073064: Epoch 210 
2025-07-11 20:37:08.074343: Current learning rate: 0.00809 
2025-07-11 20:38:16.795989: train_loss -0.9687 
2025-07-11 20:38:16.797579: val_loss -0.9467 
2025-07-11 20:38:16.799253: Pseudo dice [np.float32(0.9515)] 
2025-07-11 20:38:16.800979: Epoch time: 68.73 s 
2025-07-11 20:38:17.738503:  
2025-07-11 20:38:17.740865: Epoch 211 
2025-07-11 20:38:17.741931: Current learning rate: 0.00808 
2025-07-11 20:39:26.504280: train_loss -0.9697 
2025-07-11 20:39:26.505970: val_loss -0.9487 
2025-07-11 20:39:26.507217: Pseudo dice [np.float32(0.9534)] 
2025-07-11 20:39:26.509044: Epoch time: 68.77 s 
2025-07-11 20:39:27.437109:  
2025-07-11 20:39:27.439234: Epoch 212 
2025-07-11 20:39:27.440283: Current learning rate: 0.00807 
2025-07-11 20:40:36.300627: train_loss -0.9691 
2025-07-11 20:40:36.302364: val_loss -0.9465 
2025-07-11 20:40:36.303510: Pseudo dice [np.float32(0.9508)] 
2025-07-11 20:40:36.305233: Epoch time: 68.87 s 
2025-07-11 20:40:37.244537:  
2025-07-11 20:40:37.246675: Epoch 213 
2025-07-11 20:40:37.248240: Current learning rate: 0.00806 
2025-07-11 20:41:46.198391: train_loss -0.9698 
2025-07-11 20:41:46.199631: val_loss -0.9451 
2025-07-11 20:41:46.201315: Pseudo dice [np.float32(0.9485)] 
2025-07-11 20:41:46.203007: Epoch time: 68.96 s 
2025-07-11 20:41:47.135030:  
2025-07-11 20:41:47.137101: Epoch 214 
2025-07-11 20:41:47.138370: Current learning rate: 0.00805 
2025-07-11 20:42:55.933835: train_loss -0.9697 
2025-07-11 20:42:55.935580: val_loss -0.945 
2025-07-11 20:42:55.936931: Pseudo dice [np.float32(0.9489)] 
2025-07-11 20:42:55.938363: Epoch time: 68.8 s 
2025-07-11 20:42:56.887519:  
2025-07-11 20:42:56.889484: Epoch 215 
2025-07-11 20:42:56.890644: Current learning rate: 0.00804 
2025-07-11 20:44:05.935624: train_loss -0.9687 
2025-07-11 20:44:05.937507: val_loss -0.9527 
2025-07-11 20:44:05.939196: Pseudo dice [np.float32(0.9557)] 
2025-07-11 20:44:05.940308: Epoch time: 69.05 s 
2025-07-11 20:44:06.887499:  
2025-07-11 20:44:06.890363: Epoch 216 
2025-07-11 20:44:06.891529: Current learning rate: 0.00803 
2025-07-11 20:45:15.691831: train_loss -0.9699 
2025-07-11 20:45:15.693140: val_loss -0.9469 
2025-07-11 20:45:15.694117: Pseudo dice [np.float32(0.9514)] 
2025-07-11 20:45:15.695074: Epoch time: 68.81 s 
2025-07-11 20:45:16.619982:  
2025-07-11 20:45:16.622224: Epoch 217 
2025-07-11 20:45:16.623543: Current learning rate: 0.00802 
2025-07-11 20:46:25.539455: train_loss -0.9689 
2025-07-11 20:46:25.541179: val_loss -0.9439 
2025-07-11 20:46:25.542568: Pseudo dice [np.float32(0.949)] 
2025-07-11 20:46:25.544105: Epoch time: 68.92 s 
2025-07-11 20:46:26.463590:  
2025-07-11 20:46:26.466338: Epoch 218 
2025-07-11 20:46:26.467683: Current learning rate: 0.00801 
2025-07-11 20:47:36.011913: train_loss -0.9682 
2025-07-11 20:47:36.013236: val_loss -0.9459 
2025-07-11 20:47:36.014740: Pseudo dice [np.float32(0.9497)] 
2025-07-11 20:47:36.016229: Epoch time: 69.55 s 
2025-07-11 20:47:36.938096:  
2025-07-11 20:47:36.940318: Epoch 219 
2025-07-11 20:47:36.941680: Current learning rate: 0.00801 
2025-07-11 20:48:45.563703: train_loss -0.9668 
2025-07-11 20:48:45.565047: val_loss -0.9414 
2025-07-11 20:48:45.566448: Pseudo dice [np.float32(0.9452)] 
2025-07-11 20:48:45.567628: Epoch time: 68.63 s 
2025-07-11 20:48:46.510478:  
2025-07-11 20:48:46.512595: Epoch 220 
2025-07-11 20:48:46.513639: Current learning rate: 0.008 
2025-07-11 20:49:55.264210: train_loss -0.9692 
2025-07-11 20:49:55.265670: val_loss -0.9423 
2025-07-11 20:49:55.266953: Pseudo dice [np.float32(0.9476)] 
2025-07-11 20:49:55.268076: Epoch time: 68.76 s 
2025-07-11 20:49:56.195931:  
2025-07-11 20:49:56.197576: Epoch 221 
2025-07-11 20:49:56.198800: Current learning rate: 0.00799 
2025-07-11 20:51:05.021240: train_loss -0.9674 
2025-07-11 20:51:05.024291: val_loss -0.9465 
2025-07-11 20:51:05.026003: Pseudo dice [np.float32(0.9509)] 
2025-07-11 20:51:05.027314: Epoch time: 68.83 s 
2025-07-11 20:51:05.920026:  
2025-07-11 20:51:05.922117: Epoch 222 
2025-07-11 20:51:05.923344: Current learning rate: 0.00798 
2025-07-11 20:52:14.529147: train_loss -0.9689 
2025-07-11 20:52:14.530602: val_loss -0.9454 
2025-07-11 20:52:14.531889: Pseudo dice [np.float32(0.9492)] 
2025-07-11 20:52:14.533933: Epoch time: 68.61 s 
2025-07-11 20:52:15.474221:  
2025-07-11 20:52:15.476083: Epoch 223 
2025-07-11 20:52:15.478285: Current learning rate: 0.00797 
2025-07-11 20:53:23.945927: train_loss -0.9686 
2025-07-11 20:53:23.947156: val_loss -0.9497 
2025-07-11 20:53:23.948621: Pseudo dice [np.float32(0.9534)] 
2025-07-11 20:53:23.950801: Epoch time: 68.48 s 
2025-07-11 20:53:24.891381:  
2025-07-11 20:53:24.893429: Epoch 224 
2025-07-11 20:53:24.894732: Current learning rate: 0.00796 
2025-07-11 20:54:33.289891: train_loss -0.9694 
2025-07-11 20:54:33.291441: val_loss -0.9503 
2025-07-11 20:54:33.292584: Pseudo dice [np.float32(0.9535)] 
2025-07-11 20:54:33.293951: Epoch time: 68.4 s 
2025-07-11 20:54:34.223340:  
2025-07-11 20:54:34.225774: Epoch 225 
2025-07-11 20:54:34.227125: Current learning rate: 0.00795 
2025-07-11 20:55:42.637199: train_loss -0.9699 
2025-07-11 20:55:42.638468: val_loss -0.9473 
2025-07-11 20:55:42.639440: Pseudo dice [np.float32(0.9517)] 
2025-07-11 20:55:42.640526: Epoch time: 68.42 s 
2025-07-11 20:55:43.569479:  
2025-07-11 20:55:43.571493: Epoch 226 
2025-07-11 20:55:43.572819: Current learning rate: 0.00794 
2025-07-11 20:56:52.251627: train_loss -0.9694 
2025-07-11 20:56:52.253196: val_loss -0.9507 
2025-07-11 20:56:52.254328: Pseudo dice [np.float32(0.9551)] 
2025-07-11 20:56:52.256130: Epoch time: 68.69 s 
2025-07-11 20:56:52.258253: Yayy! New best EMA pseudo Dice: 0.9510999917984009 
2025-07-11 20:56:54.475019:  
2025-07-11 20:56:54.477308: Epoch 227 
2025-07-11 20:56:54.478589: Current learning rate: 0.00793 
2025-07-11 20:58:03.832686: train_loss -0.969 
2025-07-11 20:58:03.834302: val_loss -0.9475 
2025-07-11 20:58:03.835376: Pseudo dice [np.float32(0.9518)] 
2025-07-11 20:58:03.837180: Epoch time: 69.36 s 
2025-07-11 20:58:03.838901: Yayy! New best EMA pseudo Dice: 0.9510999917984009 
2025-07-11 20:58:06.054316:  
2025-07-11 20:58:06.056238: Epoch 228 
2025-07-11 20:58:06.057656: Current learning rate: 0.00792 
2025-07-11 20:59:14.661870: train_loss -0.9678 
2025-07-11 20:59:14.664147: val_loss -0.9415 
2025-07-11 20:59:14.665344: Pseudo dice [np.float32(0.9463)] 
2025-07-11 20:59:14.666957: Epoch time: 68.61 s 
2025-07-11 20:59:15.583169:  
2025-07-11 20:59:15.585275: Epoch 229 
2025-07-11 20:59:15.586468: Current learning rate: 0.00791 
2025-07-11 21:00:24.067996: train_loss -0.9683 
2025-07-11 21:00:24.069394: val_loss -0.9447 
2025-07-11 21:00:24.070891: Pseudo dice [np.float32(0.9484)] 
2025-07-11 21:00:24.073289: Epoch time: 68.49 s 
2025-07-11 21:00:24.988441:  
2025-07-11 21:00:24.990304: Epoch 230 
2025-07-11 21:00:24.991653: Current learning rate: 0.0079 
2025-07-11 21:01:33.501534: train_loss -0.9677 
2025-07-11 21:01:33.502772: val_loss -0.9504 
2025-07-11 21:01:33.504293: Pseudo dice [np.float32(0.9542)] 
2025-07-11 21:01:33.505691: Epoch time: 68.52 s 
2025-07-11 21:01:34.415320:  
2025-07-11 21:01:34.417446: Epoch 231 
2025-07-11 21:01:34.418771: Current learning rate: 0.00789 
2025-07-11 21:02:42.688797: train_loss -0.9665 
2025-07-11 21:02:42.689870: val_loss -0.948 
2025-07-11 21:02:42.691234: Pseudo dice [np.float32(0.952)] 
2025-07-11 21:02:42.692560: Epoch time: 68.28 s 
2025-07-11 21:02:43.624332:  
2025-07-11 21:02:43.626255: Epoch 232 
2025-07-11 21:02:43.627441: Current learning rate: 0.00789 
2025-07-11 21:03:52.103807: train_loss -0.9682 
2025-07-11 21:03:52.105286: val_loss -0.949 
2025-07-11 21:03:52.106550: Pseudo dice [np.float32(0.9524)] 
2025-07-11 21:03:52.107875: Epoch time: 68.48 s 
2025-07-11 21:03:53.023961:  
2025-07-11 21:03:53.026633: Epoch 233 
2025-07-11 21:03:53.028492: Current learning rate: 0.00788 
2025-07-11 21:05:01.872824: train_loss -0.9687 
2025-07-11 21:05:01.874346: val_loss -0.9499 
2025-07-11 21:05:01.875433: Pseudo dice [np.float32(0.9542)] 
2025-07-11 21:05:01.876979: Epoch time: 68.85 s 
2025-07-11 21:05:01.878636: Yayy! New best EMA pseudo Dice: 0.9513999819755554 
2025-07-11 21:05:04.108590:  
2025-07-11 21:05:04.110940: Epoch 234 
2025-07-11 21:05:04.112126: Current learning rate: 0.00787 
2025-07-11 21:06:12.976785: train_loss -0.9682 
2025-07-11 21:06:12.978184: val_loss -0.9477 
2025-07-11 21:06:12.979415: Pseudo dice [np.float32(0.9519)] 
2025-07-11 21:06:12.980746: Epoch time: 68.87 s 
2025-07-11 21:06:12.981787: Yayy! New best EMA pseudo Dice: 0.9513999819755554 
2025-07-11 21:06:15.427082:  
2025-07-11 21:06:15.428965: Epoch 235 
2025-07-11 21:06:15.430209: Current learning rate: 0.00786 
2025-07-11 21:07:24.232968: train_loss -0.9686 
2025-07-11 21:07:24.234521: val_loss -0.9418 
2025-07-11 21:07:24.235991: Pseudo dice [np.float32(0.9465)] 
2025-07-11 21:07:24.238168: Epoch time: 68.81 s 
2025-07-11 21:07:25.161480:  
2025-07-11 21:07:25.163488: Epoch 236 
2025-07-11 21:07:25.164672: Current learning rate: 0.00785 
2025-07-11 21:08:34.508366: train_loss -0.9679 
2025-07-11 21:08:34.509825: val_loss -0.9492 
2025-07-11 21:08:34.510935: Pseudo dice [np.float32(0.9542)] 
2025-07-11 21:08:34.512203: Epoch time: 69.35 s 
2025-07-11 21:08:35.427160:  
2025-07-11 21:08:35.428737: Epoch 237 
2025-07-11 21:08:35.429742: Current learning rate: 0.00784 
2025-07-11 21:09:43.891692: train_loss -0.9707 
2025-07-11 21:09:43.892884: val_loss -0.9487 
2025-07-11 21:09:43.893836: Pseudo dice [np.float32(0.9532)] 
2025-07-11 21:09:43.895346: Epoch time: 68.47 s 
2025-07-11 21:09:43.896973: Yayy! New best EMA pseudo Dice: 0.9514999985694885 
2025-07-11 21:09:46.239953:  
2025-07-11 21:09:46.241868: Epoch 238 
2025-07-11 21:09:46.243092: Current learning rate: 0.00783 
2025-07-11 21:10:54.672902: train_loss -0.9703 
2025-07-11 21:10:54.674659: val_loss -0.9493 
2025-07-11 21:10:54.676024: Pseudo dice [np.float32(0.9524)] 
2025-07-11 21:10:54.677588: Epoch time: 68.44 s 
2025-07-11 21:10:54.679668: Yayy! New best EMA pseudo Dice: 0.9516000151634216 
2025-07-11 21:10:57.040972:  
2025-07-11 21:10:57.042798: Epoch 239 
2025-07-11 21:10:57.044166: Current learning rate: 0.00782 
2025-07-11 21:12:05.629174: train_loss -0.9698 
2025-07-11 21:12:05.630690: val_loss -0.9483 
2025-07-11 21:12:05.631819: Pseudo dice [np.float32(0.9524)] 
2025-07-11 21:12:05.633465: Epoch time: 68.59 s 
2025-07-11 21:12:05.635064: Yayy! New best EMA pseudo Dice: 0.9516000151634216 
2025-07-11 21:12:08.016209:  
2025-07-11 21:12:08.018236: Epoch 240 
2025-07-11 21:12:08.019634: Current learning rate: 0.00781 
2025-07-11 21:13:16.826880: train_loss -0.9709 
2025-07-11 21:13:16.828643: val_loss -0.9483 
2025-07-11 21:13:16.829969: Pseudo dice [np.float32(0.9527)] 
2025-07-11 21:13:16.830930: Epoch time: 68.81 s 
2025-07-11 21:13:16.832331: Yayy! New best EMA pseudo Dice: 0.9517999887466431 
2025-07-11 21:13:19.066172:  
2025-07-11 21:13:19.067538: Epoch 241 
2025-07-11 21:13:19.069341: Current learning rate: 0.0078 
2025-07-11 21:14:27.765260: train_loss -0.9705 
2025-07-11 21:14:27.766883: val_loss -0.9464 
2025-07-11 21:14:27.768155: Pseudo dice [np.float32(0.9506)] 
2025-07-11 21:14:27.769151: Epoch time: 68.7 s 
2025-07-11 21:14:28.693866:  
2025-07-11 21:14:28.696170: Epoch 242 
2025-07-11 21:14:28.697307: Current learning rate: 0.00779 
2025-07-11 21:15:37.434449: train_loss -0.9703 
2025-07-11 21:15:37.436944: val_loss -0.9483 
2025-07-11 21:15:37.438119: Pseudo dice [np.float32(0.9514)] 
2025-07-11 21:15:37.439425: Epoch time: 68.74 s 
2025-07-11 21:15:38.365065:  
2025-07-11 21:15:38.367111: Epoch 243 
2025-07-11 21:15:38.368384: Current learning rate: 0.00778 
2025-07-11 21:16:47.178648: train_loss -0.9707 
2025-07-11 21:16:47.180229: val_loss -0.9477 
2025-07-11 21:16:47.181669: Pseudo dice [np.float32(0.9515)] 
2025-07-11 21:16:47.183043: Epoch time: 68.82 s 
2025-07-11 21:16:48.134251:  
2025-07-11 21:16:48.136395: Epoch 244 
2025-07-11 21:16:48.138384: Current learning rate: 0.00777 
2025-07-11 21:17:57.558891: train_loss -0.9704 
2025-07-11 21:17:57.560179: val_loss -0.9514 
2025-07-11 21:17:57.561613: Pseudo dice [np.float32(0.9546)] 
2025-07-11 21:17:57.563370: Epoch time: 69.43 s 
2025-07-11 21:17:57.565261: Yayy! New best EMA pseudo Dice: 0.9519000053405762 
2025-07-11 21:18:00.052975:  
2025-07-11 21:18:00.055432: Epoch 245 
2025-07-11 21:18:00.056814: Current learning rate: 0.00777 
2025-07-11 21:19:08.711477: train_loss -0.9692 
2025-07-11 21:19:08.712970: val_loss -0.9449 
2025-07-11 21:19:08.714639: Pseudo dice [np.float32(0.9497)] 
2025-07-11 21:19:08.717456: Epoch time: 68.66 s 
2025-07-11 21:19:09.635955:  
2025-07-11 21:19:09.638374: Epoch 246 
2025-07-11 21:19:09.639768: Current learning rate: 0.00776 
2025-07-11 21:20:18.350894: train_loss -0.9697 
2025-07-11 21:20:18.353271: val_loss -0.9486 
2025-07-11 21:20:18.354789: Pseudo dice [np.float32(0.9531)] 
2025-07-11 21:20:18.357146: Epoch time: 68.72 s 
2025-07-11 21:20:19.293498:  
2025-07-11 21:20:19.295295: Epoch 247 
2025-07-11 21:20:19.297160: Current learning rate: 0.00775 
2025-07-11 21:21:27.896321: train_loss -0.9695 
2025-07-11 21:21:27.899367: val_loss -0.9416 
2025-07-11 21:21:27.900806: Pseudo dice [np.float32(0.9457)] 
2025-07-11 21:21:27.901925: Epoch time: 68.61 s 
2025-07-11 21:21:28.831167:  
2025-07-11 21:21:28.833366: Epoch 248 
2025-07-11 21:21:28.834579: Current learning rate: 0.00774 
2025-07-11 21:22:37.400985: train_loss -0.9696 
2025-07-11 21:22:37.402672: val_loss -0.9468 
2025-07-11 21:22:37.404341: Pseudo dice [np.float32(0.9514)] 
2025-07-11 21:22:37.406072: Epoch time: 68.57 s 
2025-07-11 21:22:38.310703:  
2025-07-11 21:22:38.312678: Epoch 249 
2025-07-11 21:22:38.313876: Current learning rate: 0.00773 
2025-07-11 21:23:46.989689: train_loss -0.9699 
2025-07-11 21:23:46.991276: val_loss -0.949 
2025-07-11 21:23:46.992540: Pseudo dice [np.float32(0.9527)] 
2025-07-11 21:23:46.994512: Epoch time: 68.68 s 
2025-07-11 21:23:49.231040:  
2025-07-11 21:23:49.233339: Epoch 250 
2025-07-11 21:23:49.235368: Current learning rate: 0.00772 
2025-07-11 21:24:57.754101: train_loss -0.9688 
2025-07-11 21:24:57.756355: val_loss -0.9474 
2025-07-11 21:24:57.758334: Pseudo dice [np.float32(0.9518)] 
2025-07-11 21:24:57.760222: Epoch time: 68.53 s 
2025-07-11 21:24:58.709910:  
2025-07-11 21:24:58.712182: Epoch 251 
2025-07-11 21:24:58.714266: Current learning rate: 0.00771 
2025-07-11 21:26:07.220315: train_loss -0.9704 
2025-07-11 21:26:07.222421: val_loss -0.9519 
2025-07-11 21:26:07.224235: Pseudo dice [np.float32(0.956)] 
2025-07-11 21:26:07.225983: Epoch time: 68.51 s 
2025-07-11 21:26:08.150193:  
2025-07-11 21:26:08.152551: Epoch 252 
2025-07-11 21:26:08.154338: Current learning rate: 0.0077 
2025-07-11 21:27:16.613483: train_loss -0.9697 
2025-07-11 21:27:16.616066: val_loss -0.9498 
2025-07-11 21:27:16.618617: Pseudo dice [np.float32(0.9538)] 
2025-07-11 21:27:16.620709: Epoch time: 68.47 s 
2025-07-11 21:27:16.622564: Yayy! New best EMA pseudo Dice: 0.9520999789237976 
2025-07-11 21:27:18.885668:  
2025-07-11 21:27:18.888102: Epoch 253 
2025-07-11 21:27:18.889287: Current learning rate: 0.00769 
2025-07-11 21:28:28.124923: train_loss -0.9698 
2025-07-11 21:28:28.126450: val_loss -0.9449 
2025-07-11 21:28:28.127922: Pseudo dice [np.float32(0.949)] 
2025-07-11 21:28:28.128837: Epoch time: 69.24 s 
2025-07-11 21:28:29.062487:  
2025-07-11 21:28:29.064698: Epoch 254 
2025-07-11 21:28:29.066591: Current learning rate: 0.00768 
2025-07-11 21:29:37.616177: train_loss -0.9688 
2025-07-11 21:29:37.617527: val_loss -0.9492 
2025-07-11 21:29:37.618820: Pseudo dice [np.float32(0.9538)] 
2025-07-11 21:29:37.620149: Epoch time: 68.56 s 
2025-07-11 21:29:38.558339:  
2025-07-11 21:29:38.560955: Epoch 255 
2025-07-11 21:29:38.562231: Current learning rate: 0.00767 
2025-07-11 21:30:47.081156: train_loss -0.9675 
2025-07-11 21:30:47.082402: val_loss -0.9467 
2025-07-11 21:30:47.084422: Pseudo dice [np.float32(0.951)] 
2025-07-11 21:30:47.085584: Epoch time: 68.53 s 
2025-07-11 21:30:48.020440:  
2025-07-11 21:30:48.022848: Epoch 256 
2025-07-11 21:30:48.023968: Current learning rate: 0.00766 
2025-07-11 21:31:56.436390: train_loss -0.9699 
2025-07-11 21:31:56.437955: val_loss -0.9501 
2025-07-11 21:31:56.439632: Pseudo dice [np.float32(0.9538)] 
2025-07-11 21:31:56.441500: Epoch time: 68.42 s 
2025-07-11 21:31:57.367602:  
2025-07-11 21:31:57.370373: Epoch 257 
2025-07-11 21:31:57.372169: Current learning rate: 0.00765 
2025-07-11 21:33:05.769055: train_loss -0.9711 
2025-07-11 21:33:05.771054: val_loss -0.9485 
2025-07-11 21:33:05.772341: Pseudo dice [np.float32(0.9528)] 
2025-07-11 21:33:05.773461: Epoch time: 68.41 s 
2025-07-11 21:33:05.774402: Yayy! New best EMA pseudo Dice: 0.9520999789237976 
2025-07-11 21:33:08.217893:  
2025-07-11 21:33:08.219754: Epoch 258 
2025-07-11 21:33:08.220752: Current learning rate: 0.00764 
2025-07-11 21:34:16.635324: train_loss -0.9708 
2025-07-11 21:34:16.637026: val_loss -0.9458 
2025-07-11 21:34:16.638265: Pseudo dice [np.float32(0.9506)] 
2025-07-11 21:34:16.639405: Epoch time: 68.42 s 
2025-07-11 21:34:17.564488:  
2025-07-11 21:34:17.567071: Epoch 259 
2025-07-11 21:34:17.568518: Current learning rate: 0.00764 
2025-07-11 21:35:26.388443: train_loss -0.9705 
2025-07-11 21:35:26.390042: val_loss -0.9479 
2025-07-11 21:35:26.391907: Pseudo dice [np.float32(0.9526)] 
2025-07-11 21:35:26.394016: Epoch time: 68.83 s 
2025-07-11 21:35:27.317909:  
2025-07-11 21:35:27.320246: Epoch 260 
2025-07-11 21:35:27.321394: Current learning rate: 0.00763 
2025-07-11 21:36:36.292762: train_loss -0.9701 
2025-07-11 21:36:36.294508: val_loss -0.9488 
2025-07-11 21:36:36.295695: Pseudo dice [np.float32(0.9532)] 
2025-07-11 21:36:36.297004: Epoch time: 68.98 s 
2025-07-11 21:36:36.298291: Yayy! New best EMA pseudo Dice: 0.9521999955177307 
2025-07-11 21:36:38.610310:  
2025-07-11 21:36:38.612578: Epoch 261 
2025-07-11 21:36:38.613844: Current learning rate: 0.00762 
2025-07-11 21:37:47.220455: train_loss -0.9698 
2025-07-11 21:37:47.222075: val_loss -0.9491 
2025-07-11 21:37:47.223294: Pseudo dice [np.float32(0.954)] 
2025-07-11 21:37:47.224889: Epoch time: 68.61 s 
2025-07-11 21:37:47.227232: Yayy! New best EMA pseudo Dice: 0.9523000121116638 
2025-07-11 21:37:50.427794:  
2025-07-11 21:37:50.429812: Epoch 262 
2025-07-11 21:37:50.431100: Current learning rate: 0.00761 
2025-07-11 21:38:59.052802: train_loss -0.9703 
2025-07-11 21:38:59.055428: val_loss -0.9476 
2025-07-11 21:38:59.057874: Pseudo dice [np.float32(0.9515)] 
2025-07-11 21:38:59.060752: Epoch time: 68.63 s 
2025-07-11 21:39:00.017475:  
2025-07-11 21:39:00.020774: Epoch 263 
2025-07-11 21:39:00.022450: Current learning rate: 0.0076 
2025-07-11 21:40:08.716018: train_loss -0.9704 
2025-07-11 21:40:08.717820: val_loss -0.9478 
2025-07-11 21:40:08.720661: Pseudo dice [np.float32(0.9525)] 
2025-07-11 21:40:08.723750: Epoch time: 68.7 s 
2025-07-11 21:40:09.644631:  
2025-07-11 21:40:09.647125: Epoch 264 
2025-07-11 21:40:09.648336: Current learning rate: 0.00759 
2025-07-11 21:41:18.481902: train_loss -0.9709 
2025-07-11 21:41:18.484412: val_loss -0.9508 
2025-07-11 21:41:18.486331: Pseudo dice [np.float32(0.9546)] 
2025-07-11 21:41:18.489624: Epoch time: 68.84 s 
2025-07-11 21:41:18.492223: Yayy! New best EMA pseudo Dice: 0.9524999856948853 
2025-07-11 21:41:20.717308:  
2025-07-11 21:41:20.719671: Epoch 265 
2025-07-11 21:41:20.720888: Current learning rate: 0.00758 
2025-07-11 21:42:29.427795: train_loss -0.9705 
2025-07-11 21:42:29.429238: val_loss -0.9429 
2025-07-11 21:42:29.430276: Pseudo dice [np.float32(0.9467)] 
2025-07-11 21:42:29.431526: Epoch time: 68.71 s 
2025-07-11 21:42:30.357769:  
2025-07-11 21:42:30.359823: Epoch 266 
2025-07-11 21:42:30.360984: Current learning rate: 0.00757 
2025-07-11 21:43:39.174925: train_loss -0.9694 
2025-07-11 21:43:39.176836: val_loss -0.9481 
2025-07-11 21:43:39.178518: Pseudo dice [np.float32(0.9516)] 
2025-07-11 21:43:39.180200: Epoch time: 68.82 s 
2025-07-11 21:43:40.114379:  
2025-07-11 21:43:40.116805: Epoch 267 
2025-07-11 21:43:40.117724: Current learning rate: 0.00756 
2025-07-11 21:44:48.639647: train_loss -0.9682 
2025-07-11 21:44:48.640854: val_loss -0.9481 
2025-07-11 21:44:48.642113: Pseudo dice [np.float32(0.9525)] 
2025-07-11 21:44:48.643715: Epoch time: 68.53 s 
2025-07-11 21:44:49.554944:  
2025-07-11 21:44:49.557085: Epoch 268 
2025-07-11 21:44:49.558443: Current learning rate: 0.00755 
2025-07-11 21:45:58.117541: train_loss -0.9695 
2025-07-11 21:45:58.119274: val_loss -0.9485 
2025-07-11 21:45:58.121258: Pseudo dice [np.float32(0.9528)] 
2025-07-11 21:45:58.122604: Epoch time: 68.57 s 
2025-07-11 21:45:59.047115:  
2025-07-11 21:45:59.049299: Epoch 269 
2025-07-11 21:45:59.051149: Current learning rate: 0.00754 
2025-07-11 21:47:07.449728: train_loss -0.9695 
2025-07-11 21:47:07.451174: val_loss -0.9488 
2025-07-11 21:47:07.452564: Pseudo dice [np.float32(0.9528)] 
2025-07-11 21:47:07.454077: Epoch time: 68.41 s 
2025-07-11 21:47:08.384202:  
2025-07-11 21:47:08.386949: Epoch 270 
2025-07-11 21:47:08.388165: Current learning rate: 0.00753 
2025-07-11 21:48:17.725461: train_loss -0.9701 
2025-07-11 21:48:17.727168: val_loss -0.9491 
2025-07-11 21:48:17.729112: Pseudo dice [np.float32(0.9536)] 
2025-07-11 21:48:17.730332: Epoch time: 69.34 s 
2025-07-11 21:48:18.666502:  
2025-07-11 21:48:18.669107: Epoch 271 
2025-07-11 21:48:18.670556: Current learning rate: 0.00752 
2025-07-11 21:49:27.361526: train_loss -0.9699 
2025-07-11 21:49:27.363217: val_loss -0.9466 
2025-07-11 21:49:27.364302: Pseudo dice [np.float32(0.9499)] 
2025-07-11 21:49:27.365617: Epoch time: 68.7 s 
2025-07-11 21:49:28.272010:  
2025-07-11 21:49:28.273937: Epoch 272 
2025-07-11 21:49:28.275273: Current learning rate: 0.00751 
2025-07-11 21:50:36.741006: train_loss -0.9692 
2025-07-11 21:50:36.742846: val_loss -0.9506 
2025-07-11 21:50:36.744349: Pseudo dice [np.float32(0.9544)] 
2025-07-11 21:50:36.745371: Epoch time: 68.47 s 
2025-07-11 21:50:37.660023:  
2025-07-11 21:50:37.662425: Epoch 273 
2025-07-11 21:50:37.664159: Current learning rate: 0.00751 
2025-07-11 21:51:46.185380: train_loss -0.9693 
2025-07-11 21:51:46.186746: val_loss -0.9501 
2025-07-11 21:51:46.187977: Pseudo dice [np.float32(0.9541)] 
2025-07-11 21:51:46.189777: Epoch time: 68.53 s 
2025-07-11 21:51:47.112103:  
2025-07-11 21:51:47.114629: Epoch 274 
2025-07-11 21:51:47.115922: Current learning rate: 0.0075 
2025-07-11 21:52:55.724455: train_loss -0.9699 
2025-07-11 21:52:55.725620: val_loss -0.95 
2025-07-11 21:52:55.727533: Pseudo dice [np.float32(0.9539)] 
2025-07-11 21:52:55.728741: Epoch time: 68.62 s 
2025-07-11 21:52:55.730061: Yayy! New best EMA pseudo Dice: 0.9526000022888184 
2025-07-11 21:52:58.025276:  
2025-07-11 21:52:58.027768: Epoch 275 
2025-07-11 21:52:58.028862: Current learning rate: 0.00749 
2025-07-11 21:54:06.973554: train_loss -0.9687 
2025-07-11 21:54:06.975264: val_loss -0.9475 
2025-07-11 21:54:06.976696: Pseudo dice [np.float32(0.952)] 
2025-07-11 21:54:06.977944: Epoch time: 68.95 s 
2025-07-11 21:54:07.901345:  
2025-07-11 21:54:07.903683: Epoch 276 
2025-07-11 21:54:07.905100: Current learning rate: 0.00748 
2025-07-11 21:55:16.747658: train_loss -0.968 
2025-07-11 21:55:16.749150: val_loss -0.9503 
2025-07-11 21:55:16.750211: Pseudo dice [np.float32(0.9548)] 
2025-07-11 21:55:16.751260: Epoch time: 68.85 s 
2025-07-11 21:55:16.752234: Yayy! New best EMA pseudo Dice: 0.9527999758720398 
2025-07-11 21:55:18.984928:  
2025-07-11 21:55:18.987533: Epoch 277 
2025-07-11 21:55:18.989171: Current learning rate: 0.00747 
2025-07-11 21:56:27.828830: train_loss -0.9709 
2025-07-11 21:56:27.831281: val_loss -0.9494 
2025-07-11 21:56:27.832837: Pseudo dice [np.float32(0.9527)] 
2025-07-11 21:56:27.834104: Epoch time: 68.85 s 
2025-07-11 21:56:28.750722:  
2025-07-11 21:56:28.752577: Epoch 278 
2025-07-11 21:56:28.753833: Current learning rate: 0.00746 
2025-07-11 21:57:37.776152: train_loss -0.9702 
2025-07-11 21:57:37.777493: val_loss -0.9484 
2025-07-11 21:57:37.779401: Pseudo dice [np.float32(0.9522)] 
2025-07-11 21:57:37.780584: Epoch time: 69.03 s 
2025-07-11 21:57:38.697725:  
2025-07-11 21:57:38.700104: Epoch 279 
2025-07-11 21:57:38.701348: Current learning rate: 0.00745 
2025-07-11 21:58:48.599791: train_loss -0.9706 
2025-07-11 21:58:48.601414: val_loss -0.947 
2025-07-11 21:58:48.602306: Pseudo dice [np.float32(0.9498)] 
2025-07-11 21:58:48.603555: Epoch time: 69.91 s 
2025-07-11 21:58:49.547900:  
2025-07-11 21:58:49.550561: Epoch 280 
2025-07-11 21:58:49.552394: Current learning rate: 0.00744 
2025-07-11 21:59:58.669503: train_loss -0.9707 
2025-07-11 21:59:58.671225: val_loss -0.9463 
2025-07-11 21:59:58.672561: Pseudo dice [np.float32(0.951)] 
2025-07-11 21:59:58.673954: Epoch time: 69.13 s 
2025-07-11 21:59:59.609795:  
2025-07-11 21:59:59.611627: Epoch 281 
2025-07-11 21:59:59.612609: Current learning rate: 0.00743 
2025-07-11 22:01:08.355397: train_loss -0.9712 
2025-07-11 22:01:08.356865: val_loss -0.9489 
2025-07-11 22:01:08.357851: Pseudo dice [np.float32(0.9528)] 
2025-07-11 22:01:08.358981: Epoch time: 68.75 s 
2025-07-11 22:01:09.250374:  
2025-07-11 22:01:09.252700: Epoch 282 
2025-07-11 22:01:09.253891: Current learning rate: 0.00742 
2025-07-11 22:02:18.197184: train_loss -0.9714 
2025-07-11 22:02:18.198810: val_loss -0.947 
2025-07-11 22:02:18.200450: Pseudo dice [np.float32(0.9502)] 
2025-07-11 22:02:18.201639: Epoch time: 68.95 s 
2025-07-11 22:02:19.112813:  
2025-07-11 22:02:19.115137: Epoch 283 
2025-07-11 22:02:19.116697: Current learning rate: 0.00741 
2025-07-11 22:03:27.871867: train_loss -0.971 
2025-07-11 22:03:27.873419: val_loss -0.9499 
2025-07-11 22:03:27.874754: Pseudo dice [np.float32(0.9538)] 
2025-07-11 22:03:27.875786: Epoch time: 68.76 s 
2025-07-11 22:03:28.784103:  
2025-07-11 22:03:28.786307: Epoch 284 
2025-07-11 22:03:28.787467: Current learning rate: 0.0074 
2025-07-11 22:04:37.407438: train_loss -0.9703 
2025-07-11 22:04:37.409303: val_loss -0.951 
2025-07-11 22:04:37.410659: Pseudo dice [np.float32(0.9551)] 
2025-07-11 22:04:37.411992: Epoch time: 68.63 s 
2025-07-11 22:04:38.344604:  
2025-07-11 22:04:38.347100: Epoch 285 
2025-07-11 22:04:38.348358: Current learning rate: 0.00739 
2025-07-11 22:05:46.886701: train_loss -0.9721 
2025-07-11 22:05:46.888235: val_loss -0.9514 
2025-07-11 22:05:46.889263: Pseudo dice [np.float32(0.9559)] 
2025-07-11 22:05:46.890483: Epoch time: 68.55 s 
2025-07-11 22:05:46.891933: Yayy! New best EMA pseudo Dice: 0.9528999924659729 
2025-07-11 22:05:49.238234:  
2025-07-11 22:05:49.240146: Epoch 286 
2025-07-11 22:05:49.241202: Current learning rate: 0.00738 
2025-07-11 22:06:57.768620: train_loss -0.9713 
2025-07-11 22:06:57.770112: val_loss -0.9485 
2025-07-11 22:06:57.771154: Pseudo dice [np.float32(0.9521)] 
2025-07-11 22:06:57.772272: Epoch time: 68.53 s 
2025-07-11 22:06:58.699537:  
2025-07-11 22:06:58.701876: Epoch 287 
2025-07-11 22:06:58.703156: Current learning rate: 0.00738 
2025-07-11 22:08:07.638467: train_loss -0.9718 
2025-07-11 22:08:07.639740: val_loss -0.9497 
2025-07-11 22:08:07.641187: Pseudo dice [np.float32(0.9534)] 
2025-07-11 22:08:07.642897: Epoch time: 68.94 s 
2025-07-11 22:08:08.584207:  
2025-07-11 22:08:08.586554: Epoch 288 
2025-07-11 22:08:08.587904: Current learning rate: 0.00737 
2025-07-11 22:09:18.250353: train_loss -0.9705 
2025-07-11 22:09:18.252613: val_loss -0.9436 
2025-07-11 22:09:18.254595: Pseudo dice [np.float32(0.9479)] 
2025-07-11 22:09:18.255677: Epoch time: 69.67 s 
2025-07-11 22:09:19.187271:  
2025-07-11 22:09:19.189539: Epoch 289 
2025-07-11 22:09:19.190764: Current learning rate: 0.00736 
2025-07-11 22:10:27.803962: train_loss -0.9687 
2025-07-11 22:10:27.805538: val_loss -0.9507 
2025-07-11 22:10:27.806631: Pseudo dice [np.float32(0.9552)] 
2025-07-11 22:10:27.807641: Epoch time: 68.62 s 
2025-07-11 22:10:28.745578:  
2025-07-11 22:10:28.748391: Epoch 290 
2025-07-11 22:10:28.749870: Current learning rate: 0.00735 
2025-07-11 22:11:37.436723: train_loss -0.9692 
2025-07-11 22:11:37.438632: val_loss -0.9457 
2025-07-11 22:11:37.440195: Pseudo dice [np.float32(0.9505)] 
2025-07-11 22:11:37.441873: Epoch time: 68.69 s 
2025-07-11 22:11:38.403855:  
2025-07-11 22:11:38.405988: Epoch 291 
2025-07-11 22:11:38.407357: Current learning rate: 0.00734 
2025-07-11 22:12:47.184379: train_loss -0.9705 
2025-07-11 22:12:47.185642: val_loss -0.95 
2025-07-11 22:12:47.187128: Pseudo dice [np.float32(0.954)] 
2025-07-11 22:12:47.188356: Epoch time: 68.78 s 
2025-07-11 22:12:48.105202:  
2025-07-11 22:12:48.107789: Epoch 292 
2025-07-11 22:12:48.109064: Current learning rate: 0.00733 
2025-07-11 22:13:56.797671: train_loss -0.9722 
2025-07-11 22:13:56.798953: val_loss -0.9502 
2025-07-11 22:13:56.800462: Pseudo dice [np.float32(0.9548)] 
2025-07-11 22:13:56.802052: Epoch time: 68.7 s 
2025-07-11 22:13:57.730026:  
2025-07-11 22:13:57.732479: Epoch 293 
2025-07-11 22:13:57.734254: Current learning rate: 0.00732 
2025-07-11 22:15:06.345993: train_loss -0.9721 
2025-07-11 22:15:06.347220: val_loss -0.9503 
2025-07-11 22:15:06.348745: Pseudo dice [np.float32(0.9535)] 
2025-07-11 22:15:06.350772: Epoch time: 68.62 s 
2025-07-11 22:15:07.271688:  
2025-07-11 22:15:07.273831: Epoch 294 
2025-07-11 22:15:07.275223: Current learning rate: 0.00731 
2025-07-11 22:16:15.938893: train_loss -0.972 
2025-07-11 22:16:15.940358: val_loss -0.9482 
2025-07-11 22:16:15.941497: Pseudo dice [np.float32(0.9527)] 
2025-07-11 22:16:15.942762: Epoch time: 68.67 s 
2025-07-11 22:16:16.866430:  
2025-07-11 22:16:16.869101: Epoch 295 
2025-07-11 22:16:16.870840: Current learning rate: 0.0073 
2025-07-11 22:17:25.626741: train_loss -0.9707 
2025-07-11 22:17:25.628083: val_loss -0.9522 
2025-07-11 22:17:25.629132: Pseudo dice [np.float32(0.9575)] 
2025-07-11 22:17:25.630304: Epoch time: 68.76 s 
2025-07-11 22:17:25.631862: Yayy! New best EMA pseudo Dice: 0.9532999992370605 
2025-07-11 22:17:28.112646:  
2025-07-11 22:17:28.114702: Epoch 296 
2025-07-11 22:17:28.116094: Current learning rate: 0.00729 
2025-07-11 22:18:36.803915: train_loss -0.9709 
2025-07-11 22:18:36.805311: val_loss -0.948 
2025-07-11 22:18:36.806553: Pseudo dice [np.float32(0.9515)] 
2025-07-11 22:18:36.807491: Epoch time: 68.69 s 
2025-07-11 22:18:37.781187:  
2025-07-11 22:18:37.783599: Epoch 297 
2025-07-11 22:18:37.785270: Current learning rate: 0.00728 
2025-07-11 22:19:47.255066: train_loss -0.9719 
2025-07-11 22:19:47.256298: val_loss -0.9464 
2025-07-11 22:19:47.257509: Pseudo dice [np.float32(0.9515)] 
2025-07-11 22:19:47.258845: Epoch time: 69.48 s 
2025-07-11 22:19:48.216536:  
2025-07-11 22:19:48.218454: Epoch 298 
2025-07-11 22:19:48.219570: Current learning rate: 0.00727 
2025-07-11 22:20:56.855857: train_loss -0.9679 
2025-07-11 22:20:56.857578: val_loss -0.9446 
2025-07-11 22:20:56.858977: Pseudo dice [np.float32(0.9489)] 
2025-07-11 22:20:56.860056: Epoch time: 68.64 s 
2025-07-11 22:20:57.801032:  
2025-07-11 22:20:57.803559: Epoch 299 
2025-07-11 22:20:57.805452: Current learning rate: 0.00726 
2025-07-11 22:22:06.516015: train_loss -0.9662 
2025-07-11 22:22:06.517508: val_loss -0.9491 
2025-07-11 22:22:06.518687: Pseudo dice [np.float32(0.9543)] 
2025-07-11 22:22:06.520169: Epoch time: 68.72 s 
2025-07-11 22:22:08.740865:  
2025-07-11 22:22:08.742576: Epoch 300 
2025-07-11 22:22:08.743633: Current learning rate: 0.00725 
2025-07-11 22:23:17.473282: train_loss -0.9701 
2025-07-11 22:23:17.474594: val_loss -0.9501 
2025-07-11 22:23:17.475941: Pseudo dice [np.float32(0.9538)] 
2025-07-11 22:23:17.477415: Epoch time: 68.74 s 
2025-07-11 22:23:18.425977:  
2025-07-11 22:23:18.428368: Epoch 301 
2025-07-11 22:23:18.429592: Current learning rate: 0.00724 
2025-07-11 22:24:27.186296: train_loss -0.9705 
2025-07-11 22:24:27.187653: val_loss -0.9491 
2025-07-11 22:24:27.188771: Pseudo dice [np.float32(0.9533)] 
2025-07-11 22:24:27.189839: Epoch time: 68.76 s 
2025-07-11 22:24:28.118228:  
2025-07-11 22:24:28.120435: Epoch 302 
2025-07-11 22:24:28.121581: Current learning rate: 0.00724 
2025-07-11 22:25:37.027712: train_loss -0.9715 
2025-07-11 22:25:37.029035: val_loss -0.9481 
2025-07-11 22:25:37.030228: Pseudo dice [np.float32(0.9514)] 
2025-07-11 22:25:37.031230: Epoch time: 68.91 s 
2025-07-11 22:25:37.975075:  
2025-07-11 22:25:37.977013: Epoch 303 
2025-07-11 22:25:37.978935: Current learning rate: 0.00723 
2025-07-11 22:26:46.813530: train_loss -0.9707 
2025-07-11 22:26:46.815150: val_loss -0.9466 
2025-07-11 22:26:46.816306: Pseudo dice [np.float32(0.9505)] 
2025-07-11 22:26:46.818187: Epoch time: 68.84 s 
2025-07-11 22:26:47.752856:  
2025-07-11 22:26:47.754841: Epoch 304 
2025-07-11 22:26:47.756065: Current learning rate: 0.00722 
2025-07-11 22:27:56.462358: train_loss -0.97 
2025-07-11 22:27:56.463822: val_loss -0.9478 
2025-07-11 22:27:56.465252: Pseudo dice [np.float32(0.952)] 
2025-07-11 22:27:56.467422: Epoch time: 68.71 s 
2025-07-11 22:27:57.404520:  
2025-07-11 22:27:57.407363: Epoch 305 
2025-07-11 22:27:57.408857: Current learning rate: 0.00721 
2025-07-11 22:29:06.126359: train_loss -0.971 
2025-07-11 22:29:06.127556: val_loss -0.951 
2025-07-11 22:29:06.129064: Pseudo dice [np.float32(0.9549)] 
2025-07-11 22:29:06.130728: Epoch time: 68.73 s 
2025-07-11 22:29:07.830631:  
2025-07-11 22:29:07.832844: Epoch 306 
2025-07-11 22:29:07.834000: Current learning rate: 0.0072 
2025-07-11 22:30:16.390707: train_loss -0.9707 
2025-07-11 22:30:16.391980: val_loss -0.9508 
2025-07-11 22:30:16.392796: Pseudo dice [np.float32(0.9547)] 
2025-07-11 22:30:16.394066: Epoch time: 68.56 s 
2025-07-11 22:30:17.340144:  
2025-07-11 22:30:17.342179: Epoch 307 
2025-07-11 22:30:17.343256: Current learning rate: 0.00719 
2025-07-11 22:31:25.923917: train_loss -0.9712 
2025-07-11 22:31:25.925054: val_loss -0.9502 
2025-07-11 22:31:25.926194: Pseudo dice [np.float32(0.9547)] 
2025-07-11 22:31:25.927371: Epoch time: 68.59 s 
2025-07-11 22:31:26.860568:  
2025-07-11 22:31:26.862598: Epoch 308 
2025-07-11 22:31:26.863708: Current learning rate: 0.00718 
2025-07-11 22:32:35.610840: train_loss -0.9713 
2025-07-11 22:32:35.612387: val_loss -0.9443 
2025-07-11 22:32:35.613725: Pseudo dice [np.float32(0.9482)] 
2025-07-11 22:32:35.615097: Epoch time: 68.75 s 
2025-07-11 22:32:36.564286:  
2025-07-11 22:32:36.566349: Epoch 309 
2025-07-11 22:32:36.568334: Current learning rate: 0.00717 
2025-07-11 22:33:45.507462: train_loss -0.9711 
2025-07-11 22:33:45.509106: val_loss -0.9488 
2025-07-11 22:33:45.511173: Pseudo dice [np.float32(0.9532)] 
2025-07-11 22:33:45.512540: Epoch time: 68.95 s 
2025-07-11 22:33:46.418484:  
2025-07-11 22:33:46.420914: Epoch 310 
2025-07-11 22:33:46.422465: Current learning rate: 0.00716 
2025-07-11 22:34:55.304113: train_loss -0.9692 
2025-07-11 22:34:55.305345: val_loss -0.9434 
2025-07-11 22:34:55.306334: Pseudo dice [np.float32(0.9486)] 
2025-07-11 22:34:55.307576: Epoch time: 68.89 s 
2025-07-11 22:34:56.241725:  
2025-07-11 22:34:56.244413: Epoch 311 
2025-07-11 22:34:56.245809: Current learning rate: 0.00715 
2025-07-11 22:36:04.858972: train_loss -0.97 
2025-07-11 22:36:04.860543: val_loss -0.9484 
2025-07-11 22:36:04.862221: Pseudo dice [np.float32(0.9523)] 
2025-07-11 22:36:04.863597: Epoch time: 68.62 s 
2025-07-11 22:36:05.802315:  
2025-07-11 22:36:05.804920: Epoch 312 
2025-07-11 22:36:05.806213: Current learning rate: 0.00714 
2025-07-11 22:37:14.594237: train_loss -0.9708 
2025-07-11 22:37:14.595676: val_loss -0.9498 
2025-07-11 22:37:14.596950: Pseudo dice [np.float32(0.9534)] 
2025-07-11 22:37:14.598085: Epoch time: 68.8 s 
2025-07-11 22:37:15.530227:  
2025-07-11 22:37:15.532627: Epoch 313 
2025-07-11 22:37:15.533768: Current learning rate: 0.00713 
2025-07-11 22:38:24.719570: train_loss -0.9699 
2025-07-11 22:38:24.720901: val_loss -0.9459 
2025-07-11 22:38:24.721864: Pseudo dice [np.float32(0.9502)] 
2025-07-11 22:38:24.722815: Epoch time: 69.19 s 
2025-07-11 22:38:25.678349:  
2025-07-11 22:38:25.680339: Epoch 314 
2025-07-11 22:38:25.681816: Current learning rate: 0.00712 
2025-07-11 22:39:34.614118: train_loss -0.9715 
2025-07-11 22:39:34.615427: val_loss -0.9487 
2025-07-11 22:39:34.616753: Pseudo dice [np.float32(0.9534)] 
2025-07-11 22:39:34.618194: Epoch time: 68.94 s 
2025-07-11 22:39:36.432255:  
2025-07-11 22:39:36.434173: Epoch 315 
2025-07-11 22:39:36.435553: Current learning rate: 0.00711 
2025-07-11 22:40:45.028626: train_loss -0.9693 
2025-07-11 22:40:45.030056: val_loss -0.9483 
2025-07-11 22:40:45.031337: Pseudo dice [np.float32(0.9529)] 
2025-07-11 22:40:45.032434: Epoch time: 68.6 s 
2025-07-11 22:40:45.973557:  
2025-07-11 22:40:45.976085: Epoch 316 
2025-07-11 22:40:45.977381: Current learning rate: 0.0071 
2025-07-11 22:41:54.755713: train_loss -0.97 
2025-07-11 22:41:54.757195: val_loss -0.9485 
2025-07-11 22:41:54.758430: Pseudo dice [np.float32(0.9522)] 
2025-07-11 22:41:54.759486: Epoch time: 68.79 s 
2025-07-11 22:41:55.700262:  
2025-07-11 22:41:55.702347: Epoch 317 
2025-07-11 22:41:55.703420: Current learning rate: 0.0071 
2025-07-11 22:43:04.583310: train_loss -0.9699 
2025-07-11 22:43:04.584574: val_loss -0.9425 
2025-07-11 22:43:04.585675: Pseudo dice [np.float32(0.9467)] 
2025-07-11 22:43:04.586889: Epoch time: 68.89 s 
2025-07-11 22:43:05.527397:  
2025-07-11 22:43:05.529465: Epoch 318 
2025-07-11 22:43:05.530432: Current learning rate: 0.00709 
2025-07-11 22:44:14.369813: train_loss -0.9701 
2025-07-11 22:44:14.371421: val_loss -0.9519 
2025-07-11 22:44:14.372380: Pseudo dice [np.float32(0.9558)] 
2025-07-11 22:44:14.373462: Epoch time: 68.85 s 
2025-07-11 22:44:15.323617:  
2025-07-11 22:44:15.326125: Epoch 319 
2025-07-11 22:44:15.327286: Current learning rate: 0.00708 
2025-07-11 22:45:24.033769: train_loss -0.9702 
2025-07-11 22:45:24.035130: val_loss -0.9468 
2025-07-11 22:45:24.036407: Pseudo dice [np.float32(0.9497)] 
2025-07-11 22:45:24.037535: Epoch time: 68.71 s 
2025-07-11 22:45:24.985010:  
2025-07-11 22:45:24.987448: Epoch 320 
2025-07-11 22:45:24.988725: Current learning rate: 0.00707 
2025-07-11 22:46:33.780971: train_loss -0.9707 
2025-07-11 22:46:33.782717: val_loss -0.9513 
2025-07-11 22:46:33.784430: Pseudo dice [np.float32(0.956)] 
2025-07-11 22:46:33.785542: Epoch time: 68.8 s 
2025-07-11 22:46:34.685377:  
2025-07-11 22:46:34.687552: Epoch 321 
2025-07-11 22:46:34.688575: Current learning rate: 0.00706 
2025-07-11 22:47:43.426821: train_loss -0.9716 
2025-07-11 22:47:43.428409: val_loss -0.9484 
2025-07-11 22:47:43.430236: Pseudo dice [np.float32(0.9523)] 
2025-07-11 22:47:43.431367: Epoch time: 68.75 s 
2025-07-11 22:47:44.371723:  
2025-07-11 22:47:44.374090: Epoch 322 
2025-07-11 22:47:44.375140: Current learning rate: 0.00705 
2025-07-11 22:48:52.912105: train_loss -0.972 
2025-07-11 22:48:52.913422: val_loss -0.9499 
2025-07-11 22:48:52.914528: Pseudo dice [np.float32(0.9539)] 
2025-07-11 22:48:52.915524: Epoch time: 68.54 s 
2025-07-11 22:48:53.880346:  
2025-07-11 22:48:53.882938: Epoch 323 
2025-07-11 22:48:53.884437: Current learning rate: 0.00704 
2025-07-11 22:50:03.275529: train_loss -0.9717 
2025-07-11 22:50:03.276685: val_loss -0.9522 
2025-07-11 22:50:03.278169: Pseudo dice [np.float32(0.9565)] 
2025-07-11 22:50:03.279591: Epoch time: 69.4 s 
2025-07-11 22:50:04.220355:  
2025-07-11 22:50:04.222856: Epoch 324 
2025-07-11 22:50:04.224181: Current learning rate: 0.00703 
2025-07-11 22:51:13.361288: train_loss -0.9724 
2025-07-11 22:51:13.362573: val_loss -0.9366 
2025-07-11 22:51:13.364528: Pseudo dice [np.float32(0.942)] 
2025-07-11 22:51:13.366023: Epoch time: 69.14 s 
2025-07-11 22:51:14.335999:  
2025-07-11 22:51:14.338035: Epoch 325 
2025-07-11 22:51:14.339276: Current learning rate: 0.00702 
2025-07-11 22:52:23.302301: train_loss -0.9714 
2025-07-11 22:52:23.304216: val_loss -0.9485 
2025-07-11 22:52:23.306131: Pseudo dice [np.float32(0.9527)] 
2025-07-11 22:52:23.307484: Epoch time: 68.97 s 
2025-07-11 22:52:24.270339:  
2025-07-11 22:52:24.272687: Epoch 326 
2025-07-11 22:52:24.273832: Current learning rate: 0.00701 
2025-07-11 22:53:33.200251: train_loss -0.9711 
2025-07-11 22:53:33.202187: val_loss -0.9473 
2025-07-11 22:53:33.203882: Pseudo dice [np.float32(0.9518)] 
2025-07-11 22:53:33.204877: Epoch time: 68.93 s 
2025-07-11 22:53:34.166215:  
2025-07-11 22:53:34.168153: Epoch 327 
2025-07-11 22:53:34.169510: Current learning rate: 0.007 
2025-07-11 22:54:43.104646: train_loss -0.9711 
2025-07-11 22:54:43.106151: val_loss -0.9472 
2025-07-11 22:54:43.107282: Pseudo dice [np.float32(0.9515)] 
2025-07-11 22:54:43.108637: Epoch time: 68.94 s 
2025-07-11 22:54:44.067642:  
2025-07-11 22:54:44.070400: Epoch 328 
2025-07-11 22:54:44.071635: Current learning rate: 0.00699 
2025-07-11 22:55:52.816221: train_loss -0.9722 
2025-07-11 22:55:52.817791: val_loss -0.9452 
2025-07-11 22:55:52.819170: Pseudo dice [np.float32(0.9503)] 
2025-07-11 22:55:52.820324: Epoch time: 68.75 s 
2025-07-11 22:55:53.760560:  
2025-07-11 22:55:53.763106: Epoch 329 
2025-07-11 22:55:53.764394: Current learning rate: 0.00698 
2025-07-11 22:57:02.355259: train_loss -0.9719 
2025-07-11 22:57:02.356895: val_loss -0.9474 
2025-07-11 22:57:02.358842: Pseudo dice [np.float32(0.9518)] 
2025-07-11 22:57:02.360704: Epoch time: 68.6 s 
2025-07-11 22:57:03.297113:  
2025-07-11 22:57:03.299314: Epoch 330 
2025-07-11 22:57:03.300419: Current learning rate: 0.00697 
2025-07-11 22:58:12.066026: train_loss -0.9717 
2025-07-11 22:58:12.067506: val_loss -0.9457 
2025-07-11 22:58:12.068986: Pseudo dice [np.float32(0.9495)] 
2025-07-11 22:58:12.070345: Epoch time: 68.77 s 
2025-07-11 22:58:13.000506:  
2025-07-11 22:58:13.003063: Epoch 331 
2025-07-11 22:58:13.004315: Current learning rate: 0.00696 
2025-07-11 22:59:21.792083: train_loss -0.9714 
2025-07-11 22:59:21.793487: val_loss -0.9459 
2025-07-11 22:59:21.794654: Pseudo dice [np.float32(0.9497)] 
2025-07-11 22:59:21.796105: Epoch time: 68.8 s 
2025-07-11 22:59:22.729115:  
2025-07-11 22:59:22.731798: Epoch 332 
2025-07-11 22:59:22.732935: Current learning rate: 0.00696 
2025-07-11 23:00:32.579237: train_loss -0.9722 
2025-07-11 23:00:32.580596: val_loss -0.9474 
2025-07-11 23:00:32.581972: Pseudo dice [np.float32(0.9511)] 
2025-07-11 23:00:32.584387: Epoch time: 69.85 s 
2025-07-11 23:00:33.505777:  
2025-07-11 23:00:33.507896: Epoch 333 
2025-07-11 23:00:33.509073: Current learning rate: 0.00695 
2025-07-11 23:01:42.208461: train_loss -0.9728 
2025-07-11 23:01:42.211006: val_loss -0.9521 
2025-07-11 23:01:42.212589: Pseudo dice [np.float32(0.9558)] 
2025-07-11 23:01:42.214378: Epoch time: 68.71 s 
2025-07-11 23:01:43.142847:  
2025-07-11 23:01:43.145308: Epoch 334 
2025-07-11 23:01:43.146970: Current learning rate: 0.00694 
2025-07-11 23:02:51.925055: train_loss -0.9731 
2025-07-11 23:02:51.926433: val_loss -0.9468 
2025-07-11 23:02:51.928207: Pseudo dice [np.float32(0.9513)] 
2025-07-11 23:02:51.929563: Epoch time: 68.79 s 
2025-07-11 23:02:52.873176:  
2025-07-11 23:02:52.875853: Epoch 335 
2025-07-11 23:02:52.876958: Current learning rate: 0.00693 
2025-07-11 23:04:01.887375: train_loss -0.9713 
2025-07-11 23:04:01.888833: val_loss -0.9469 
2025-07-11 23:04:01.890612: Pseudo dice [np.float32(0.9517)] 
2025-07-11 23:04:01.892041: Epoch time: 69.02 s 
2025-07-11 23:04:02.835487:  
2025-07-11 23:04:02.838338: Epoch 336 
2025-07-11 23:04:02.839581: Current learning rate: 0.00692 
2025-07-11 23:05:11.865362: train_loss -0.9693 
2025-07-11 23:05:11.866593: val_loss -0.9474 
2025-07-11 23:05:11.867797: Pseudo dice [np.float32(0.9513)] 
2025-07-11 23:05:11.869491: Epoch time: 69.03 s 
2025-07-11 23:05:12.834608:  
2025-07-11 23:05:12.836842: Epoch 337 
2025-07-11 23:05:12.838336: Current learning rate: 0.00691 
2025-07-11 23:06:22.006707: train_loss -0.971 
2025-07-11 23:06:22.007869: val_loss -0.9448 
2025-07-11 23:06:22.008721: Pseudo dice [np.float32(0.9499)] 
2025-07-11 23:06:22.010037: Epoch time: 69.18 s 
2025-07-11 23:06:22.928634:  
2025-07-11 23:06:22.931128: Epoch 338 
2025-07-11 23:06:22.932505: Current learning rate: 0.0069 
2025-07-11 23:07:31.791327: train_loss -0.9716 
2025-07-11 23:07:31.792586: val_loss -0.9513 
2025-07-11 23:07:31.793887: Pseudo dice [np.float32(0.9559)] 
2025-07-11 23:07:31.795243: Epoch time: 68.87 s 
2025-07-11 23:07:32.727021:  
2025-07-11 23:07:32.729123: Epoch 339 
2025-07-11 23:07:32.730407: Current learning rate: 0.00689 
2025-07-11 23:08:41.489439: train_loss -0.9716 
2025-07-11 23:08:41.490777: val_loss -0.9473 
2025-07-11 23:08:41.492803: Pseudo dice [np.float32(0.9504)] 
2025-07-11 23:08:41.494391: Epoch time: 68.77 s 
2025-07-11 23:08:42.458674:  
2025-07-11 23:08:42.460959: Epoch 340 
2025-07-11 23:08:42.462077: Current learning rate: 0.00688 
2025-07-11 23:09:51.202310: train_loss -0.9722 
2025-07-11 23:09:51.203737: val_loss -0.9454 
2025-07-11 23:09:51.204996: Pseudo dice [np.float32(0.95)] 
2025-07-11 23:09:51.206075: Epoch time: 68.75 s 
2025-07-11 23:09:52.166707:  
2025-07-11 23:09:52.169700: Epoch 341 
2025-07-11 23:09:52.171298: Current learning rate: 0.00687 
2025-07-11 23:11:02.246518: train_loss -0.9726 
2025-07-11 23:11:02.247735: val_loss -0.9522 
2025-07-11 23:11:02.249045: Pseudo dice [np.float32(0.9559)] 
2025-07-11 23:11:02.250175: Epoch time: 70.08 s 
2025-07-11 23:11:03.204142:  
2025-07-11 23:11:03.206224: Epoch 342 
2025-07-11 23:11:03.207455: Current learning rate: 0.00686 
2025-07-11 23:12:12.239740: train_loss -0.9729 
2025-07-11 23:12:12.241410: val_loss -0.9498 
2025-07-11 23:12:12.242565: Pseudo dice [np.float32(0.9546)] 
2025-07-11 23:12:12.243766: Epoch time: 69.04 s 
2025-07-11 23:12:13.202485:  
2025-07-11 23:12:13.204774: Epoch 343 
2025-07-11 23:12:13.206467: Current learning rate: 0.00685 
2025-07-11 23:13:22.260751: train_loss -0.9724 
2025-07-11 23:13:22.262201: val_loss -0.9505 
2025-07-11 23:13:22.263343: Pseudo dice [np.float32(0.9538)] 
2025-07-11 23:13:22.264316: Epoch time: 69.06 s 
2025-07-11 23:13:23.220390:  
2025-07-11 23:13:23.222747: Epoch 344 
2025-07-11 23:13:23.223837: Current learning rate: 0.00684 
2025-07-11 23:14:32.201250: train_loss -0.9715 
2025-07-11 23:14:32.203138: val_loss -0.9467 
2025-07-11 23:14:32.204262: Pseudo dice [np.float32(0.9494)] 
2025-07-11 23:14:32.205572: Epoch time: 68.98 s 
2025-07-11 23:14:33.124280:  
2025-07-11 23:14:33.126715: Epoch 345 
2025-07-11 23:14:33.127703: Current learning rate: 0.00683 
2025-07-11 23:15:42.038010: train_loss -0.9731 
2025-07-11 23:15:42.039322: val_loss -0.9482 
2025-07-11 23:15:42.040340: Pseudo dice [np.float32(0.9516)] 
2025-07-11 23:15:42.041787: Epoch time: 68.92 s 
2025-07-11 23:15:43.007493:  
2025-07-11 23:15:43.010001: Epoch 346 
2025-07-11 23:15:43.011240: Current learning rate: 0.00682 
2025-07-11 23:16:51.962670: train_loss -0.9713 
2025-07-11 23:16:51.964028: val_loss -0.9486 
2025-07-11 23:16:51.965288: Pseudo dice [np.float32(0.9537)] 
2025-07-11 23:16:51.966264: Epoch time: 68.96 s 
2025-07-11 23:16:52.905782:  
2025-07-11 23:16:52.908331: Epoch 347 
2025-07-11 23:16:52.909829: Current learning rate: 0.00681 
2025-07-11 23:18:01.671818: train_loss -0.9731 
2025-07-11 23:18:01.673519: val_loss -0.9529 
2025-07-11 23:18:01.674596: Pseudo dice [np.float32(0.9567)] 
2025-07-11 23:18:01.675745: Epoch time: 68.77 s 
2025-07-11 23:18:02.650292:  
2025-07-11 23:18:02.652497: Epoch 348 
2025-07-11 23:18:02.653725: Current learning rate: 0.0068 
2025-07-11 23:19:11.532683: train_loss -0.9722 
2025-07-11 23:19:11.534173: val_loss -0.9515 
2025-07-11 23:19:11.535383: Pseudo dice [np.float32(0.9556)] 
2025-07-11 23:19:11.536773: Epoch time: 68.89 s 
2025-07-11 23:19:12.442256:  
2025-07-11 23:19:12.444557: Epoch 349 
2025-07-11 23:19:12.445775: Current learning rate: 0.0068 
2025-07-11 23:20:21.441840: train_loss -0.9718 
2025-07-11 23:20:21.443254: val_loss -0.9515 
2025-07-11 23:20:21.444534: Pseudo dice [np.float32(0.9558)] 
2025-07-11 23:20:21.446083: Epoch time: 69.0 s 
2025-07-11 23:20:23.503226:  
2025-07-11 23:20:23.505647: Epoch 350 
2025-07-11 23:20:23.507053: Current learning rate: 0.00679 
2025-07-11 23:21:32.944831: train_loss -0.9719 
2025-07-11 23:21:32.946807: val_loss -0.9485 
2025-07-11 23:21:32.948530: Pseudo dice [np.float32(0.9532)] 
2025-07-11 23:21:32.949493: Epoch time: 69.45 s 
2025-07-11 23:21:33.925122:  
2025-07-11 23:21:33.927011: Epoch 351 
2025-07-11 23:21:33.928084: Current learning rate: 0.00678 
2025-07-11 23:22:42.444807: train_loss -0.9693 
2025-07-11 23:22:42.446457: val_loss -0.946 
2025-07-11 23:22:42.447514: Pseudo dice [np.float32(0.9508)] 
2025-07-11 23:22:42.448551: Epoch time: 68.52 s 
2025-07-11 23:22:43.415856:  
2025-07-11 23:22:43.418471: Epoch 352 
2025-07-11 23:22:43.420196: Current learning rate: 0.00677 
2025-07-11 23:23:52.129894: train_loss -0.9721 
2025-07-11 23:23:52.131474: val_loss -0.9403 
2025-07-11 23:23:52.132448: Pseudo dice [np.float32(0.944)] 
2025-07-11 23:23:52.133776: Epoch time: 68.72 s 
2025-07-11 23:23:53.065837:  
2025-07-11 23:23:53.067848: Epoch 353 
2025-07-11 23:23:53.068961: Current learning rate: 0.00676 
2025-07-11 23:25:01.878755: train_loss -0.9721 
2025-07-11 23:25:01.880175: val_loss -0.9483 
2025-07-11 23:25:01.881665: Pseudo dice [np.float32(0.9533)] 
2025-07-11 23:25:01.883791: Epoch time: 68.82 s 
2025-07-11 23:25:02.826138:  
2025-07-11 23:25:02.828585: Epoch 354 
2025-07-11 23:25:02.829668: Current learning rate: 0.00675 
2025-07-11 23:26:11.842810: train_loss -0.9707 
2025-07-11 23:26:11.844656: val_loss -0.9468 
2025-07-11 23:26:11.846682: Pseudo dice [np.float32(0.9525)] 
2025-07-11 23:26:11.848151: Epoch time: 69.02 s 
2025-07-11 23:26:12.786400:  
2025-07-11 23:26:12.790075: Epoch 355 
2025-07-11 23:26:12.791257: Current learning rate: 0.00674 
2025-07-11 23:27:21.804640: train_loss -0.9691 
2025-07-11 23:27:21.806916: val_loss -0.9482 
2025-07-11 23:27:21.808160: Pseudo dice [np.float32(0.9523)] 
2025-07-11 23:27:21.809476: Epoch time: 69.02 s 
2025-07-11 23:27:22.757386:  
2025-07-11 23:27:22.759737: Epoch 356 
2025-07-11 23:27:22.760785: Current learning rate: 0.00673 
2025-07-11 23:28:31.736740: train_loss -0.9714 
2025-07-11 23:28:31.738702: val_loss -0.9476 
2025-07-11 23:28:31.739990: Pseudo dice [np.float32(0.9518)] 
2025-07-11 23:28:31.741160: Epoch time: 68.98 s 
2025-07-11 23:28:32.642353:  
2025-07-11 23:28:32.644353: Epoch 357 
2025-07-11 23:28:32.645674: Current learning rate: 0.00672 
2025-07-11 23:29:41.637954: train_loss -0.9712 
2025-07-11 23:29:41.639313: val_loss -0.9478 
2025-07-11 23:29:41.640363: Pseudo dice [np.float32(0.9522)] 
2025-07-11 23:29:41.641348: Epoch time: 69.0 s 
2025-07-11 23:29:42.608292:  
2025-07-11 23:29:42.610686: Epoch 358 
2025-07-11 23:29:42.612054: Current learning rate: 0.00671 
2025-07-11 23:30:51.461473: train_loss -0.9694 
2025-07-11 23:30:51.462897: val_loss -0.9479 
2025-07-11 23:30:51.463833: Pseudo dice [np.float32(0.9523)] 
2025-07-11 23:30:51.465350: Epoch time: 68.86 s 
2025-07-11 23:30:52.400759:  
2025-07-11 23:30:52.402759: Epoch 359 
2025-07-11 23:30:52.404538: Current learning rate: 0.0067 
2025-07-11 23:32:01.853261: train_loss -0.9686 
2025-07-11 23:32:01.854929: val_loss -0.9436 
2025-07-11 23:32:01.857408: Pseudo dice [np.float32(0.9473)] 
2025-07-11 23:32:01.860258: Epoch time: 69.46 s 
2025-07-11 23:32:02.827236:  
2025-07-11 23:32:02.830491: Epoch 360 
2025-07-11 23:32:02.832278: Current learning rate: 0.00669 
2025-07-11 23:33:11.342513: train_loss -0.9698 
2025-07-11 23:33:11.344288: val_loss -0.9454 
2025-07-11 23:33:11.346766: Pseudo dice [np.float32(0.9495)] 
2025-07-11 23:33:11.349822: Epoch time: 68.52 s 
2025-07-11 23:33:12.326045:  
2025-07-11 23:33:12.328773: Epoch 361 
2025-07-11 23:33:12.330245: Current learning rate: 0.00668 
2025-07-11 23:34:21.030504: train_loss -0.97 
2025-07-11 23:34:21.032814: val_loss -0.9501 
2025-07-11 23:34:21.034991: Pseudo dice [np.float32(0.9545)] 
2025-07-11 23:34:21.037038: Epoch time: 68.71 s 
2025-07-11 23:34:22.003433:  
2025-07-11 23:34:22.005960: Epoch 362 
2025-07-11 23:34:22.007317: Current learning rate: 0.00667 
2025-07-11 23:35:30.745972: train_loss -0.9713 
2025-07-11 23:35:30.748634: val_loss -0.947 
2025-07-11 23:35:30.750718: Pseudo dice [np.float32(0.9515)] 
2025-07-11 23:35:30.752162: Epoch time: 68.75 s 
2025-07-11 23:35:31.719358:  
2025-07-11 23:35:31.721564: Epoch 363 
2025-07-11 23:35:31.723204: Current learning rate: 0.00666 
2025-07-11 23:36:40.875631: train_loss -0.9725 
2025-07-11 23:36:40.877553: val_loss -0.9498 
2025-07-11 23:36:40.879812: Pseudo dice [np.float32(0.9546)] 
2025-07-11 23:36:40.881564: Epoch time: 69.16 s 
2025-07-11 23:36:41.848639:  
2025-07-11 23:36:41.851494: Epoch 364 
2025-07-11 23:36:41.852833: Current learning rate: 0.00665 
2025-07-11 23:37:50.868194: train_loss -0.9718 
2025-07-11 23:37:50.870539: val_loss -0.9428 
2025-07-11 23:37:50.873257: Pseudo dice [np.float32(0.9467)] 
2025-07-11 23:37:50.874973: Epoch time: 69.02 s 
2025-07-11 23:37:51.851746:  
2025-07-11 23:37:51.854561: Epoch 365 
2025-07-11 23:37:51.856493: Current learning rate: 0.00665 
2025-07-11 23:39:00.794375: train_loss -0.9686 
2025-07-11 23:39:00.796174: val_loss -0.9453 
2025-07-11 23:39:00.798126: Pseudo dice [np.float32(0.9486)] 
2025-07-11 23:39:00.800762: Epoch time: 68.95 s 
2025-07-11 23:39:01.781687:  
2025-07-11 23:39:01.784271: Epoch 366 
2025-07-11 23:39:01.785522: Current learning rate: 0.00664 
2025-07-11 23:40:10.527301: train_loss -0.971 
2025-07-11 23:40:10.529702: val_loss -0.9457 
2025-07-11 23:40:10.530919: Pseudo dice [np.float32(0.9501)] 
2025-07-11 23:40:10.532315: Epoch time: 68.75 s 
2025-07-11 23:40:11.514204:  
2025-07-11 23:40:11.517238: Epoch 367 
2025-07-11 23:40:11.518282: Current learning rate: 0.00663 
2025-07-11 23:41:20.278219: train_loss -0.9715 
2025-07-11 23:41:20.279959: val_loss -0.9429 
2025-07-11 23:41:20.282102: Pseudo dice [np.float32(0.9468)] 
2025-07-11 23:41:20.284317: Epoch time: 68.77 s 
2025-07-11 23:41:22.084899:  
2025-07-11 23:41:22.086714: Epoch 368 
2025-07-11 23:41:22.088338: Current learning rate: 0.00662 
2025-07-11 23:42:30.868385: train_loss -0.9725 
2025-07-11 23:42:30.869879: val_loss -0.947 
2025-07-11 23:42:30.870992: Pseudo dice [np.float32(0.9511)] 
2025-07-11 23:42:30.872966: Epoch time: 68.79 s 
2025-07-11 23:42:31.831732:  
2025-07-11 23:42:31.833497: Epoch 369 
2025-07-11 23:42:31.834745: Current learning rate: 0.00661 
2025-07-11 23:43:40.615580: train_loss -0.973 
2025-07-11 23:43:40.617037: val_loss -0.9512 
2025-07-11 23:43:40.618385: Pseudo dice [np.float32(0.9542)] 
2025-07-11 23:43:40.619366: Epoch time: 68.79 s 
2025-07-11 23:43:41.581912:  
2025-07-11 23:43:41.584213: Epoch 370 
2025-07-11 23:43:41.585361: Current learning rate: 0.0066 
2025-07-11 23:44:50.426293: train_loss -0.9715 
2025-07-11 23:44:50.427876: val_loss -0.9498 
2025-07-11 23:44:50.429351: Pseudo dice [np.float32(0.9541)] 
2025-07-11 23:44:50.430687: Epoch time: 68.85 s 
2025-07-11 23:44:51.383196:  
2025-07-11 23:44:51.385289: Epoch 371 
2025-07-11 23:44:51.386396: Current learning rate: 0.00659 
2025-07-11 23:46:00.307740: train_loss -0.9716 
2025-07-11 23:46:00.309288: val_loss -0.9439 
2025-07-11 23:46:00.310414: Pseudo dice [np.float32(0.9477)] 
2025-07-11 23:46:00.311468: Epoch time: 68.93 s 
2025-07-11 23:46:01.294311:  
2025-07-11 23:46:01.296144: Epoch 372 
2025-07-11 23:46:01.297904: Current learning rate: 0.00658 
2025-07-11 23:47:10.064462: train_loss -0.9734 
2025-07-11 23:47:10.066153: val_loss -0.9484 
2025-07-11 23:47:10.067636: Pseudo dice [np.float32(0.952)] 
2025-07-11 23:47:10.068722: Epoch time: 68.77 s 
2025-07-11 23:47:11.019578:  
2025-07-11 23:47:11.022585: Epoch 373 
2025-07-11 23:47:11.023854: Current learning rate: 0.00657 
2025-07-11 23:48:19.757951: train_loss -0.9727 
2025-07-11 23:48:19.759701: val_loss -0.9502 
2025-07-11 23:48:19.760776: Pseudo dice [np.float32(0.9543)] 
2025-07-11 23:48:19.762009: Epoch time: 68.74 s 
2025-07-11 23:48:20.720719:  
2025-07-11 23:48:20.723268: Epoch 374 
2025-07-11 23:48:20.724478: Current learning rate: 0.00656 
2025-07-11 23:49:29.374981: train_loss -0.9732 
2025-07-11 23:49:29.376278: val_loss -0.9463 
2025-07-11 23:49:29.377676: Pseudo dice [np.float32(0.9514)] 
2025-07-11 23:49:29.379220: Epoch time: 68.66 s 
2025-07-11 23:49:30.320204:  
2025-07-11 23:49:30.322461: Epoch 375 
2025-07-11 23:49:30.323786: Current learning rate: 0.00655 
2025-07-11 23:50:39.063063: train_loss -0.9738 
2025-07-11 23:50:39.064496: val_loss -0.9503 
2025-07-11 23:50:39.065485: Pseudo dice [np.float32(0.9544)] 
2025-07-11 23:50:39.066967: Epoch time: 68.75 s 
2025-07-11 23:50:40.021774:  
2025-07-11 23:50:40.024626: Epoch 376 
2025-07-11 23:50:40.025789: Current learning rate: 0.00654 
2025-07-11 23:51:48.895279: train_loss -0.9725 
2025-07-11 23:51:48.896946: val_loss -0.9509 
2025-07-11 23:51:48.898334: Pseudo dice [np.float32(0.9553)] 
2025-07-11 23:51:48.900312: Epoch time: 68.88 s 
2025-07-11 23:51:50.716217:  
2025-07-11 23:51:50.718213: Epoch 377 
2025-07-11 23:51:50.719236: Current learning rate: 0.00653 
2025-07-11 23:52:59.529149: train_loss -0.972 
2025-07-11 23:52:59.530758: val_loss -0.9544 
2025-07-11 23:52:59.532254: Pseudo dice [np.float32(0.9581)] 
2025-07-11 23:52:59.533306: Epoch time: 68.82 s 
2025-07-11 23:53:00.488578:  
2025-07-11 23:53:00.491271: Epoch 378 
2025-07-11 23:53:00.492938: Current learning rate: 0.00652 
2025-07-11 23:54:09.273711: train_loss -0.9726 
2025-07-11 23:54:09.275216: val_loss -0.9524 
2025-07-11 23:54:09.276377: Pseudo dice [np.float32(0.9562)] 
2025-07-11 23:54:09.277591: Epoch time: 68.79 s 
2025-07-11 23:54:10.258452:  
2025-07-11 23:54:10.260510: Epoch 379 
2025-07-11 23:54:10.262341: Current learning rate: 0.00651 
2025-07-11 23:55:18.935515: train_loss -0.9737 
2025-07-11 23:55:18.937059: val_loss -0.9485 
2025-07-11 23:55:18.938506: Pseudo dice [np.float32(0.9526)] 
2025-07-11 23:55:18.940053: Epoch time: 68.68 s 
2025-07-11 23:55:19.880767:  
2025-07-11 23:55:19.883109: Epoch 380 
2025-07-11 23:55:19.884576: Current learning rate: 0.0065 
2025-07-11 23:56:28.467237: train_loss -0.9724 
2025-07-11 23:56:28.468620: val_loss -0.9474 
2025-07-11 23:56:28.469947: Pseudo dice [np.float32(0.9516)] 
2025-07-11 23:56:28.472007: Epoch time: 68.59 s 
2025-07-11 23:56:29.440723:  
2025-07-11 23:56:29.443292: Epoch 381 
2025-07-11 23:56:29.444245: Current learning rate: 0.00649 
2025-07-11 23:57:38.115542: train_loss -0.9719 
2025-07-11 23:57:38.117170: val_loss -0.9432 
2025-07-11 23:57:38.118173: Pseudo dice [np.float32(0.9475)] 
2025-07-11 23:57:38.119454: Epoch time: 68.68 s 
2025-07-11 23:57:39.072084:  
2025-07-11 23:57:39.074388: Epoch 382 
2025-07-11 23:57:39.075844: Current learning rate: 0.00648 
2025-07-11 23:58:47.723112: train_loss -0.9724 
2025-07-11 23:58:47.724493: val_loss -0.9499 
2025-07-11 23:58:47.726004: Pseudo dice [np.float32(0.9534)] 
2025-07-11 23:58:47.727729: Epoch time: 68.65 s 
2025-07-11 23:58:48.690612:  
2025-07-11 23:58:48.693090: Epoch 383 
2025-07-11 23:58:48.694203: Current learning rate: 0.00648 
2025-07-11 23:59:57.491161: train_loss -0.9733 
2025-07-11 23:59:57.492696: val_loss -0.9517 
2025-07-11 23:59:57.493725: Pseudo dice [np.float32(0.9547)] 
2025-07-11 23:59:57.494922: Epoch time: 68.8 s 
2025-07-11 23:59:58.445271:  
2025-07-11 23:59:58.447609: Epoch 384 
2025-07-11 23:59:58.448667: Current learning rate: 0.00647 
2025-07-12 00:01:07.229342: train_loss -0.9737 
2025-07-12 00:01:07.231039: val_loss -0.9473 
2025-07-12 00:01:07.232308: Pseudo dice [np.float32(0.9505)] 
2025-07-12 00:01:07.233251: Epoch time: 68.79 s 
2025-07-12 00:01:08.189948:  
2025-07-12 00:01:08.192148: Epoch 385 
2025-07-12 00:01:08.193415: Current learning rate: 0.00646 
2025-07-12 00:02:16.768114: train_loss -0.9723 
2025-07-12 00:02:16.769343: val_loss -0.9446 
2025-07-12 00:02:16.770380: Pseudo dice [np.float32(0.9484)] 
2025-07-12 00:02:16.771810: Epoch time: 68.58 s 
2025-07-12 00:02:17.737308:  
2025-07-12 00:02:17.739339: Epoch 386 
2025-07-12 00:02:17.740524: Current learning rate: 0.00645 
2025-07-12 00:03:27.261244: train_loss -0.9719 
2025-07-12 00:03:27.262512: val_loss -0.9458 
2025-07-12 00:03:27.263666: Pseudo dice [np.float32(0.9495)] 
2025-07-12 00:03:27.264788: Epoch time: 69.53 s 
2025-07-12 00:03:28.266700:  
2025-07-12 00:03:28.269306: Epoch 387 
2025-07-12 00:03:28.270868: Current learning rate: 0.00644 
2025-07-12 00:04:37.114537: train_loss -0.9708 
2025-07-12 00:04:37.116243: val_loss -0.9505 
2025-07-12 00:04:37.117148: Pseudo dice [np.float32(0.9542)] 
2025-07-12 00:04:37.118514: Epoch time: 68.85 s 
2025-07-12 00:04:38.089232:  
2025-07-12 00:04:38.091411: Epoch 388 
2025-07-12 00:04:38.092810: Current learning rate: 0.00643 
2025-07-12 00:05:46.890232: train_loss -0.9728 
2025-07-12 00:05:46.891690: val_loss -0.9479 
2025-07-12 00:05:46.893445: Pseudo dice [np.float32(0.9522)] 
2025-07-12 00:05:46.894582: Epoch time: 68.8 s 
2025-07-12 00:05:47.835956:  
2025-07-12 00:05:47.838282: Epoch 389 
2025-07-12 00:05:47.839380: Current learning rate: 0.00642 
2025-07-12 00:06:56.755546: train_loss -0.9724 
2025-07-12 00:06:56.758421: val_loss -0.949 
2025-07-12 00:06:56.759742: Pseudo dice [np.float32(0.9525)] 
2025-07-12 00:06:56.760968: Epoch time: 68.92 s 
2025-07-12 00:06:57.727427:  
2025-07-12 00:06:57.729823: Epoch 390 
2025-07-12 00:06:57.731023: Current learning rate: 0.00641 
2025-07-12 00:08:06.666390: train_loss -0.972 
2025-07-12 00:08:06.668259: val_loss -0.9518 
2025-07-12 00:08:06.669634: Pseudo dice [np.float32(0.9554)] 
2025-07-12 00:08:06.670633: Epoch time: 68.94 s 
2025-07-12 00:08:07.631945:  
2025-07-12 00:08:07.633849: Epoch 391 
2025-07-12 00:08:07.634956: Current learning rate: 0.0064 
2025-07-12 00:09:16.829689: train_loss -0.9738 
2025-07-12 00:09:16.831242: val_loss -0.9515 
2025-07-12 00:09:16.832672: Pseudo dice [np.float32(0.9538)] 
2025-07-12 00:09:16.833932: Epoch time: 69.2 s 
2025-07-12 00:09:17.782951:  
2025-07-12 00:09:17.785135: Epoch 392 
2025-07-12 00:09:17.786315: Current learning rate: 0.00639 
2025-07-12 00:10:26.815186: train_loss -0.9735 
2025-07-12 00:10:26.816702: val_loss -0.9481 
2025-07-12 00:10:26.818288: Pseudo dice [np.float32(0.9521)] 
2025-07-12 00:10:26.819498: Epoch time: 69.04 s 
2025-07-12 00:10:27.796907:  
2025-07-12 00:10:27.798815: Epoch 393 
2025-07-12 00:10:27.799861: Current learning rate: 0.00638 
2025-07-12 00:11:36.745620: train_loss -0.9737 
2025-07-12 00:11:36.747275: val_loss -0.9502 
2025-07-12 00:11:36.749269: Pseudo dice [np.float32(0.9539)] 
2025-07-12 00:11:36.751260: Epoch time: 68.95 s 
2025-07-12 00:11:37.720507:  
2025-07-12 00:11:37.722809: Epoch 394 
2025-07-12 00:11:37.723933: Current learning rate: 0.00637 
2025-07-12 00:12:46.391267: train_loss -0.974 
2025-07-12 00:12:46.393323: val_loss -0.9481 
2025-07-12 00:12:46.394717: Pseudo dice [np.float32(0.953)] 
2025-07-12 00:12:46.395911: Epoch time: 68.67 s 
2025-07-12 00:12:48.283079:  
2025-07-12 00:12:48.285512: Epoch 395 
2025-07-12 00:12:48.286716: Current learning rate: 0.00636 
2025-07-12 00:13:56.946399: train_loss -0.9732 
2025-07-12 00:13:56.947802: val_loss -0.9486 
2025-07-12 00:13:56.948749: Pseudo dice [np.float32(0.9527)] 
2025-07-12 00:13:56.949805: Epoch time: 68.67 s 
2025-07-12 00:13:57.930957:  
2025-07-12 00:13:57.933357: Epoch 396 
2025-07-12 00:13:57.934498: Current learning rate: 0.00635 
2025-07-12 00:15:06.771064: train_loss -0.9737 
2025-07-12 00:15:06.772408: val_loss -0.9467 
2025-07-12 00:15:06.773664: Pseudo dice [np.float32(0.9507)] 
2025-07-12 00:15:06.775233: Epoch time: 68.84 s 
2025-07-12 00:15:07.745846:  
2025-07-12 00:15:07.748520: Epoch 397 
2025-07-12 00:15:07.749836: Current learning rate: 0.00634 
2025-07-12 00:16:16.425609: train_loss -0.971 
2025-07-12 00:16:16.426972: val_loss -0.9487 
2025-07-12 00:16:16.427985: Pseudo dice [np.float32(0.9523)] 
2025-07-12 00:16:16.428936: Epoch time: 68.68 s 
2025-07-12 00:16:17.400907:  
2025-07-12 00:16:17.403119: Epoch 398 
2025-07-12 00:16:17.404370: Current learning rate: 0.00633 
2025-07-12 00:17:26.142506: train_loss -0.9719 
2025-07-12 00:17:26.143890: val_loss -0.952 
2025-07-12 00:17:26.145170: Pseudo dice [np.float32(0.9555)] 
2025-07-12 00:17:26.146960: Epoch time: 68.75 s 
2025-07-12 00:17:27.065424:  
2025-07-12 00:17:27.067643: Epoch 399 
2025-07-12 00:17:27.069143: Current learning rate: 0.00632 
2025-07-12 00:18:35.744860: train_loss -0.9715 
2025-07-12 00:18:35.746230: val_loss -0.9469 
2025-07-12 00:18:35.748558: Pseudo dice [np.float32(0.95)] 
2025-07-12 00:18:35.749792: Epoch time: 68.68 s 
2025-07-12 00:18:38.107733:  
2025-07-12 00:18:38.110198: Epoch 400 
2025-07-12 00:18:38.111414: Current learning rate: 0.00631 
2025-07-12 00:19:46.784683: train_loss -0.972 
2025-07-12 00:19:46.786355: val_loss -0.9476 
2025-07-12 00:19:46.787718: Pseudo dice [np.float32(0.951)] 
2025-07-12 00:19:46.788946: Epoch time: 68.68 s 
2025-07-12 00:19:47.745856:  
2025-07-12 00:19:47.748204: Epoch 401 
2025-07-12 00:19:47.749696: Current learning rate: 0.0063 
2025-07-12 00:20:56.491134: train_loss -0.972 
2025-07-12 00:20:56.492709: val_loss -0.9452 
2025-07-12 00:20:56.494196: Pseudo dice [np.float32(0.9492)] 
2025-07-12 00:20:56.495234: Epoch time: 68.75 s 
2025-07-12 00:20:57.475296:  
2025-07-12 00:20:57.477588: Epoch 402 
2025-07-12 00:20:57.478588: Current learning rate: 0.0063 
2025-07-12 00:22:06.197438: train_loss -0.9723 
2025-07-12 00:22:06.199038: val_loss -0.9491 
2025-07-12 00:22:06.200326: Pseudo dice [np.float32(0.9534)] 
2025-07-12 00:22:06.201461: Epoch time: 68.73 s 
2025-07-12 00:22:07.148217:  
2025-07-12 00:22:07.150222: Epoch 403 
2025-07-12 00:22:07.151386: Current learning rate: 0.00629 
2025-07-12 00:23:16.633841: train_loss -0.9728 
2025-07-12 00:23:16.635117: val_loss -0.9449 
2025-07-12 00:23:16.636093: Pseudo dice [np.float32(0.9485)] 
2025-07-12 00:23:16.638297: Epoch time: 69.49 s 
2025-07-12 00:23:17.619589:  
2025-07-12 00:23:17.622386: Epoch 404 
2025-07-12 00:23:17.623873: Current learning rate: 0.00628 
2025-07-12 00:24:26.344916: train_loss -0.9743 
2025-07-12 00:24:26.346220: val_loss -0.9468 
2025-07-12 00:24:26.347252: Pseudo dice [np.float32(0.9509)] 
2025-07-12 00:24:26.348547: Epoch time: 68.73 s 
2025-07-12 00:24:27.287339:  
2025-07-12 00:24:27.289657: Epoch 405 
2025-07-12 00:24:27.290882: Current learning rate: 0.00627 
2025-07-12 00:25:36.081724: train_loss -0.9733 
2025-07-12 00:25:36.084078: val_loss -0.9472 
2025-07-12 00:25:36.085255: Pseudo dice [np.float32(0.9513)] 
2025-07-12 00:25:36.086297: Epoch time: 68.8 s 
2025-07-12 00:25:37.045454:  
2025-07-12 00:25:37.047525: Epoch 406 
2025-07-12 00:25:37.048514: Current learning rate: 0.00626 
2025-07-12 00:26:45.662828: train_loss -0.9738 
2025-07-12 00:26:45.665003: val_loss -0.9485 
2025-07-12 00:26:45.666312: Pseudo dice [np.float32(0.952)] 
2025-07-12 00:26:45.667458: Epoch time: 68.62 s 
2025-07-12 00:26:46.634722:  
2025-07-12 00:26:46.637035: Epoch 407 
2025-07-12 00:26:46.638139: Current learning rate: 0.00625 
2025-07-12 00:27:55.276379: train_loss -0.9741 
2025-07-12 00:27:55.277827: val_loss -0.949 
2025-07-12 00:27:55.278857: Pseudo dice [np.float32(0.953)] 
2025-07-12 00:27:55.280011: Epoch time: 68.65 s 
2025-07-12 00:27:56.242054:  
2025-07-12 00:27:56.244236: Epoch 408 
2025-07-12 00:27:56.245441: Current learning rate: 0.00624 
2025-07-12 00:29:04.973502: train_loss -0.9737 
2025-07-12 00:29:04.974776: val_loss -0.9487 
2025-07-12 00:29:04.976039: Pseudo dice [np.float32(0.952)] 
2025-07-12 00:29:04.977636: Epoch time: 68.74 s 
2025-07-12 00:29:05.955084:  
2025-07-12 00:29:05.957540: Epoch 409 
2025-07-12 00:29:05.958610: Current learning rate: 0.00623 
2025-07-12 00:30:14.824867: train_loss -0.9744 
2025-07-12 00:30:14.826447: val_loss -0.9482 
2025-07-12 00:30:14.827546: Pseudo dice [np.float32(0.9521)] 
2025-07-12 00:30:14.828378: Epoch time: 68.87 s 
2025-07-12 00:30:15.806380:  
2025-07-12 00:30:15.808344: Epoch 410 
2025-07-12 00:30:15.809554: Current learning rate: 0.00622 
2025-07-12 00:31:24.594172: train_loss -0.9729 
2025-07-12 00:31:24.595514: val_loss -0.943 
2025-07-12 00:31:24.596433: Pseudo dice [np.float32(0.9469)] 
2025-07-12 00:31:24.598263: Epoch time: 68.79 s 
2025-07-12 00:31:25.539505:  
2025-07-12 00:31:25.541842: Epoch 411 
2025-07-12 00:31:25.543588: Current learning rate: 0.00621 
2025-07-12 00:32:34.148445: train_loss -0.9719 
2025-07-12 00:32:34.150047: val_loss -0.9443 
2025-07-12 00:32:34.151119: Pseudo dice [np.float32(0.9489)] 
2025-07-12 00:32:34.152469: Epoch time: 68.61 s 
2025-07-12 00:32:35.081947:  
2025-07-12 00:32:35.084801: Epoch 412 
2025-07-12 00:32:35.086249: Current learning rate: 0.0062 
2025-07-12 00:33:44.604355: train_loss -0.9734 
2025-07-12 00:33:44.606035: val_loss -0.9447 
2025-07-12 00:33:44.607862: Pseudo dice [np.float32(0.9481)] 
2025-07-12 00:33:44.608918: Epoch time: 69.53 s 
2025-07-12 00:33:45.543355:  
2025-07-12 00:33:45.545776: Epoch 413 
2025-07-12 00:33:45.547436: Current learning rate: 0.00619 
2025-07-12 00:34:54.402915: train_loss -0.973 
2025-07-12 00:34:54.404339: val_loss -0.9443 
2025-07-12 00:34:54.406164: Pseudo dice [np.float32(0.9491)] 
2025-07-12 00:34:54.407346: Epoch time: 68.86 s 
2025-07-12 00:34:55.314830:  
2025-07-12 00:34:55.317260: Epoch 414 
2025-07-12 00:34:55.318488: Current learning rate: 0.00618 
2025-07-12 00:36:04.085510: train_loss -0.9731 
2025-07-12 00:36:04.087055: val_loss -0.945 
2025-07-12 00:36:04.088235: Pseudo dice [np.float32(0.9489)] 
2025-07-12 00:36:04.089343: Epoch time: 68.77 s 
2025-07-12 00:36:05.030670:  
2025-07-12 00:36:05.033696: Epoch 415 
2025-07-12 00:36:05.035428: Current learning rate: 0.00617 
2025-07-12 00:37:13.796959: train_loss -0.9732 
2025-07-12 00:37:13.798149: val_loss -0.9487 
2025-07-12 00:37:13.799701: Pseudo dice [np.float32(0.9525)] 
2025-07-12 00:37:13.801174: Epoch time: 68.77 s 
2025-07-12 00:37:14.749117:  
2025-07-12 00:37:14.751359: Epoch 416 
2025-07-12 00:37:14.752660: Current learning rate: 0.00616 
2025-07-12 00:38:23.553169: train_loss -0.9729 
2025-07-12 00:38:23.554514: val_loss -0.9418 
2025-07-12 00:38:23.555811: Pseudo dice [np.float32(0.9465)] 
2025-07-12 00:38:23.557137: Epoch time: 68.81 s 
2025-07-12 00:38:24.489207:  
2025-07-12 00:38:24.491705: Epoch 417 
2025-07-12 00:38:24.493029: Current learning rate: 0.00615 
2025-07-12 00:39:33.255788: train_loss -0.9717 
2025-07-12 00:39:33.257864: val_loss -0.9504 
2025-07-12 00:39:33.259594: Pseudo dice [np.float32(0.9543)] 
2025-07-12 00:39:33.261256: Epoch time: 68.77 s 
2025-07-12 00:39:34.211230:  
2025-07-12 00:39:34.213696: Epoch 418 
2025-07-12 00:39:34.214717: Current learning rate: 0.00614 
2025-07-12 00:40:42.908822: train_loss -0.9733 
2025-07-12 00:40:42.911117: val_loss -0.9481 
2025-07-12 00:40:42.912823: Pseudo dice [np.float32(0.9515)] 
2025-07-12 00:40:42.914118: Epoch time: 68.7 s 
2025-07-12 00:40:43.810431:  
2025-07-12 00:40:43.813011: Epoch 419 
2025-07-12 00:40:43.814247: Current learning rate: 0.00613 
2025-07-12 00:41:52.533857: train_loss -0.9736 
2025-07-12 00:41:52.535261: val_loss -0.9506 
2025-07-12 00:41:52.536793: Pseudo dice [np.float32(0.9539)] 
2025-07-12 00:41:52.538171: Epoch time: 68.73 s 
2025-07-12 00:41:53.491635:  
2025-07-12 00:41:53.494520: Epoch 420 
2025-07-12 00:41:53.496300: Current learning rate: 0.00612 
2025-07-12 00:43:02.224396: train_loss -0.9751 
2025-07-12 00:43:02.225715: val_loss -0.9493 
2025-07-12 00:43:02.227083: Pseudo dice [np.float32(0.9535)] 
2025-07-12 00:43:02.229054: Epoch time: 68.74 s 
2025-07-12 00:43:03.147446:  
2025-07-12 00:43:03.149888: Epoch 421 
2025-07-12 00:43:03.150898: Current learning rate: 0.00612 
2025-07-12 00:44:12.713359: train_loss -0.9728 
2025-07-12 00:44:12.714704: val_loss -0.9477 
2025-07-12 00:44:12.716876: Pseudo dice [np.float32(0.9526)] 
2025-07-12 00:44:12.718498: Epoch time: 69.57 s 
2025-07-12 00:44:13.653157:  
2025-07-12 00:44:13.655877: Epoch 422 
2025-07-12 00:44:13.657208: Current learning rate: 0.00611 
2025-07-12 00:45:22.556388: train_loss -0.9731 
2025-07-12 00:45:22.557791: val_loss -0.9486 
2025-07-12 00:45:22.559557: Pseudo dice [np.float32(0.9524)] 
2025-07-12 00:45:22.560856: Epoch time: 68.91 s 
2025-07-12 00:45:23.500738:  
2025-07-12 00:45:23.503630: Epoch 423 
2025-07-12 00:45:23.504835: Current learning rate: 0.0061 
2025-07-12 00:46:32.221244: train_loss -0.9753 
2025-07-12 00:46:32.222541: val_loss -0.9531 
2025-07-12 00:46:32.224162: Pseudo dice [np.float32(0.957)] 
2025-07-12 00:46:32.225668: Epoch time: 68.72 s 
2025-07-12 00:46:33.151149:  
2025-07-12 00:46:33.153559: Epoch 424 
2025-07-12 00:46:33.154827: Current learning rate: 0.00609 
2025-07-12 00:47:41.722037: train_loss -0.9741 
2025-07-12 00:47:41.723380: val_loss -0.9514 
2025-07-12 00:47:41.724395: Pseudo dice [np.float32(0.9553)] 
2025-07-12 00:47:41.725816: Epoch time: 68.57 s 
2025-07-12 00:47:42.665640:  
2025-07-12 00:47:42.667739: Epoch 425 
2025-07-12 00:47:42.668970: Current learning rate: 0.00608 
2025-07-12 00:48:51.275913: train_loss -0.9735 
2025-07-12 00:48:51.277122: val_loss -0.9469 
2025-07-12 00:48:51.278295: Pseudo dice [np.float32(0.9515)] 
2025-07-12 00:48:51.279371: Epoch time: 68.61 s 
2025-07-12 00:48:52.242634:  
2025-07-12 00:48:52.244735: Epoch 426 
2025-07-12 00:48:52.245942: Current learning rate: 0.00607 
2025-07-12 00:50:00.842554: train_loss -0.9734 
2025-07-12 00:50:00.843785: val_loss -0.9537 
2025-07-12 00:50:00.844795: Pseudo dice [np.float32(0.9569)] 
2025-07-12 00:50:00.846158: Epoch time: 68.6 s 
2025-07-12 00:50:01.800360:  
2025-07-12 00:50:01.802743: Epoch 427 
2025-07-12 00:50:01.803845: Current learning rate: 0.00606 
2025-07-12 00:51:10.417026: train_loss -0.9739 
2025-07-12 00:51:10.418293: val_loss -0.9478 
2025-07-12 00:51:10.419344: Pseudo dice [np.float32(0.9529)] 
2025-07-12 00:51:10.420666: Epoch time: 68.62 s 
2025-07-12 00:51:11.349419:  
2025-07-12 00:51:11.351484: Epoch 428 
2025-07-12 00:51:11.352868: Current learning rate: 0.00605 
2025-07-12 00:52:20.005675: train_loss -0.9742 
2025-07-12 00:52:20.007177: val_loss -0.9483 
2025-07-12 00:52:20.008297: Pseudo dice [np.float32(0.9525)] 
2025-07-12 00:52:20.010083: Epoch time: 68.66 s 
2025-07-12 00:52:20.955804:  
2025-07-12 00:52:20.958084: Epoch 429 
2025-07-12 00:52:20.959170: Current learning rate: 0.00604 
2025-07-12 00:53:29.757445: train_loss -0.9739 
2025-07-12 00:53:29.758808: val_loss -0.9485 
2025-07-12 00:53:29.759885: Pseudo dice [np.float32(0.9527)] 
2025-07-12 00:53:29.761678: Epoch time: 68.81 s 
2025-07-12 00:53:30.714033:  
2025-07-12 00:53:30.716338: Epoch 430 
2025-07-12 00:53:30.718192: Current learning rate: 0.00603 
2025-07-12 00:54:40.167555: train_loss -0.9742 
2025-07-12 00:54:40.168952: val_loss -0.948 
2025-07-12 00:54:40.170103: Pseudo dice [np.float32(0.9529)] 
2025-07-12 00:54:40.171181: Epoch time: 69.46 s 
2025-07-12 00:54:41.112767:  
2025-07-12 00:54:41.115359: Epoch 431 
2025-07-12 00:54:41.116790: Current learning rate: 0.00602 
2025-07-12 00:55:50.132103: train_loss -0.9735 
2025-07-12 00:55:50.133433: val_loss -0.9473 
2025-07-12 00:55:50.134615: Pseudo dice [np.float32(0.9519)] 
2025-07-12 00:55:50.135977: Epoch time: 69.02 s 
2025-07-12 00:55:51.069474:  
2025-07-12 00:55:51.071692: Epoch 432 
2025-07-12 00:55:51.072981: Current learning rate: 0.00601 
2025-07-12 00:56:59.896811: train_loss -0.9749 
2025-07-12 00:56:59.898130: val_loss -0.9513 
2025-07-12 00:56:59.899299: Pseudo dice [np.float32(0.9551)] 
2025-07-12 00:56:59.900475: Epoch time: 68.83 s 
2025-07-12 00:57:00.845670:  
2025-07-12 00:57:00.847611: Epoch 433 
2025-07-12 00:57:00.848637: Current learning rate: 0.006 
2025-07-12 00:58:09.520996: train_loss -0.9742 
2025-07-12 00:58:09.523118: val_loss -0.9514 
2025-07-12 00:58:09.524683: Pseudo dice [np.float32(0.9556)] 
2025-07-12 00:58:09.525929: Epoch time: 68.68 s 
2025-07-12 00:58:10.474422:  
2025-07-12 00:58:10.476769: Epoch 434 
2025-07-12 00:58:10.478396: Current learning rate: 0.00599 
2025-07-12 00:59:19.055336: train_loss -0.9739 
2025-07-12 00:59:19.056761: val_loss -0.9463 
2025-07-12 00:59:19.058187: Pseudo dice [np.float32(0.9499)] 
2025-07-12 00:59:19.059534: Epoch time: 68.58 s 
2025-07-12 00:59:19.993544:  
2025-07-12 00:59:19.995984: Epoch 435 
2025-07-12 00:59:19.996984: Current learning rate: 0.00598 
2025-07-12 01:00:28.621338: train_loss -0.9736 
2025-07-12 01:00:28.622901: val_loss -0.9513 
2025-07-12 01:00:28.624056: Pseudo dice [np.float32(0.9559)] 
2025-07-12 01:00:28.625568: Epoch time: 68.63 s 
2025-07-12 01:00:29.552395:  
2025-07-12 01:00:29.554593: Epoch 436 
2025-07-12 01:00:29.555927: Current learning rate: 0.00597 
2025-07-12 01:01:38.295775: train_loss -0.9744 
2025-07-12 01:01:38.297577: val_loss -0.9494 
2025-07-12 01:01:38.299134: Pseudo dice [np.float32(0.9536)] 
2025-07-12 01:01:38.300445: Epoch time: 68.75 s 
2025-07-12 01:01:39.255755:  
2025-07-12 01:01:39.257704: Epoch 437 
2025-07-12 01:01:39.258954: Current learning rate: 0.00596 
2025-07-12 01:02:48.046948: train_loss -0.9734 
2025-07-12 01:02:48.048547: val_loss -0.9481 
2025-07-12 01:02:48.049511: Pseudo dice [np.float32(0.9516)] 
2025-07-12 01:02:48.050980: Epoch time: 68.8 s 
2025-07-12 01:02:48.974794:  
2025-07-12 01:02:48.976931: Epoch 438 
2025-07-12 01:02:48.978259: Current learning rate: 0.00595 
2025-07-12 01:03:57.608213: train_loss -0.9736 
2025-07-12 01:03:57.609522: val_loss -0.947 
2025-07-12 01:03:57.610562: Pseudo dice [np.float32(0.9501)] 
2025-07-12 01:03:57.611857: Epoch time: 68.64 s 
2025-07-12 01:03:58.540106:  
2025-07-12 01:03:58.542201: Epoch 439 
2025-07-12 01:03:58.543496: Current learning rate: 0.00594 
2025-07-12 01:05:08.105474: train_loss -0.9741 
2025-07-12 01:05:08.107239: val_loss -0.9499 
2025-07-12 01:05:08.108366: Pseudo dice [np.float32(0.9543)] 
2025-07-12 01:05:08.109336: Epoch time: 69.57 s 
2025-07-12 01:05:09.297587:  
2025-07-12 01:05:09.299579: Epoch 440 
2025-07-12 01:05:09.301250: Current learning rate: 0.00593 
2025-07-12 01:06:18.061990: train_loss -0.9751 
2025-07-12 01:06:18.063487: val_loss -0.9538 
2025-07-12 01:06:18.064516: Pseudo dice [np.float32(0.9572)] 
2025-07-12 01:06:18.065489: Epoch time: 68.77 s 
2025-07-12 01:06:18.066360: Yayy! New best EMA pseudo Dice: 0.9532999992370605 
2025-07-12 01:06:20.183164:  
2025-07-12 01:06:20.185795: Epoch 441 
2025-07-12 01:06:20.186830: Current learning rate: 0.00592 
2025-07-12 01:07:29.097087: train_loss -0.9751 
2025-07-12 01:07:29.098630: val_loss -0.952 
2025-07-12 01:07:29.099650: Pseudo dice [np.float32(0.956)] 
2025-07-12 01:07:29.100911: Epoch time: 68.92 s 
2025-07-12 01:07:29.102372: Yayy! New best EMA pseudo Dice: 0.9535999894142151 
2025-07-12 01:07:31.440962:  
2025-07-12 01:07:31.442531: Epoch 442 
2025-07-12 01:07:31.443907: Current learning rate: 0.00592 
2025-07-12 01:08:40.204355: train_loss -0.9763 
2025-07-12 01:08:40.205586: val_loss -0.9506 
2025-07-12 01:08:40.206569: Pseudo dice [np.float32(0.9541)] 
2025-07-12 01:08:40.207704: Epoch time: 68.77 s 
2025-07-12 01:08:40.209440: Yayy! New best EMA pseudo Dice: 0.9535999894142151 
2025-07-12 01:08:42.504064:  
2025-07-12 01:08:42.506506: Epoch 443 
2025-07-12 01:08:42.507965: Current learning rate: 0.00591 
2025-07-12 01:09:51.468841: train_loss -0.9752 
2025-07-12 01:09:51.470574: val_loss -0.949 
2025-07-12 01:09:51.471723: Pseudo dice [np.float32(0.9536)] 
2025-07-12 01:09:51.473071: Epoch time: 68.97 s 
2025-07-12 01:09:52.393060:  
2025-07-12 01:09:52.395334: Epoch 444 
2025-07-12 01:09:52.396558: Current learning rate: 0.0059 
2025-07-12 01:11:01.265328: train_loss -0.9751 
2025-07-12 01:11:01.266693: val_loss -0.9485 
2025-07-12 01:11:01.268123: Pseudo dice [np.float32(0.9526)] 
2025-07-12 01:11:01.269267: Epoch time: 68.88 s 
2025-07-12 01:11:02.192828:  
2025-07-12 01:11:02.194934: Epoch 445 
2025-07-12 01:11:02.196110: Current learning rate: 0.00589 
2025-07-12 01:12:11.049452: train_loss -0.9742 
2025-07-12 01:12:11.052182: val_loss -0.9522 
2025-07-12 01:12:11.053486: Pseudo dice [np.float32(0.9553)] 
2025-07-12 01:12:11.054678: Epoch time: 68.86 s 
2025-07-12 01:12:11.055976: Yayy! New best EMA pseudo Dice: 0.9537000060081482 
2025-07-12 01:12:13.272504:  
2025-07-12 01:12:13.274823: Epoch 446 
2025-07-12 01:12:13.276051: Current learning rate: 0.00588 
2025-07-12 01:13:21.854520: train_loss -0.9751 
2025-07-12 01:13:21.856276: val_loss -0.9457 
2025-07-12 01:13:21.858746: Pseudo dice [np.float32(0.9497)] 
2025-07-12 01:13:21.859812: Epoch time: 68.59 s 
2025-07-12 01:13:22.773155:  
2025-07-12 01:13:22.775393: Epoch 447 
2025-07-12 01:13:22.776731: Current learning rate: 0.00587 
2025-07-12 01:14:32.446097: train_loss -0.9746 
2025-07-12 01:14:32.447312: val_loss -0.9456 
2025-07-12 01:14:32.448753: Pseudo dice [np.float32(0.9496)] 
2025-07-12 01:14:32.450579: Epoch time: 69.68 s 
2025-07-12 01:14:33.371534:  
2025-07-12 01:14:33.373819: Epoch 448 
2025-07-12 01:14:33.374973: Current learning rate: 0.00586 
2025-07-12 01:15:42.452228: train_loss -0.9752 
2025-07-12 01:15:42.453649: val_loss -0.9491 
2025-07-12 01:15:42.454738: Pseudo dice [np.float32(0.9525)] 
2025-07-12 01:15:42.455892: Epoch time: 69.08 s 
2025-07-12 01:15:43.378286:  
2025-07-12 01:15:43.380418: Epoch 449 
2025-07-12 01:15:43.381559: Current learning rate: 0.00585 
2025-07-12 01:16:52.418104: train_loss -0.9749 
2025-07-12 01:16:52.419502: val_loss -0.9492 
2025-07-12 01:16:52.420812: Pseudo dice [np.float32(0.9529)] 
2025-07-12 01:16:52.422338: Epoch time: 69.04 s 
2025-07-12 01:16:54.625087:  
2025-07-12 01:16:54.627245: Epoch 450 
2025-07-12 01:16:54.628459: Current learning rate: 0.00584 
2025-07-12 01:18:03.473724: train_loss -0.9737 
2025-07-12 01:18:03.475199: val_loss -0.948 
2025-07-12 01:18:03.476423: Pseudo dice [np.float32(0.9519)] 
2025-07-12 01:18:03.477455: Epoch time: 68.85 s 
2025-07-12 01:18:04.407180:  
2025-07-12 01:18:04.409766: Epoch 451 
2025-07-12 01:18:04.411280: Current learning rate: 0.00583 
2025-07-12 01:19:13.324293: train_loss -0.9735 
2025-07-12 01:19:13.325622: val_loss -0.9509 
2025-07-12 01:19:13.326627: Pseudo dice [np.float32(0.9545)] 
2025-07-12 01:19:13.328006: Epoch time: 68.92 s 
2025-07-12 01:19:14.249998:  
2025-07-12 01:19:14.252214: Epoch 452 
2025-07-12 01:19:14.253412: Current learning rate: 0.00582 
2025-07-12 01:20:23.226913: train_loss -0.9739 
2025-07-12 01:20:23.228314: val_loss -0.9483 
2025-07-12 01:20:23.229509: Pseudo dice [np.float32(0.9514)] 
2025-07-12 01:20:23.231190: Epoch time: 68.98 s 
2025-07-12 01:20:24.169568:  
2025-07-12 01:20:24.172047: Epoch 453 
2025-07-12 01:20:24.173347: Current learning rate: 0.00581 
2025-07-12 01:21:33.160928: train_loss -0.975 
2025-07-12 01:21:33.162199: val_loss -0.95 
2025-07-12 01:21:33.163382: Pseudo dice [np.float32(0.9547)] 
2025-07-12 01:21:33.164545: Epoch time: 69.0 s 
2025-07-12 01:21:34.083185:  
2025-07-12 01:21:34.085267: Epoch 454 
2025-07-12 01:21:34.086312: Current learning rate: 0.0058 
2025-07-12 01:22:42.819756: train_loss -0.9758 
2025-07-12 01:22:42.821045: val_loss -0.9491 
2025-07-12 01:22:42.822259: Pseudo dice [np.float32(0.9533)] 
2025-07-12 01:22:42.823591: Epoch time: 68.74 s 
2025-07-12 01:22:43.730577:  
2025-07-12 01:22:43.733137: Epoch 455 
2025-07-12 01:22:43.734421: Current learning rate: 0.00579 
2025-07-12 01:23:52.763051: train_loss -0.9756 
2025-07-12 01:23:52.764396: val_loss -0.9528 
2025-07-12 01:23:52.766092: Pseudo dice [np.float32(0.9569)] 
2025-07-12 01:23:52.767230: Epoch time: 69.04 s 
2025-07-12 01:23:53.702594:  
2025-07-12 01:23:53.705283: Epoch 456 
2025-07-12 01:23:53.706517: Current learning rate: 0.00578 
2025-07-12 01:25:03.660566: train_loss -0.9753 
2025-07-12 01:25:03.661874: val_loss -0.9488 
2025-07-12 01:25:03.662812: Pseudo dice [np.float32(0.9522)] 
2025-07-12 01:25:03.663984: Epoch time: 69.96 s 
2025-07-12 01:25:04.594234:  
2025-07-12 01:25:04.596637: Epoch 457 
2025-07-12 01:25:04.597680: Current learning rate: 0.00577 
2025-07-12 01:26:13.690582: train_loss -0.9742 
2025-07-12 01:26:13.692383: val_loss -0.9492 
2025-07-12 01:26:13.693764: Pseudo dice [np.float32(0.9523)] 
2025-07-12 01:26:13.695212: Epoch time: 69.1 s 
2025-07-12 01:26:14.665199:  
2025-07-12 01:26:14.668089: Epoch 458 
2025-07-12 01:26:14.669469: Current learning rate: 0.00576 
2025-07-12 01:27:23.846363: train_loss -0.9748 
2025-07-12 01:27:23.847749: val_loss -0.9512 
2025-07-12 01:27:23.848914: Pseudo dice [np.float32(0.9548)] 
2025-07-12 01:27:23.850070: Epoch time: 69.18 s 
2025-07-12 01:27:24.784863:  
2025-07-12 01:27:24.787002: Epoch 459 
2025-07-12 01:27:24.788231: Current learning rate: 0.00575 
2025-07-12 01:28:33.971947: train_loss -0.9749 
2025-07-12 01:28:33.973619: val_loss -0.9497 
2025-07-12 01:28:33.974967: Pseudo dice [np.float32(0.9547)] 
2025-07-12 01:28:33.976180: Epoch time: 69.19 s 
2025-07-12 01:28:34.910219:  
2025-07-12 01:28:34.912550: Epoch 460 
2025-07-12 01:28:34.914147: Current learning rate: 0.00574 
2025-07-12 01:29:43.690464: train_loss -0.9756 
2025-07-12 01:29:43.691839: val_loss -0.9505 
2025-07-12 01:29:43.692864: Pseudo dice [np.float32(0.9546)] 
2025-07-12 01:29:43.693992: Epoch time: 68.78 s 
2025-07-12 01:29:44.617901:  
2025-07-12 01:29:44.620152: Epoch 461 
2025-07-12 01:29:44.621318: Current learning rate: 0.00573 
2025-07-12 01:30:53.526661: train_loss -0.9729 
2025-07-12 01:30:53.528139: val_loss -0.9464 
2025-07-12 01:30:53.529565: Pseudo dice [np.float32(0.9512)] 
2025-07-12 01:30:53.531241: Epoch time: 68.91 s 
2025-07-12 01:30:54.453618:  
2025-07-12 01:30:54.455912: Epoch 462 
2025-07-12 01:30:54.457116: Current learning rate: 0.00572 
2025-07-12 01:32:03.315190: train_loss -0.9734 
2025-07-12 01:32:03.316404: val_loss -0.9501 
2025-07-12 01:32:03.317566: Pseudo dice [np.float32(0.9538)] 
2025-07-12 01:32:03.318629: Epoch time: 68.87 s 
2025-07-12 01:32:04.241341:  
2025-07-12 01:32:04.244174: Epoch 463 
2025-07-12 01:32:04.245797: Current learning rate: 0.00571 
2025-07-12 01:33:13.039609: train_loss -0.9739 
2025-07-12 01:33:13.040973: val_loss -0.9469 
2025-07-12 01:33:13.042310: Pseudo dice [np.float32(0.9505)] 
2025-07-12 01:33:13.043618: Epoch time: 68.8 s 
2025-07-12 01:33:13.956271:  
2025-07-12 01:33:13.958103: Epoch 464 
2025-07-12 01:33:13.959452: Current learning rate: 0.0057 
2025-07-12 01:34:22.825248: train_loss -0.9751 
2025-07-12 01:34:22.826592: val_loss -0.9515 
2025-07-12 01:34:22.827853: Pseudo dice [np.float32(0.9558)] 
2025-07-12 01:34:22.828739: Epoch time: 68.87 s 
2025-07-12 01:34:23.742209:  
2025-07-12 01:34:23.744335: Epoch 465 
2025-07-12 01:34:23.745543: Current learning rate: 0.0057 
2025-07-12 01:35:32.773364: train_loss -0.9734 
2025-07-12 01:35:32.775737: val_loss -0.9463 
2025-07-12 01:35:32.777435: Pseudo dice [np.float32(0.9506)] 
2025-07-12 01:35:32.779263: Epoch time: 69.03 s 
2025-07-12 01:35:34.507654:  
2025-07-12 01:35:34.509863: Epoch 466 
2025-07-12 01:35:34.511417: Current learning rate: 0.00569 
2025-07-12 01:36:43.559077: train_loss -0.9739 
2025-07-12 01:36:43.560536: val_loss -0.9493 
2025-07-12 01:36:43.561811: Pseudo dice [np.float32(0.9532)] 
2025-07-12 01:36:43.562751: Epoch time: 69.06 s 
2025-07-12 01:36:44.493283:  
2025-07-12 01:36:44.496226: Epoch 467 
2025-07-12 01:36:44.497442: Current learning rate: 0.00568 
2025-07-12 01:37:53.401317: train_loss -0.9752 
2025-07-12 01:37:53.402643: val_loss -0.9472 
2025-07-12 01:37:53.403771: Pseudo dice [np.float32(0.951)] 
2025-07-12 01:37:53.405606: Epoch time: 68.91 s 
2025-07-12 01:37:54.337209:  
2025-07-12 01:37:54.339746: Epoch 468 
2025-07-12 01:37:54.340999: Current learning rate: 0.00567 
2025-07-12 01:39:03.096257: train_loss -0.9743 
2025-07-12 01:39:03.097694: val_loss -0.9457 
2025-07-12 01:39:03.098915: Pseudo dice [np.float32(0.9504)] 
2025-07-12 01:39:03.099955: Epoch time: 68.76 s 
2025-07-12 01:39:04.000719:  
2025-07-12 01:39:04.002558: Epoch 469 
2025-07-12 01:39:04.003695: Current learning rate: 0.00566 
2025-07-12 01:40:13.061968: train_loss -0.9723 
2025-07-12 01:40:13.067801: val_loss -0.9485 
2025-07-12 01:40:13.069085: Pseudo dice [np.float32(0.9516)] 
2025-07-12 01:40:13.070451: Epoch time: 69.06 s 
2025-07-12 01:40:14.017837:  
2025-07-12 01:40:14.020183: Epoch 470 
2025-07-12 01:40:14.021472: Current learning rate: 0.00565 
2025-07-12 01:41:22.894231: train_loss -0.9734 
2025-07-12 01:41:22.895757: val_loss -0.9519 
2025-07-12 01:41:22.897095: Pseudo dice [np.float32(0.9554)] 
2025-07-12 01:41:22.898475: Epoch time: 68.88 s 
2025-07-12 01:41:23.820052:  
2025-07-12 01:41:23.822457: Epoch 471 
2025-07-12 01:41:23.823839: Current learning rate: 0.00564 
2025-07-12 01:42:32.719062: train_loss -0.9742 
2025-07-12 01:42:32.720672: val_loss -0.9463 
2025-07-12 01:42:32.722188: Pseudo dice [np.float32(0.9502)] 
2025-07-12 01:42:32.723331: Epoch time: 68.9 s 
2025-07-12 01:42:33.647127:  
2025-07-12 01:42:33.649173: Epoch 472 
2025-07-12 01:42:33.650322: Current learning rate: 0.00563 
2025-07-12 01:43:42.654207: train_loss -0.973 
2025-07-12 01:43:42.656035: val_loss -0.9494 
2025-07-12 01:43:42.657147: Pseudo dice [np.float32(0.9527)] 
2025-07-12 01:43:42.658563: Epoch time: 69.01 s 
2025-07-12 01:43:43.600545:  
2025-07-12 01:43:43.603037: Epoch 473 
2025-07-12 01:43:43.604294: Current learning rate: 0.00562 
2025-07-12 01:44:52.781489: train_loss -0.9753 
2025-07-12 01:44:52.782736: val_loss -0.9518 
2025-07-12 01:44:52.783648: Pseudo dice [np.float32(0.9559)] 
2025-07-12 01:44:52.784659: Epoch time: 69.18 s 
2025-07-12 01:44:53.726999:  
2025-07-12 01:44:53.729581: Epoch 474 
2025-07-12 01:44:53.731268: Current learning rate: 0.00561 
2025-07-12 01:46:02.489800: train_loss -0.975 
2025-07-12 01:46:02.491035: val_loss -0.9499 
2025-07-12 01:46:02.492119: Pseudo dice [np.float32(0.9537)] 
2025-07-12 01:46:02.493887: Epoch time: 68.77 s 
2025-07-12 01:46:03.415502:  
2025-07-12 01:46:03.417742: Epoch 475 
2025-07-12 01:46:03.419480: Current learning rate: 0.0056 
2025-07-12 01:47:13.190273: train_loss -0.9752 
2025-07-12 01:47:13.192050: val_loss -0.9472 
2025-07-12 01:47:13.193729: Pseudo dice [np.float32(0.9518)] 
2025-07-12 01:47:13.195348: Epoch time: 69.78 s 
2025-07-12 01:47:14.093771:  
2025-07-12 01:47:14.096078: Epoch 476 
2025-07-12 01:47:14.097281: Current learning rate: 0.00559 
2025-07-12 01:48:23.173888: train_loss -0.9734 
2025-07-12 01:48:23.175204: val_loss -0.9484 
2025-07-12 01:48:23.176120: Pseudo dice [np.float32(0.9523)] 
2025-07-12 01:48:23.177299: Epoch time: 69.08 s 
2025-07-12 01:48:24.097925:  
2025-07-12 01:48:24.100664: Epoch 477 
2025-07-12 01:48:24.101952: Current learning rate: 0.00558 
2025-07-12 01:49:32.956564: train_loss -0.975 
2025-07-12 01:49:32.958233: val_loss -0.9469 
2025-07-12 01:49:32.959347: Pseudo dice [np.float32(0.9507)] 
2025-07-12 01:49:32.960451: Epoch time: 68.86 s 
2025-07-12 01:49:33.896369:  
2025-07-12 01:49:33.898520: Epoch 478 
2025-07-12 01:49:33.899726: Current learning rate: 0.00557 
2025-07-12 01:50:42.756306: train_loss -0.9753 
2025-07-12 01:50:42.757805: val_loss -0.9469 
2025-07-12 01:50:42.758965: Pseudo dice [np.float32(0.9509)] 
2025-07-12 01:50:42.759958: Epoch time: 68.86 s 
2025-07-12 01:50:43.674639:  
2025-07-12 01:50:43.677229: Epoch 479 
2025-07-12 01:50:43.678398: Current learning rate: 0.00556 
2025-07-12 01:51:52.548907: train_loss -0.9753 
2025-07-12 01:51:52.550451: val_loss -0.9507 
2025-07-12 01:51:52.551616: Pseudo dice [np.float32(0.9543)] 
2025-07-12 01:51:52.552939: Epoch time: 68.88 s 
2025-07-12 01:51:53.578469:  
2025-07-12 01:51:53.581228: Epoch 480 
2025-07-12 01:51:53.582324: Current learning rate: 0.00555 
2025-07-12 01:53:02.610843: train_loss -0.9747 
2025-07-12 01:53:02.612333: val_loss -0.9491 
2025-07-12 01:53:02.613396: Pseudo dice [np.float32(0.9524)] 
2025-07-12 01:53:02.614396: Epoch time: 69.04 s 
2025-07-12 01:53:03.547842:  
2025-07-12 01:53:03.550567: Epoch 481 
2025-07-12 01:53:03.552262: Current learning rate: 0.00554 
2025-07-12 01:54:12.594741: train_loss -0.9746 
2025-07-12 01:54:12.596879: val_loss -0.9499 
2025-07-12 01:54:12.598552: Pseudo dice [np.float32(0.9535)] 
2025-07-12 01:54:12.599622: Epoch time: 69.05 s 
2025-07-12 01:54:13.538162:  
2025-07-12 01:54:13.540842: Epoch 482 
2025-07-12 01:54:13.542161: Current learning rate: 0.00553 
2025-07-12 01:55:22.562884: train_loss -0.9748 
2025-07-12 01:55:22.564095: val_loss -0.9477 
2025-07-12 01:55:22.565086: Pseudo dice [np.float32(0.9518)] 
2025-07-12 01:55:22.566256: Epoch time: 69.03 s 
2025-07-12 01:55:23.498551:  
2025-07-12 01:55:23.500705: Epoch 483 
2025-07-12 01:55:23.501924: Current learning rate: 0.00552 
2025-07-12 01:56:32.154204: train_loss -0.9741 
2025-07-12 01:56:32.155599: val_loss -0.9504 
2025-07-12 01:56:32.156713: Pseudo dice [np.float32(0.9549)] 
2025-07-12 01:56:32.157900: Epoch time: 68.66 s 
2025-07-12 01:56:33.084166:  
2025-07-12 01:56:33.086207: Epoch 484 
2025-07-12 01:56:33.087243: Current learning rate: 0.00551 
2025-07-12 01:57:42.320215: train_loss -0.9735 
2025-07-12 01:57:42.322562: val_loss -0.9492 
2025-07-12 01:57:42.323666: Pseudo dice [np.float32(0.9524)] 
2025-07-12 01:57:42.324626: Epoch time: 69.24 s 
2025-07-12 01:57:43.307914:  
2025-07-12 01:57:43.310539: Epoch 485 
2025-07-12 01:57:43.311831: Current learning rate: 0.0055 
2025-07-12 01:58:51.947373: train_loss -0.9732 
2025-07-12 01:58:51.948863: val_loss -0.9482 
2025-07-12 01:58:51.950700: Pseudo dice [np.float32(0.9514)] 
2025-07-12 01:58:51.952337: Epoch time: 68.64 s 
2025-07-12 01:58:52.878054:  
2025-07-12 01:58:52.880356: Epoch 486 
2025-07-12 01:58:52.881554: Current learning rate: 0.00549 
2025-07-12 02:00:01.706043: train_loss -0.9742 
2025-07-12 02:00:01.707577: val_loss -0.9473 
2025-07-12 02:00:01.708997: Pseudo dice [np.float32(0.9507)] 
2025-07-12 02:00:01.710643: Epoch time: 68.83 s 
2025-07-12 02:00:02.658254:  
2025-07-12 02:00:02.660541: Epoch 487 
2025-07-12 02:00:02.661793: Current learning rate: 0.00548 
2025-07-12 02:01:11.346988: train_loss -0.9738 
2025-07-12 02:01:11.348785: val_loss -0.9464 
2025-07-12 02:01:11.350359: Pseudo dice [np.float32(0.9503)] 
2025-07-12 02:01:11.351524: Epoch time: 68.69 s 
2025-07-12 02:01:12.321310:  
2025-07-12 02:01:12.323878: Epoch 488 
2025-07-12 02:01:12.325221: Current learning rate: 0.00547 
2025-07-12 02:02:20.970393: train_loss -0.9739 
2025-07-12 02:02:20.972180: val_loss -0.9497 
2025-07-12 02:02:20.974265: Pseudo dice [np.float32(0.9537)] 
2025-07-12 02:02:20.975599: Epoch time: 68.65 s 
2025-07-12 02:02:21.910772:  
2025-07-12 02:02:21.913673: Epoch 489 
2025-07-12 02:02:21.915373: Current learning rate: 0.00546 
2025-07-12 02:03:30.647546: train_loss -0.9751 
2025-07-12 02:03:30.649010: val_loss -0.9501 
2025-07-12 02:03:30.650182: Pseudo dice [np.float32(0.954)] 
2025-07-12 02:03:30.651394: Epoch time: 68.74 s 
2025-07-12 02:03:31.587438:  
2025-07-12 02:03:31.589577: Epoch 490 
2025-07-12 02:03:31.591440: Current learning rate: 0.00546 
2025-07-12 02:04:40.366642: train_loss -0.9738 
2025-07-12 02:04:40.368958: val_loss -0.9489 
2025-07-12 02:04:40.370125: Pseudo dice [np.float32(0.952)] 
2025-07-12 02:04:40.371247: Epoch time: 68.78 s 
2025-07-12 02:04:41.323225:  
2025-07-12 02:04:41.324997: Epoch 491 
2025-07-12 02:04:41.326384: Current learning rate: 0.00545 
2025-07-12 02:05:50.219523: train_loss -0.9753 
2025-07-12 02:05:50.221833: val_loss -0.9508 
2025-07-12 02:05:50.223415: Pseudo dice [np.float32(0.9542)] 
2025-07-12 02:05:50.224777: Epoch time: 68.9 s 
2025-07-12 02:05:51.176039:  
2025-07-12 02:05:51.178072: Epoch 492 
2025-07-12 02:05:51.179553: Current learning rate: 0.00544 
2025-07-12 02:06:59.885134: train_loss -0.9755 
2025-07-12 02:06:59.886438: val_loss -0.9516 
2025-07-12 02:06:59.888117: Pseudo dice [np.float32(0.9547)] 
2025-07-12 02:06:59.889452: Epoch time: 68.71 s 
2025-07-12 02:07:00.814538:  
2025-07-12 02:07:00.816504: Epoch 493 
2025-07-12 02:07:00.817822: Current learning rate: 0.00543 
2025-07-12 02:08:10.357630: train_loss -0.9759 
2025-07-12 02:08:10.359430: val_loss -0.95 
2025-07-12 02:08:10.360887: Pseudo dice [np.float32(0.9533)] 
2025-07-12 02:08:10.362281: Epoch time: 69.55 s 
2025-07-12 02:08:11.302969:  
2025-07-12 02:08:11.305141: Epoch 494 
2025-07-12 02:08:11.306289: Current learning rate: 0.00542 
2025-07-12 02:09:20.013177: train_loss -0.9757 
2025-07-12 02:09:20.014475: val_loss -0.9483 
2025-07-12 02:09:20.016343: Pseudo dice [np.float32(0.9517)] 
2025-07-12 02:09:20.017870: Epoch time: 68.71 s 
2025-07-12 02:09:20.941828:  
2025-07-12 02:09:20.944125: Epoch 495 
2025-07-12 02:09:20.945243: Current learning rate: 0.00541 
2025-07-12 02:10:29.688267: train_loss -0.9752 
2025-07-12 02:10:29.690364: val_loss -0.9489 
2025-07-12 02:10:29.692120: Pseudo dice [np.float32(0.9528)] 
2025-07-12 02:10:29.693225: Epoch time: 68.75 s 
2025-07-12 02:10:30.634131:  
2025-07-12 02:10:30.636294: Epoch 496 
2025-07-12 02:10:30.637439: Current learning rate: 0.0054 
2025-07-12 02:11:39.316970: train_loss -0.9757 
2025-07-12 02:11:39.318184: val_loss -0.9475 
2025-07-12 02:11:39.319231: Pseudo dice [np.float32(0.9512)] 
2025-07-12 02:11:39.320471: Epoch time: 68.69 s 
2025-07-12 02:11:40.248183:  
2025-07-12 02:11:40.250565: Epoch 497 
2025-07-12 02:11:40.252337: Current learning rate: 0.00539 
2025-07-12 02:12:48.885760: train_loss -0.9754 
2025-07-12 02:12:48.886910: val_loss -0.95 
2025-07-12 02:12:48.888837: Pseudo dice [np.float32(0.9536)] 
2025-07-12 02:12:48.890489: Epoch time: 68.64 s 
2025-07-12 02:12:49.786694:  
2025-07-12 02:12:49.789094: Epoch 498 
2025-07-12 02:12:49.790292: Current learning rate: 0.00538 
2025-07-12 02:13:58.345812: train_loss -0.9757 
2025-07-12 02:13:58.347511: val_loss -0.9529 
2025-07-12 02:13:58.348702: Pseudo dice [np.float32(0.9571)] 
2025-07-12 02:13:58.349694: Epoch time: 68.56 s 
2025-07-12 02:13:59.288720:  
2025-07-12 02:13:59.290530: Epoch 499 
2025-07-12 02:13:59.291498: Current learning rate: 0.00537 
2025-07-12 02:15:07.907995: train_loss -0.9754 
2025-07-12 02:15:07.909712: val_loss -0.9489 
2025-07-12 02:15:07.910936: Pseudo dice [np.float32(0.953)] 
2025-07-12 02:15:07.912159: Epoch time: 68.62 s 
2025-07-12 02:15:10.344255:  
2025-07-12 02:15:10.346442: Epoch 500 
2025-07-12 02:15:10.347485: Current learning rate: 0.00536 
2025-07-12 02:16:19.155950: train_loss -0.9746 
2025-07-12 02:16:19.157493: val_loss -0.9464 
2025-07-12 02:16:19.158420: Pseudo dice [np.float32(0.951)] 
2025-07-12 02:16:19.159590: Epoch time: 68.82 s 
2025-07-12 02:16:20.090360:  
2025-07-12 02:16:20.093150: Epoch 501 
2025-07-12 02:16:20.094652: Current learning rate: 0.00535 
2025-07-12 02:17:28.901591: train_loss -0.9743 
2025-07-12 02:17:28.904279: val_loss -0.9523 
2025-07-12 02:17:28.905338: Pseudo dice [np.float32(0.9559)] 
2025-07-12 02:17:28.906620: Epoch time: 68.81 s 
2025-07-12 02:17:30.657215:  
2025-07-12 02:17:30.659186: Epoch 502 
2025-07-12 02:17:30.660271: Current learning rate: 0.00534 
2025-07-12 02:18:39.440756: train_loss -0.974 
2025-07-12 02:18:39.442209: val_loss -0.9433 
2025-07-12 02:18:39.443281: Pseudo dice [np.float32(0.9467)] 
2025-07-12 02:18:39.444645: Epoch time: 68.79 s 
2025-07-12 02:18:40.383452:  
2025-07-12 02:18:40.385379: Epoch 503 
2025-07-12 02:18:40.386698: Current learning rate: 0.00533 
2025-07-12 02:19:48.990139: train_loss -0.9747 
2025-07-12 02:19:48.991660: val_loss -0.9471 
2025-07-12 02:19:48.992851: Pseudo dice [np.float32(0.9498)] 
2025-07-12 02:19:48.994014: Epoch time: 68.61 s 
2025-07-12 02:19:49.935079:  
2025-07-12 02:19:49.937162: Epoch 504 
2025-07-12 02:19:49.938349: Current learning rate: 0.00532 
2025-07-12 02:20:58.538121: train_loss -0.9742 
2025-07-12 02:20:58.539247: val_loss -0.9491 
2025-07-12 02:20:58.540274: Pseudo dice [np.float32(0.9528)] 
2025-07-12 02:20:58.541765: Epoch time: 68.61 s 
2025-07-12 02:20:59.508484:  
2025-07-12 02:20:59.510681: Epoch 505 
2025-07-12 02:20:59.511840: Current learning rate: 0.00531 
2025-07-12 02:22:08.082850: train_loss -0.9758 
2025-07-12 02:22:08.084252: val_loss -0.9477 
2025-07-12 02:22:08.085536: Pseudo dice [np.float32(0.9513)] 
2025-07-12 02:22:08.087114: Epoch time: 68.58 s 
2025-07-12 02:22:09.023692:  
2025-07-12 02:22:09.025748: Epoch 506 
2025-07-12 02:22:09.026936: Current learning rate: 0.0053 
2025-07-12 02:23:17.711864: train_loss -0.9759 
2025-07-12 02:23:17.713421: val_loss -0.95 
2025-07-12 02:23:17.714400: Pseudo dice [np.float32(0.9538)] 
2025-07-12 02:23:17.715672: Epoch time: 68.69 s 
2025-07-12 02:23:18.606679:  
2025-07-12 02:23:18.609212: Epoch 507 
2025-07-12 02:23:18.610329: Current learning rate: 0.00529 
2025-07-12 02:24:27.394483: train_loss -0.9765 
2025-07-12 02:24:27.395852: val_loss -0.9503 
2025-07-12 02:24:27.397044: Pseudo dice [np.float32(0.9534)] 
2025-07-12 02:24:27.399015: Epoch time: 68.79 s 
2025-07-12 02:24:28.330882:  
2025-07-12 02:24:28.333223: Epoch 508 
2025-07-12 02:24:28.334563: Current learning rate: 0.00528 
2025-07-12 02:25:37.091046: train_loss -0.9758 
2025-07-12 02:25:37.092356: val_loss -0.9501 
2025-07-12 02:25:37.093405: Pseudo dice [np.float32(0.9549)] 
2025-07-12 02:25:37.094463: Epoch time: 68.76 s 
2025-07-12 02:25:38.031439:  
2025-07-12 02:25:38.034209: Epoch 509 
2025-07-12 02:25:38.035458: Current learning rate: 0.00527 
2025-07-12 02:26:47.048216: train_loss -0.9767 
2025-07-12 02:26:47.049377: val_loss -0.9495 
2025-07-12 02:26:47.050444: Pseudo dice [np.float32(0.9526)] 
2025-07-12 02:26:47.051463: Epoch time: 69.02 s 
2025-07-12 02:26:47.971156:  
2025-07-12 02:26:47.973200: Epoch 510 
2025-07-12 02:26:47.974470: Current learning rate: 0.00526 
2025-07-12 02:27:56.961056: train_loss -0.9769 
2025-07-12 02:27:56.962729: val_loss -0.9483 
2025-07-12 02:27:56.963789: Pseudo dice [np.float32(0.9525)] 
2025-07-12 02:27:56.964980: Epoch time: 68.99 s 
2025-07-12 02:27:58.701763:  
2025-07-12 02:27:58.703894: Epoch 511 
2025-07-12 02:27:58.705225: Current learning rate: 0.00525 
2025-07-12 02:29:07.724409: train_loss -0.9767 
2025-07-12 02:29:07.725683: val_loss -0.9491 
2025-07-12 02:29:07.727238: Pseudo dice [np.float32(0.9526)] 
2025-07-12 02:29:07.728148: Epoch time: 69.03 s 
2025-07-12 02:29:08.667475:  
2025-07-12 02:29:08.669841: Epoch 512 
2025-07-12 02:29:08.670869: Current learning rate: 0.00524 
2025-07-12 02:30:17.639364: train_loss -0.9764 
2025-07-12 02:30:17.640851: val_loss -0.9467 
2025-07-12 02:30:17.641905: Pseudo dice [np.float32(0.9507)] 
2025-07-12 02:30:17.643022: Epoch time: 68.98 s 
2025-07-12 02:30:18.558312:  
2025-07-12 02:30:18.560313: Epoch 513 
2025-07-12 02:30:18.561662: Current learning rate: 0.00523 
2025-07-12 02:31:27.646652: train_loss -0.9764 
2025-07-12 02:31:27.647936: val_loss -0.9465 
2025-07-12 02:31:27.649506: Pseudo dice [np.float32(0.9505)] 
2025-07-12 02:31:27.650611: Epoch time: 69.09 s 
2025-07-12 02:31:28.585139:  
2025-07-12 02:31:28.587254: Epoch 514 
2025-07-12 02:31:28.588351: Current learning rate: 0.00522 
2025-07-12 02:32:37.592439: train_loss -0.9758 
2025-07-12 02:32:37.593899: val_loss -0.9477 
2025-07-12 02:32:37.595564: Pseudo dice [np.float32(0.9516)] 
2025-07-12 02:32:37.596987: Epoch time: 69.01 s 
2025-07-12 02:32:38.532892:  
2025-07-12 02:32:38.535125: Epoch 515 
2025-07-12 02:32:38.536570: Current learning rate: 0.00521 
2025-07-12 02:33:47.633246: train_loss -0.9756 
2025-07-12 02:33:47.634621: val_loss -0.9508 
2025-07-12 02:33:47.635783: Pseudo dice [np.float32(0.9539)] 
2025-07-12 02:33:47.637009: Epoch time: 69.1 s 
2025-07-12 02:33:48.558008:  
2025-07-12 02:33:48.560099: Epoch 516 
2025-07-12 02:33:48.561536: Current learning rate: 0.0052 
2025-07-12 02:34:57.653154: train_loss -0.9753 
2025-07-12 02:34:57.654366: val_loss -0.9506 
2025-07-12 02:34:57.655475: Pseudo dice [np.float32(0.9541)] 
2025-07-12 02:34:57.656494: Epoch time: 69.1 s 
2025-07-12 02:34:58.576236:  
2025-07-12 02:34:58.578738: Epoch 517 
2025-07-12 02:34:58.580202: Current learning rate: 0.00519 
2025-07-12 02:36:07.523683: train_loss -0.9761 
2025-07-12 02:36:07.524964: val_loss -0.9481 
2025-07-12 02:36:07.526192: Pseudo dice [np.float32(0.9518)] 
2025-07-12 02:36:07.527447: Epoch time: 68.95 s 
2025-07-12 02:36:08.462317:  
2025-07-12 02:36:08.464705: Epoch 518 
2025-07-12 02:36:08.465909: Current learning rate: 0.00518 
2025-07-12 02:37:17.688094: train_loss -0.9746 
2025-07-12 02:37:17.689426: val_loss -0.9442 
2025-07-12 02:37:17.690467: Pseudo dice [np.float32(0.9485)] 
2025-07-12 02:37:17.691666: Epoch time: 69.23 s 
2025-07-12 02:37:18.629663:  
2025-07-12 02:37:18.631832: Epoch 519 
2025-07-12 02:37:18.633010: Current learning rate: 0.00518 
2025-07-12 02:38:27.766199: train_loss -0.9757 
2025-07-12 02:38:27.767807: val_loss -0.9491 
2025-07-12 02:38:27.768776: Pseudo dice [np.float32(0.953)] 
2025-07-12 02:38:27.770209: Epoch time: 69.14 s 
2025-07-12 02:38:28.679800:  
2025-07-12 02:38:28.681720: Epoch 520 
2025-07-12 02:38:28.682915: Current learning rate: 0.00517 
2025-07-12 02:39:38.316576: train_loss -0.9754 
2025-07-12 02:39:38.318228: val_loss -0.948 
2025-07-12 02:39:38.319890: Pseudo dice [np.float32(0.9521)] 
2025-07-12 02:39:38.321085: Epoch time: 69.64 s 
2025-07-12 02:39:39.241866:  
2025-07-12 02:39:39.244346: Epoch 521 
2025-07-12 02:39:39.245716: Current learning rate: 0.00516 
2025-07-12 02:40:48.089696: train_loss -0.9759 
2025-07-12 02:40:48.090984: val_loss -0.9528 
2025-07-12 02:40:48.092169: Pseudo dice [np.float32(0.9556)] 
2025-07-12 02:40:48.093632: Epoch time: 68.85 s 
2025-07-12 02:40:48.981703:  
2025-07-12 02:40:48.984199: Epoch 522 
2025-07-12 02:40:48.985405: Current learning rate: 0.00515 
2025-07-12 02:41:57.803942: train_loss -0.9761 
2025-07-12 02:41:57.805401: val_loss -0.9485 
2025-07-12 02:41:57.806530: Pseudo dice [np.float32(0.9513)] 
2025-07-12 02:41:57.807923: Epoch time: 68.83 s 
2025-07-12 02:41:58.734972:  
2025-07-12 02:41:58.737377: Epoch 523 
2025-07-12 02:41:58.738601: Current learning rate: 0.00514 
2025-07-12 02:43:07.557806: train_loss -0.9772 
2025-07-12 02:43:07.559806: val_loss -0.9501 
2025-07-12 02:43:07.561559: Pseudo dice [np.float32(0.9536)] 
2025-07-12 02:43:07.562647: Epoch time: 68.83 s 
2025-07-12 02:43:08.492245:  
2025-07-12 02:43:08.494185: Epoch 524 
2025-07-12 02:43:08.495184: Current learning rate: 0.00513 
2025-07-12 02:44:17.265266: train_loss -0.9766 
2025-07-12 02:44:17.266846: val_loss -0.9466 
2025-07-12 02:44:17.268059: Pseudo dice [np.float32(0.9505)] 
2025-07-12 02:44:17.269361: Epoch time: 68.78 s 
2025-07-12 02:44:18.193255:  
2025-07-12 02:44:18.195839: Epoch 525 
2025-07-12 02:44:18.197236: Current learning rate: 0.00512 
2025-07-12 02:45:26.880702: train_loss -0.9746 
2025-07-12 02:45:26.881989: val_loss -0.9504 
2025-07-12 02:45:26.883345: Pseudo dice [np.float32(0.9538)] 
2025-07-12 02:45:26.884565: Epoch time: 68.69 s 
2025-07-12 02:45:27.818674:  
2025-07-12 02:45:27.820595: Epoch 526 
2025-07-12 02:45:27.821880: Current learning rate: 0.00511 
2025-07-12 02:46:36.693262: train_loss -0.9751 
2025-07-12 02:46:36.694772: val_loss -0.9471 
2025-07-12 02:46:36.696118: Pseudo dice [np.float32(0.9507)] 
2025-07-12 02:46:36.697029: Epoch time: 68.88 s 
2025-07-12 02:46:37.632501:  
2025-07-12 02:46:37.634759: Epoch 527 
2025-07-12 02:46:37.635951: Current learning rate: 0.0051 
2025-07-12 02:47:46.586162: train_loss -0.9757 
2025-07-12 02:47:46.587511: val_loss -0.9499 
2025-07-12 02:47:46.588754: Pseudo dice [np.float32(0.9541)] 
2025-07-12 02:47:46.589885: Epoch time: 68.96 s 
2025-07-12 02:47:47.524034:  
2025-07-12 02:47:47.525971: Epoch 528 
2025-07-12 02:47:47.527069: Current learning rate: 0.00509 
2025-07-12 02:48:56.525614: train_loss -0.9752 
2025-07-12 02:48:56.527137: val_loss -0.9463 
2025-07-12 02:48:56.528208: Pseudo dice [np.float32(0.9505)] 
2025-07-12 02:48:56.529269: Epoch time: 69.01 s 
2025-07-12 02:48:57.465907:  
2025-07-12 02:48:57.468377: Epoch 529 
2025-07-12 02:48:57.469812: Current learning rate: 0.00508 
2025-07-12 02:50:07.182580: train_loss -0.9757 
2025-07-12 02:50:07.184176: val_loss -0.9524 
2025-07-12 02:50:07.185361: Pseudo dice [np.float32(0.9561)] 
2025-07-12 02:50:07.186314: Epoch time: 69.72 s 
2025-07-12 02:50:08.130283:  
2025-07-12 02:50:08.132321: Epoch 530 
2025-07-12 02:50:08.133605: Current learning rate: 0.00507 
2025-07-12 02:51:17.149822: train_loss -0.9759 
2025-07-12 02:51:17.151226: val_loss -0.9491 
2025-07-12 02:51:17.152297: Pseudo dice [np.float32(0.9534)] 
2025-07-12 02:51:17.153513: Epoch time: 69.02 s 
2025-07-12 02:51:18.085285:  
2025-07-12 02:51:18.087335: Epoch 531 
2025-07-12 02:51:18.088431: Current learning rate: 0.00506 
2025-07-12 02:52:27.124656: train_loss -0.9769 
2025-07-12 02:52:27.126132: val_loss -0.953 
2025-07-12 02:52:27.127259: Pseudo dice [np.float32(0.956)] 
2025-07-12 02:52:27.128538: Epoch time: 69.04 s 
2025-07-12 02:52:28.064749:  
2025-07-12 02:52:28.067379: Epoch 532 
2025-07-12 02:52:28.068587: Current learning rate: 0.00505 
2025-07-12 02:53:37.176454: train_loss -0.9763 
2025-07-12 02:53:37.177938: val_loss -0.9494 
2025-07-12 02:53:37.179094: Pseudo dice [np.float32(0.953)] 
2025-07-12 02:53:37.180502: Epoch time: 69.12 s 
2025-07-12 02:53:38.118920:  
2025-07-12 02:53:38.121260: Epoch 533 
2025-07-12 02:53:38.122273: Current learning rate: 0.00504 
2025-07-12 02:54:47.145463: train_loss -0.9765 
2025-07-12 02:54:47.146756: val_loss -0.9495 
2025-07-12 02:54:47.147758: Pseudo dice [np.float32(0.9532)] 
2025-07-12 02:54:47.148889: Epoch time: 69.03 s 
2025-07-12 02:54:48.074836:  
2025-07-12 02:54:48.077097: Epoch 534 
2025-07-12 02:54:48.078372: Current learning rate: 0.00503 
2025-07-12 02:55:57.438169: train_loss -0.9753 
2025-07-12 02:55:57.439580: val_loss -0.9464 
2025-07-12 02:55:57.440575: Pseudo dice [np.float32(0.9501)] 
2025-07-12 02:55:57.441654: Epoch time: 69.37 s 
2025-07-12 02:55:58.356656:  
2025-07-12 02:55:58.358972: Epoch 535 
2025-07-12 02:55:58.360342: Current learning rate: 0.00502 
2025-07-12 02:57:07.544568: train_loss -0.9745 
2025-07-12 02:57:07.545879: val_loss -0.9481 
2025-07-12 02:57:07.547056: Pseudo dice [np.float32(0.9526)] 
2025-07-12 02:57:07.548015: Epoch time: 69.19 s 
2025-07-12 02:57:08.482166:  
2025-07-12 02:57:08.484055: Epoch 536 
2025-07-12 02:57:08.485359: Current learning rate: 0.00501 
2025-07-12 02:58:17.571959: train_loss -0.9752 
2025-07-12 02:58:17.573572: val_loss -0.9468 
2025-07-12 02:58:17.574997: Pseudo dice [np.float32(0.9507)] 
2025-07-12 02:58:17.575995: Epoch time: 69.09 s 
2025-07-12 02:58:18.507167:  
2025-07-12 02:58:18.509112: Epoch 537 
2025-07-12 02:58:18.510404: Current learning rate: 0.005 
2025-07-12 02:59:27.540693: train_loss -0.9753 
2025-07-12 02:59:27.541853: val_loss -0.9431 
2025-07-12 02:59:27.543085: Pseudo dice [np.float32(0.9474)] 
2025-07-12 02:59:27.544204: Epoch time: 69.04 s 
2025-07-12 02:59:28.478414:  
2025-07-12 02:59:28.480631: Epoch 538 
2025-07-12 02:59:28.481884: Current learning rate: 0.00499 
2025-07-12 03:00:38.140162: train_loss -0.9747 
2025-07-12 03:00:38.141432: val_loss -0.9471 
2025-07-12 03:00:38.142658: Pseudo dice [np.float32(0.9505)] 
2025-07-12 03:00:38.143743: Epoch time: 69.67 s 
2025-07-12 03:00:39.065127:  
2025-07-12 03:00:39.067241: Epoch 539 
2025-07-12 03:00:39.068544: Current learning rate: 0.00498 
2025-07-12 03:01:48.057154: train_loss -0.9759 
2025-07-12 03:01:48.058538: val_loss -0.9498 
2025-07-12 03:01:48.059990: Pseudo dice [np.float32(0.9541)] 
2025-07-12 03:01:48.061033: Epoch time: 69.0 s 
2025-07-12 03:01:48.970899:  
2025-07-12 03:01:48.972933: Epoch 540 
2025-07-12 03:01:48.974172: Current learning rate: 0.00497 
2025-07-12 03:02:58.185271: train_loss -0.9762 
2025-07-12 03:02:58.186626: val_loss -0.9516 
2025-07-12 03:02:58.187872: Pseudo dice [np.float32(0.9549)] 
2025-07-12 03:02:58.188885: Epoch time: 69.22 s 
2025-07-12 03:02:59.121009:  
2025-07-12 03:02:59.123497: Epoch 541 
2025-07-12 03:02:59.124537: Current learning rate: 0.00496 
2025-07-12 03:04:08.054270: train_loss -0.9763 
2025-07-12 03:04:08.055522: val_loss -0.9491 
2025-07-12 03:04:08.056903: Pseudo dice [np.float32(0.9524)] 
2025-07-12 03:04:08.057787: Epoch time: 68.94 s 
2025-07-12 03:04:08.986504:  
2025-07-12 03:04:08.988696: Epoch 542 
2025-07-12 03:04:08.990356: Current learning rate: 0.00495 
2025-07-12 03:05:18.111598: train_loss -0.9761 
2025-07-12 03:05:18.113407: val_loss -0.9497 
2025-07-12 03:05:18.114630: Pseudo dice [np.float32(0.9541)] 
2025-07-12 03:05:18.115675: Epoch time: 69.13 s 
2025-07-12 03:05:19.034493:  
2025-07-12 03:05:19.036397: Epoch 543 
2025-07-12 03:05:19.037407: Current learning rate: 0.00494 
2025-07-12 03:06:27.951803: train_loss -0.976 
2025-07-12 03:06:27.953106: val_loss -0.9449 
2025-07-12 03:06:27.954400: Pseudo dice [np.float32(0.9482)] 
2025-07-12 03:06:27.956262: Epoch time: 68.92 s 
2025-07-12 03:06:28.911247:  
2025-07-12 03:06:28.913286: Epoch 544 
2025-07-12 03:06:28.914568: Current learning rate: 0.00493 
2025-07-12 03:07:37.979641: train_loss -0.976 
2025-07-12 03:07:37.981087: val_loss -0.9464 
2025-07-12 03:07:37.982463: Pseudo dice [np.float32(0.9506)] 
2025-07-12 03:07:37.983740: Epoch time: 69.07 s 
2025-07-12 03:07:38.918676:  
2025-07-12 03:07:38.920964: Epoch 545 
2025-07-12 03:07:38.922111: Current learning rate: 0.00492 
2025-07-12 03:08:48.067658: train_loss -0.9763 
2025-07-12 03:08:48.068799: val_loss -0.9465 
2025-07-12 03:08:48.069843: Pseudo dice [np.float32(0.9504)] 
2025-07-12 03:08:48.071283: Epoch time: 69.15 s 
2025-07-12 03:08:49.011565:  
2025-07-12 03:08:49.013885: Epoch 546 
2025-07-12 03:08:49.015364: Current learning rate: 0.00491 
2025-07-12 03:09:58.067190: train_loss -0.9769 
2025-07-12 03:09:58.068639: val_loss -0.9506 
2025-07-12 03:09:58.069931: Pseudo dice [np.float32(0.9542)] 
2025-07-12 03:09:58.071049: Epoch time: 69.06 s 
2025-07-12 03:09:59.004760:  
2025-07-12 03:09:59.007257: Epoch 547 
2025-07-12 03:09:59.008451: Current learning rate: 0.0049 
2025-07-12 03:11:08.846522: train_loss -0.9765 
2025-07-12 03:11:08.847837: val_loss -0.9527 
2025-07-12 03:11:08.848784: Pseudo dice [np.float32(0.9565)] 
2025-07-12 03:11:08.849862: Epoch time: 69.85 s 
2025-07-12 03:11:09.788007:  
2025-07-12 03:11:09.790099: Epoch 548 
2025-07-12 03:11:09.791481: Current learning rate: 0.00489 
2025-07-12 03:12:18.851444: train_loss -0.9772 
2025-07-12 03:12:18.852788: val_loss -0.9495 
2025-07-12 03:12:18.854250: Pseudo dice [np.float32(0.9536)] 
2025-07-12 03:12:18.855195: Epoch time: 69.07 s 
2025-07-12 03:12:19.782147:  
2025-07-12 03:12:19.784603: Epoch 549 
2025-07-12 03:12:19.786144: Current learning rate: 0.00488 
2025-07-12 03:13:28.889037: train_loss -0.9767 
2025-07-12 03:13:28.890528: val_loss -0.9511 
2025-07-12 03:13:28.891590: Pseudo dice [np.float32(0.9549)] 
2025-07-12 03:13:28.893373: Epoch time: 69.11 s 
2025-07-12 03:13:30.941299:  
2025-07-12 03:13:30.943490: Epoch 550 
2025-07-12 03:13:30.944703: Current learning rate: 0.00487 
2025-07-12 03:14:40.237736: train_loss -0.9764 
2025-07-12 03:14:40.238982: val_loss -0.9461 
2025-07-12 03:14:40.239960: Pseudo dice [np.float32(0.9509)] 
2025-07-12 03:14:40.241153: Epoch time: 69.3 s 
2025-07-12 03:14:41.164106:  
2025-07-12 03:14:41.166153: Epoch 551 
2025-07-12 03:14:41.167355: Current learning rate: 0.00486 
2025-07-12 03:15:50.234242: train_loss -0.9763 
2025-07-12 03:15:50.235620: val_loss -0.9481 
2025-07-12 03:15:50.236685: Pseudo dice [np.float32(0.9524)] 
2025-07-12 03:15:50.237773: Epoch time: 69.07 s 
2025-07-12 03:15:51.170228:  
2025-07-12 03:15:51.172575: Epoch 552 
2025-07-12 03:15:51.173846: Current learning rate: 0.00485 
2025-07-12 03:17:00.042149: train_loss -0.9763 
2025-07-12 03:17:00.043561: val_loss -0.9491 
2025-07-12 03:17:00.045218: Pseudo dice [np.float32(0.9526)] 
2025-07-12 03:17:00.046306: Epoch time: 68.88 s 
2025-07-12 03:17:00.981878:  
2025-07-12 03:17:00.984460: Epoch 553 
2025-07-12 03:17:00.985826: Current learning rate: 0.00484 
2025-07-12 03:18:09.814452: train_loss -0.9751 
2025-07-12 03:18:09.815860: val_loss -0.9456 
2025-07-12 03:18:09.817065: Pseudo dice [np.float32(0.9494)] 
2025-07-12 03:18:09.818069: Epoch time: 68.84 s 
2025-07-12 03:18:10.736084:  
2025-07-12 03:18:10.738011: Epoch 554 
2025-07-12 03:18:10.739237: Current learning rate: 0.00484 
2025-07-12 03:19:19.661246: train_loss -0.9747 
2025-07-12 03:19:19.662452: val_loss -0.9482 
2025-07-12 03:19:19.664145: Pseudo dice [np.float32(0.9525)] 
2025-07-12 03:19:19.665292: Epoch time: 68.93 s 
2025-07-12 03:19:20.578678:  
2025-07-12 03:19:20.580559: Epoch 555 
2025-07-12 03:19:20.581686: Current learning rate: 0.00483 
2025-07-12 03:20:29.489303: train_loss -0.976 
2025-07-12 03:20:29.491043: val_loss -0.945 
2025-07-12 03:20:29.492280: Pseudo dice [np.float32(0.9491)] 
2025-07-12 03:20:29.493406: Epoch time: 68.91 s 
2025-07-12 03:20:31.224682:  
2025-07-12 03:20:31.226837: Epoch 556 
2025-07-12 03:20:31.228310: Current learning rate: 0.00482 
2025-07-12 03:21:40.055140: train_loss -0.9757 
2025-07-12 03:21:40.056827: val_loss -0.9503 
2025-07-12 03:21:40.057814: Pseudo dice [np.float32(0.9544)] 
2025-07-12 03:21:40.059062: Epoch time: 68.83 s 
2025-07-12 03:21:40.990703:  
2025-07-12 03:21:40.992834: Epoch 557 
2025-07-12 03:21:40.993991: Current learning rate: 0.00481 
2025-07-12 03:22:49.699168: train_loss -0.9766 
2025-07-12 03:22:49.701414: val_loss -0.9471 
2025-07-12 03:22:49.702476: Pseudo dice [np.float32(0.9503)] 
2025-07-12 03:22:49.703731: Epoch time: 68.71 s 
2025-07-12 03:22:50.646313:  
2025-07-12 03:22:50.649182: Epoch 558 
2025-07-12 03:22:50.650296: Current learning rate: 0.0048 
2025-07-12 03:23:59.484364: train_loss -0.9774 
2025-07-12 03:23:59.485667: val_loss -0.9448 
2025-07-12 03:23:59.486681: Pseudo dice [np.float32(0.949)] 
2025-07-12 03:23:59.487792: Epoch time: 68.84 s 
2025-07-12 03:24:00.418545:  
2025-07-12 03:24:00.420559: Epoch 559 
2025-07-12 03:24:00.421818: Current learning rate: 0.00479 
2025-07-12 03:25:09.355554: train_loss -0.9761 
2025-07-12 03:25:09.356961: val_loss -0.947 
2025-07-12 03:25:09.358191: Pseudo dice [np.float32(0.9511)] 
2025-07-12 03:25:09.359620: Epoch time: 68.94 s 
2025-07-12 03:25:10.288927:  
2025-07-12 03:25:10.291290: Epoch 560 
2025-07-12 03:25:10.292495: Current learning rate: 0.00478 
2025-07-12 03:26:19.354045: train_loss -0.9771 
2025-07-12 03:26:19.355212: val_loss -0.9485 
2025-07-12 03:26:19.356241: Pseudo dice [np.float32(0.9525)] 
2025-07-12 03:26:19.357256: Epoch time: 69.07 s 
2025-07-12 03:26:20.283724:  
2025-07-12 03:26:20.285623: Epoch 561 
2025-07-12 03:26:20.286655: Current learning rate: 0.00477 
2025-07-12 03:27:29.400560: train_loss -0.9765 
2025-07-12 03:27:29.402309: val_loss -0.9521 
2025-07-12 03:27:29.403716: Pseudo dice [np.float32(0.9568)] 
2025-07-12 03:27:29.404992: Epoch time: 69.12 s 
2025-07-12 03:27:30.315804:  
2025-07-12 03:27:30.318070: Epoch 562 
2025-07-12 03:27:30.319293: Current learning rate: 0.00476 
2025-07-12 03:28:39.341747: train_loss -0.9779 
2025-07-12 03:28:39.343492: val_loss -0.9488 
2025-07-12 03:28:39.344584: Pseudo dice [np.float32(0.9528)] 
2025-07-12 03:28:39.345537: Epoch time: 69.03 s 
2025-07-12 03:28:40.267977:  
2025-07-12 03:28:40.270007: Epoch 563 
2025-07-12 03:28:40.271130: Current learning rate: 0.00475 
2025-07-12 03:29:49.280464: train_loss -0.9757 
2025-07-12 03:29:49.281795: val_loss -0.9483 
2025-07-12 03:29:49.282860: Pseudo dice [np.float32(0.9513)] 
2025-07-12 03:29:49.284003: Epoch time: 69.02 s 
2025-07-12 03:29:50.215241:  
2025-07-12 03:29:50.216983: Epoch 564 
2025-07-12 03:29:50.218209: Current learning rate: 0.00474 
2025-07-12 03:30:59.087675: train_loss -0.9753 
2025-07-12 03:30:59.089045: val_loss -0.9496 
2025-07-12 03:30:59.090164: Pseudo dice [np.float32(0.9529)] 
2025-07-12 03:30:59.091474: Epoch time: 68.88 s 
2025-07-12 03:31:00.020356:  
2025-07-12 03:31:00.022671: Epoch 565 
2025-07-12 03:31:00.023861: Current learning rate: 0.00473 
2025-07-12 03:32:09.668303: train_loss -0.9756 
2025-07-12 03:32:09.669553: val_loss -0.945 
2025-07-12 03:32:09.670615: Pseudo dice [np.float32(0.9488)] 
2025-07-12 03:32:09.671845: Epoch time: 69.65 s 
2025-07-12 03:32:10.596617:  
2025-07-12 03:32:10.598765: Epoch 566 
2025-07-12 03:32:10.600020: Current learning rate: 0.00472 
2025-07-12 03:33:19.614957: train_loss -0.9752 
2025-07-12 03:33:19.616403: val_loss -0.9445 
2025-07-12 03:33:19.617446: Pseudo dice [np.float32(0.9492)] 
2025-07-12 03:33:19.618443: Epoch time: 69.02 s 
2025-07-12 03:33:20.521699:  
2025-07-12 03:33:20.523832: Epoch 567 
2025-07-12 03:33:20.525068: Current learning rate: 0.00471 
2025-07-12 03:34:29.525254: train_loss -0.9753 
2025-07-12 03:34:29.526668: val_loss -0.9493 
2025-07-12 03:34:29.527839: Pseudo dice [np.float32(0.9539)] 
2025-07-12 03:34:29.529180: Epoch time: 69.01 s 
2025-07-12 03:34:30.454838:  
2025-07-12 03:34:30.457361: Epoch 568 
2025-07-12 03:34:30.459156: Current learning rate: 0.0047 
2025-07-12 03:35:39.372747: train_loss -0.9773 
2025-07-12 03:35:39.373930: val_loss -0.9517 
2025-07-12 03:35:39.375040: Pseudo dice [np.float32(0.9544)] 
2025-07-12 03:35:39.376303: Epoch time: 68.92 s 
2025-07-12 03:35:40.313899:  
2025-07-12 03:35:40.315892: Epoch 569 
2025-07-12 03:35:40.316970: Current learning rate: 0.00469 
2025-07-12 03:36:49.083270: train_loss -0.9765 
2025-07-12 03:36:49.084634: val_loss -0.9492 
2025-07-12 03:36:49.085640: Pseudo dice [np.float32(0.9522)] 
2025-07-12 03:36:49.086828: Epoch time: 68.77 s 
2025-07-12 03:36:50.010240:  
2025-07-12 03:36:50.012375: Epoch 570 
2025-07-12 03:36:50.013515: Current learning rate: 0.00468 
2025-07-12 03:37:58.957705: train_loss -0.9772 
2025-07-12 03:37:58.959115: val_loss -0.9485 
2025-07-12 03:37:58.960382: Pseudo dice [np.float32(0.9528)] 
2025-07-12 03:37:58.961378: Epoch time: 68.95 s 
2025-07-12 03:37:59.879442:  
2025-07-12 03:37:59.881403: Epoch 571 
2025-07-12 03:37:59.882696: Current learning rate: 0.00467 
2025-07-12 03:39:09.047619: train_loss -0.9758 
2025-07-12 03:39:09.048906: val_loss -0.9479 
2025-07-12 03:39:09.049982: Pseudo dice [np.float32(0.9524)] 
2025-07-12 03:39:09.051238: Epoch time: 69.17 s 
2025-07-12 03:39:09.961746:  
2025-07-12 03:39:09.963788: Epoch 572 
2025-07-12 03:39:09.964831: Current learning rate: 0.00466 
2025-07-12 03:40:19.105276: train_loss -0.9767 
2025-07-12 03:40:19.106755: val_loss -0.9499 
2025-07-12 03:40:19.108022: Pseudo dice [np.float32(0.954)] 
2025-07-12 03:40:19.109175: Epoch time: 69.15 s 
2025-07-12 03:40:20.053729:  
2025-07-12 03:40:20.055372: Epoch 573 
2025-07-12 03:40:20.056404: Current learning rate: 0.00465 
2025-07-12 03:41:29.535833: train_loss -0.9759 
2025-07-12 03:41:29.537150: val_loss -0.9478 
2025-07-12 03:41:29.538132: Pseudo dice [np.float32(0.9511)] 
2025-07-12 03:41:29.539203: Epoch time: 69.49 s 
2025-07-12 03:41:30.465988:  
2025-07-12 03:41:30.467457: Epoch 574 
2025-07-12 03:41:30.468483: Current learning rate: 0.00464 
2025-07-12 03:42:40.702400: train_loss -0.9756 
2025-07-12 03:42:40.704341: val_loss -0.9462 
2025-07-12 03:42:40.705552: Pseudo dice [np.float32(0.9501)] 
2025-07-12 03:42:40.706688: Epoch time: 70.24 s 
2025-07-12 03:42:41.621523:  
2025-07-12 03:42:41.623436: Epoch 575 
2025-07-12 03:42:41.624795: Current learning rate: 0.00463 
2025-07-12 03:43:50.912927: train_loss -0.9773 
2025-07-12 03:43:50.914405: val_loss -0.9449 
2025-07-12 03:43:50.915858: Pseudo dice [np.float32(0.9492)] 
2025-07-12 03:43:50.917155: Epoch time: 69.29 s 
2025-07-12 03:43:51.857210:  
2025-07-12 03:43:51.859100: Epoch 576 
2025-07-12 03:43:51.860153: Current learning rate: 0.00462 
2025-07-12 03:45:01.240841: train_loss -0.9764 
2025-07-12 03:45:01.242192: val_loss -0.9448 
2025-07-12 03:45:01.243478: Pseudo dice [np.float32(0.9493)] 
2025-07-12 03:45:01.244540: Epoch time: 69.39 s 
2025-07-12 03:45:02.189625:  
2025-07-12 03:45:02.191521: Epoch 577 
2025-07-12 03:45:02.192769: Current learning rate: 0.00461 
2025-07-12 03:46:11.598045: train_loss -0.9761 
2025-07-12 03:46:11.599464: val_loss -0.9476 
2025-07-12 03:46:11.601246: Pseudo dice [np.float32(0.9516)] 
2025-07-12 03:46:11.602656: Epoch time: 69.41 s 
2025-07-12 03:46:12.543139:  
2025-07-12 03:46:12.545153: Epoch 578 
2025-07-12 03:46:12.546218: Current learning rate: 0.0046 
2025-07-12 03:47:21.979769: train_loss -0.9752 
2025-07-12 03:47:21.981029: val_loss -0.9486 
2025-07-12 03:47:21.982323: Pseudo dice [np.float32(0.9531)] 
2025-07-12 03:47:21.983637: Epoch time: 69.44 s 
2025-07-12 03:47:22.920801:  
2025-07-12 03:47:22.923234: Epoch 579 
2025-07-12 03:47:22.924418: Current learning rate: 0.00459 
2025-07-12 03:48:32.546151: train_loss -0.9764 
2025-07-12 03:48:32.548130: val_loss -0.9507 
2025-07-12 03:48:32.549193: Pseudo dice [np.float32(0.9545)] 
2025-07-12 03:48:32.550232: Epoch time: 69.63 s 
2025-07-12 03:48:33.460999:  
2025-07-12 03:48:33.462611: Epoch 580 
2025-07-12 03:48:33.463978: Current learning rate: 0.00458 
2025-07-12 03:49:43.182490: train_loss -0.977 
2025-07-12 03:49:43.184018: val_loss -0.9494 
2025-07-12 03:49:43.185369: Pseudo dice [np.float32(0.9529)] 
2025-07-12 03:49:43.186551: Epoch time: 69.73 s 
2025-07-12 03:49:44.120522:  
2025-07-12 03:49:44.122407: Epoch 581 
2025-07-12 03:49:44.123623: Current learning rate: 0.00457 
2025-07-12 03:50:54.817976: train_loss -0.9775 
2025-07-12 03:50:54.819398: val_loss -0.9511 
2025-07-12 03:50:54.820675: Pseudo dice [np.float32(0.9546)] 
2025-07-12 03:50:54.821884: Epoch time: 70.7 s 
2025-07-12 03:50:55.764041:  
2025-07-12 03:50:55.766253: Epoch 582 
2025-07-12 03:50:55.767854: Current learning rate: 0.00456 
2025-07-12 03:52:04.835531: train_loss -0.9771 
2025-07-12 03:52:04.836931: val_loss -0.9485 
2025-07-12 03:52:04.838626: Pseudo dice [np.float32(0.9522)] 
2025-07-12 03:52:04.839815: Epoch time: 69.08 s 
2025-07-12 03:52:05.762862:  
2025-07-12 03:52:05.765140: Epoch 583 
2025-07-12 03:52:05.766402: Current learning rate: 0.00455 
2025-07-12 03:53:15.691629: train_loss -0.9772 
2025-07-12 03:53:15.692867: val_loss -0.9469 
2025-07-12 03:53:15.693738: Pseudo dice [np.float32(0.9514)] 
2025-07-12 03:53:15.694706: Epoch time: 69.93 s 
2025-07-12 03:53:16.623110:  
2025-07-12 03:53:16.625002: Epoch 584 
2025-07-12 03:53:16.626241: Current learning rate: 0.00454 
2025-07-12 03:54:25.923040: train_loss -0.9773 
2025-07-12 03:54:25.924700: val_loss -0.9459 
2025-07-12 03:54:25.925631: Pseudo dice [np.float32(0.9499)] 
2025-07-12 03:54:25.926812: Epoch time: 69.3 s 
2025-07-12 03:54:26.870483:  
2025-07-12 03:54:26.872393: Epoch 585 
2025-07-12 03:54:26.873510: Current learning rate: 0.00453 
2025-07-12 03:55:36.259389: train_loss -0.9766 
2025-07-12 03:55:36.260523: val_loss -0.9467 
2025-07-12 03:55:36.261379: Pseudo dice [np.float32(0.9497)] 
2025-07-12 03:55:36.262371: Epoch time: 69.39 s 
2025-07-12 03:55:37.177052:  
2025-07-12 03:55:37.179149: Epoch 586 
2025-07-12 03:55:37.180215: Current learning rate: 0.00452 
2025-07-12 03:56:46.790254: train_loss -0.9766 
2025-07-12 03:56:46.791590: val_loss -0.9491 
2025-07-12 03:56:46.792761: Pseudo dice [np.float32(0.9527)] 
2025-07-12 03:56:46.793839: Epoch time: 69.62 s 
2025-07-12 03:56:47.727431:  
2025-07-12 03:56:47.729368: Epoch 587 
2025-07-12 03:56:47.730414: Current learning rate: 0.00451 
2025-07-12 03:57:57.444677: train_loss -0.9757 
2025-07-12 03:57:57.445811: val_loss -0.9484 
2025-07-12 03:57:57.447299: Pseudo dice [np.float32(0.9521)] 
2025-07-12 03:57:57.448174: Epoch time: 69.72 s 
2025-07-12 03:57:58.357619:  
2025-07-12 03:57:58.359408: Epoch 588 
2025-07-12 03:57:58.360671: Current learning rate: 0.0045 
2025-07-12 03:59:08.064896: train_loss -0.9765 
2025-07-12 03:59:08.066198: val_loss -0.9486 
2025-07-12 03:59:08.067476: Pseudo dice [np.float32(0.9526)] 
2025-07-12 03:59:08.068681: Epoch time: 69.71 s 
2025-07-12 03:59:08.990539:  
2025-07-12 03:59:08.992427: Epoch 589 
2025-07-12 03:59:08.993813: Current learning rate: 0.00449 
2025-07-12 04:00:18.347749: train_loss -0.9774 
2025-07-12 04:00:18.349428: val_loss -0.9488 
2025-07-12 04:00:18.350423: Pseudo dice [np.float32(0.9528)] 
2025-07-12 04:00:18.351412: Epoch time: 69.36 s 
2025-07-12 04:00:19.275972:  
2025-07-12 04:00:19.277854: Epoch 590 
2025-07-12 04:00:19.279009: Current learning rate: 0.00448 
2025-07-12 04:01:28.697198: train_loss -0.9779 
2025-07-12 04:01:28.698332: val_loss -0.9496 
2025-07-12 04:01:28.699327: Pseudo dice [np.float32(0.9539)] 
2025-07-12 04:01:28.700761: Epoch time: 69.42 s 
2025-07-12 04:01:29.628976:  
2025-07-12 04:01:29.630507: Epoch 591 
2025-07-12 04:01:29.631604: Current learning rate: 0.00447 
2025-07-12 04:02:39.139580: train_loss -0.9768 
2025-07-12 04:02:39.141209: val_loss -0.9481 
2025-07-12 04:02:39.142295: Pseudo dice [np.float32(0.9514)] 
2025-07-12 04:02:39.143222: Epoch time: 69.51 s 
2025-07-12 04:02:40.936605:  
2025-07-12 04:02:40.938325: Epoch 592 
2025-07-12 04:02:40.939291: Current learning rate: 0.00446 
2025-07-12 04:03:50.574054: train_loss -0.977 
2025-07-12 04:03:50.576429: val_loss -0.9489 
2025-07-12 04:03:50.577822: Pseudo dice [np.float32(0.9529)] 
2025-07-12 04:03:50.578950: Epoch time: 69.64 s 
2025-07-12 04:03:51.515005:  
2025-07-12 04:03:51.516700: Epoch 593 
2025-07-12 04:03:51.517823: Current learning rate: 0.00445 
2025-07-12 04:05:01.209708: train_loss -0.9772 
2025-07-12 04:05:01.210980: val_loss -0.9502 
2025-07-12 04:05:01.212623: Pseudo dice [np.float32(0.9544)] 
2025-07-12 04:05:01.214203: Epoch time: 69.7 s 
2025-07-12 04:05:02.139616:  
2025-07-12 04:05:02.141454: Epoch 594 
2025-07-12 04:05:02.142504: Current learning rate: 0.00444 
2025-07-12 04:06:11.562592: train_loss -0.9775 
2025-07-12 04:06:11.564464: val_loss -0.9487 
2025-07-12 04:06:11.565616: Pseudo dice [np.float32(0.9533)] 
2025-07-12 04:06:11.566826: Epoch time: 69.43 s 
2025-07-12 04:06:12.508302:  
2025-07-12 04:06:12.510226: Epoch 595 
2025-07-12 04:06:12.511443: Current learning rate: 0.00443 
2025-07-12 04:07:21.860424: train_loss -0.9775 
2025-07-12 04:07:21.862256: val_loss -0.9515 
2025-07-12 04:07:21.863711: Pseudo dice [np.float32(0.9549)] 
2025-07-12 04:07:21.865231: Epoch time: 69.36 s 
2025-07-12 04:07:22.804804:  
2025-07-12 04:07:22.806718: Epoch 596 
2025-07-12 04:07:22.807689: Current learning rate: 0.00442 
2025-07-12 04:08:32.142855: train_loss -0.9775 
2025-07-12 04:08:32.144806: val_loss -0.9511 
2025-07-12 04:08:32.146644: Pseudo dice [np.float32(0.9552)] 
2025-07-12 04:08:32.148200: Epoch time: 69.34 s 
2025-07-12 04:08:33.083256:  
2025-07-12 04:08:33.085460: Epoch 597 
2025-07-12 04:08:33.086533: Current learning rate: 0.00441 
2025-07-12 04:09:42.503847: train_loss -0.9779 
2025-07-12 04:09:42.505373: val_loss -0.951 
2025-07-12 04:09:42.506648: Pseudo dice [np.float32(0.9552)] 
2025-07-12 04:09:42.507683: Epoch time: 69.42 s 
2025-07-12 04:09:43.447047:  
2025-07-12 04:09:43.448802: Epoch 598 
2025-07-12 04:09:43.450176: Current learning rate: 0.0044 
2025-07-12 04:10:56.708639: train_loss -0.9769 
2025-07-12 04:10:56.709942: val_loss -0.9483 
2025-07-12 04:10:56.711139: Pseudo dice [np.float32(0.952)] 
2025-07-12 04:10:56.712265: Epoch time: 73.27 s 
2025-07-12 04:10:57.953157:  
2025-07-12 04:10:57.955075: Epoch 599 
2025-07-12 04:10:57.956226: Current learning rate: 0.00439 
2025-07-12 04:12:13.559809: train_loss -0.9772 
2025-07-12 04:12:13.561495: val_loss -0.9479 
2025-07-12 04:12:13.562658: Pseudo dice [np.float32(0.9523)] 
2025-07-12 04:12:13.563766: Epoch time: 75.61 s 
2025-07-12 04:12:15.612604:  
2025-07-12 04:12:15.614354: Epoch 600 
2025-07-12 04:12:15.615522: Current learning rate: 0.00438 
2025-07-12 04:13:24.639004: train_loss -0.9769 
2025-07-12 04:13:24.641031: val_loss -0.9449 
2025-07-12 04:13:24.642620: Pseudo dice [np.float32(0.9491)] 
2025-07-12 04:13:24.643569: Epoch time: 69.03 s 
2025-07-12 04:13:26.397530:  
2025-07-12 04:13:26.399603: Epoch 601 
2025-07-12 04:13:26.401275: Current learning rate: 0.00437 
2025-07-12 04:14:35.843553: train_loss -0.9768 
2025-07-12 04:14:35.845323: val_loss -0.9482 
2025-07-12 04:14:35.846915: Pseudo dice [np.float32(0.9507)] 
2025-07-12 04:14:35.848282: Epoch time: 69.45 s 
2025-07-12 04:14:36.796095:  
2025-07-12 04:14:36.798061: Epoch 602 
2025-07-12 04:14:36.799200: Current learning rate: 0.00436 
2025-07-12 04:15:46.069833: train_loss -0.9774 
2025-07-12 04:15:46.071082: val_loss -0.948 
2025-07-12 04:15:46.072805: Pseudo dice [np.float32(0.9513)] 
2025-07-12 04:15:46.075020: Epoch time: 69.28 s 
2025-07-12 04:15:47.009411:  
2025-07-12 04:15:47.011287: Epoch 603 
2025-07-12 04:15:47.012508: Current learning rate: 0.00435 
2025-07-12 04:16:56.366227: train_loss -0.9773 
2025-07-12 04:16:56.367465: val_loss -0.94 
2025-07-12 04:16:56.368442: Pseudo dice [np.float32(0.9437)] 
2025-07-12 04:16:56.369520: Epoch time: 69.36 s 
2025-07-12 04:16:57.323015:  
2025-07-12 04:16:57.325145: Epoch 604 
2025-07-12 04:16:57.326266: Current learning rate: 0.00434 
2025-07-12 04:18:06.816944: train_loss -0.9752 
2025-07-12 04:18:06.818119: val_loss -0.947 
2025-07-12 04:18:06.819114: Pseudo dice [np.float32(0.951)] 
2025-07-12 04:18:06.821140: Epoch time: 69.5 s 
2025-07-12 04:18:07.752073:  
2025-07-12 04:18:07.754291: Epoch 605 
2025-07-12 04:18:07.755670: Current learning rate: 0.00433 
2025-07-12 04:19:17.306142: train_loss -0.9774 
2025-07-12 04:19:17.307727: val_loss -0.9483 
2025-07-12 04:19:17.309303: Pseudo dice [np.float32(0.9521)] 
2025-07-12 04:19:17.310297: Epoch time: 69.56 s 
2025-07-12 04:19:18.264199:  
2025-07-12 04:19:18.266200: Epoch 606 
2025-07-12 04:19:18.267555: Current learning rate: 0.00432 
2025-07-12 04:20:27.892436: train_loss -0.9769 
2025-07-12 04:20:27.894201: val_loss -0.9513 
2025-07-12 04:20:27.896307: Pseudo dice [np.float32(0.9553)] 
2025-07-12 04:20:27.897988: Epoch time: 69.63 s 
2025-07-12 04:20:28.801541:  
2025-07-12 04:20:28.803540: Epoch 607 
2025-07-12 04:20:28.804661: Current learning rate: 0.00431 
2025-07-12 04:21:38.427968: train_loss -0.9766 
2025-07-12 04:21:38.429999: val_loss -0.9482 
2025-07-12 04:21:38.432335: Pseudo dice [np.float32(0.9529)] 
2025-07-12 04:21:38.433897: Epoch time: 69.63 s 
2025-07-12 04:21:39.423807:  
2025-07-12 04:21:39.425696: Epoch 608 
2025-07-12 04:21:39.426822: Current learning rate: 0.0043 
2025-07-12 04:22:50.385310: train_loss -0.9779 
2025-07-12 04:22:50.386545: val_loss -0.9442 
2025-07-12 04:22:50.387599: Pseudo dice [np.float32(0.947)] 
2025-07-12 04:22:50.388606: Epoch time: 70.97 s 
2025-07-12 04:22:51.328948:  
2025-07-12 04:22:51.331124: Epoch 609 
2025-07-12 04:22:51.332349: Current learning rate: 0.00429 
2025-07-12 04:24:04.910985: train_loss -0.9768 
2025-07-12 04:24:04.912202: val_loss -0.9484 
2025-07-12 04:24:04.913122: Pseudo dice [np.float32(0.9519)] 
2025-07-12 04:24:04.914232: Epoch time: 73.59 s 
2025-07-12 04:24:05.819947:  
2025-07-12 04:24:05.821787: Epoch 610 
2025-07-12 04:24:05.822961: Current learning rate: 0.00429 
2025-07-12 04:25:15.278228: train_loss -0.9774 
2025-07-12 04:25:15.279470: val_loss -0.9449 
2025-07-12 04:25:15.280463: Pseudo dice [np.float32(0.9487)] 
2025-07-12 04:25:15.281586: Epoch time: 69.46 s 
2025-07-12 04:25:16.205029:  
2025-07-12 04:25:16.207231: Epoch 611 
2025-07-12 04:25:16.208457: Current learning rate: 0.00428 
2025-07-12 04:26:25.749776: train_loss -0.9766 
2025-07-12 04:26:25.751800: val_loss -0.9481 
2025-07-12 04:26:25.752873: Pseudo dice [np.float32(0.9517)] 
2025-07-12 04:26:25.753935: Epoch time: 69.55 s 
2025-07-12 04:26:26.708928:  
2025-07-12 04:26:26.710453: Epoch 612 
2025-07-12 04:26:26.711571: Current learning rate: 0.00427 
2025-07-12 04:27:36.131084: train_loss -0.9778 
2025-07-12 04:27:36.132388: val_loss -0.9488 
2025-07-12 04:27:36.133531: Pseudo dice [np.float32(0.9516)] 
2025-07-12 04:27:36.134620: Epoch time: 69.43 s 
2025-07-12 04:27:37.097377:  
2025-07-12 04:27:37.098897: Epoch 613 
2025-07-12 04:27:37.099967: Current learning rate: 0.00426 
2025-07-12 04:28:53.074078: train_loss -0.9772 
2025-07-12 04:28:53.076238: val_loss -0.9467 
2025-07-12 04:28:53.077470: Pseudo dice [np.float32(0.951)] 
2025-07-12 04:28:53.078850: Epoch time: 75.98 s 
2025-07-12 04:28:54.025273:  
2025-07-12 04:28:54.027407: Epoch 614 
2025-07-12 04:28:54.028586: Current learning rate: 0.00425 
2025-07-12 04:30:09.893012: train_loss -0.9772 
2025-07-12 04:30:09.894685: val_loss -0.947 
2025-07-12 04:30:09.896105: Pseudo dice [np.float32(0.9501)] 
2025-07-12 04:30:09.897143: Epoch time: 75.87 s 
2025-07-12 04:30:10.846180:  
2025-07-12 04:30:10.847981: Epoch 615 
2025-07-12 04:30:10.849045: Current learning rate: 0.00424 
2025-07-12 04:31:20.713401: train_loss -0.9766 
2025-07-12 04:31:20.714785: val_loss -0.9464 
2025-07-12 04:31:20.715870: Pseudo dice [np.float32(0.9499)] 
2025-07-12 04:31:20.717013: Epoch time: 69.87 s 
2025-07-12 04:31:21.657250:  
2025-07-12 04:31:21.659145: Epoch 616 
2025-07-12 04:31:21.660420: Current learning rate: 0.00423 
2025-07-12 04:32:31.215103: train_loss -0.9771 
2025-07-12 04:32:31.216470: val_loss -0.9489 
2025-07-12 04:32:31.217534: Pseudo dice [np.float32(0.9531)] 
2025-07-12 04:32:31.218581: Epoch time: 69.56 s 
2025-07-12 04:32:32.166806:  
2025-07-12 04:32:32.168539: Epoch 617 
2025-07-12 04:32:32.169986: Current learning rate: 0.00422 
2025-07-12 04:33:41.859396: train_loss -0.9779 
2025-07-12 04:33:41.861480: val_loss -0.9462 
2025-07-12 04:33:41.862441: Pseudo dice [np.float32(0.9507)] 
2025-07-12 04:33:41.863411: Epoch time: 69.7 s 
2025-07-12 04:33:42.796986:  
2025-07-12 04:33:42.799003: Epoch 618 
2025-07-12 04:33:42.800022: Current learning rate: 0.00421 
2025-07-12 04:34:53.335072: train_loss -0.9771 
2025-07-12 04:34:53.336270: val_loss -0.9478 
2025-07-12 04:34:53.337286: Pseudo dice [np.float32(0.9516)] 
2025-07-12 04:34:53.338261: Epoch time: 70.54 s 
2025-07-12 04:34:54.261891:  
2025-07-12 04:34:54.263860: Epoch 619 
2025-07-12 04:34:54.264865: Current learning rate: 0.0042 
2025-07-12 04:36:03.859221: train_loss -0.978 
2025-07-12 04:36:03.860588: val_loss -0.9473 
2025-07-12 04:36:03.861884: Pseudo dice [np.float32(0.9519)] 
2025-07-12 04:36:03.862806: Epoch time: 69.6 s 
2025-07-12 04:36:04.760282:  
2025-07-12 04:36:04.762145: Epoch 620 
2025-07-12 04:36:04.763212: Current learning rate: 0.00419 
2025-07-12 04:37:14.001221: train_loss -0.9776 
2025-07-12 04:37:14.002530: val_loss -0.9496 
2025-07-12 04:37:14.003689: Pseudo dice [np.float32(0.9533)] 
2025-07-12 04:37:14.004685: Epoch time: 69.24 s 
2025-07-12 04:37:14.935446:  
2025-07-12 04:37:14.937296: Epoch 621 
2025-07-12 04:37:14.938389: Current learning rate: 0.00418 
2025-07-12 04:38:34.110363: train_loss -0.978 
2025-07-12 04:38:34.111552: val_loss -0.9474 
2025-07-12 04:38:34.112880: Pseudo dice [np.float32(0.9514)] 
2025-07-12 04:38:34.113756: Epoch time: 79.18 s 
2025-07-12 04:38:35.042712:  
2025-07-12 04:38:35.044444: Epoch 622 
2025-07-12 04:38:35.045653: Current learning rate: 0.00417 
2025-07-12 04:39:47.147027: train_loss -0.9772 
2025-07-12 04:39:47.148309: val_loss -0.9515 
2025-07-12 04:39:47.149558: Pseudo dice [np.float32(0.9551)] 
2025-07-12 04:39:47.151248: Epoch time: 72.11 s 
2025-07-12 04:39:48.098408:  
2025-07-12 04:39:48.100496: Epoch 623 
2025-07-12 04:39:48.101796: Current learning rate: 0.00416 
2025-07-12 04:40:57.443646: train_loss -0.9788 
2025-07-12 04:40:57.444923: val_loss -0.9495 
2025-07-12 04:40:57.446226: Pseudo dice [np.float32(0.9532)] 
2025-07-12 04:40:57.447360: Epoch time: 69.35 s 
2025-07-12 04:40:58.392517:  
2025-07-12 04:40:58.394541: Epoch 624 
2025-07-12 04:40:58.395795: Current learning rate: 0.00415 
2025-07-12 04:42:07.707641: train_loss -0.9787 
2025-07-12 04:42:07.709153: val_loss -0.9463 
2025-07-12 04:42:07.710184: Pseudo dice [np.float32(0.9512)] 
2025-07-12 04:42:07.711555: Epoch time: 69.32 s 
2025-07-12 04:42:08.636179:  
2025-07-12 04:42:08.637962: Epoch 625 
2025-07-12 04:42:08.638963: Current learning rate: 0.00414 
2025-07-12 04:43:18.115421: train_loss -0.9779 
2025-07-12 04:43:18.116933: val_loss -0.9484 
2025-07-12 04:43:18.117978: Pseudo dice [np.float32(0.9523)] 
2025-07-12 04:43:18.119273: Epoch time: 69.48 s 
2025-07-12 04:43:19.067375:  
2025-07-12 04:43:19.069203: Epoch 626 
2025-07-12 04:43:19.070278: Current learning rate: 0.00413 
2025-07-12 04:44:28.642699: train_loss -0.9772 
2025-07-12 04:44:28.643974: val_loss -0.9534 
2025-07-12 04:44:28.644954: Pseudo dice [np.float32(0.9566)] 
2025-07-12 04:44:28.645863: Epoch time: 69.58 s 
2025-07-12 04:44:29.587460:  
2025-07-12 04:44:29.589453: Epoch 627 
2025-07-12 04:44:29.590452: Current learning rate: 0.00412 
2025-07-12 04:45:50.243384: train_loss -0.9778 
2025-07-12 04:45:50.244605: val_loss -0.9506 
2025-07-12 04:45:50.245771: Pseudo dice [np.float32(0.9543)] 
2025-07-12 04:45:50.246773: Epoch time: 80.66 s 
2025-07-12 04:45:51.189901:  
2025-07-12 04:45:51.191557: Epoch 628 
2025-07-12 04:45:51.192863: Current learning rate: 0.00411 
2025-07-12 04:47:02.765949: train_loss -0.9775 
2025-07-12 04:47:02.767515: val_loss -0.9515 
2025-07-12 04:47:02.768659: Pseudo dice [np.float32(0.9554)] 
2025-07-12 04:47:02.769754: Epoch time: 71.58 s 
2025-07-12 04:47:03.701296:  
2025-07-12 04:47:03.703149: Epoch 629 
2025-07-12 04:47:03.704196: Current learning rate: 0.0041 
2025-07-12 04:48:12.804950: train_loss -0.978 
2025-07-12 04:48:12.806161: val_loss -0.9508 
2025-07-12 04:48:12.807111: Pseudo dice [np.float32(0.9544)] 
2025-07-12 04:48:12.808160: Epoch time: 69.11 s 
2025-07-12 04:48:13.744418:  
2025-07-12 04:48:13.746256: Epoch 630 
2025-07-12 04:48:13.747340: Current learning rate: 0.00409 
2025-07-12 04:49:23.168359: train_loss -0.9775 
2025-07-12 04:49:23.169790: val_loss -0.948 
2025-07-12 04:49:23.171159: Pseudo dice [np.float32(0.9531)] 
2025-07-12 04:49:23.172338: Epoch time: 69.43 s 
2025-07-12 04:49:24.115941:  
2025-07-12 04:49:24.117676: Epoch 631 
2025-07-12 04:49:24.118742: Current learning rate: 0.00408 
2025-07-12 04:50:33.436576: train_loss -0.9783 
2025-07-12 04:50:33.437878: val_loss -0.9494 
2025-07-12 04:50:33.438925: Pseudo dice [np.float32(0.9533)] 
2025-07-12 04:50:33.440474: Epoch time: 69.32 s 
2025-07-12 04:50:34.382310:  
2025-07-12 04:50:34.384269: Epoch 632 
2025-07-12 04:50:34.385433: Current learning rate: 0.00407 
2025-07-12 04:51:44.136074: train_loss -0.9774 
2025-07-12 04:51:44.137200: val_loss -0.9511 
2025-07-12 04:51:44.138461: Pseudo dice [np.float32(0.9557)] 
2025-07-12 04:51:44.139495: Epoch time: 69.76 s 
2025-07-12 04:51:45.092249:  
2025-07-12 04:51:45.094118: Epoch 633 
2025-07-12 04:51:45.095282: Current learning rate: 0.00406 
2025-07-12 04:52:54.435543: train_loss -0.9779 
2025-07-12 04:52:54.437065: val_loss -0.9512 
2025-07-12 04:52:54.438182: Pseudo dice [np.float32(0.9549)] 
2025-07-12 04:52:54.439123: Epoch time: 69.35 s 
2025-07-12 04:52:55.368087:  
2025-07-12 04:52:55.370167: Epoch 634 
2025-07-12 04:52:55.371789: Current learning rate: 0.00405 
2025-07-12 04:54:04.644905: train_loss -0.9779 
2025-07-12 04:54:04.646396: val_loss -0.9511 
2025-07-12 04:54:04.647591: Pseudo dice [np.float32(0.9543)] 
2025-07-12 04:54:04.649357: Epoch time: 69.28 s 
2025-07-12 04:54:05.589601:  
2025-07-12 04:54:05.591090: Epoch 635 
2025-07-12 04:54:05.592118: Current learning rate: 0.00404 
2025-07-12 04:55:15.025113: train_loss -0.9782 
2025-07-12 04:55:15.026348: val_loss -0.9469 
2025-07-12 04:55:15.027347: Pseudo dice [np.float32(0.951)] 
2025-07-12 04:55:15.028342: Epoch time: 69.44 s 
2025-07-12 04:55:15.965488:  
2025-07-12 04:55:15.967516: Epoch 636 
2025-07-12 04:55:15.968554: Current learning rate: 0.00403 
2025-07-12 04:56:26.540093: train_loss -0.9771 
2025-07-12 04:56:26.541383: val_loss -0.9501 
2025-07-12 04:56:26.542530: Pseudo dice [np.float32(0.9535)] 
2025-07-12 04:56:26.543617: Epoch time: 70.58 s 
2025-07-12 04:56:27.473273:  
2025-07-12 04:56:27.475256: Epoch 637 
2025-07-12 04:56:27.476439: Current learning rate: 0.00402 
2025-07-12 04:57:37.038167: train_loss -0.9764 
2025-07-12 04:57:37.039433: val_loss -0.9511 
2025-07-12 04:57:37.040391: Pseudo dice [np.float32(0.9556)] 
2025-07-12 04:57:37.041546: Epoch time: 69.57 s 
2025-07-12 04:57:37.968178:  
2025-07-12 04:57:37.969624: Epoch 638 
2025-07-12 04:57:37.970758: Current learning rate: 0.00401 
2025-07-12 04:58:47.464734: train_loss -0.9779 
2025-07-12 04:58:47.466169: val_loss -0.9497 
2025-07-12 04:58:47.467274: Pseudo dice [np.float32(0.9543)] 
2025-07-12 04:58:47.468402: Epoch time: 69.5 s 
2025-07-12 04:58:48.396865:  
2025-07-12 04:58:48.398445: Epoch 639 
2025-07-12 04:58:48.399460: Current learning rate: 0.004 
2025-07-12 04:59:57.681774: train_loss -0.9774 
2025-07-12 04:59:57.683307: val_loss -0.9511 
2025-07-12 04:59:57.684329: Pseudo dice [np.float32(0.9542)] 
2025-07-12 04:59:57.685878: Epoch time: 69.29 s 
2025-07-12 04:59:58.604167:  
2025-07-12 04:59:58.606273: Epoch 640 
2025-07-12 04:59:58.607242: Current learning rate: 0.00399 
2025-07-12 05:01:08.047602: train_loss -0.977 
2025-07-12 05:01:08.049097: val_loss -0.949 
2025-07-12 05:01:08.050331: Pseudo dice [np.float32(0.953)] 
2025-07-12 05:01:08.051383: Epoch time: 69.45 s 
2025-07-12 05:01:08.990481:  
2025-07-12 05:01:08.992415: Epoch 641 
2025-07-12 05:01:08.993546: Current learning rate: 0.00398 
2025-07-12 05:02:18.350808: train_loss -0.9775 
2025-07-12 05:02:18.352036: val_loss -0.9474 
2025-07-12 05:02:18.353208: Pseudo dice [np.float32(0.9513)] 
2025-07-12 05:02:18.354543: Epoch time: 69.36 s 
2025-07-12 05:02:19.280270:  
2025-07-12 05:02:19.282456: Epoch 642 
2025-07-12 05:02:19.283587: Current learning rate: 0.00397 
2025-07-12 05:03:28.823380: train_loss -0.9773 
2025-07-12 05:03:28.824825: val_loss -0.9485 
2025-07-12 05:03:28.826182: Pseudo dice [np.float32(0.9522)] 
2025-07-12 05:03:28.827331: Epoch time: 69.55 s 
2025-07-12 05:03:29.778902:  
2025-07-12 05:03:29.780868: Epoch 643 
2025-07-12 05:03:29.781850: Current learning rate: 0.00396 
2025-07-12 05:04:39.381452: train_loss -0.9774 
2025-07-12 05:04:39.382689: val_loss -0.9466 
2025-07-12 05:04:39.383880: Pseudo dice [np.float32(0.9497)] 
2025-07-12 05:04:39.384887: Epoch time: 69.61 s 
2025-07-12 05:04:40.313597:  
2025-07-12 05:04:40.315273: Epoch 644 
2025-07-12 05:04:40.316244: Current learning rate: 0.00395 
2025-07-12 05:05:49.780014: train_loss -0.9772 
2025-07-12 05:05:49.781560: val_loss -0.9448 
2025-07-12 05:05:49.782659: Pseudo dice [np.float32(0.948)] 
2025-07-12 05:05:49.783679: Epoch time: 69.47 s 
2025-07-12 05:05:50.725111:  
2025-07-12 05:05:50.727197: Epoch 645 
2025-07-12 05:05:50.728285: Current learning rate: 0.00394 
2025-07-12 05:07:00.848066: train_loss -0.9769 
2025-07-12 05:07:00.849499: val_loss -0.9495 
2025-07-12 05:07:00.850585: Pseudo dice [np.float32(0.9534)] 
2025-07-12 05:07:00.851792: Epoch time: 70.13 s 
2025-07-12 05:07:01.803122:  
2025-07-12 05:07:01.804810: Epoch 646 
2025-07-12 05:07:01.805806: Current learning rate: 0.00393 
2025-07-12 05:08:11.259954: train_loss -0.9776 
2025-07-12 05:08:11.261390: val_loss -0.9502 
2025-07-12 05:08:11.262290: Pseudo dice [np.float32(0.9542)] 
2025-07-12 05:08:11.263279: Epoch time: 69.46 s 
2025-07-12 05:08:12.190381:  
2025-07-12 05:08:12.192302: Epoch 647 
2025-07-12 05:08:12.193819: Current learning rate: 0.00392 
2025-07-12 05:09:21.759188: train_loss -0.9777 
2025-07-12 05:09:21.760377: val_loss -0.9526 
2025-07-12 05:09:21.761389: Pseudo dice [np.float32(0.9564)] 
2025-07-12 05:09:21.762337: Epoch time: 69.57 s 
2025-07-12 05:09:22.698003:  
2025-07-12 05:09:22.700069: Epoch 648 
2025-07-12 05:09:22.701293: Current learning rate: 0.00391 
2025-07-12 05:10:32.272800: train_loss -0.9773 
2025-07-12 05:10:32.274048: val_loss -0.9474 
2025-07-12 05:10:32.274972: Pseudo dice [np.float32(0.9515)] 
2025-07-12 05:10:32.275995: Epoch time: 69.58 s 
2025-07-12 05:10:33.229092:  
2025-07-12 05:10:33.231144: Epoch 649 
2025-07-12 05:10:33.232494: Current learning rate: 0.0039 
2025-07-12 05:11:42.902508: train_loss -0.9769 
2025-07-12 05:11:42.903811: val_loss -0.9491 
2025-07-12 05:11:42.905458: Pseudo dice [np.float32(0.9534)] 
2025-07-12 05:11:42.907450: Epoch time: 69.68 s 
2025-07-12 05:11:44.936122:  
2025-07-12 05:11:44.938069: Epoch 650 
2025-07-12 05:11:44.939271: Current learning rate: 0.00389 
2025-07-12 05:12:54.363955: train_loss -0.9782 
2025-07-12 05:12:54.365279: val_loss -0.9473 
2025-07-12 05:12:54.366706: Pseudo dice [np.float32(0.9508)] 
2025-07-12 05:12:54.367952: Epoch time: 69.43 s 
2025-07-12 05:12:55.302003:  
2025-07-12 05:12:55.303735: Epoch 651 
2025-07-12 05:12:55.304848: Current learning rate: 0.00388 
2025-07-12 05:14:04.856971: train_loss -0.9781 
2025-07-12 05:14:04.858253: val_loss -0.9504 
2025-07-12 05:14:04.859316: Pseudo dice [np.float32(0.9533)] 
2025-07-12 05:14:04.860518: Epoch time: 69.56 s 
2025-07-12 05:14:05.754864:  
2025-07-12 05:14:05.756937: Epoch 652 
2025-07-12 05:14:05.757974: Current learning rate: 0.00387 
2025-07-12 05:15:15.233509: train_loss -0.9784 
2025-07-12 05:15:15.234915: val_loss -0.9519 
2025-07-12 05:15:15.236097: Pseudo dice [np.float32(0.9558)] 
2025-07-12 05:15:15.237114: Epoch time: 69.48 s 
2025-07-12 05:15:16.169785:  
2025-07-12 05:15:16.171610: Epoch 653 
2025-07-12 05:15:16.172671: Current learning rate: 0.00386 
2025-07-12 05:16:25.695451: train_loss -0.9775 
2025-07-12 05:16:25.696720: val_loss -0.9511 
2025-07-12 05:16:25.697987: Pseudo dice [np.float32(0.9549)] 
2025-07-12 05:16:25.699030: Epoch time: 69.53 s 
2025-07-12 05:16:27.411869:  
2025-07-12 05:16:27.414104: Epoch 654 
2025-07-12 05:16:27.415260: Current learning rate: 0.00385 
2025-07-12 05:17:37.087554: train_loss -0.976 
2025-07-12 05:17:37.089059: val_loss -0.9478 
2025-07-12 05:17:37.090729: Pseudo dice [np.float32(0.9515)] 
2025-07-12 05:17:37.091828: Epoch time: 69.68 s 
2025-07-12 05:17:38.020592:  
2025-07-12 05:17:38.022314: Epoch 655 
2025-07-12 05:17:38.023409: Current learning rate: 0.00384 
2025-07-12 05:18:47.425393: train_loss -0.9771 
2025-07-12 05:18:47.426594: val_loss -0.9535 
2025-07-12 05:18:47.427489: Pseudo dice [np.float32(0.9571)] 
2025-07-12 05:18:47.428775: Epoch time: 69.41 s 
2025-07-12 05:18:48.357897:  
2025-07-12 05:18:48.359700: Epoch 656 
2025-07-12 05:18:48.360882: Current learning rate: 0.00383 
2025-07-12 05:19:57.816103: train_loss -0.9789 
2025-07-12 05:19:57.817284: val_loss -0.9525 
2025-07-12 05:19:57.818392: Pseudo dice [np.float32(0.9556)] 
2025-07-12 05:19:57.819808: Epoch time: 69.46 s 
2025-07-12 05:19:58.756418:  
2025-07-12 05:19:58.758350: Epoch 657 
2025-07-12 05:19:58.759527: Current learning rate: 0.00382 
2025-07-12 05:21:08.075485: train_loss -0.9788 
2025-07-12 05:21:08.076776: val_loss -0.9485 
2025-07-12 05:21:08.077972: Pseudo dice [np.float32(0.9523)] 
2025-07-12 05:21:08.078971: Epoch time: 69.32 s 
2025-07-12 05:21:09.034111:  
2025-07-12 05:21:09.036166: Epoch 658 
2025-07-12 05:21:09.037303: Current learning rate: 0.00381 
2025-07-12 05:22:18.497839: train_loss -0.9773 
2025-07-12 05:22:18.499114: val_loss -0.9514 
2025-07-12 05:22:18.500213: Pseudo dice [np.float32(0.9548)] 
2025-07-12 05:22:18.501238: Epoch time: 69.47 s 
2025-07-12 05:22:19.429038:  
2025-07-12 05:22:19.430720: Epoch 659 
2025-07-12 05:22:19.432187: Current learning rate: 0.0038 
2025-07-12 05:23:28.688231: train_loss -0.9784 
2025-07-12 05:23:28.689849: val_loss -0.9515 
2025-07-12 05:23:28.691205: Pseudo dice [np.float32(0.9548)] 
2025-07-12 05:23:28.692209: Epoch time: 69.26 s 
2025-07-12 05:23:28.693267: Yayy! New best EMA pseudo Dice: 0.9538000226020813 
2025-07-12 05:23:30.779873:  
2025-07-12 05:23:30.781678: Epoch 660 
2025-07-12 05:23:30.782848: Current learning rate: 0.00379 
2025-07-12 05:24:40.087032: train_loss -0.9773 
2025-07-12 05:24:40.088382: val_loss -0.948 
2025-07-12 05:24:40.089623: Pseudo dice [np.float32(0.9511)] 
2025-07-12 05:24:40.090660: Epoch time: 69.31 s 
2025-07-12 05:24:41.015921:  
2025-07-12 05:24:41.018124: Epoch 661 
2025-07-12 05:24:41.019277: Current learning rate: 0.00378 
2025-07-12 05:25:50.672675: train_loss -0.9771 
2025-07-12 05:25:50.673991: val_loss -0.9483 
2025-07-12 05:25:50.674903: Pseudo dice [np.float32(0.9519)] 
2025-07-12 05:25:50.675914: Epoch time: 69.66 s 
2025-07-12 05:25:51.605342:  
2025-07-12 05:25:51.607217: Epoch 662 
2025-07-12 05:25:51.608526: Current learning rate: 0.00377 
2025-07-12 05:27:00.791094: train_loss -0.9779 
2025-07-12 05:27:00.792482: val_loss -0.9479 
2025-07-12 05:27:00.793793: Pseudo dice [np.float32(0.9516)] 
2025-07-12 05:27:00.795002: Epoch time: 69.19 s 
2025-07-12 05:27:02.573403:  
2025-07-12 05:27:02.575614: Epoch 663 
2025-07-12 05:27:02.577226: Current learning rate: 0.00376 
2025-07-12 05:28:11.257185: train_loss -0.9781 
2025-07-12 05:28:11.258794: val_loss -0.9464 
2025-07-12 05:28:11.259714: Pseudo dice [np.float32(0.9517)] 
2025-07-12 05:28:11.260881: Epoch time: 68.69 s 
2025-07-12 05:28:12.199873:  
2025-07-12 05:28:12.202407: Epoch 664 
2025-07-12 05:28:12.203763: Current learning rate: 0.00375 
2025-07-12 05:29:21.135855: train_loss -0.9773 
2025-07-12 05:29:21.137221: val_loss -0.9498 
2025-07-12 05:29:21.138354: Pseudo dice [np.float32(0.9538)] 
2025-07-12 05:29:21.139365: Epoch time: 68.94 s 
2025-07-12 05:29:22.075649:  
2025-07-12 05:29:22.077801: Epoch 665 
2025-07-12 05:29:22.078783: Current learning rate: 0.00374 
2025-07-12 05:30:31.301569: train_loss -0.9787 
2025-07-12 05:30:31.302644: val_loss -0.948 
2025-07-12 05:30:31.303648: Pseudo dice [np.float32(0.9521)] 
2025-07-12 05:30:31.304627: Epoch time: 69.23 s 
2025-07-12 05:30:32.232414:  
2025-07-12 05:30:32.234570: Epoch 666 
2025-07-12 05:30:32.235554: Current learning rate: 0.00373 
2025-07-12 05:31:41.628931: train_loss -0.9773 
2025-07-12 05:31:41.630317: val_loss -0.9491 
2025-07-12 05:31:41.631346: Pseudo dice [np.float32(0.9529)] 
2025-07-12 05:31:41.632270: Epoch time: 69.4 s 
2025-07-12 05:31:42.572714:  
2025-07-12 05:31:42.574898: Epoch 667 
2025-07-12 05:31:42.576105: Current learning rate: 0.00372 
2025-07-12 05:32:51.840891: train_loss -0.9791 
2025-07-12 05:32:51.842342: val_loss -0.9454 
2025-07-12 05:32:51.843547: Pseudo dice [np.float32(0.9495)] 
2025-07-12 05:32:51.844725: Epoch time: 69.27 s 
2025-07-12 05:32:52.779451:  
2025-07-12 05:32:52.781827: Epoch 668 
2025-07-12 05:32:52.782805: Current learning rate: 0.00371 
2025-07-12 05:34:02.191894: train_loss -0.9782 
2025-07-12 05:34:02.194499: val_loss -0.9462 
2025-07-12 05:34:02.195668: Pseudo dice [np.float32(0.9505)] 
2025-07-12 05:34:02.196849: Epoch time: 69.42 s 
2025-07-12 05:34:03.139589:  
2025-07-12 05:34:03.141828: Epoch 669 
2025-07-12 05:34:03.142890: Current learning rate: 0.0037 
2025-07-12 05:35:12.547894: train_loss -0.978 
2025-07-12 05:35:12.549378: val_loss -0.9496 
2025-07-12 05:35:12.550937: Pseudo dice [np.float32(0.9535)] 
2025-07-12 05:35:12.551948: Epoch time: 69.41 s 
2025-07-12 05:35:13.509411:  
2025-07-12 05:35:13.511626: Epoch 670 
2025-07-12 05:35:13.512710: Current learning rate: 0.00369 
2025-07-12 05:36:22.912207: train_loss -0.9777 
2025-07-12 05:36:22.914197: val_loss -0.9531 
2025-07-12 05:36:22.915448: Pseudo dice [np.float32(0.9564)] 
2025-07-12 05:36:22.916921: Epoch time: 69.41 s 
2025-07-12 05:36:23.873070:  
2025-07-12 05:36:23.875211: Epoch 671 
2025-07-12 05:36:23.876343: Current learning rate: 0.00368 
2025-07-12 05:37:33.098125: train_loss -0.9781 
2025-07-12 05:37:33.099305: val_loss -0.9458 
2025-07-12 05:37:33.100307: Pseudo dice [np.float32(0.9498)] 
2025-07-12 05:37:33.101370: Epoch time: 69.23 s 
2025-07-12 05:37:34.861850:  
2025-07-12 05:37:34.863715: Epoch 672 
2025-07-12 05:37:34.864828: Current learning rate: 0.00367 
2025-07-12 05:38:44.146599: train_loss -0.9759 
2025-07-12 05:38:44.148068: val_loss -0.946 
2025-07-12 05:38:44.149165: Pseudo dice [np.float32(0.9501)] 
2025-07-12 05:38:44.150458: Epoch time: 69.29 s 
2025-07-12 05:38:45.076481:  
2025-07-12 05:38:45.078522: Epoch 673 
2025-07-12 05:38:45.079755: Current learning rate: 0.00366 
2025-07-12 05:39:54.610017: train_loss -0.9786 
2025-07-12 05:39:54.611336: val_loss -0.9528 
2025-07-12 05:39:54.612447: Pseudo dice [np.float32(0.9568)] 
2025-07-12 05:39:54.613548: Epoch time: 69.54 s 
2025-07-12 05:39:55.560635:  
2025-07-12 05:39:55.562250: Epoch 674 
2025-07-12 05:39:55.563290: Current learning rate: 0.00365 
2025-07-12 05:41:05.900650: train_loss -0.978 
2025-07-12 05:41:05.902111: val_loss -0.9494 
2025-07-12 05:41:05.903176: Pseudo dice [np.float32(0.9535)] 
2025-07-12 05:41:05.904321: Epoch time: 70.34 s 
2025-07-12 05:41:06.848035:  
2025-07-12 05:41:06.849968: Epoch 675 
2025-07-12 05:41:06.851109: Current learning rate: 0.00364 
2025-07-12 05:42:16.134082: train_loss -0.9784 
2025-07-12 05:42:16.135469: val_loss -0.9492 
2025-07-12 05:42:16.136458: Pseudo dice [np.float32(0.9533)] 
2025-07-12 05:42:16.137327: Epoch time: 69.29 s 
2025-07-12 05:42:17.066205:  
2025-07-12 05:42:17.068150: Epoch 676 
2025-07-12 05:42:17.069168: Current learning rate: 0.00363 
2025-07-12 05:43:26.090243: train_loss -0.9783 
2025-07-12 05:43:26.091456: val_loss -0.9465 
2025-07-12 05:43:26.092390: Pseudo dice [np.float32(0.9501)] 
2025-07-12 05:43:26.093656: Epoch time: 69.03 s 
2025-07-12 05:43:27.025624:  
2025-07-12 05:43:27.027215: Epoch 677 
2025-07-12 05:43:27.028321: Current learning rate: 0.00362 
2025-07-12 05:44:36.109387: train_loss -0.9779 
2025-07-12 05:44:36.110661: val_loss -0.9519 
2025-07-12 05:44:36.111744: Pseudo dice [np.float32(0.9554)] 
2025-07-12 05:44:36.112694: Epoch time: 69.09 s 
2025-07-12 05:44:37.061556:  
2025-07-12 05:44:37.063407: Epoch 678 
2025-07-12 05:44:37.064613: Current learning rate: 0.00361 
2025-07-12 05:45:46.250907: train_loss -0.9774 
2025-07-12 05:45:46.252151: val_loss -0.9436 
2025-07-12 05:45:46.253338: Pseudo dice [np.float32(0.9472)] 
2025-07-12 05:45:46.254542: Epoch time: 69.19 s 
2025-07-12 05:45:47.201633:  
2025-07-12 05:45:47.203401: Epoch 679 
2025-07-12 05:45:47.205300: Current learning rate: 0.0036 
2025-07-12 05:46:56.453122: train_loss -0.978 
2025-07-12 05:46:56.454282: val_loss -0.9472 
2025-07-12 05:46:56.455311: Pseudo dice [np.float32(0.9512)] 
2025-07-12 05:46:56.456870: Epoch time: 69.26 s 
2025-07-12 05:46:57.408475:  
2025-07-12 05:46:57.410843: Epoch 680 
2025-07-12 05:46:57.411881: Current learning rate: 0.00359 
2025-07-12 05:48:06.775157: train_loss -0.9791 
2025-07-12 05:48:06.776676: val_loss -0.9452 
2025-07-12 05:48:06.777666: Pseudo dice [np.float32(0.949)] 
2025-07-12 05:48:06.778628: Epoch time: 69.37 s 
2025-07-12 05:48:08.490754:  
2025-07-12 05:48:08.492698: Epoch 681 
2025-07-12 05:48:08.494164: Current learning rate: 0.00358 
2025-07-12 05:49:17.936252: train_loss -0.9781 
2025-07-12 05:49:17.937619: val_loss -0.9505 
2025-07-12 05:49:17.938854: Pseudo dice [np.float32(0.9541)] 
2025-07-12 05:49:17.940453: Epoch time: 69.45 s 
2025-07-12 05:49:18.898047:  
2025-07-12 05:49:18.900284: Epoch 682 
2025-07-12 05:49:18.901714: Current learning rate: 0.00357 
2025-07-12 05:50:28.402150: train_loss -0.9791 
2025-07-12 05:50:28.403601: val_loss -0.9525 
2025-07-12 05:50:28.404636: Pseudo dice [np.float32(0.956)] 
2025-07-12 05:50:28.405866: Epoch time: 69.51 s 
2025-07-12 05:50:29.367134:  
2025-07-12 05:50:29.369118: Epoch 683 
2025-07-12 05:50:29.370348: Current learning rate: 0.00356 
2025-07-12 05:51:38.920074: train_loss -0.979 
2025-07-12 05:51:38.921775: val_loss -0.9504 
2025-07-12 05:51:38.923292: Pseudo dice [np.float32(0.9536)] 
2025-07-12 05:51:38.924528: Epoch time: 69.56 s 
2025-07-12 05:51:39.875353:  
2025-07-12 05:51:39.877171: Epoch 684 
2025-07-12 05:51:39.878217: Current learning rate: 0.00355 
2025-07-12 05:52:49.780438: train_loss -0.9782 
2025-07-12 05:52:49.781628: val_loss -0.95 
2025-07-12 05:52:49.782939: Pseudo dice [np.float32(0.9537)] 
2025-07-12 05:52:49.784169: Epoch time: 69.91 s 
2025-07-12 05:52:50.737018:  
2025-07-12 05:52:50.738987: Epoch 685 
2025-07-12 05:52:50.740118: Current learning rate: 0.00354 
2025-07-12 05:54:00.277413: train_loss -0.9779 
2025-07-12 05:54:00.278976: val_loss -0.9514 
2025-07-12 05:54:00.280219: Pseudo dice [np.float32(0.9542)] 
2025-07-12 05:54:00.281460: Epoch time: 69.54 s 
2025-07-12 05:54:01.232124:  
2025-07-12 05:54:01.234247: Epoch 686 
2025-07-12 05:54:01.235382: Current learning rate: 0.00353 
2025-07-12 05:55:10.812074: train_loss -0.977 
2025-07-12 05:55:10.813430: val_loss -0.9516 
2025-07-12 05:55:10.814464: Pseudo dice [np.float32(0.9553)] 
2025-07-12 05:55:10.815517: Epoch time: 69.58 s 
2025-07-12 05:55:11.782042:  
2025-07-12 05:55:11.783762: Epoch 687 
2025-07-12 05:55:11.785241: Current learning rate: 0.00352 
2025-07-12 05:56:29.106438: train_loss -0.9784 
2025-07-12 05:56:29.107834: val_loss -0.9453 
2025-07-12 05:56:29.108939: Pseudo dice [np.float32(0.9499)] 
2025-07-12 05:56:29.110147: Epoch time: 77.33 s 
2025-07-12 05:56:30.050397:  
2025-07-12 05:56:30.052703: Epoch 688 
2025-07-12 05:56:30.054174: Current learning rate: 0.00351 
2025-07-12 05:57:41.358374: train_loss -0.9774 
2025-07-12 05:57:41.360303: val_loss -0.9483 
2025-07-12 05:57:41.361682: Pseudo dice [np.float32(0.952)] 
2025-07-12 05:57:41.362933: Epoch time: 71.31 s 
2025-07-12 05:57:42.320197:  
2025-07-12 05:57:42.322033: Epoch 689 
2025-07-12 05:57:42.323288: Current learning rate: 0.0035 
2025-07-12 05:58:51.258122: train_loss -0.9777 
2025-07-12 05:58:51.259385: val_loss -0.9527 
2025-07-12 05:58:51.260532: Pseudo dice [np.float32(0.9559)] 
2025-07-12 05:58:51.261806: Epoch time: 68.94 s 
2025-07-12 05:58:53.072292:  
2025-07-12 05:58:53.074274: Epoch 690 
2025-07-12 05:58:53.075788: Current learning rate: 0.00349 
2025-07-12 06:00:02.208416: train_loss -0.9787 
2025-07-12 06:00:02.210576: val_loss -0.9532 
2025-07-12 06:00:02.211548: Pseudo dice [np.float32(0.9575)] 
2025-07-12 06:00:02.212703: Epoch time: 69.14 s 
2025-07-12 06:00:03.175272:  
2025-07-12 06:00:03.177226: Epoch 691 
2025-07-12 06:00:03.178405: Current learning rate: 0.00348 
2025-07-12 06:01:12.328786: train_loss -0.9787 
2025-07-12 06:01:12.330134: val_loss -0.9521 
2025-07-12 06:01:12.331397: Pseudo dice [np.float32(0.9546)] 
2025-07-12 06:01:12.332694: Epoch time: 69.16 s 
2025-07-12 06:01:13.282145:  
2025-07-12 06:01:13.283977: Epoch 692 
2025-07-12 06:01:13.285069: Current learning rate: 0.00346 
2025-07-12 06:02:22.533789: train_loss -0.9785 
2025-07-12 06:02:22.535102: val_loss -0.948 
2025-07-12 06:02:22.536445: Pseudo dice [np.float32(0.9512)] 
2025-07-12 06:02:22.537646: Epoch time: 69.26 s 
2025-07-12 06:02:23.489051:  
2025-07-12 06:02:23.491044: Epoch 693 
2025-07-12 06:02:23.492156: Current learning rate: 0.00345 
2025-07-12 06:03:32.765917: train_loss -0.979 
2025-07-12 06:03:32.767159: val_loss -0.9471 
2025-07-12 06:03:32.768124: Pseudo dice [np.float32(0.9515)] 
2025-07-12 06:03:32.769060: Epoch time: 69.28 s 
2025-07-12 06:03:33.745407:  
2025-07-12 06:03:33.747188: Epoch 694 
2025-07-12 06:03:33.748231: Current learning rate: 0.00344 
2025-07-12 06:04:43.013904: train_loss -0.9787 
2025-07-12 06:04:43.015167: val_loss -0.9495 
2025-07-12 06:04:43.016164: Pseudo dice [np.float32(0.9533)] 
2025-07-12 06:04:43.017310: Epoch time: 69.27 s 
2025-07-12 06:04:43.948073:  
2025-07-12 06:04:43.950295: Epoch 695 
2025-07-12 06:04:43.951270: Current learning rate: 0.00343 
2025-07-12 06:05:53.405879: train_loss -0.9799 
2025-07-12 06:05:53.407335: val_loss -0.9489 
2025-07-12 06:05:53.408296: Pseudo dice [np.float32(0.9523)] 
2025-07-12 06:05:53.409231: Epoch time: 69.46 s 
2025-07-12 06:05:54.357628:  
2025-07-12 06:05:54.359245: Epoch 696 
2025-07-12 06:05:54.360374: Current learning rate: 0.00342 
2025-07-12 06:07:03.710235: train_loss -0.9793 
2025-07-12 06:07:03.711532: val_loss -0.9516 
2025-07-12 06:07:03.712669: Pseudo dice [np.float32(0.9557)] 
2025-07-12 06:07:03.714054: Epoch time: 69.36 s 
2025-07-12 06:07:04.640561:  
2025-07-12 06:07:04.642118: Epoch 697 
2025-07-12 06:07:04.643168: Current learning rate: 0.00341 
2025-07-12 06:08:13.860340: train_loss -0.9803 
2025-07-12 06:08:13.861582: val_loss -0.9533 
2025-07-12 06:08:13.862660: Pseudo dice [np.float32(0.9563)] 
2025-07-12 06:08:13.863858: Epoch time: 69.22 s 
2025-07-12 06:08:14.821158:  
2025-07-12 06:08:14.822732: Epoch 698 
2025-07-12 06:08:14.823806: Current learning rate: 0.0034 
2025-07-12 06:09:24.023973: train_loss -0.9798 
2025-07-12 06:09:24.025293: val_loss -0.9522 
2025-07-12 06:09:24.026277: Pseudo dice [np.float32(0.9547)] 
2025-07-12 06:09:24.027428: Epoch time: 69.21 s 
2025-07-12 06:09:25.789970:  
2025-07-12 06:09:25.791664: Epoch 699 
2025-07-12 06:09:25.792759: Current learning rate: 0.00339 
2025-07-12 06:10:35.298810: train_loss -0.9795 
2025-07-12 06:10:35.300141: val_loss -0.9485 
2025-07-12 06:10:35.301128: Pseudo dice [np.float32(0.9525)] 
2025-07-12 06:10:35.302101: Epoch time: 69.51 s 
2025-07-12 06:10:37.685174:  
2025-07-12 06:10:37.687207: Epoch 700 
2025-07-12 06:10:37.688205: Current learning rate: 0.00338 
2025-07-12 06:11:46.943625: train_loss -0.9782 
2025-07-12 06:11:46.945059: val_loss -0.9455 
2025-07-12 06:11:46.946101: Pseudo dice [np.float32(0.9493)] 
2025-07-12 06:11:46.947111: Epoch time: 69.26 s 
2025-07-12 06:11:47.847097:  
2025-07-12 06:11:47.849208: Epoch 701 
2025-07-12 06:11:47.850261: Current learning rate: 0.00337 
2025-07-12 06:12:57.265839: train_loss -0.9775 
2025-07-12 06:12:57.267275: val_loss -0.9487 
2025-07-12 06:12:57.268351: Pseudo dice [np.float32(0.9517)] 
2025-07-12 06:12:57.269368: Epoch time: 69.42 s 
2025-07-12 06:12:58.213349:  
2025-07-12 06:12:58.215243: Epoch 702 
2025-07-12 06:12:58.216265: Current learning rate: 0.00336 
2025-07-12 06:14:07.554619: train_loss -0.9788 
2025-07-12 06:14:07.556078: val_loss -0.9474 
2025-07-12 06:14:07.557115: Pseudo dice [np.float32(0.9513)] 
2025-07-12 06:14:07.558118: Epoch time: 69.34 s 
2025-07-12 06:14:08.467885:  
2025-07-12 06:14:08.469796: Epoch 703 
2025-07-12 06:14:08.470897: Current learning rate: 0.00335 
2025-07-12 06:15:17.928952: train_loss -0.9797 
2025-07-12 06:15:17.930403: val_loss -0.9496 
2025-07-12 06:15:17.931515: Pseudo dice [np.float32(0.9527)] 
2025-07-12 06:15:17.932442: Epoch time: 69.46 s 
2025-07-12 06:15:18.855942:  
2025-07-12 06:15:18.858083: Epoch 704 
2025-07-12 06:15:18.859180: Current learning rate: 0.00334 
2025-07-12 06:16:28.411413: train_loss -0.9782 
2025-07-12 06:16:28.412579: val_loss -0.9527 
2025-07-12 06:16:28.413560: Pseudo dice [np.float32(0.9563)] 
2025-07-12 06:16:28.414553: Epoch time: 69.56 s 
2025-07-12 06:16:29.360833:  
2025-07-12 06:16:29.362376: Epoch 705 
2025-07-12 06:16:29.363500: Current learning rate: 0.00333 
2025-07-12 06:17:38.829400: train_loss -0.9783 
2025-07-12 06:17:38.830678: val_loss -0.951 
2025-07-12 06:17:38.831583: Pseudo dice [np.float32(0.9542)] 
2025-07-12 06:17:38.832691: Epoch time: 69.47 s 
2025-07-12 06:17:39.785073:  
2025-07-12 06:17:39.786926: Epoch 706 
2025-07-12 06:17:39.787927: Current learning rate: 0.00332 
2025-07-12 06:18:49.003364: train_loss -0.978 
2025-07-12 06:18:49.004678: val_loss -0.9496 
2025-07-12 06:18:49.006092: Pseudo dice [np.float32(0.9526)] 
2025-07-12 06:18:49.007566: Epoch time: 69.22 s 
2025-07-12 06:18:49.952786:  
2025-07-12 06:18:49.954605: Epoch 707 
2025-07-12 06:18:49.955956: Current learning rate: 0.00331 
2025-07-12 06:19:59.900298: train_loss -0.9777 
2025-07-12 06:19:59.901590: val_loss -0.9507 
2025-07-12 06:19:59.902994: Pseudo dice [np.float32(0.954)] 
2025-07-12 06:19:59.904429: Epoch time: 69.95 s 
2025-07-12 06:20:00.842933:  
2025-07-12 06:20:00.844771: Epoch 708 
2025-07-12 06:20:00.845784: Current learning rate: 0.0033 
2025-07-12 06:21:10.194060: train_loss -0.9782 
2025-07-12 06:21:10.195233: val_loss -0.9488 
2025-07-12 06:21:10.196622: Pseudo dice [np.float32(0.9521)] 
2025-07-12 06:21:10.197617: Epoch time: 69.35 s 
2025-07-12 06:21:11.151463:  
2025-07-12 06:21:11.153219: Epoch 709 
2025-07-12 06:21:11.154201: Current learning rate: 0.00329 
2025-07-12 06:22:20.507521: train_loss -0.9787 
2025-07-12 06:22:20.508676: val_loss -0.9484 
2025-07-12 06:22:20.509700: Pseudo dice [np.float32(0.9521)] 
2025-07-12 06:22:20.510711: Epoch time: 69.36 s 
2025-07-12 06:22:21.472026:  
2025-07-12 06:22:21.473943: Epoch 710 
2025-07-12 06:22:21.475249: Current learning rate: 0.00328 
2025-07-12 06:23:30.897666: train_loss -0.9771 
2025-07-12 06:23:30.898959: val_loss -0.9493 
2025-07-12 06:23:30.899909: Pseudo dice [np.float32(0.9533)] 
2025-07-12 06:23:30.900995: Epoch time: 69.43 s 
2025-07-12 06:23:31.862903:  
2025-07-12 06:23:31.864672: Epoch 711 
2025-07-12 06:23:31.865595: Current learning rate: 0.00327 
2025-07-12 06:24:41.751600: train_loss -0.9784 
2025-07-12 06:24:41.752817: val_loss -0.9468 
2025-07-12 06:24:41.754020: Pseudo dice [np.float32(0.9508)] 
2025-07-12 06:24:41.755220: Epoch time: 69.89 s 
2025-07-12 06:24:42.717734:  
2025-07-12 06:24:42.719478: Epoch 712 
2025-07-12 06:24:42.720470: Current learning rate: 0.00326 
2025-07-12 06:25:53.390443: train_loss -0.979 
2025-07-12 06:25:53.391801: val_loss -0.9495 
2025-07-12 06:25:53.392865: Pseudo dice [np.float32(0.9527)] 
2025-07-12 06:25:53.394000: Epoch time: 70.68 s 
2025-07-12 06:25:54.351114:  
2025-07-12 06:25:54.353091: Epoch 713 
2025-07-12 06:25:54.354386: Current learning rate: 0.00325 
2025-07-12 06:27:03.930452: train_loss -0.9795 
2025-07-12 06:27:03.931800: val_loss -0.9509 
2025-07-12 06:27:03.932975: Pseudo dice [np.float32(0.9544)] 
2025-07-12 06:27:03.934200: Epoch time: 69.58 s 
2025-07-12 06:27:04.877769:  
2025-07-12 06:27:04.879573: Epoch 714 
2025-07-12 06:27:04.880632: Current learning rate: 0.00324 
2025-07-12 06:28:13.467119: train_loss -0.9787 
2025-07-12 06:28:13.468342: val_loss -0.9543 
2025-07-12 06:28:13.469336: Pseudo dice [np.float32(0.9572)] 
2025-07-12 06:28:13.470482: Epoch time: 68.59 s 
2025-07-12 06:28:14.419404:  
2025-07-12 06:28:14.421248: Epoch 715 
2025-07-12 06:28:14.422745: Current learning rate: 0.00323 
2025-07-12 06:29:23.277518: train_loss -0.9784 
2025-07-12 06:29:23.283183: val_loss -0.9476 
2025-07-12 06:29:23.284184: Pseudo dice [np.float32(0.9511)] 
2025-07-12 06:29:23.285307: Epoch time: 68.86 s 
2025-07-12 06:29:24.230442:  
2025-07-12 06:29:24.232504: Epoch 716 
2025-07-12 06:29:24.233868: Current learning rate: 0.00322 
2025-07-12 06:30:34.069813: train_loss -0.9795 
2025-07-12 06:30:34.071065: val_loss -0.9474 
2025-07-12 06:30:34.072090: Pseudo dice [np.float32(0.9512)] 
2025-07-12 06:30:34.073015: Epoch time: 69.84 s 
2025-07-12 06:30:35.045086:  
2025-07-12 06:30:35.047245: Epoch 717 
2025-07-12 06:30:35.048291: Current learning rate: 0.00321 
2025-07-12 06:31:44.598925: train_loss -0.9787 
2025-07-12 06:31:44.600059: val_loss -0.9489 
2025-07-12 06:31:44.601099: Pseudo dice [np.float32(0.9528)] 
2025-07-12 06:31:44.602353: Epoch time: 69.56 s 
2025-07-12 06:31:45.548755:  
2025-07-12 06:31:45.550586: Epoch 718 
2025-07-12 06:31:45.551755: Current learning rate: 0.0032 
2025-07-12 06:32:55.229076: train_loss -0.9787 
2025-07-12 06:32:55.230526: val_loss -0.9491 
2025-07-12 06:32:55.231661: Pseudo dice [np.float32(0.9532)] 
2025-07-12 06:32:55.232785: Epoch time: 69.68 s 
2025-07-12 06:32:56.215444:  
2025-07-12 06:32:56.217776: Epoch 719 
2025-07-12 06:32:56.219011: Current learning rate: 0.00319 
2025-07-12 06:34:05.809858: train_loss -0.9799 
2025-07-12 06:34:05.811220: val_loss -0.9473 
2025-07-12 06:34:05.812212: Pseudo dice [np.float32(0.9514)] 
2025-07-12 06:34:05.813399: Epoch time: 69.6 s 
2025-07-12 06:34:06.767027:  
2025-07-12 06:34:06.769209: Epoch 720 
2025-07-12 06:34:06.770364: Current learning rate: 0.00318 
2025-07-12 06:35:16.273974: train_loss -0.9786 
2025-07-12 06:35:16.275423: val_loss -0.9485 
2025-07-12 06:35:16.277019: Pseudo dice [np.float32(0.9526)] 
2025-07-12 06:35:16.278342: Epoch time: 69.51 s 
2025-07-12 06:35:17.241541:  
2025-07-12 06:35:17.243837: Epoch 721 
2025-07-12 06:35:17.244869: Current learning rate: 0.00317 
2025-07-12 06:36:26.612754: train_loss -0.9792 
2025-07-12 06:36:26.613899: val_loss -0.9508 
2025-07-12 06:36:26.615443: Pseudo dice [np.float32(0.9555)] 
2025-07-12 06:36:26.617101: Epoch time: 69.37 s 
2025-07-12 06:36:27.574306:  
2025-07-12 06:36:27.576334: Epoch 722 
2025-07-12 06:36:27.577461: Current learning rate: 0.00316 
2025-07-12 06:37:36.981925: train_loss -0.9785 
2025-07-12 06:37:36.983151: val_loss -0.9494 
2025-07-12 06:37:36.984465: Pseudo dice [np.float32(0.9527)] 
2025-07-12 06:37:36.985694: Epoch time: 69.41 s 
2025-07-12 06:37:37.940978:  
2025-07-12 06:37:37.943250: Epoch 723 
2025-07-12 06:37:37.944426: Current learning rate: 0.00315 
2025-07-12 06:38:47.239972: train_loss -0.9803 
2025-07-12 06:38:47.241091: val_loss -0.9465 
2025-07-12 06:38:47.242234: Pseudo dice [np.float32(0.951)] 
2025-07-12 06:38:47.243165: Epoch time: 69.3 s 
2025-07-12 06:38:48.202434:  
2025-07-12 06:38:48.204737: Epoch 724 
2025-07-12 06:38:48.206172: Current learning rate: 0.00314 
2025-07-12 06:39:57.670514: train_loss -0.9791 
2025-07-12 06:39:57.672901: val_loss -0.9497 
2025-07-12 06:39:57.673984: Pseudo dice [np.float32(0.9539)] 
2025-07-12 06:39:57.675144: Epoch time: 69.47 s 
2025-07-12 06:39:58.628583:  
2025-07-12 06:39:58.630347: Epoch 725 
2025-07-12 06:39:58.631477: Current learning rate: 0.00313 
2025-07-12 06:41:13.796208: train_loss -0.9784 
2025-07-12 06:41:13.797404: val_loss -0.9489 
2025-07-12 06:41:13.798364: Pseudo dice [np.float32(0.9527)] 
2025-07-12 06:41:13.799541: Epoch time: 75.17 s 
2025-07-12 06:41:14.753196:  
2025-07-12 06:41:14.755140: Epoch 726 
2025-07-12 06:41:14.756230: Current learning rate: 0.00312 
2025-07-12 06:42:24.291359: train_loss -0.9794 
2025-07-12 06:42:24.292962: val_loss -0.9509 
2025-07-12 06:42:24.294226: Pseudo dice [np.float32(0.9546)] 
2025-07-12 06:42:24.295877: Epoch time: 69.54 s 
2025-07-12 06:42:25.251331:  
2025-07-12 06:42:25.253127: Epoch 727 
2025-07-12 06:42:25.254167: Current learning rate: 0.00311 
2025-07-12 06:43:34.462283: train_loss -0.9791 
2025-07-12 06:43:34.463423: val_loss -0.9455 
2025-07-12 06:43:34.464492: Pseudo dice [np.float32(0.9496)] 
2025-07-12 06:43:34.465558: Epoch time: 69.21 s 
2025-07-12 06:43:35.407551:  
2025-07-12 06:43:35.409355: Epoch 728 
2025-07-12 06:43:35.410415: Current learning rate: 0.0031 
2025-07-12 06:44:44.888046: train_loss -0.9784 
2025-07-12 06:44:44.889428: val_loss -0.9499 
2025-07-12 06:44:44.890384: Pseudo dice [np.float32(0.9538)] 
2025-07-12 06:44:44.891614: Epoch time: 69.48 s 
2025-07-12 06:44:45.841769:  
2025-07-12 06:44:45.843527: Epoch 729 
2025-07-12 06:44:45.844922: Current learning rate: 0.00309 
2025-07-12 06:45:55.211798: train_loss -0.9793 
2025-07-12 06:45:55.213029: val_loss -0.947 
2025-07-12 06:45:55.214497: Pseudo dice [np.float32(0.9503)] 
2025-07-12 06:45:55.215685: Epoch time: 69.37 s 
2025-07-12 06:45:56.173685:  
2025-07-12 06:45:56.175575: Epoch 730 
2025-07-12 06:45:56.176764: Current learning rate: 0.00308 
2025-07-12 06:47:05.735204: train_loss -0.979 
2025-07-12 06:47:05.736453: val_loss -0.949 
2025-07-12 06:47:05.737454: Pseudo dice [np.float32(0.9529)] 
2025-07-12 06:47:05.738687: Epoch time: 69.57 s 
2025-07-12 06:47:06.693335:  
2025-07-12 06:47:06.695131: Epoch 731 
2025-07-12 06:47:06.696177: Current learning rate: 0.00307 
2025-07-12 06:48:16.219893: train_loss -0.9792 
2025-07-12 06:48:16.221632: val_loss -0.9502 
2025-07-12 06:48:16.223094: Pseudo dice [np.float32(0.9534)] 
2025-07-12 06:48:16.224172: Epoch time: 69.53 s 
2025-07-12 06:48:17.175106:  
2025-07-12 06:48:17.176874: Epoch 732 
2025-07-12 06:48:17.177924: Current learning rate: 0.00306 
2025-07-12 06:49:26.765622: train_loss -0.9797 
2025-07-12 06:49:26.766892: val_loss -0.9508 
2025-07-12 06:49:26.767888: Pseudo dice [np.float32(0.9544)] 
2025-07-12 06:49:26.769511: Epoch time: 69.59 s 
2025-07-12 06:49:27.723833:  
2025-07-12 06:49:27.725905: Epoch 733 
2025-07-12 06:49:27.726968: Current learning rate: 0.00305 
2025-07-12 06:50:37.408910: train_loss -0.9794 
2025-07-12 06:50:37.410168: val_loss -0.9505 
2025-07-12 06:50:37.411123: Pseudo dice [np.float32(0.9547)] 
2025-07-12 06:50:37.412824: Epoch time: 69.69 s 
2025-07-12 06:50:38.373000:  
2025-07-12 06:50:38.375032: Epoch 734 
2025-07-12 06:50:38.376111: Current learning rate: 0.00304 
2025-07-12 06:51:48.664514: train_loss -0.9798 
2025-07-12 06:51:48.666080: val_loss -0.9496 
2025-07-12 06:51:48.667510: Pseudo dice [np.float32(0.9532)] 
2025-07-12 06:51:48.669174: Epoch time: 70.3 s 
2025-07-12 06:51:49.613974:  
2025-07-12 06:51:49.615645: Epoch 735 
2025-07-12 06:51:49.616764: Current learning rate: 0.00303 
2025-07-12 06:52:59.362097: train_loss -0.9802 
2025-07-12 06:52:59.363738: val_loss -0.9501 
2025-07-12 06:52:59.365139: Pseudo dice [np.float32(0.954)] 
2025-07-12 06:52:59.366102: Epoch time: 69.75 s 
2025-07-12 06:53:00.324931:  
2025-07-12 06:53:00.326863: Epoch 736 
2025-07-12 06:53:00.327885: Current learning rate: 0.00302 
2025-07-12 06:54:09.957801: train_loss -0.9799 
2025-07-12 06:54:09.959470: val_loss -0.9487 
2025-07-12 06:54:09.960845: Pseudo dice [np.float32(0.9524)] 
2025-07-12 06:54:09.961924: Epoch time: 69.64 s 
2025-07-12 06:54:10.908354:  
2025-07-12 06:54:10.909990: Epoch 737 
2025-07-12 06:54:10.911159: Current learning rate: 0.00301 
2025-07-12 06:55:20.343611: train_loss -0.9799 
2025-07-12 06:55:20.345060: val_loss -0.9523 
2025-07-12 06:55:20.345957: Pseudo dice [np.float32(0.9562)] 
2025-07-12 06:55:20.347063: Epoch time: 69.44 s 
2025-07-12 06:55:21.290735:  
2025-07-12 06:55:21.292473: Epoch 738 
2025-07-12 06:55:21.293737: Current learning rate: 0.003 
2025-07-12 06:56:30.735142: train_loss -0.9795 
2025-07-12 06:56:30.736722: val_loss -0.9474 
2025-07-12 06:56:30.738870: Pseudo dice [np.float32(0.9512)] 
2025-07-12 06:56:30.740255: Epoch time: 69.45 s 
2025-07-12 06:56:31.700154:  
2025-07-12 06:56:31.702044: Epoch 739 
2025-07-12 06:56:31.703073: Current learning rate: 0.00299 
2025-07-12 06:57:41.059114: train_loss -0.9795 
2025-07-12 06:57:41.060326: val_loss -0.9474 
2025-07-12 06:57:41.061395: Pseudo dice [np.float32(0.9503)] 
2025-07-12 06:57:41.062687: Epoch time: 69.36 s 
2025-07-12 06:57:41.987038:  
2025-07-12 06:57:41.988976: Epoch 740 
2025-07-12 06:57:41.990083: Current learning rate: 0.00297 
2025-07-12 06:58:51.791706: train_loss -0.9797 
2025-07-12 06:58:51.793011: val_loss -0.9509 
2025-07-12 06:58:51.794823: Pseudo dice [np.float32(0.9541)] 
2025-07-12 06:58:51.795942: Epoch time: 69.81 s 
2025-07-12 06:58:52.758094:  
2025-07-12 06:58:52.760201: Epoch 741 
2025-07-12 06:58:52.761499: Current learning rate: 0.00296 
2025-07-12 07:00:02.156528: train_loss -0.9798 
2025-07-12 07:00:02.157803: val_loss -0.9507 
2025-07-12 07:00:02.159007: Pseudo dice [np.float32(0.9546)] 
2025-07-12 07:00:02.160313: Epoch time: 69.4 s 
2025-07-12 07:00:03.105839:  
2025-07-12 07:00:03.107840: Epoch 742 
2025-07-12 07:00:03.108978: Current learning rate: 0.00295 
2025-07-12 07:01:12.626663: train_loss -0.9804 
2025-07-12 07:01:12.627896: val_loss -0.9516 
2025-07-12 07:01:12.628907: Pseudo dice [np.float32(0.9548)] 
2025-07-12 07:01:12.629923: Epoch time: 69.52 s 
2025-07-12 07:01:13.586064:  
2025-07-12 07:01:13.587790: Epoch 743 
2025-07-12 07:01:13.588903: Current learning rate: 0.00294 
2025-07-12 07:02:23.807120: train_loss -0.9802 
2025-07-12 07:02:23.808606: val_loss -0.9488 
2025-07-12 07:02:23.809831: Pseudo dice [np.float32(0.9523)] 
2025-07-12 07:02:23.811095: Epoch time: 70.22 s 
2025-07-12 07:02:24.778716:  
2025-07-12 07:02:24.780791: Epoch 744 
2025-07-12 07:02:24.782251: Current learning rate: 0.00293 
2025-07-12 07:03:34.235199: train_loss -0.9805 
2025-07-12 07:03:34.236509: val_loss -0.9526 
2025-07-12 07:03:34.237534: Pseudo dice [np.float32(0.9557)] 
2025-07-12 07:03:34.238600: Epoch time: 69.46 s 
2025-07-12 07:03:35.174457:  
2025-07-12 07:03:35.176014: Epoch 745 
2025-07-12 07:03:35.176971: Current learning rate: 0.00292 
2025-07-12 07:04:44.592640: train_loss -0.9801 
2025-07-12 07:04:44.594069: val_loss -0.9503 
2025-07-12 07:04:44.595089: Pseudo dice [np.float32(0.9543)] 
2025-07-12 07:04:44.596246: Epoch time: 69.42 s 
2025-07-12 07:04:45.552414:  
2025-07-12 07:04:45.554140: Epoch 746 
2025-07-12 07:04:45.555252: Current learning rate: 0.00291 
2025-07-12 07:05:55.044232: train_loss -0.9796 
2025-07-12 07:05:55.045452: val_loss -0.951 
2025-07-12 07:05:55.046549: Pseudo dice [np.float32(0.9548)] 
2025-07-12 07:05:55.047522: Epoch time: 69.5 s 
2025-07-12 07:05:56.012775:  
2025-07-12 07:05:56.014652: Epoch 747 
2025-07-12 07:05:56.015687: Current learning rate: 0.0029 
2025-07-12 07:07:05.582360: train_loss -0.9805 
2025-07-12 07:07:05.583582: val_loss -0.9494 
2025-07-12 07:07:05.584864: Pseudo dice [np.float32(0.9523)] 
2025-07-12 07:07:05.585944: Epoch time: 69.57 s 
2025-07-12 07:07:06.535104:  
2025-07-12 07:07:06.536912: Epoch 748 
2025-07-12 07:07:06.538125: Current learning rate: 0.00289 
2025-07-12 07:08:16.050640: train_loss -0.9796 
2025-07-12 07:08:16.052286: val_loss -0.9473 
2025-07-12 07:08:16.053279: Pseudo dice [np.float32(0.9506)] 
2025-07-12 07:08:16.054269: Epoch time: 69.52 s 
2025-07-12 07:08:17.005634:  
2025-07-12 07:08:17.008158: Epoch 749 
2025-07-12 07:08:17.009643: Current learning rate: 0.00288 
2025-07-12 07:09:26.780649: train_loss -0.9792 
2025-07-12 07:09:26.781879: val_loss -0.9516 
2025-07-12 07:09:26.783129: Pseudo dice [np.float32(0.9556)] 
2025-07-12 07:09:26.784230: Epoch time: 69.78 s 
2025-07-12 07:09:29.302286:  
2025-07-12 07:09:29.304105: Epoch 750 
2025-07-12 07:09:29.305231: Current learning rate: 0.00287 
2025-07-12 07:10:38.497644: train_loss -0.9794 
2025-07-12 07:10:38.498743: val_loss -0.9472 
2025-07-12 07:10:38.499630: Pseudo dice [np.float32(0.9512)] 
2025-07-12 07:10:38.501196: Epoch time: 69.2 s 
2025-07-12 07:10:39.464039:  
2025-07-12 07:10:39.465482: Epoch 751 
2025-07-12 07:10:39.466755: Current learning rate: 0.00286 
2025-07-12 07:11:48.629262: train_loss -0.9793 
2025-07-12 07:11:48.630510: val_loss -0.9495 
2025-07-12 07:11:48.632835: Pseudo dice [np.float32(0.9534)] 
2025-07-12 07:11:48.634047: Epoch time: 69.17 s 
2025-07-12 07:11:50.352863:  
2025-07-12 07:11:50.354736: Epoch 752 
2025-07-12 07:11:50.355934: Current learning rate: 0.00285 
2025-07-12 07:12:59.570250: train_loss -0.98 
2025-07-12 07:12:59.571594: val_loss -0.9538 
2025-07-12 07:12:59.572691: Pseudo dice [np.float32(0.9571)] 
2025-07-12 07:12:59.574204: Epoch time: 69.22 s 
2025-07-12 07:13:00.514427:  
2025-07-12 07:13:00.516146: Epoch 753 
2025-07-12 07:13:00.517491: Current learning rate: 0.00284 
2025-07-12 07:14:09.773494: train_loss -0.9802 
2025-07-12 07:14:09.774993: val_loss -0.9527 
2025-07-12 07:14:09.776003: Pseudo dice [np.float32(0.9571)] 
2025-07-12 07:14:09.777122: Epoch time: 69.26 s 
2025-07-12 07:14:09.778474: Yayy! New best EMA pseudo Dice: 0.9539999961853027 
2025-07-12 07:14:12.554337:  
2025-07-12 07:14:12.556168: Epoch 754 
2025-07-12 07:14:12.557325: Current learning rate: 0.00283 
2025-07-12 07:15:21.695733: train_loss -0.9792 
2025-07-12 07:15:21.696949: val_loss -0.9503 
2025-07-12 07:15:21.697942: Pseudo dice [np.float32(0.9542)] 
2025-07-12 07:15:21.698955: Epoch time: 69.14 s 
2025-07-12 07:15:21.699856: Yayy! New best EMA pseudo Dice: 0.9539999961853027 
2025-07-12 07:15:23.990310:  
2025-07-12 07:15:23.992011: Epoch 755 
2025-07-12 07:15:23.993390: Current learning rate: 0.00282 
2025-07-12 07:16:33.310327: train_loss -0.9804 
2025-07-12 07:16:33.311503: val_loss -0.9488 
2025-07-12 07:16:33.312540: Pseudo dice [np.float32(0.9521)] 
2025-07-12 07:16:33.313504: Epoch time: 69.32 s 
2025-07-12 07:16:34.245013:  
2025-07-12 07:16:34.246634: Epoch 756 
2025-07-12 07:16:34.247790: Current learning rate: 0.00281 
2025-07-12 07:17:43.893238: train_loss -0.9802 
2025-07-12 07:17:43.894663: val_loss -0.9496 
2025-07-12 07:17:43.895705: Pseudo dice [np.float32(0.9537)] 
2025-07-12 07:17:43.896969: Epoch time: 69.65 s 
2025-07-12 07:17:44.848617:  
2025-07-12 07:17:44.850415: Epoch 757 
2025-07-12 07:17:44.851691: Current learning rate: 0.0028 
2025-07-12 07:18:53.983325: train_loss -0.9801 
2025-07-12 07:18:53.984866: val_loss -0.9481 
2025-07-12 07:18:53.986072: Pseudo dice [np.float32(0.9518)] 
2025-07-12 07:18:53.987155: Epoch time: 69.14 s 
2025-07-12 07:18:54.931658:  
2025-07-12 07:18:54.933098: Epoch 758 
2025-07-12 07:18:54.934269: Current learning rate: 0.00279 
2025-07-12 07:20:04.005863: train_loss -0.9805 
2025-07-12 07:20:04.007111: val_loss -0.9483 
2025-07-12 07:20:04.008217: Pseudo dice [np.float32(0.9519)] 
2025-07-12 07:20:04.009887: Epoch time: 69.08 s 
2025-07-12 07:20:04.950044:  
2025-07-12 07:20:04.951766: Epoch 759 
2025-07-12 07:20:04.952770: Current learning rate: 0.00278 
2025-07-12 07:21:14.155349: train_loss -0.98 
2025-07-12 07:21:14.156487: val_loss -0.9536 
2025-07-12 07:21:14.157584: Pseudo dice [np.float32(0.957)] 
2025-07-12 07:21:14.158598: Epoch time: 69.21 s 
2025-07-12 07:21:15.109798:  
2025-07-12 07:21:15.111517: Epoch 760 
2025-07-12 07:21:15.112633: Current learning rate: 0.00277 
2025-07-12 07:22:25.364354: train_loss -0.9796 
2025-07-12 07:22:25.365630: val_loss -0.9516 
2025-07-12 07:22:25.366647: Pseudo dice [np.float32(0.9551)] 
2025-07-12 07:22:25.367686: Epoch time: 70.26 s 
2025-07-12 07:22:26.344136:  
2025-07-12 07:22:26.345876: Epoch 761 
2025-07-12 07:22:26.346853: Current learning rate: 0.00276 
2025-07-12 07:23:35.795972: train_loss -0.9808 
2025-07-12 07:23:35.797419: val_loss -0.9513 
2025-07-12 07:23:35.798342: Pseudo dice [np.float32(0.9554)] 
2025-07-12 07:23:35.799489: Epoch time: 69.46 s 
2025-07-12 07:23:35.800609: Yayy! New best EMA pseudo Dice: 0.9541000127792358 
2025-07-12 07:23:38.024773:  
2025-07-12 07:23:38.026773: Epoch 762 
2025-07-12 07:23:38.027961: Current learning rate: 0.00275 
2025-07-12 07:24:47.595469: train_loss -0.9808 
2025-07-12 07:24:47.596871: val_loss -0.95 
2025-07-12 07:24:47.598127: Pseudo dice [np.float32(0.9536)] 
2025-07-12 07:24:47.599594: Epoch time: 69.57 s 
2025-07-12 07:24:48.551817:  
2025-07-12 07:24:48.553874: Epoch 763 
2025-07-12 07:24:48.554962: Current learning rate: 0.00274 
2025-07-12 07:26:02.589598: train_loss -0.981 
2025-07-12 07:26:02.590846: val_loss -0.9521 
2025-07-12 07:26:02.591920: Pseudo dice [np.float32(0.9545)] 
2025-07-12 07:26:02.592982: Epoch time: 74.04 s 
2025-07-12 07:26:03.545871:  
2025-07-12 07:26:03.547704: Epoch 764 
2025-07-12 07:26:03.548829: Current learning rate: 0.00273 
2025-07-12 07:27:12.676382: train_loss -0.9809 
2025-07-12 07:27:12.677712: val_loss -0.9492 
2025-07-12 07:27:12.678699: Pseudo dice [np.float32(0.9532)] 
2025-07-12 07:27:12.679606: Epoch time: 69.13 s 
2025-07-12 07:27:13.641983:  
2025-07-12 07:27:13.644040: Epoch 765 
2025-07-12 07:27:13.645013: Current learning rate: 0.00272 
2025-07-12 07:28:22.069690: train_loss -0.9809 
2025-07-12 07:28:22.071148: val_loss -0.9503 
2025-07-12 07:28:22.072373: Pseudo dice [np.float32(0.9536)] 
2025-07-12 07:28:22.073627: Epoch time: 68.43 s 
2025-07-12 07:28:23.021215:  
2025-07-12 07:28:23.023144: Epoch 766 
2025-07-12 07:28:23.024245: Current learning rate: 0.00271 
2025-07-12 07:29:31.419652: train_loss -0.9811 
2025-07-12 07:29:31.420762: val_loss -0.9481 
2025-07-12 07:29:31.421957: Pseudo dice [np.float32(0.9508)] 
2025-07-12 07:29:31.423192: Epoch time: 68.4 s 
2025-07-12 07:29:32.390435:  
2025-07-12 07:29:32.391973: Epoch 767 
2025-07-12 07:29:32.393029: Current learning rate: 0.0027 
2025-07-12 07:30:40.831941: train_loss -0.9804 
2025-07-12 07:30:40.833237: val_loss -0.944 
2025-07-12 07:30:40.834408: Pseudo dice [np.float32(0.9488)] 
2025-07-12 07:30:40.835611: Epoch time: 68.45 s 
2025-07-12 07:30:41.784960:  
2025-07-12 07:30:41.786981: Epoch 768 
2025-07-12 07:30:41.788148: Current learning rate: 0.00268 
2025-07-12 07:31:50.317528: train_loss -0.9806 
2025-07-12 07:31:50.319147: val_loss -0.9479 
2025-07-12 07:31:50.320546: Pseudo dice [np.float32(0.9521)] 
2025-07-12 07:31:50.321551: Epoch time: 68.54 s 
2025-07-12 07:31:52.122023:  
2025-07-12 07:31:52.124057: Epoch 769 
2025-07-12 07:31:52.125053: Current learning rate: 0.00267 
2025-07-12 07:33:00.915711: train_loss -0.9813 
2025-07-12 07:33:00.916891: val_loss -0.9483 
2025-07-12 07:33:00.918012: Pseudo dice [np.float32(0.9521)] 
2025-07-12 07:33:00.919203: Epoch time: 68.8 s 
2025-07-12 07:33:01.874196:  
2025-07-12 07:33:01.875910: Epoch 770 
2025-07-12 07:33:01.876918: Current learning rate: 0.00266 
2025-07-12 07:34:10.879734: train_loss -0.9805 
2025-07-12 07:34:10.880959: val_loss -0.9477 
2025-07-12 07:34:10.882600: Pseudo dice [np.float32(0.9507)] 
2025-07-12 07:34:10.883590: Epoch time: 69.01 s 
2025-07-12 07:34:11.847790:  
2025-07-12 07:34:11.849888: Epoch 771 
2025-07-12 07:34:11.850899: Current learning rate: 0.00265 
2025-07-12 07:35:21.099446: train_loss -0.9804 
2025-07-12 07:35:21.100954: val_loss -0.9496 
2025-07-12 07:35:21.102034: Pseudo dice [np.float32(0.9536)] 
2025-07-12 07:35:21.103077: Epoch time: 69.26 s 
2025-07-12 07:35:22.066829:  
2025-07-12 07:35:22.068952: Epoch 772 
2025-07-12 07:35:22.070111: Current learning rate: 0.00264 
2025-07-12 07:36:31.462265: train_loss -0.9799 
2025-07-12 07:36:31.463719: val_loss -0.9469 
2025-07-12 07:36:31.464885: Pseudo dice [np.float32(0.9502)] 
2025-07-12 07:36:31.465961: Epoch time: 69.4 s 
2025-07-12 07:36:32.406513:  
2025-07-12 07:36:32.408170: Epoch 773 
2025-07-12 07:36:32.409177: Current learning rate: 0.00263 
2025-07-12 07:37:41.899877: train_loss -0.9807 
2025-07-12 07:37:41.901159: val_loss -0.9472 
2025-07-12 07:37:41.902328: Pseudo dice [np.float32(0.95)] 
2025-07-12 07:37:41.903664: Epoch time: 69.5 s 
2025-07-12 07:37:42.845539:  
2025-07-12 07:37:42.847588: Epoch 774 
2025-07-12 07:37:42.848611: Current learning rate: 0.00262 
2025-07-12 07:38:52.215004: train_loss -0.9801 
2025-07-12 07:38:52.216308: val_loss -0.952 
2025-07-12 07:38:52.217416: Pseudo dice [np.float32(0.9554)] 
2025-07-12 07:38:52.218488: Epoch time: 69.37 s 
2025-07-12 07:38:53.174957:  
2025-07-12 07:38:53.177124: Epoch 775 
2025-07-12 07:38:53.178210: Current learning rate: 0.00261 
2025-07-12 07:40:02.635082: train_loss -0.9805 
2025-07-12 07:40:02.636326: val_loss -0.9513 
2025-07-12 07:40:02.637340: Pseudo dice [np.float32(0.9548)] 
2025-07-12 07:40:02.638360: Epoch time: 69.46 s 
2025-07-12 07:40:03.610414:  
2025-07-12 07:40:03.612532: Epoch 776 
2025-07-12 07:40:03.613777: Current learning rate: 0.0026 
2025-07-12 07:41:12.969934: train_loss -0.9795 
2025-07-12 07:41:12.971162: val_loss -0.9509 
2025-07-12 07:41:12.972461: Pseudo dice [np.float32(0.9545)] 
2025-07-12 07:41:12.973627: Epoch time: 69.36 s 
2025-07-12 07:41:13.924861:  
2025-07-12 07:41:13.926527: Epoch 777 
2025-07-12 07:41:13.928288: Current learning rate: 0.00259 
2025-07-12 07:42:23.316200: train_loss -0.9787 
2025-07-12 07:42:23.317651: val_loss -0.9457 
2025-07-12 07:42:23.318854: Pseudo dice [np.float32(0.9496)] 
2025-07-12 07:42:23.319850: Epoch time: 69.4 s 
2025-07-12 07:42:25.132596:  
2025-07-12 07:42:25.134559: Epoch 778 
2025-07-12 07:42:25.135577: Current learning rate: 0.00258 
2025-07-12 07:43:34.574261: train_loss -0.9794 
2025-07-12 07:43:34.575517: val_loss -0.9465 
2025-07-12 07:43:34.576506: Pseudo dice [np.float32(0.9504)] 
2025-07-12 07:43:34.577683: Epoch time: 69.45 s 
2025-07-12 07:43:35.538862:  
2025-07-12 07:43:35.541271: Epoch 779 
2025-07-12 07:43:35.542298: Current learning rate: 0.00257 
2025-07-12 07:44:45.003597: train_loss -0.9797 
2025-07-12 07:44:45.005259: val_loss -0.9448 
2025-07-12 07:44:45.006406: Pseudo dice [np.float32(0.9488)] 
2025-07-12 07:44:45.007368: Epoch time: 69.47 s 
2025-07-12 07:44:45.969767:  
2025-07-12 07:44:45.971567: Epoch 780 
2025-07-12 07:44:45.972740: Current learning rate: 0.00256 
2025-07-12 07:45:55.429363: train_loss -0.9803 
2025-07-12 07:45:55.431035: val_loss -0.9468 
2025-07-12 07:45:55.432271: Pseudo dice [np.float32(0.9499)] 
2025-07-12 07:45:55.433277: Epoch time: 69.46 s 
2025-07-12 07:45:56.393377:  
2025-07-12 07:45:56.395101: Epoch 781 
2025-07-12 07:45:56.396050: Current learning rate: 0.00255 
2025-07-12 07:47:06.146985: train_loss -0.9802 
2025-07-12 07:47:06.148148: val_loss -0.9478 
2025-07-12 07:47:06.149136: Pseudo dice [np.float32(0.9516)] 
2025-07-12 07:47:06.150422: Epoch time: 69.76 s 
2025-07-12 07:47:07.100817:  
2025-07-12 07:47:07.103127: Epoch 782 
2025-07-12 07:47:07.104270: Current learning rate: 0.00254 
2025-07-12 07:48:16.624182: train_loss -0.9806 
2025-07-12 07:48:16.625366: val_loss -0.9508 
2025-07-12 07:48:16.626384: Pseudo dice [np.float32(0.9535)] 
2025-07-12 07:48:16.627237: Epoch time: 69.53 s 
2025-07-12 07:48:17.587276:  
2025-07-12 07:48:17.589106: Epoch 783 
2025-07-12 07:48:17.590119: Current learning rate: 0.00253 
2025-07-12 07:49:26.707691: train_loss -0.9802 
2025-07-12 07:49:26.709169: val_loss -0.9463 
2025-07-12 07:49:26.710522: Pseudo dice [np.float32(0.9488)] 
2025-07-12 07:49:26.711448: Epoch time: 69.12 s 
2025-07-12 07:49:27.677814:  
2025-07-12 07:49:27.679480: Epoch 784 
2025-07-12 07:49:27.680708: Current learning rate: 0.00252 
2025-07-12 07:50:36.911797: train_loss -0.9805 
2025-07-12 07:50:36.913165: val_loss -0.9462 
2025-07-12 07:50:36.914325: Pseudo dice [np.float32(0.9506)] 
2025-07-12 07:50:36.915253: Epoch time: 69.24 s 
2025-07-12 07:50:37.869852:  
2025-07-12 07:50:37.871344: Epoch 785 
2025-07-12 07:50:37.872339: Current learning rate: 0.00251 
2025-07-12 07:51:47.268308: train_loss -0.9808 
2025-07-12 07:51:47.269624: val_loss -0.9477 
2025-07-12 07:51:47.271057: Pseudo dice [np.float32(0.951)] 
2025-07-12 07:51:47.271990: Epoch time: 69.4 s 
2025-07-12 07:51:48.239289:  
2025-07-12 07:51:48.241181: Epoch 786 
2025-07-12 07:51:48.242182: Current learning rate: 0.0025 
2025-07-12 07:52:57.681936: train_loss -0.9807 
2025-07-12 07:52:57.683444: val_loss -0.9473 
2025-07-12 07:52:57.684964: Pseudo dice [np.float32(0.951)] 
2025-07-12 07:52:57.686099: Epoch time: 69.45 s 
2025-07-12 07:52:59.442440:  
2025-07-12 07:52:59.444249: Epoch 787 
2025-07-12 07:52:59.445296: Current learning rate: 0.00249 
2025-07-12 07:54:08.843192: train_loss -0.9801 
2025-07-12 07:54:08.844505: val_loss -0.9525 
2025-07-12 07:54:08.845559: Pseudo dice [np.float32(0.9563)] 
2025-07-12 07:54:08.846587: Epoch time: 69.4 s 
2025-07-12 07:54:09.809076:  
2025-07-12 07:54:09.811176: Epoch 788 
2025-07-12 07:54:09.812372: Current learning rate: 0.00248 
2025-07-12 07:55:19.367012: train_loss -0.9804 
2025-07-12 07:55:19.368165: val_loss -0.9506 
2025-07-12 07:55:19.369138: Pseudo dice [np.float32(0.9537)] 
2025-07-12 07:55:19.370318: Epoch time: 69.56 s 
2025-07-12 07:55:20.327578:  
2025-07-12 07:55:20.329473: Epoch 789 
2025-07-12 07:55:20.330642: Current learning rate: 0.00247 
2025-07-12 07:56:34.052147: train_loss -0.9806 
2025-07-12 07:56:34.053445: val_loss -0.9473 
2025-07-12 07:56:34.054351: Pseudo dice [np.float32(0.9519)] 
2025-07-12 07:56:34.055375: Epoch time: 73.73 s 
2025-07-12 07:56:35.014432:  
2025-07-12 07:56:35.016309: Epoch 790 
2025-07-12 07:56:35.017370: Current learning rate: 0.00245 
2025-07-12 07:57:44.207189: train_loss -0.981 
2025-07-12 07:57:44.208648: val_loss -0.952 
2025-07-12 07:57:44.209702: Pseudo dice [np.float32(0.9548)] 
2025-07-12 07:57:44.210678: Epoch time: 69.2 s 
2025-07-12 07:57:45.160681:  
2025-07-12 07:57:45.162715: Epoch 791 
2025-07-12 07:57:45.163978: Current learning rate: 0.00244 
2025-07-12 07:58:54.336113: train_loss -0.9804 
2025-07-12 07:58:54.337539: val_loss -0.9491 
2025-07-12 07:58:54.338672: Pseudo dice [np.float32(0.953)] 
2025-07-12 07:58:54.339643: Epoch time: 69.18 s 
2025-07-12 07:58:55.294347:  
2025-07-12 07:58:55.296336: Epoch 792 
2025-07-12 07:58:55.297281: Current learning rate: 0.00243 
2025-07-12 08:00:04.662999: train_loss -0.9798 
2025-07-12 08:00:04.664197: val_loss -0.9498 
2025-07-12 08:00:04.665164: Pseudo dice [np.float32(0.9534)] 
2025-07-12 08:00:04.666296: Epoch time: 69.37 s 
2025-07-12 08:00:05.633540:  
2025-07-12 08:00:05.635335: Epoch 793 
2025-07-12 08:00:05.636396: Current learning rate: 0.00242 
2025-07-12 08:01:14.978679: train_loss -0.9801 
2025-07-12 08:01:14.980093: val_loss -0.9505 
2025-07-12 08:01:14.981904: Pseudo dice [np.float32(0.9541)] 
2025-07-12 08:01:14.983272: Epoch time: 69.35 s 
2025-07-12 08:01:15.943695:  
2025-07-12 08:01:15.945387: Epoch 794 
2025-07-12 08:01:15.946479: Current learning rate: 0.00241 
2025-07-12 08:02:25.275885: train_loss -0.9811 
2025-07-12 08:02:25.277499: val_loss -0.9532 
2025-07-12 08:02:25.278507: Pseudo dice [np.float32(0.9556)] 
2025-07-12 08:02:25.279575: Epoch time: 69.34 s 
2025-07-12 08:02:26.216566:  
2025-07-12 08:02:26.218669: Epoch 795 
2025-07-12 08:02:26.219881: Current learning rate: 0.0024 
2025-07-12 08:03:35.555294: train_loss -0.9811 
2025-07-12 08:03:35.557100: val_loss -0.9517 
2025-07-12 08:03:35.558094: Pseudo dice [np.float32(0.9548)] 
2025-07-12 08:03:35.559086: Epoch time: 69.34 s 
2025-07-12 08:03:37.331428:  
2025-07-12 08:03:37.333319: Epoch 796 
2025-07-12 08:03:37.334523: Current learning rate: 0.00239 
2025-07-12 08:04:46.582373: train_loss -0.9812 
2025-07-12 08:04:46.583551: val_loss -0.9543 
2025-07-12 08:04:46.584559: Pseudo dice [np.float32(0.9579)] 
2025-07-12 08:04:46.585792: Epoch time: 69.25 s 
2025-07-12 08:04:47.537967:  
2025-07-12 08:04:47.539754: Epoch 797 
2025-07-12 08:04:47.540706: Current learning rate: 0.00238 
2025-07-12 08:05:57.248277: train_loss -0.9806 
2025-07-12 08:05:57.249577: val_loss -0.9468 
2025-07-12 08:05:57.250583: Pseudo dice [np.float32(0.9503)] 
2025-07-12 08:05:57.251564: Epoch time: 69.71 s 
2025-07-12 08:05:58.229275:  
2025-07-12 08:05:58.231280: Epoch 798 
2025-07-12 08:05:58.232292: Current learning rate: 0.00237 
2025-07-12 08:07:13.757213: train_loss -0.9798 
2025-07-12 08:07:13.758727: val_loss -0.9482 
2025-07-12 08:07:13.760231: Pseudo dice [np.float32(0.9515)] 
2025-07-12 08:07:13.761394: Epoch time: 75.53 s 
2025-07-12 08:07:14.747664:  
2025-07-12 08:07:14.749743: Epoch 799 
2025-07-12 08:07:14.750791: Current learning rate: 0.00236 
2025-07-12 08:08:24.234026: train_loss -0.9798 
2025-07-12 08:08:24.235342: val_loss -0.9493 
2025-07-12 08:08:24.236289: Pseudo dice [np.float32(0.9526)] 
2025-07-12 08:08:24.237423: Epoch time: 69.49 s 
2025-07-12 08:08:26.806094:  
2025-07-12 08:08:26.808061: Epoch 800 
2025-07-12 08:08:26.809197: Current learning rate: 0.00235 
2025-07-12 08:09:35.706220: train_loss -0.9803 
2025-07-12 08:09:35.707603: val_loss -0.9469 
2025-07-12 08:09:35.708545: Pseudo dice [np.float32(0.9504)] 
2025-07-12 08:09:35.710053: Epoch time: 68.9 s 
2025-07-12 08:09:36.667799:  
2025-07-12 08:09:36.669788: Epoch 801 
2025-07-12 08:09:36.670952: Current learning rate: 0.00234 
2025-07-12 08:10:45.710042: train_loss -0.9808 
2025-07-12 08:10:45.715340: val_loss -0.9494 
2025-07-12 08:10:45.716477: Pseudo dice [np.float32(0.9526)] 
2025-07-12 08:10:45.717505: Epoch time: 69.05 s 
2025-07-12 08:10:46.689844:  
2025-07-12 08:10:46.691520: Epoch 802 
2025-07-12 08:10:46.693161: Current learning rate: 0.00233 
2025-07-12 08:11:55.864363: train_loss -0.9815 
2025-07-12 08:11:55.865572: val_loss -0.9511 
2025-07-12 08:11:55.866683: Pseudo dice [np.float32(0.954)] 
2025-07-12 08:11:55.867804: Epoch time: 69.18 s 
2025-07-12 08:11:56.820918:  
2025-07-12 08:11:56.823146: Epoch 803 
2025-07-12 08:11:56.824136: Current learning rate: 0.00232 
2025-07-12 08:13:06.246974: train_loss -0.9809 
2025-07-12 08:13:06.248323: val_loss -0.9491 
2025-07-12 08:13:06.249439: Pseudo dice [np.float32(0.9519)] 
2025-07-12 08:13:06.250476: Epoch time: 69.43 s 
2025-07-12 08:13:07.230395:  
2025-07-12 08:13:07.232150: Epoch 804 
2025-07-12 08:13:07.233304: Current learning rate: 0.00231 
2025-07-12 08:14:17.376642: train_loss -0.981 
2025-07-12 08:14:17.377797: val_loss -0.9533 
2025-07-12 08:14:17.378918: Pseudo dice [np.float32(0.9566)] 
2025-07-12 08:14:17.379977: Epoch time: 70.15 s 
2025-07-12 08:14:18.340596:  
2025-07-12 08:14:18.342278: Epoch 805 
2025-07-12 08:14:18.343249: Current learning rate: 0.0023 
2025-07-12 08:15:27.772363: train_loss -0.9811 
2025-07-12 08:15:27.773663: val_loss -0.9502 
2025-07-12 08:15:27.774899: Pseudo dice [np.float32(0.9527)] 
2025-07-12 08:15:27.776351: Epoch time: 69.44 s 
2025-07-12 08:15:28.743247:  
2025-07-12 08:15:28.745183: Epoch 806 
2025-07-12 08:15:28.746313: Current learning rate: 0.00229 
2025-07-12 08:16:38.178885: train_loss -0.9807 
2025-07-12 08:16:38.180082: val_loss -0.9477 
2025-07-12 08:16:38.181087: Pseudo dice [np.float32(0.9508)] 
2025-07-12 08:16:38.182066: Epoch time: 69.44 s 
2025-07-12 08:16:39.150800:  
2025-07-12 08:16:39.152153: Epoch 807 
2025-07-12 08:16:39.153130: Current learning rate: 0.00228 
2025-07-12 08:17:48.504519: train_loss -0.9806 
2025-07-12 08:17:48.505813: val_loss -0.9492 
2025-07-12 08:17:48.507310: Pseudo dice [np.float32(0.9539)] 
2025-07-12 08:17:48.508403: Epoch time: 69.36 s 
2025-07-12 08:17:49.481988:  
2025-07-12 08:17:49.483589: Epoch 808 
2025-07-12 08:17:49.484589: Current learning rate: 0.00226 
2025-07-12 08:18:58.870827: train_loss -0.9813 
2025-07-12 08:18:58.871945: val_loss -0.9528 
2025-07-12 08:18:58.873051: Pseudo dice [np.float32(0.9566)] 
2025-07-12 08:18:58.874007: Epoch time: 69.39 s 
2025-07-12 08:18:59.850197:  
2025-07-12 08:18:59.852160: Epoch 809 
2025-07-12 08:18:59.853242: Current learning rate: 0.00225 
2025-07-12 08:20:09.465541: train_loss -0.9809 
2025-07-12 08:20:09.467097: val_loss -0.947 
2025-07-12 08:20:09.468078: Pseudo dice [np.float32(0.9504)] 
2025-07-12 08:20:09.469038: Epoch time: 69.62 s 
2025-07-12 08:20:10.435783:  
2025-07-12 08:20:10.437950: Epoch 810 
2025-07-12 08:20:10.439352: Current learning rate: 0.00224 
2025-07-12 08:21:19.901518: train_loss -0.9811 
2025-07-12 08:21:19.903202: val_loss -0.9473 
2025-07-12 08:21:19.904232: Pseudo dice [np.float32(0.9504)] 
2025-07-12 08:21:19.905091: Epoch time: 69.47 s 
2025-07-12 08:21:20.853586:  
2025-07-12 08:21:20.855292: Epoch 811 
2025-07-12 08:21:20.857061: Current learning rate: 0.00223 
2025-07-12 08:22:30.342431: train_loss -0.9812 
2025-07-12 08:22:30.343614: val_loss -0.9496 
2025-07-12 08:22:30.344603: Pseudo dice [np.float32(0.9527)] 
2025-07-12 08:22:30.345870: Epoch time: 69.49 s 
2025-07-12 08:22:31.304856:  
2025-07-12 08:22:31.306223: Epoch 812 
2025-07-12 08:22:31.307283: Current learning rate: 0.00222 
2025-07-12 08:23:40.652112: train_loss -0.9807 
2025-07-12 08:23:40.653220: val_loss -0.9511 
2025-07-12 08:23:40.654156: Pseudo dice [np.float32(0.9535)] 
2025-07-12 08:23:40.655156: Epoch time: 69.35 s 
2025-07-12 08:23:41.607518:  
2025-07-12 08:23:41.609310: Epoch 813 
2025-07-12 08:23:41.610894: Current learning rate: 0.00221 
2025-07-12 08:24:52.120499: train_loss -0.9814 
2025-07-12 08:24:52.122100: val_loss -0.9521 
2025-07-12 08:24:52.123235: Pseudo dice [np.float32(0.9552)] 
2025-07-12 08:24:52.124289: Epoch time: 70.52 s 
2025-07-12 08:24:53.082138:  
2025-07-12 08:24:53.084103: Epoch 814 
2025-07-12 08:24:53.085292: Current learning rate: 0.0022 
2025-07-12 08:26:02.664416: train_loss -0.9808 
2025-07-12 08:26:02.665601: val_loss -0.9493 
2025-07-12 08:26:02.666531: Pseudo dice [np.float32(0.9522)] 
2025-07-12 08:26:02.667867: Epoch time: 69.59 s 
2025-07-12 08:26:03.635263:  
2025-07-12 08:26:03.637294: Epoch 815 
2025-07-12 08:26:03.638425: Current learning rate: 0.00219 
2025-07-12 08:27:13.131905: train_loss -0.9821 
2025-07-12 08:27:13.133210: val_loss -0.9531 
2025-07-12 08:27:13.134365: Pseudo dice [np.float32(0.9568)] 
2025-07-12 08:27:13.135698: Epoch time: 69.5 s 
2025-07-12 08:27:14.103476:  
2025-07-12 08:27:14.105717: Epoch 816 
2025-07-12 08:27:14.107252: Current learning rate: 0.00218 
2025-07-12 08:28:23.125801: train_loss -0.9819 
2025-07-12 08:28:23.126944: val_loss -0.9528 
2025-07-12 08:28:23.127934: Pseudo dice [np.float32(0.9569)] 
2025-07-12 08:28:23.128968: Epoch time: 69.03 s 
2025-07-12 08:28:24.095771:  
2025-07-12 08:28:24.097526: Epoch 817 
2025-07-12 08:28:24.098730: Current learning rate: 0.00217 
2025-07-12 08:29:33.357034: train_loss -0.9817 
2025-07-12 08:29:33.358886: val_loss -0.9539 
2025-07-12 08:29:33.360115: Pseudo dice [np.float32(0.9571)] 
2025-07-12 08:29:33.361125: Epoch time: 69.26 s 
2025-07-12 08:29:34.322898:  
2025-07-12 08:29:34.324589: Epoch 818 
2025-07-12 08:29:34.325592: Current learning rate: 0.00216 
2025-07-12 08:30:43.415829: train_loss -0.981 
2025-07-12 08:30:43.417263: val_loss -0.9515 
2025-07-12 08:30:43.418541: Pseudo dice [np.float32(0.9552)] 
2025-07-12 08:30:43.419684: Epoch time: 69.1 s 
2025-07-12 08:30:43.420777: Yayy! New best EMA pseudo Dice: 0.954200029373169 
2025-07-12 08:30:45.559497:  
2025-07-12 08:30:45.561025: Epoch 819 
2025-07-12 08:30:45.561988: Current learning rate: 0.00215 
2025-07-12 08:31:54.938478: train_loss -0.9825 
2025-07-12 08:31:54.939847: val_loss -0.9515 
2025-07-12 08:31:54.940828: Pseudo dice [np.float32(0.9548)] 
2025-07-12 08:31:54.941815: Epoch time: 69.38 s 
2025-07-12 08:31:54.942816: Yayy! New best EMA pseudo Dice: 0.954200029373169 
2025-07-12 08:31:57.199039:  
2025-07-12 08:31:57.201015: Epoch 820 
2025-07-12 08:31:57.202021: Current learning rate: 0.00214 
2025-07-12 08:33:06.473135: train_loss -0.9821 
2025-07-12 08:33:06.474688: val_loss -0.9501 
2025-07-12 08:33:06.475935: Pseudo dice [np.float32(0.9536)] 
2025-07-12 08:33:06.477017: Epoch time: 69.28 s 
2025-07-12 08:33:07.395061:  
2025-07-12 08:33:07.396981: Epoch 821 
2025-07-12 08:33:07.398101: Current learning rate: 0.00213 
2025-07-12 08:34:16.718786: train_loss -0.9813 
2025-07-12 08:34:16.720289: val_loss -0.9481 
2025-07-12 08:34:16.721429: Pseudo dice [np.float32(0.9506)] 
2025-07-12 08:34:16.722588: Epoch time: 69.33 s 
2025-07-12 08:34:18.497444:  
2025-07-12 08:34:18.499295: Epoch 822 
2025-07-12 08:34:18.500394: Current learning rate: 0.00212 
2025-07-12 08:35:27.771391: train_loss -0.9812 
2025-07-12 08:35:27.772991: val_loss -0.95 
2025-07-12 08:35:27.773973: Pseudo dice [np.float32(0.9536)] 
2025-07-12 08:35:27.775151: Epoch time: 69.28 s 
2025-07-12 08:35:28.710930:  
2025-07-12 08:35:28.712713: Epoch 823 
2025-07-12 08:35:28.714147: Current learning rate: 0.0021 
2025-07-12 08:36:38.426070: train_loss -0.9817 
2025-07-12 08:36:38.427525: val_loss -0.9494 
2025-07-12 08:36:38.428544: Pseudo dice [np.float32(0.9519)] 
2025-07-12 08:36:38.429685: Epoch time: 69.72 s 
2025-07-12 08:36:39.360093:  
2025-07-12 08:36:39.361729: Epoch 824 
2025-07-12 08:36:39.363172: Current learning rate: 0.00209 
2025-07-12 08:37:49.673416: train_loss -0.9816 
2025-07-12 08:37:49.674632: val_loss -0.9511 
2025-07-12 08:37:49.675592: Pseudo dice [np.float32(0.9537)] 
2025-07-12 08:37:49.676694: Epoch time: 70.32 s 
2025-07-12 08:37:50.605654:  
2025-07-12 08:37:50.607146: Epoch 825 
2025-07-12 08:37:50.608157: Current learning rate: 0.00208 
2025-07-12 08:38:59.470968: train_loss -0.9813 
2025-07-12 08:38:59.472064: val_loss -0.9538 
2025-07-12 08:38:59.473089: Pseudo dice [np.float32(0.9571)] 
2025-07-12 08:38:59.474297: Epoch time: 68.87 s 
2025-07-12 08:39:00.414285:  
2025-07-12 08:39:00.416229: Epoch 826 
2025-07-12 08:39:00.417508: Current learning rate: 0.00207 
2025-07-12 08:40:09.471236: train_loss -0.9817 
2025-07-12 08:40:09.472631: val_loss -0.9513 
2025-07-12 08:40:09.474079: Pseudo dice [np.float32(0.9538)] 
2025-07-12 08:40:09.475783: Epoch time: 69.06 s 
2025-07-12 08:40:10.405261:  
2025-07-12 08:40:10.407142: Epoch 827 
2025-07-12 08:40:10.408156: Current learning rate: 0.00206 
2025-07-12 08:41:19.706703: train_loss -0.9819 
2025-07-12 08:41:19.708047: val_loss -0.9501 
2025-07-12 08:41:19.709216: Pseudo dice [np.float32(0.9535)] 
2025-07-12 08:41:19.710191: Epoch time: 69.31 s 
2025-07-12 08:41:20.659310:  
2025-07-12 08:41:20.661101: Epoch 828 
2025-07-12 08:41:20.662222: Current learning rate: 0.00205 
2025-07-12 08:42:30.878185: train_loss -0.9814 
2025-07-12 08:42:30.879446: val_loss -0.9517 
2025-07-12 08:42:30.880710: Pseudo dice [np.float32(0.955)] 
2025-07-12 08:42:30.881619: Epoch time: 70.22 s 
2025-07-12 08:42:31.816659:  
2025-07-12 08:42:31.818256: Epoch 829 
2025-07-12 08:42:31.819368: Current learning rate: 0.00204 
2025-07-12 08:43:41.222636: train_loss -0.9821 
2025-07-12 08:43:41.224289: val_loss -0.9503 
2025-07-12 08:43:41.225828: Pseudo dice [np.float32(0.953)] 
2025-07-12 08:43:41.226831: Epoch time: 69.41 s 
2025-07-12 08:43:42.146705:  
2025-07-12 08:43:42.148818: Epoch 830 
2025-07-12 08:43:42.149930: Current learning rate: 0.00203 
2025-07-12 08:44:51.138217: train_loss -0.982 
2025-07-12 08:44:51.139666: val_loss -0.9501 
2025-07-12 08:44:51.140713: Pseudo dice [np.float32(0.9535)] 
2025-07-12 08:44:51.141672: Epoch time: 69.0 s 
2025-07-12 08:44:52.081497:  
2025-07-12 08:44:52.083485: Epoch 831 
2025-07-12 08:44:52.084640: Current learning rate: 0.00202 
2025-07-12 08:46:01.938557: train_loss -0.9816 
2025-07-12 08:46:01.939706: val_loss -0.9474 
2025-07-12 08:46:01.940706: Pseudo dice [np.float32(0.9508)] 
2025-07-12 08:46:01.941963: Epoch time: 69.86 s 
2025-07-12 08:46:02.862052:  
2025-07-12 08:46:02.863724: Epoch 832 
2025-07-12 08:46:02.864712: Current learning rate: 0.00201 
2025-07-12 08:47:12.142674: train_loss -0.9809 
2025-07-12 08:47:12.144412: val_loss -0.9471 
2025-07-12 08:47:12.145496: Pseudo dice [np.float32(0.9502)] 
2025-07-12 08:47:12.146608: Epoch time: 69.28 s 
2025-07-12 08:47:13.108436:  
2025-07-12 08:47:13.110979: Epoch 833 
2025-07-12 08:47:13.112034: Current learning rate: 0.002 
2025-07-12 08:48:22.565960: train_loss -0.9813 
2025-07-12 08:48:22.567817: val_loss -0.9498 
2025-07-12 08:48:22.568923: Pseudo dice [np.float32(0.9532)] 
2025-07-12 08:48:22.569950: Epoch time: 69.46 s 
2025-07-12 08:48:23.502228:  
2025-07-12 08:48:23.503994: Epoch 834 
2025-07-12 08:48:23.505152: Current learning rate: 0.00199 
2025-07-12 08:49:32.821133: train_loss -0.9803 
2025-07-12 08:49:32.823029: val_loss -0.9478 
2025-07-12 08:49:32.824534: Pseudo dice [np.float32(0.9511)] 
2025-07-12 08:49:32.825809: Epoch time: 69.32 s 
2025-07-12 08:49:33.756387:  
2025-07-12 08:49:33.758016: Epoch 835 
2025-07-12 08:49:33.759173: Current learning rate: 0.00198 
2025-07-12 08:50:43.030244: train_loss -0.9811 
2025-07-12 08:50:43.032351: val_loss -0.9502 
2025-07-12 08:50:43.033484: Pseudo dice [np.float32(0.9531)] 
2025-07-12 08:50:43.034615: Epoch time: 69.28 s 
2025-07-12 08:50:43.956752:  
2025-07-12 08:50:43.958449: Epoch 836 
2025-07-12 08:50:43.959582: Current learning rate: 0.00196 
2025-07-12 08:51:53.246460: train_loss -0.9812 
2025-07-12 08:51:53.247786: val_loss -0.953 
2025-07-12 08:51:53.248790: Pseudo dice [np.float32(0.9556)] 
2025-07-12 08:51:53.249758: Epoch time: 69.29 s 
2025-07-12 08:51:54.151139:  
2025-07-12 08:51:54.153095: Epoch 837 
2025-07-12 08:51:54.154277: Current learning rate: 0.00195 
2025-07-12 08:53:03.468520: train_loss -0.9817 
2025-07-12 08:53:03.470612: val_loss -0.9524 
2025-07-12 08:53:03.472109: Pseudo dice [np.float32(0.9552)] 
2025-07-12 08:53:03.473330: Epoch time: 69.32 s 
2025-07-12 08:53:04.396539:  
2025-07-12 08:53:04.398100: Epoch 838 
2025-07-12 08:53:04.399216: Current learning rate: 0.00194 
2025-07-12 08:54:13.900912: train_loss -0.9816 
2025-07-12 08:54:13.902136: val_loss -0.9543 
2025-07-12 08:54:13.903610: Pseudo dice [np.float32(0.9566)] 
2025-07-12 08:54:13.904731: Epoch time: 69.51 s 
2025-07-12 08:54:14.831912:  
2025-07-12 08:54:14.833628: Epoch 839 
2025-07-12 08:54:14.834734: Current learning rate: 0.00193 
2025-07-12 08:55:24.283582: train_loss -0.9817 
2025-07-12 08:55:24.285578: val_loss -0.9512 
2025-07-12 08:55:24.286470: Pseudo dice [np.float32(0.9552)] 
2025-07-12 08:55:24.287470: Epoch time: 69.46 s 
2025-07-12 08:55:25.221813:  
2025-07-12 08:55:25.223819: Epoch 840 
2025-07-12 08:55:25.225067: Current learning rate: 0.00192 
2025-07-12 08:56:35.426622: train_loss -0.9811 
2025-07-12 08:56:35.427902: val_loss -0.9512 
2025-07-12 08:56:35.428994: Pseudo dice [np.float32(0.9544)] 
2025-07-12 08:56:35.430263: Epoch time: 70.21 s 
2025-07-12 08:56:36.357186:  
2025-07-12 08:56:36.358867: Epoch 841 
2025-07-12 08:56:36.359961: Current learning rate: 0.00191 
2025-07-12 08:57:45.864347: train_loss -0.9805 
2025-07-12 08:57:45.866169: val_loss -0.9473 
2025-07-12 08:57:45.867453: Pseudo dice [np.float32(0.9509)] 
2025-07-12 08:57:45.868433: Epoch time: 69.51 s 
2025-07-12 08:57:46.754488:  
2025-07-12 08:57:46.756588: Epoch 842 
2025-07-12 08:57:46.757769: Current learning rate: 0.0019 
2025-07-12 08:58:56.058357: train_loss -0.9809 
2025-07-12 08:58:56.059515: val_loss -0.9475 
2025-07-12 08:58:56.060653: Pseudo dice [np.float32(0.9507)] 
2025-07-12 08:58:56.061813: Epoch time: 69.31 s 
2025-07-12 08:58:57.000751:  
2025-07-12 08:58:57.002283: Epoch 843 
2025-07-12 08:58:57.003310: Current learning rate: 0.00189 
2025-07-12 09:00:07.010573: train_loss -0.9812 
2025-07-12 09:00:07.011738: val_loss -0.9486 
2025-07-12 09:00:07.012815: Pseudo dice [np.float32(0.9519)] 
2025-07-12 09:00:07.014272: Epoch time: 70.01 s 
2025-07-12 09:00:07.933634:  
2025-07-12 09:00:07.935268: Epoch 844 
2025-07-12 09:00:07.936286: Current learning rate: 0.00188 
2025-07-12 09:01:23.187218: train_loss -0.9824 
2025-07-12 09:01:23.188396: val_loss -0.9535 
2025-07-12 09:01:23.189416: Pseudo dice [np.float32(0.9559)] 
2025-07-12 09:01:23.190334: Epoch time: 75.26 s 
2025-07-12 09:01:24.112987:  
2025-07-12 09:01:24.114958: Epoch 845 
2025-07-12 09:01:24.116131: Current learning rate: 0.00187 
2025-07-12 09:02:32.695076: train_loss -0.9824 
2025-07-12 09:02:32.696554: val_loss -0.9479 
2025-07-12 09:02:32.697734: Pseudo dice [np.float32(0.9516)] 
2025-07-12 09:02:32.699029: Epoch time: 68.59 s 
2025-07-12 09:02:33.626662:  
2025-07-12 09:02:33.628591: Epoch 846 
2025-07-12 09:02:33.629815: Current learning rate: 0.00186 
2025-07-12 09:03:42.462829: train_loss -0.9819 
2025-07-12 09:03:42.463978: val_loss -0.9522 
2025-07-12 09:03:42.465010: Pseudo dice [np.float32(0.9555)] 
2025-07-12 09:03:42.466009: Epoch time: 68.84 s 
2025-07-12 09:03:43.396896:  
2025-07-12 09:03:43.398807: Epoch 847 
2025-07-12 09:03:43.400454: Current learning rate: 0.00185 
2025-07-12 09:04:52.316379: train_loss -0.981 
2025-07-12 09:04:52.317674: val_loss -0.9517 
2025-07-12 09:04:52.318683: Pseudo dice [np.float32(0.9554)] 
2025-07-12 09:04:52.319709: Epoch time: 68.92 s 
2025-07-12 09:04:53.237213:  
2025-07-12 09:04:53.238974: Epoch 848 
2025-07-12 09:04:53.240056: Current learning rate: 0.00184 
2025-07-12 09:06:02.716576: train_loss -0.9809 
2025-07-12 09:06:02.717730: val_loss -0.954 
2025-07-12 09:06:02.718693: Pseudo dice [np.float32(0.957)] 
2025-07-12 09:06:02.719752: Epoch time: 69.48 s 
2025-07-12 09:06:03.651583:  
2025-07-12 09:06:03.653494: Epoch 849 
2025-07-12 09:06:03.654534: Current learning rate: 0.00182 
2025-07-12 09:07:13.862153: train_loss -0.9816 
2025-07-12 09:07:13.863327: val_loss -0.9508 
2025-07-12 09:07:13.864173: Pseudo dice [np.float32(0.9543)] 
2025-07-12 09:07:13.865492: Epoch time: 70.21 s 
2025-07-12 09:07:16.179487:  
2025-07-12 09:07:16.181244: Epoch 850 
2025-07-12 09:07:16.182278: Current learning rate: 0.00181 
2025-07-12 09:08:25.444247: train_loss -0.982 
2025-07-12 09:08:25.445664: val_loss -0.9554 
2025-07-12 09:08:25.446870: Pseudo dice [np.float32(0.9586)] 
2025-07-12 09:08:25.448153: Epoch time: 69.27 s 
2025-07-12 09:08:25.449222: Yayy! New best EMA pseudo Dice: 0.9545000195503235 
2025-07-12 09:08:27.757919:  
2025-07-12 09:08:27.759641: Epoch 851 
2025-07-12 09:08:27.760731: Current learning rate: 0.0018 
2025-07-12 09:09:37.074115: train_loss -0.9812 
2025-07-12 09:09:37.075295: val_loss -0.9484 
2025-07-12 09:09:37.076541: Pseudo dice [np.float32(0.9519)] 
2025-07-12 09:09:37.077631: Epoch time: 69.32 s 
2025-07-12 09:09:37.991609:  
2025-07-12 09:09:37.993420: Epoch 852 
2025-07-12 09:09:37.994702: Current learning rate: 0.00179 
2025-07-12 09:10:47.778912: train_loss -0.982 
2025-07-12 09:10:47.780102: val_loss -0.9528 
2025-07-12 09:10:47.781538: Pseudo dice [np.float32(0.9563)] 
2025-07-12 09:10:47.782924: Epoch time: 69.79 s 
2025-07-12 09:10:48.720641:  
2025-07-12 09:10:48.722705: Epoch 853 
2025-07-12 09:10:48.723669: Current learning rate: 0.00178 
2025-07-12 09:11:58.119856: train_loss -0.9823 
2025-07-12 09:11:58.121221: val_loss -0.9512 
2025-07-12 09:11:58.122551: Pseudo dice [np.float32(0.9541)] 
2025-07-12 09:11:58.124030: Epoch time: 69.4 s 
2025-07-12 09:11:59.049324:  
2025-07-12 09:11:59.051588: Epoch 854 
2025-07-12 09:11:59.052872: Current learning rate: 0.00177 
2025-07-12 09:13:08.086023: train_loss -0.9822 
2025-07-12 09:13:08.087309: val_loss -0.9495 
2025-07-12 09:13:08.088494: Pseudo dice [np.float32(0.953)] 
2025-07-12 09:13:08.089473: Epoch time: 69.04 s 
2025-07-12 09:13:09.001826:  
2025-07-12 09:13:09.003850: Epoch 855 
2025-07-12 09:13:09.004915: Current learning rate: 0.00176 
2025-07-12 09:14:18.183098: train_loss -0.9817 
2025-07-12 09:14:18.184295: val_loss -0.9504 
2025-07-12 09:14:18.185289: Pseudo dice [np.float32(0.9546)] 
2025-07-12 09:14:18.186256: Epoch time: 69.18 s 
2025-07-12 09:14:19.120812:  
2025-07-12 09:14:19.122329: Epoch 856 
2025-07-12 09:14:19.123334: Current learning rate: 0.00175 
2025-07-12 09:15:28.317561: train_loss -0.9826 
2025-07-12 09:15:28.318806: val_loss -0.9536 
2025-07-12 09:15:28.319845: Pseudo dice [np.float32(0.9572)] 
2025-07-12 09:15:28.320832: Epoch time: 69.2 s 
2025-07-12 09:15:28.321923: Yayy! New best EMA pseudo Dice: 0.9545999765396118 
2025-07-12 09:15:30.607395:  
2025-07-12 09:15:30.609625: Epoch 857 
2025-07-12 09:15:30.610802: Current learning rate: 0.00174 
2025-07-12 09:16:40.535000: train_loss -0.9821 
2025-07-12 09:16:40.536381: val_loss -0.9506 
2025-07-12 09:16:40.538057: Pseudo dice [np.float32(0.9538)] 
2025-07-12 09:16:40.539511: Epoch time: 69.93 s 
2025-07-12 09:16:41.452809:  
2025-07-12 09:16:41.454564: Epoch 858 
2025-07-12 09:16:41.455548: Current learning rate: 0.00173 
2025-07-12 09:17:50.894182: train_loss -0.9824 
2025-07-12 09:17:50.895507: val_loss -0.9541 
2025-07-12 09:17:50.896444: Pseudo dice [np.float32(0.957)] 
2025-07-12 09:17:50.897635: Epoch time: 69.44 s 
2025-07-12 09:17:50.898567: Yayy! New best EMA pseudo Dice: 0.954800009727478 
2025-07-12 09:17:53.127736:  
2025-07-12 09:17:53.129184: Epoch 859 
2025-07-12 09:17:53.130158: Current learning rate: 0.00172 
2025-07-12 09:19:02.392725: train_loss -0.9816 
2025-07-12 09:19:02.393834: val_loss -0.9545 
2025-07-12 09:19:02.395039: Pseudo dice [np.float32(0.9576)] 
2025-07-12 09:19:02.396473: Epoch time: 69.27 s 
2025-07-12 09:19:02.397647: Yayy! New best EMA pseudo Dice: 0.9550999999046326 
2025-07-12 09:19:04.664917:  
2025-07-12 09:19:04.666105: Epoch 860 
2025-07-12 09:19:04.667037: Current learning rate: 0.0017 
2025-07-12 09:20:13.824562: train_loss -0.9826 
2025-07-12 09:20:13.825723: val_loss -0.9524 
2025-07-12 09:20:13.826674: Pseudo dice [np.float32(0.9557)] 
2025-07-12 09:20:13.827724: Epoch time: 69.16 s 
2025-07-12 09:20:13.828927: Yayy! New best EMA pseudo Dice: 0.9550999999046326 
2025-07-12 09:20:16.096852:  
2025-07-12 09:20:16.098665: Epoch 861 
2025-07-12 09:20:16.099695: Current learning rate: 0.00169 
2025-07-12 09:21:25.653090: train_loss -0.9817 
2025-07-12 09:21:25.654526: val_loss -0.9508 
2025-07-12 09:21:25.655539: Pseudo dice [np.float32(0.9541)] 
2025-07-12 09:21:25.656415: Epoch time: 69.56 s 
2025-07-12 09:21:26.568758:  
2025-07-12 09:21:26.570503: Epoch 862 
2025-07-12 09:21:26.571570: Current learning rate: 0.00168 
2025-07-12 09:22:36.449126: train_loss -0.9816 
2025-07-12 09:22:36.450953: val_loss -0.9534 
2025-07-12 09:22:36.452147: Pseudo dice [np.float32(0.957)] 
2025-07-12 09:22:36.453321: Epoch time: 69.88 s 
2025-07-12 09:22:36.454359: Yayy! New best EMA pseudo Dice: 0.9552000164985657 
2025-07-12 09:22:38.749482:  
2025-07-12 09:22:38.751248: Epoch 863 
2025-07-12 09:22:38.752481: Current learning rate: 0.00167 
2025-07-12 09:23:47.775121: train_loss -0.9816 
2025-07-12 09:23:47.776391: val_loss -0.9471 
2025-07-12 09:23:47.777420: Pseudo dice [np.float32(0.95)] 
2025-07-12 09:23:47.778909: Epoch time: 69.03 s 
2025-07-12 09:23:48.703165:  
2025-07-12 09:23:48.705514: Epoch 864 
2025-07-12 09:23:48.706715: Current learning rate: 0.00166 
2025-07-12 09:24:57.193895: train_loss -0.9823 
2025-07-12 09:24:57.195918: val_loss -0.9532 
2025-07-12 09:24:57.197531: Pseudo dice [np.float32(0.9567)] 
2025-07-12 09:24:57.198608: Epoch time: 68.49 s 
2025-07-12 09:24:58.093287:  
2025-07-12 09:24:58.095170: Epoch 865 
2025-07-12 09:24:58.096222: Current learning rate: 0.00165 
2025-07-12 09:26:06.238001: train_loss -0.9822 
2025-07-12 09:26:06.239338: val_loss -0.9501 
2025-07-12 09:26:06.240410: Pseudo dice [np.float32(0.9541)] 
2025-07-12 09:26:06.241694: Epoch time: 68.15 s 
2025-07-12 09:26:07.938799:  
2025-07-12 09:26:07.940920: Epoch 866 
2025-07-12 09:26:07.942042: Current learning rate: 0.00164 
2025-07-12 09:27:16.214300: train_loss -0.982 
2025-07-12 09:27:16.215632: val_loss -0.9491 
2025-07-12 09:27:16.216751: Pseudo dice [np.float32(0.9528)] 
2025-07-12 09:27:16.217876: Epoch time: 68.28 s 
2025-07-12 09:27:17.135774:  
2025-07-12 09:27:17.137607: Epoch 867 
2025-07-12 09:27:17.138717: Current learning rate: 0.00163 
2025-07-12 09:28:25.605894: train_loss -0.9816 
2025-07-12 09:28:25.607754: val_loss -0.9485 
2025-07-12 09:28:25.609720: Pseudo dice [np.float32(0.952)] 
2025-07-12 09:28:25.611285: Epoch time: 68.47 s 
2025-07-12 09:28:26.528753:  
2025-07-12 09:28:26.530500: Epoch 868 
2025-07-12 09:28:26.531856: Current learning rate: 0.00162 
2025-07-12 09:29:35.203857: train_loss -0.9817 
2025-07-12 09:29:35.205239: val_loss -0.9492 
2025-07-12 09:29:35.206319: Pseudo dice [np.float32(0.952)] 
2025-07-12 09:29:35.207719: Epoch time: 68.68 s 
2025-07-12 09:29:36.134483:  
2025-07-12 09:29:36.137209: Epoch 869 
2025-07-12 09:29:36.138214: Current learning rate: 0.00161 
2025-07-12 09:30:45.193557: train_loss -0.9818 
2025-07-12 09:30:45.195253: val_loss -0.9518 
2025-07-12 09:30:45.196295: Pseudo dice [np.float32(0.9547)] 
2025-07-12 09:30:45.197774: Epoch time: 69.06 s 
2025-07-12 09:30:46.122038:  
2025-07-12 09:30:46.124143: Epoch 870 
2025-07-12 09:30:46.125188: Current learning rate: 0.00159 
2025-07-12 09:31:55.273275: train_loss -0.982 
2025-07-12 09:31:55.274673: val_loss -0.9487 
2025-07-12 09:31:55.276528: Pseudo dice [np.float32(0.9528)] 
2025-07-12 09:31:55.278384: Epoch time: 69.15 s 
2025-07-12 09:31:56.199722:  
2025-07-12 09:31:56.202075: Epoch 871 
2025-07-12 09:31:56.203505: Current learning rate: 0.00158 
2025-07-12 09:33:06.276085: train_loss -0.9819 
2025-07-12 09:33:06.277271: val_loss -0.9516 
2025-07-12 09:33:06.278293: Pseudo dice [np.float32(0.9547)] 
2025-07-12 09:33:06.279489: Epoch time: 70.08 s 
2025-07-12 09:33:07.201553:  
2025-07-12 09:33:07.203227: Epoch 872 
2025-07-12 09:33:07.204382: Current learning rate: 0.00157 
2025-07-12 09:34:18.388695: train_loss -0.9818 
2025-07-12 09:34:18.390015: val_loss -0.9485 
2025-07-12 09:34:18.391212: Pseudo dice [np.float32(0.9518)] 
2025-07-12 09:34:18.392371: Epoch time: 71.19 s 
2025-07-12 09:34:19.310252:  
2025-07-12 09:34:19.312203: Epoch 873 
2025-07-12 09:34:19.313264: Current learning rate: 0.00156 
2025-07-12 09:35:27.829789: train_loss -0.9823 
2025-07-12 09:35:27.831948: val_loss -0.9515 
2025-07-12 09:35:27.833863: Pseudo dice [np.float32(0.9542)] 
2025-07-12 09:35:27.835496: Epoch time: 68.52 s 
2025-07-12 09:35:28.750317:  
2025-07-12 09:35:28.752140: Epoch 874 
2025-07-12 09:35:28.753313: Current learning rate: 0.00155 
2025-07-12 09:36:36.983757: train_loss -0.9826 
2025-07-12 09:36:36.985835: val_loss -0.9512 
2025-07-12 09:36:36.987517: Pseudo dice [np.float32(0.9544)] 
2025-07-12 09:36:36.988550: Epoch time: 68.24 s 
2025-07-12 09:36:37.874525:  
2025-07-12 09:36:37.876423: Epoch 875 
2025-07-12 09:36:37.877635: Current learning rate: 0.00154 
2025-07-12 09:37:46.810163: train_loss -0.9829 
2025-07-12 09:37:46.812270: val_loss -0.9512 
2025-07-12 09:37:46.814408: Pseudo dice [np.float32(0.9544)] 
2025-07-12 09:37:46.815629: Epoch time: 68.94 s 
2025-07-12 09:37:47.736783:  
2025-07-12 09:37:47.738357: Epoch 876 
2025-07-12 09:37:47.739303: Current learning rate: 0.00153 
2025-07-12 09:38:56.406303: train_loss -0.9835 
2025-07-12 09:38:56.407918: val_loss -0.9524 
2025-07-12 09:38:56.409750: Pseudo dice [np.float32(0.9548)] 
2025-07-12 09:38:56.411030: Epoch time: 68.67 s 
2025-07-12 09:38:57.346280:  
2025-07-12 09:38:57.348222: Epoch 877 
2025-07-12 09:38:57.349725: Current learning rate: 0.00152 
2025-07-12 09:40:06.377173: train_loss -0.9824 
2025-07-12 09:40:06.378305: val_loss -0.9526 
2025-07-12 09:40:06.379761: Pseudo dice [np.float32(0.9564)] 
2025-07-12 09:40:06.381821: Epoch time: 69.03 s 
2025-07-12 09:40:07.302963:  
2025-07-12 09:40:07.304554: Epoch 878 
2025-07-12 09:40:07.305653: Current learning rate: 0.00151 
2025-07-12 09:41:16.563855: train_loss -0.9822 
2025-07-12 09:41:16.565033: val_loss -0.9504 
2025-07-12 09:41:16.566067: Pseudo dice [np.float32(0.9536)] 
2025-07-12 09:41:16.567330: Epoch time: 69.26 s 
2025-07-12 09:41:17.503420:  
2025-07-12 09:41:17.505229: Epoch 879 
2025-07-12 09:41:17.506246: Current learning rate: 0.00149 
2025-07-12 09:42:26.726454: train_loss -0.983 
2025-07-12 09:42:26.727846: val_loss -0.9484 
2025-07-12 09:42:26.729906: Pseudo dice [np.float32(0.9514)] 
2025-07-12 09:42:26.731401: Epoch time: 69.23 s 
2025-07-12 09:42:27.649616:  
2025-07-12 09:42:27.651675: Epoch 880 
2025-07-12 09:42:27.652863: Current learning rate: 0.00148 
2025-07-12 09:43:36.880896: train_loss -0.9824 
2025-07-12 09:43:36.882202: val_loss -0.9529 
2025-07-12 09:43:36.884067: Pseudo dice [np.float32(0.9553)] 
2025-07-12 09:43:36.886101: Epoch time: 69.23 s 
2025-07-12 09:43:37.806911:  
2025-07-12 09:43:37.808585: Epoch 881 
2025-07-12 09:43:37.810176: Current learning rate: 0.00147 
2025-07-12 09:44:47.264722: train_loss -0.9824 
2025-07-12 09:44:47.266566: val_loss -0.9507 
2025-07-12 09:44:47.267668: Pseudo dice [np.float32(0.9535)] 
2025-07-12 09:44:47.269438: Epoch time: 69.46 s 
2025-07-12 09:44:48.178080:  
2025-07-12 09:44:48.180110: Epoch 882 
2025-07-12 09:44:48.181146: Current learning rate: 0.00146 
2025-07-12 09:45:57.690548: train_loss -0.9832 
2025-07-12 09:45:57.692032: val_loss -0.9517 
2025-07-12 09:45:57.693312: Pseudo dice [np.float32(0.9545)] 
2025-07-12 09:45:57.694783: Epoch time: 69.52 s 
2025-07-12 09:45:58.627962:  
2025-07-12 09:45:58.629033: Epoch 883 
2025-07-12 09:45:58.630148: Current learning rate: 0.00145 
2025-07-12 09:47:07.957528: train_loss -0.9825 
2025-07-12 09:47:07.959041: val_loss -0.9518 
2025-07-12 09:47:07.960496: Pseudo dice [np.float32(0.9543)] 
2025-07-12 09:47:07.961892: Epoch time: 69.33 s 
2025-07-12 09:47:08.843548:  
2025-07-12 09:47:08.845264: Epoch 884 
2025-07-12 09:47:08.846453: Current learning rate: 0.00144 
2025-07-12 09:48:18.748466: train_loss -0.9825 
2025-07-12 09:48:18.750153: val_loss -0.95 
2025-07-12 09:48:18.751553: Pseudo dice [np.float32(0.9529)] 
2025-07-12 09:48:18.752509: Epoch time: 69.91 s 
2025-07-12 09:48:19.667451:  
2025-07-12 09:48:19.669475: Epoch 885 
2025-07-12 09:48:19.670432: Current learning rate: 0.00143 
2025-07-12 09:49:28.938057: train_loss -0.9825 
2025-07-12 09:49:28.940279: val_loss -0.9476 
2025-07-12 09:49:28.941448: Pseudo dice [np.float32(0.9513)] 
2025-07-12 09:49:28.943001: Epoch time: 69.27 s 
2025-07-12 09:49:29.855776:  
2025-07-12 09:49:29.857594: Epoch 886 
2025-07-12 09:49:29.859337: Current learning rate: 0.00142 
2025-07-12 09:50:40.318924: train_loss -0.9824 
2025-07-12 09:50:40.320184: val_loss -0.9509 
2025-07-12 09:50:40.321104: Pseudo dice [np.float32(0.9538)] 
2025-07-12 09:50:40.322137: Epoch time: 70.47 s 
2025-07-12 09:50:41.242007:  
2025-07-12 09:50:41.243940: Epoch 887 
2025-07-12 09:50:41.245042: Current learning rate: 0.00141 
2025-07-12 09:51:54.741602: train_loss -0.9825 
2025-07-12 09:51:54.742954: val_loss -0.9493 
2025-07-12 09:51:54.744652: Pseudo dice [np.float32(0.9523)] 
2025-07-12 09:51:54.746378: Epoch time: 73.5 s 
2025-07-12 09:51:55.665013:  
2025-07-12 09:51:55.667243: Epoch 888 
2025-07-12 09:51:55.668545: Current learning rate: 0.00139 
2025-07-12 09:53:04.684278: train_loss -0.9829 
2025-07-12 09:53:04.685730: val_loss -0.9498 
2025-07-12 09:53:04.686937: Pseudo dice [np.float32(0.9535)] 
2025-07-12 09:53:04.687846: Epoch time: 69.02 s 
2025-07-12 09:53:05.602578:  
2025-07-12 09:53:05.604502: Epoch 889 
2025-07-12 09:53:05.606437: Current learning rate: 0.00138 
2025-07-12 09:54:14.883661: train_loss -0.9825 
2025-07-12 09:54:14.885351: val_loss -0.9456 
2025-07-12 09:54:14.887314: Pseudo dice [np.float32(0.9493)] 
2025-07-12 09:54:14.889007: Epoch time: 69.28 s 
2025-07-12 09:54:15.810753:  
2025-07-12 09:54:15.812704: Epoch 890 
2025-07-12 09:54:15.813839: Current learning rate: 0.00137 
2025-07-12 09:55:25.168296: train_loss -0.983 
2025-07-12 09:55:25.171349: val_loss -0.9471 
2025-07-12 09:55:25.172622: Pseudo dice [np.float32(0.951)] 
2025-07-12 09:55:25.173652: Epoch time: 69.36 s 
2025-07-12 09:55:26.090405:  
2025-07-12 09:55:26.092403: Epoch 891 
2025-07-12 09:55:26.093573: Current learning rate: 0.00136 
2025-07-12 09:56:35.376954: train_loss -0.9828 
2025-07-12 09:56:35.378645: val_loss -0.9498 
2025-07-12 09:56:35.380706: Pseudo dice [np.float32(0.9524)] 
2025-07-12 09:56:35.382185: Epoch time: 69.29 s 
2025-07-12 09:56:36.294949:  
2025-07-12 09:56:36.296853: Epoch 892 
2025-07-12 09:56:36.298211: Current learning rate: 0.00135 
2025-07-12 09:57:45.921849: train_loss -0.983 
2025-07-12 09:57:45.923659: val_loss -0.9493 
2025-07-12 09:57:45.924793: Pseudo dice [np.float32(0.9516)] 
2025-07-12 09:57:45.926710: Epoch time: 69.63 s 
2025-07-12 09:57:46.837592:  
2025-07-12 09:57:46.839559: Epoch 893 
2025-07-12 09:57:46.841212: Current learning rate: 0.00134 
2025-07-12 09:59:01.843591: train_loss -0.9831 
2025-07-12 09:59:01.845199: val_loss -0.9513 
2025-07-12 09:59:01.846250: Pseudo dice [np.float32(0.9537)] 
2025-07-12 09:59:01.847168: Epoch time: 75.01 s 
2025-07-12 09:59:02.755334:  
2025-07-12 09:59:02.757316: Epoch 894 
2025-07-12 09:59:02.758504: Current learning rate: 0.00133 
2025-07-12 10:00:18.763158: train_loss -0.9827 
2025-07-12 10:00:18.764520: val_loss -0.9515 
2025-07-12 10:00:18.765772: Pseudo dice [np.float32(0.954)] 
2025-07-12 10:00:18.766986: Epoch time: 76.01 s 
2025-07-12 10:00:19.680631:  
2025-07-12 10:00:19.682574: Epoch 895 
2025-07-12 10:00:19.684164: Current learning rate: 0.00132 
2025-07-12 10:01:28.353999: train_loss -0.9825 
2025-07-12 10:01:28.355563: val_loss -0.9479 
2025-07-12 10:01:28.356762: Pseudo dice [np.float32(0.9509)] 
2025-07-12 10:01:28.357953: Epoch time: 68.68 s 
2025-07-12 10:01:29.271828:  
2025-07-12 10:01:29.274109: Epoch 896 
2025-07-12 10:01:29.275380: Current learning rate: 0.0013 
2025-07-12 10:02:38.255380: train_loss -0.9827 
2025-07-12 10:02:38.257180: val_loss -0.9474 
2025-07-12 10:02:38.258885: Pseudo dice [np.float32(0.9504)] 
2025-07-12 10:02:38.260494: Epoch time: 68.99 s 
2025-07-12 10:02:39.175905:  
2025-07-12 10:02:39.178034: Epoch 897 
2025-07-12 10:02:39.179231: Current learning rate: 0.00129 
2025-07-12 10:03:48.230548: train_loss -0.9827 
2025-07-12 10:03:48.231962: val_loss -0.9527 
2025-07-12 10:03:48.233480: Pseudo dice [np.float32(0.9563)] 
2025-07-12 10:03:48.234358: Epoch time: 69.06 s 
2025-07-12 10:03:49.160346:  
2025-07-12 10:03:49.162153: Epoch 898 
2025-07-12 10:03:49.163282: Current learning rate: 0.00128 
2025-07-12 10:04:58.299565: train_loss -0.9821 
2025-07-12 10:04:58.300977: val_loss -0.9461 
2025-07-12 10:04:58.302268: Pseudo dice [np.float32(0.9498)] 
2025-07-12 10:04:58.304556: Epoch time: 69.14 s 
2025-07-12 10:04:59.226500:  
2025-07-12 10:04:59.228597: Epoch 899 
2025-07-12 10:04:59.229903: Current learning rate: 0.00127 
2025-07-12 10:06:08.529622: train_loss -0.9833 
2025-07-12 10:06:08.531258: val_loss -0.9502 
2025-07-12 10:06:08.532687: Pseudo dice [np.float32(0.9534)] 
2025-07-12 10:06:08.533800: Epoch time: 69.31 s 
2025-07-12 10:06:10.760606:  
2025-07-12 10:06:10.762524: Epoch 900 
2025-07-12 10:06:10.763617: Current learning rate: 0.00126 
2025-07-12 10:07:19.906650: train_loss -0.983 
2025-07-12 10:07:19.908135: val_loss -0.9484 
2025-07-12 10:07:19.909713: Pseudo dice [np.float32(0.952)] 
2025-07-12 10:07:19.911451: Epoch time: 69.15 s 
2025-07-12 10:07:20.822295:  
2025-07-12 10:07:20.824083: Epoch 901 
2025-07-12 10:07:20.825159: Current learning rate: 0.00125 
2025-07-12 10:08:30.203347: train_loss -0.9827 
2025-07-12 10:08:30.205321: val_loss -0.9511 
2025-07-12 10:08:30.206798: Pseudo dice [np.float32(0.9542)] 
2025-07-12 10:08:30.208539: Epoch time: 69.38 s 
2025-07-12 10:08:31.116614:  
2025-07-12 10:08:31.118040: Epoch 902 
2025-07-12 10:08:31.119210: Current learning rate: 0.00124 
2025-07-12 10:09:41.155421: train_loss -0.983 
2025-07-12 10:09:41.156864: val_loss -0.9531 
2025-07-12 10:09:41.157851: Pseudo dice [np.float32(0.9566)] 
2025-07-12 10:09:41.159028: Epoch time: 70.04 s 
2025-07-12 10:09:42.052303:  
2025-07-12 10:09:42.054422: Epoch 903 
2025-07-12 10:09:42.055645: Current learning rate: 0.00122 
2025-07-12 10:10:51.773830: train_loss -0.9833 
2025-07-12 10:10:51.775065: val_loss -0.9526 
2025-07-12 10:10:51.776105: Pseudo dice [np.float32(0.955)] 
2025-07-12 10:10:51.777313: Epoch time: 69.73 s 
2025-07-12 10:10:52.674073:  
2025-07-12 10:10:52.675806: Epoch 904 
2025-07-12 10:10:52.677072: Current learning rate: 0.00121 
2025-07-12 10:12:02.177867: train_loss -0.9829 
2025-07-12 10:12:02.179129: val_loss -0.9497 
2025-07-12 10:12:02.180171: Pseudo dice [np.float32(0.9525)] 
2025-07-12 10:12:02.181201: Epoch time: 69.51 s 
2025-07-12 10:12:03.103148:  
2025-07-12 10:12:03.105088: Epoch 905 
2025-07-12 10:12:03.106182: Current learning rate: 0.0012 
2025-07-12 10:13:12.609503: train_loss -0.9828 
2025-07-12 10:13:12.610899: val_loss -0.9467 
2025-07-12 10:13:12.611894: Pseudo dice [np.float32(0.95)] 
2025-07-12 10:13:12.612914: Epoch time: 69.51 s 
2025-07-12 10:13:13.531289:  
2025-07-12 10:13:13.533032: Epoch 906 
2025-07-12 10:13:13.534196: Current learning rate: 0.00119 
2025-07-12 10:14:22.809841: train_loss -0.9818 
2025-07-12 10:14:22.811405: val_loss -0.9521 
2025-07-12 10:14:22.812376: Pseudo dice [np.float32(0.9553)] 
2025-07-12 10:14:22.813423: Epoch time: 69.28 s 
2025-07-12 10:14:23.723357:  
2025-07-12 10:14:23.724959: Epoch 907 
2025-07-12 10:14:23.726032: Current learning rate: 0.00118 
2025-07-12 10:15:32.994740: train_loss -0.9826 
2025-07-12 10:15:32.996407: val_loss -0.9529 
2025-07-12 10:15:32.997474: Pseudo dice [np.float32(0.9556)] 
2025-07-12 10:15:32.998549: Epoch time: 69.27 s 
2025-07-12 10:15:33.915697:  
2025-07-12 10:15:33.917567: Epoch 908 
2025-07-12 10:15:33.918543: Current learning rate: 0.00117 
2025-07-12 10:16:43.466335: train_loss -0.9826 
2025-07-12 10:16:43.468392: val_loss -0.9483 
2025-07-12 10:16:43.469521: Pseudo dice [np.float32(0.9512)] 
2025-07-12 10:16:43.470669: Epoch time: 69.55 s 
2025-07-12 10:16:44.401847:  
2025-07-12 10:16:44.403646: Epoch 909 
2025-07-12 10:16:44.404940: Current learning rate: 0.00116 
2025-07-12 10:17:53.712157: train_loss -0.9828 
2025-07-12 10:17:53.713600: val_loss -0.9476 
2025-07-12 10:17:53.714637: Pseudo dice [np.float32(0.9504)] 
2025-07-12 10:17:53.716098: Epoch time: 69.32 s 
2025-07-12 10:17:54.659836:  
2025-07-12 10:17:54.661713: Epoch 910 
2025-07-12 10:17:54.662797: Current learning rate: 0.00115 
2025-07-12 10:19:03.800346: train_loss -0.9832 
2025-07-12 10:19:03.801767: val_loss -0.95 
2025-07-12 10:19:03.802611: Pseudo dice [np.float32(0.9532)] 
2025-07-12 10:19:03.803653: Epoch time: 69.14 s 
2025-07-12 10:19:04.732346:  
2025-07-12 10:19:04.734166: Epoch 911 
2025-07-12 10:19:04.735460: Current learning rate: 0.00113 
2025-07-12 10:20:14.761680: train_loss -0.9838 
2025-07-12 10:20:14.766589: val_loss -0.95 
2025-07-12 10:20:14.768421: Pseudo dice [np.float32(0.9528)] 
2025-07-12 10:20:14.769563: Epoch time: 70.03 s 
2025-07-12 10:20:15.685968:  
2025-07-12 10:20:15.687702: Epoch 912 
2025-07-12 10:20:15.688833: Current learning rate: 0.00112 
2025-07-12 10:21:24.835556: train_loss -0.9829 
2025-07-12 10:21:24.836733: val_loss -0.9473 
2025-07-12 10:21:24.837659: Pseudo dice [np.float32(0.9501)] 
2025-07-12 10:21:24.838888: Epoch time: 69.15 s 
2025-07-12 10:21:25.755920:  
2025-07-12 10:21:25.757620: Epoch 913 
2025-07-12 10:21:25.758611: Current learning rate: 0.00111 
2025-07-12 10:22:35.146929: train_loss -0.9828 
2025-07-12 10:22:35.148153: val_loss -0.9471 
2025-07-12 10:22:35.149293: Pseudo dice [np.float32(0.95)] 
2025-07-12 10:22:35.150259: Epoch time: 69.39 s 
2025-07-12 10:22:36.070174:  
2025-07-12 10:22:36.071938: Epoch 914 
2025-07-12 10:22:36.072947: Current learning rate: 0.0011 
2025-07-12 10:23:46.204376: train_loss -0.9835 
2025-07-12 10:23:46.205618: val_loss -0.95 
2025-07-12 10:23:46.206688: Pseudo dice [np.float32(0.9528)] 
2025-07-12 10:23:46.207937: Epoch time: 70.14 s 
2025-07-12 10:23:47.123164:  
2025-07-12 10:23:47.125164: Epoch 915 
2025-07-12 10:23:47.126607: Current learning rate: 0.00109 
2025-07-12 10:24:57.005155: train_loss -0.9829 
2025-07-12 10:24:57.006713: val_loss -0.9464 
2025-07-12 10:24:57.007804: Pseudo dice [np.float32(0.9493)] 
2025-07-12 10:24:57.008817: Epoch time: 69.89 s 
2025-07-12 10:24:57.920617:  
2025-07-12 10:24:57.922599: Epoch 916 
2025-07-12 10:24:57.923704: Current learning rate: 0.00108 
2025-07-12 10:26:06.455420: train_loss -0.983 
2025-07-12 10:26:06.456703: val_loss -0.9485 
2025-07-12 10:26:06.457726: Pseudo dice [np.float32(0.9514)] 
2025-07-12 10:26:06.458783: Epoch time: 68.54 s 
2025-07-12 10:26:07.374027:  
2025-07-12 10:26:07.376327: Epoch 917 
2025-07-12 10:26:07.377733: Current learning rate: 0.00106 
2025-07-12 10:27:15.887887: train_loss -0.9834 
2025-07-12 10:27:15.889038: val_loss -0.9524 
2025-07-12 10:27:15.890089: Pseudo dice [np.float32(0.9546)] 
2025-07-12 10:27:15.891147: Epoch time: 68.52 s 
2025-07-12 10:27:16.812223:  
2025-07-12 10:27:16.814920: Epoch 918 
2025-07-12 10:27:16.816211: Current learning rate: 0.00105 
2025-07-12 10:28:25.261461: train_loss -0.9834 
2025-07-12 10:28:25.263046: val_loss -0.9522 
2025-07-12 10:28:25.264146: Pseudo dice [np.float32(0.954)] 
2025-07-12 10:28:25.264994: Epoch time: 68.45 s 
2025-07-12 10:28:26.170388:  
2025-07-12 10:28:26.172294: Epoch 919 
2025-07-12 10:28:26.173508: Current learning rate: 0.00104 
2025-07-12 10:29:34.616710: train_loss -0.9829 
2025-07-12 10:29:34.618047: val_loss -0.9534 
2025-07-12 10:29:34.619148: Pseudo dice [np.float32(0.9557)] 
2025-07-12 10:29:34.620169: Epoch time: 68.45 s 
2025-07-12 10:29:35.538267:  
2025-07-12 10:29:35.540072: Epoch 920 
2025-07-12 10:29:35.541239: Current learning rate: 0.00103 
2025-07-12 10:30:45.156142: train_loss -0.9833 
2025-07-12 10:30:45.157278: val_loss -0.9519 
2025-07-12 10:30:45.158167: Pseudo dice [np.float32(0.9549)] 
2025-07-12 10:30:45.159632: Epoch time: 69.62 s 
2025-07-12 10:30:46.083699:  
2025-07-12 10:30:46.085613: Epoch 921 
2025-07-12 10:30:46.086560: Current learning rate: 0.00102 
2025-07-12 10:31:55.160774: train_loss -0.9832 
2025-07-12 10:31:55.162141: val_loss -0.9549 
2025-07-12 10:31:55.163317: Pseudo dice [np.float32(0.9576)] 
2025-07-12 10:31:55.164562: Epoch time: 69.08 s 
2025-07-12 10:31:56.072288:  
2025-07-12 10:31:56.074276: Epoch 922 
2025-07-12 10:31:56.075653: Current learning rate: 0.00101 
2025-07-12 10:33:05.385692: train_loss -0.983 
2025-07-12 10:33:05.386898: val_loss -0.9481 
2025-07-12 10:33:05.387784: Pseudo dice [np.float32(0.9522)] 
2025-07-12 10:33:05.388942: Epoch time: 69.32 s 
2025-07-12 10:33:06.297078:  
2025-07-12 10:33:06.299100: Epoch 923 
2025-07-12 10:33:06.300502: Current learning rate: 0.001 
2025-07-12 10:34:15.696341: train_loss -0.9826 
2025-07-12 10:34:15.697710: val_loss -0.9531 
2025-07-12 10:34:15.698888: Pseudo dice [np.float32(0.9556)] 
2025-07-12 10:34:15.699878: Epoch time: 69.4 s 
2025-07-12 10:34:16.619919:  
2025-07-12 10:34:16.621610: Epoch 924 
2025-07-12 10:34:16.622863: Current learning rate: 0.00098 
2025-07-12 10:35:25.957354: train_loss -0.983 
2025-07-12 10:35:25.958862: val_loss -0.9549 
2025-07-12 10:35:25.959867: Pseudo dice [np.float32(0.9576)] 
2025-07-12 10:35:25.960806: Epoch time: 69.34 s 
2025-07-12 10:35:26.873625:  
2025-07-12 10:35:26.875647: Epoch 925 
2025-07-12 10:35:26.876810: Current learning rate: 0.00097 
2025-07-12 10:36:36.325551: train_loss -0.9829 
2025-07-12 10:36:36.327263: val_loss -0.9473 
2025-07-12 10:36:36.328318: Pseudo dice [np.float32(0.9504)] 
2025-07-12 10:36:36.329325: Epoch time: 69.46 s 
2025-07-12 10:36:37.248514:  
2025-07-12 10:36:37.250587: Epoch 926 
2025-07-12 10:36:37.252161: Current learning rate: 0.00096 
2025-07-12 10:37:46.620814: train_loss -0.9834 
2025-07-12 10:37:46.622111: val_loss -0.9511 
2025-07-12 10:37:46.623183: Pseudo dice [np.float32(0.9535)] 
2025-07-12 10:37:46.624321: Epoch time: 69.38 s 
2025-07-12 10:37:47.537918:  
2025-07-12 10:37:47.539682: Epoch 927 
2025-07-12 10:37:47.540671: Current learning rate: 0.00095 
2025-07-12 10:38:56.856236: train_loss -0.983 
2025-07-12 10:38:56.857862: val_loss -0.9511 
2025-07-12 10:38:56.859220: Pseudo dice [np.float32(0.9534)] 
2025-07-12 10:38:56.860381: Epoch time: 69.32 s 
2025-07-12 10:38:57.774408:  
2025-07-12 10:38:57.776418: Epoch 928 
2025-07-12 10:38:57.777657: Current learning rate: 0.00094 
2025-07-12 10:40:07.192019: train_loss -0.9832 
2025-07-12 10:40:07.193239: val_loss -0.948 
2025-07-12 10:40:07.194328: Pseudo dice [np.float32(0.9521)] 
2025-07-12 10:40:07.195397: Epoch time: 69.42 s 
2025-07-12 10:40:08.112773:  
2025-07-12 10:40:08.114634: Epoch 929 
2025-07-12 10:40:08.116083: Current learning rate: 0.00092 
2025-07-12 10:41:18.376874: train_loss -0.9831 
2025-07-12 10:41:18.378060: val_loss -0.9497 
2025-07-12 10:41:18.379122: Pseudo dice [np.float32(0.9522)] 
2025-07-12 10:41:18.380425: Epoch time: 70.27 s 
2025-07-12 10:41:19.278349:  
2025-07-12 10:41:19.280510: Epoch 930 
2025-07-12 10:41:19.281638: Current learning rate: 0.00091 
2025-07-12 10:42:28.738950: train_loss -0.9833 
2025-07-12 10:42:28.740143: val_loss -0.9528 
2025-07-12 10:42:28.741077: Pseudo dice [np.float32(0.9556)] 
2025-07-12 10:42:28.741936: Epoch time: 69.46 s 
2025-07-12 10:42:29.659713:  
2025-07-12 10:42:29.661575: Epoch 931 
2025-07-12 10:42:29.662775: Current learning rate: 0.0009 
2025-07-12 10:43:40.030037: train_loss -0.9831 
2025-07-12 10:43:40.031677: val_loss -0.9507 
2025-07-12 10:43:40.032977: Pseudo dice [np.float32(0.9528)] 
2025-07-12 10:43:40.034307: Epoch time: 70.37 s 
2025-07-12 10:43:40.965538:  
2025-07-12 10:43:40.967596: Epoch 932 
2025-07-12 10:43:40.968726: Current learning rate: 0.00089 
2025-07-12 10:44:49.939240: train_loss -0.9838 
2025-07-12 10:44:49.940483: val_loss -0.9493 
2025-07-12 10:44:49.941464: Pseudo dice [np.float32(0.9521)] 
2025-07-12 10:44:49.942498: Epoch time: 68.98 s 
2025-07-12 10:44:50.852626:  
2025-07-12 10:44:50.854561: Epoch 933 
2025-07-12 10:44:50.855802: Current learning rate: 0.00088 
2025-07-12 10:45:59.709723: train_loss -0.9834 
2025-07-12 10:45:59.711171: val_loss -0.9521 
2025-07-12 10:45:59.712332: Pseudo dice [np.float32(0.9555)] 
2025-07-12 10:45:59.713312: Epoch time: 68.86 s 
2025-07-12 10:46:00.632181:  
2025-07-12 10:46:00.634089: Epoch 934 
2025-07-12 10:46:00.635155: Current learning rate: 0.00087 
2025-07-12 10:47:09.873493: train_loss -0.9832 
2025-07-12 10:47:09.874743: val_loss -0.9509 
2025-07-12 10:47:09.875849: Pseudo dice [np.float32(0.9543)] 
2025-07-12 10:47:09.877430: Epoch time: 69.24 s 
2025-07-12 10:47:10.780802:  
2025-07-12 10:47:10.782464: Epoch 935 
2025-07-12 10:47:10.783594: Current learning rate: 0.00085 
2025-07-12 10:48:20.189035: train_loss -0.9838 
2025-07-12 10:48:20.190771: val_loss -0.9497 
2025-07-12 10:48:20.191951: Pseudo dice [np.float32(0.9526)] 
2025-07-12 10:48:20.193085: Epoch time: 69.41 s 
2025-07-12 10:48:21.119667:  
2025-07-12 10:48:21.121474: Epoch 936 
2025-07-12 10:48:21.122574: Current learning rate: 0.00084 
2025-07-12 10:49:30.464068: train_loss -0.9833 
2025-07-12 10:49:30.465242: val_loss -0.9518 
2025-07-12 10:49:30.466231: Pseudo dice [np.float32(0.955)] 
2025-07-12 10:49:30.467414: Epoch time: 69.35 s 
2025-07-12 10:49:31.392911:  
2025-07-12 10:49:31.394790: Epoch 937 
2025-07-12 10:49:31.396412: Current learning rate: 0.00083 
2025-07-12 10:50:40.885844: train_loss -0.9838 
2025-07-12 10:50:40.887038: val_loss -0.9478 
2025-07-12 10:50:40.888219: Pseudo dice [np.float32(0.9519)] 
2025-07-12 10:50:40.889165: Epoch time: 69.5 s 
2025-07-12 10:50:41.798112:  
2025-07-12 10:50:41.799590: Epoch 938 
2025-07-12 10:50:41.800631: Current learning rate: 0.00082 
2025-07-12 10:51:51.995766: train_loss -0.9833 
2025-07-12 10:51:51.996933: val_loss -0.9479 
2025-07-12 10:51:51.998039: Pseudo dice [np.float32(0.9512)] 
2025-07-12 10:51:51.999401: Epoch time: 70.2 s 
2025-07-12 10:51:52.929538:  
2025-07-12 10:51:52.931327: Epoch 939 
2025-07-12 10:51:52.932318: Current learning rate: 0.00081 
2025-07-12 10:53:02.300334: train_loss -0.9836 
2025-07-12 10:53:02.301589: val_loss -0.9467 
2025-07-12 10:53:02.302839: Pseudo dice [np.float32(0.9499)] 
2025-07-12 10:53:02.303981: Epoch time: 69.37 s 
2025-07-12 10:53:03.219505:  
2025-07-12 10:53:03.221380: Epoch 940 
2025-07-12 10:53:03.222802: Current learning rate: 0.00079 
2025-07-12 10:54:12.691948: train_loss -0.9829 
2025-07-12 10:54:12.693234: val_loss -0.9505 
2025-07-12 10:54:12.694277: Pseudo dice [np.float32(0.9535)] 
2025-07-12 10:54:12.695435: Epoch time: 69.48 s 
2025-07-12 10:54:13.610087:  
2025-07-12 10:54:13.612181: Epoch 941 
2025-07-12 10:54:13.613275: Current learning rate: 0.00078 
2025-07-12 10:55:23.209491: train_loss -0.9837 
2025-07-12 10:55:23.210769: val_loss -0.9488 
2025-07-12 10:55:23.212089: Pseudo dice [np.float32(0.9518)] 
2025-07-12 10:55:23.213978: Epoch time: 69.6 s 
2025-07-12 10:55:24.142905:  
2025-07-12 10:55:24.145118: Epoch 942 
2025-07-12 10:55:24.146390: Current learning rate: 0.00077 
2025-07-12 10:56:33.928657: train_loss -0.9836 
2025-07-12 10:56:33.930031: val_loss -0.9525 
2025-07-12 10:56:33.931514: Pseudo dice [np.float32(0.955)] 
2025-07-12 10:56:33.932663: Epoch time: 69.79 s 
2025-07-12 10:56:34.847709:  
2025-07-12 10:56:34.849940: Epoch 943 
2025-07-12 10:56:34.851215: Current learning rate: 0.00076 
2025-07-12 10:57:44.471370: train_loss -0.9834 
2025-07-12 10:57:44.472527: val_loss -0.9502 
2025-07-12 10:57:44.473678: Pseudo dice [np.float32(0.9534)] 
2025-07-12 10:57:44.474815: Epoch time: 69.63 s 
2025-07-12 10:57:45.388348:  
2025-07-12 10:57:45.390664: Epoch 944 
2025-07-12 10:57:45.391866: Current learning rate: 0.00075 
2025-07-12 10:58:54.380174: train_loss -0.9838 
2025-07-12 10:58:54.381675: val_loss -0.9505 
2025-07-12 10:58:54.382668: Pseudo dice [np.float32(0.954)] 
2025-07-12 10:58:54.383610: Epoch time: 69.0 s 
2025-07-12 10:58:55.305019:  
2025-07-12 10:58:55.307258: Epoch 945 
2025-07-12 10:58:55.308532: Current learning rate: 0.00074 
2025-07-12 11:00:04.325764: train_loss -0.9832 
2025-07-12 11:00:04.327260: val_loss -0.9508 
2025-07-12 11:00:04.328494: Pseudo dice [np.float32(0.9539)] 
2025-07-12 11:00:04.329633: Epoch time: 69.02 s 
2025-07-12 11:00:05.254052:  
2025-07-12 11:00:05.256222: Epoch 946 
2025-07-12 11:00:05.257623: Current learning rate: 0.00072 
2025-07-12 11:01:14.337507: train_loss -0.9832 
2025-07-12 11:01:14.339884: val_loss -0.9496 
2025-07-12 11:01:14.341295: Pseudo dice [np.float32(0.9522)] 
2025-07-12 11:01:14.342479: Epoch time: 69.09 s 
2025-07-12 11:01:15.263885:  
2025-07-12 11:01:15.266186: Epoch 947 
2025-07-12 11:01:15.267529: Current learning rate: 0.00071 
2025-07-12 11:02:24.780054: train_loss -0.9841 
2025-07-12 11:02:24.781320: val_loss -0.9505 
2025-07-12 11:02:24.782670: Pseudo dice [np.float32(0.9532)] 
2025-07-12 11:02:24.783832: Epoch time: 69.52 s 
2025-07-12 11:02:25.714175:  
2025-07-12 11:02:25.716558: Epoch 948 
2025-07-12 11:02:25.717682: Current learning rate: 0.0007 
2025-07-12 11:03:34.458435: train_loss -0.9843 
2025-07-12 11:03:34.459634: val_loss -0.9496 
2025-07-12 11:03:34.461214: Pseudo dice [np.float32(0.9532)] 
2025-07-12 11:03:34.462458: Epoch time: 68.75 s 
2025-07-12 11:03:35.381537:  
2025-07-12 11:03:35.384308: Epoch 949 
2025-07-12 11:03:35.385343: Current learning rate: 0.00069 
2025-07-12 11:04:44.312430: train_loss -0.9835 
2025-07-12 11:04:44.313710: val_loss -0.9506 
2025-07-12 11:04:44.315452: Pseudo dice [np.float32(0.953)] 
2025-07-12 11:04:44.317006: Epoch time: 68.93 s 
2025-07-12 11:04:46.590887:  
2025-07-12 11:04:46.592859: Epoch 950 
2025-07-12 11:04:46.594390: Current learning rate: 0.00067 
2025-07-12 11:05:55.192229: train_loss -0.9834 
2025-07-12 11:05:55.193899: val_loss -0.9486 
2025-07-12 11:05:55.195002: Pseudo dice [np.float32(0.9516)] 
2025-07-12 11:05:55.196038: Epoch time: 68.61 s 
2025-07-12 11:05:56.113684:  
2025-07-12 11:05:56.115981: Epoch 951 
2025-07-12 11:05:56.117171: Current learning rate: 0.00066 
2025-07-12 11:07:04.795367: train_loss -0.9846 
2025-07-12 11:07:04.796810: val_loss -0.9523 
2025-07-12 11:07:04.798378: Pseudo dice [np.float32(0.9548)] 
2025-07-12 11:07:04.799638: Epoch time: 68.69 s 
2025-07-12 11:07:05.719346:  
2025-07-12 11:07:05.721580: Epoch 952 
2025-07-12 11:07:05.723215: Current learning rate: 0.00065 
2025-07-12 11:08:14.650515: train_loss -0.9835 
2025-07-12 11:08:14.652410: val_loss -0.9528 
2025-07-12 11:08:14.653650: Pseudo dice [np.float32(0.9552)] 
2025-07-12 11:08:14.654649: Epoch time: 68.93 s 
2025-07-12 11:08:15.573622:  
2025-07-12 11:08:15.575400: Epoch 953 
2025-07-12 11:08:15.576570: Current learning rate: 0.00064 
2025-07-12 11:09:24.336907: train_loss -0.9838 
2025-07-12 11:09:24.338291: val_loss -0.9484 
2025-07-12 11:09:24.339672: Pseudo dice [np.float32(0.951)] 
2025-07-12 11:09:24.341066: Epoch time: 68.77 s 
2025-07-12 11:09:25.282967:  
2025-07-12 11:09:25.285093: Epoch 954 
2025-07-12 11:09:25.286197: Current learning rate: 0.00063 
2025-07-12 11:10:33.840564: train_loss -0.9835 
2025-07-12 11:10:33.842392: val_loss -0.9499 
2025-07-12 11:10:33.843761: Pseudo dice [np.float32(0.9526)] 
2025-07-12 11:10:33.845330: Epoch time: 68.56 s 
2025-07-12 11:10:34.773001:  
2025-07-12 11:10:34.775091: Epoch 955 
2025-07-12 11:10:34.776488: Current learning rate: 0.00061 
2025-07-12 11:11:43.470828: train_loss -0.9837 
2025-07-12 11:11:43.472019: val_loss -0.9528 
2025-07-12 11:11:43.473466: Pseudo dice [np.float32(0.9554)] 
2025-07-12 11:11:43.474794: Epoch time: 68.7 s 
2025-07-12 11:11:44.406029:  
2025-07-12 11:11:44.408402: Epoch 956 
2025-07-12 11:11:44.409765: Current learning rate: 0.0006 
2025-07-12 11:12:53.977489: train_loss -0.984 
2025-07-12 11:12:53.978661: val_loss -0.9501 
2025-07-12 11:12:53.979531: Pseudo dice [np.float32(0.9532)] 
2025-07-12 11:12:53.980405: Epoch time: 69.58 s 
2025-07-12 11:12:54.901675:  
2025-07-12 11:12:54.903726: Epoch 957 
2025-07-12 11:12:54.904913: Current learning rate: 0.00059 
2025-07-12 11:14:04.041636: train_loss -0.984 
2025-07-12 11:14:04.043195: val_loss -0.9512 
2025-07-12 11:14:04.044689: Pseudo dice [np.float32(0.9538)] 
2025-07-12 11:14:04.045742: Epoch time: 69.14 s 
2025-07-12 11:14:04.969174:  
2025-07-12 11:14:04.971390: Epoch 958 
2025-07-12 11:14:04.972590: Current learning rate: 0.00058 
2025-07-12 11:15:14.326003: train_loss -0.9836 
2025-07-12 11:15:14.327714: val_loss -0.954 
2025-07-12 11:15:14.329184: Pseudo dice [np.float32(0.9568)] 
2025-07-12 11:15:14.330482: Epoch time: 69.36 s 
2025-07-12 11:15:15.226135:  
2025-07-12 11:15:15.228137: Epoch 959 
2025-07-12 11:15:15.229453: Current learning rate: 0.00056 
2025-07-12 11:16:24.698998: train_loss -0.9838 
2025-07-12 11:16:24.700273: val_loss -0.9502 
2025-07-12 11:16:24.701251: Pseudo dice [np.float32(0.9527)] 
2025-07-12 11:16:24.702234: Epoch time: 69.48 s 
2025-07-12 11:16:25.634800:  
2025-07-12 11:16:25.637570: Epoch 960 
2025-07-12 11:16:25.639166: Current learning rate: 0.00055 
2025-07-12 11:17:34.886091: train_loss -0.9838 
2025-07-12 11:17:34.887407: val_loss -0.9497 
2025-07-12 11:17:34.888459: Pseudo dice [np.float32(0.9527)] 
2025-07-12 11:17:34.889658: Epoch time: 69.25 s 
2025-07-12 11:17:35.834993:  
2025-07-12 11:17:35.837262: Epoch 961 
2025-07-12 11:17:35.838439: Current learning rate: 0.00054 
2025-07-12 11:18:44.758061: train_loss -0.9836 
2025-07-12 11:18:44.759494: val_loss -0.9506 
2025-07-12 11:18:44.760712: Pseudo dice [np.float32(0.9537)] 
2025-07-12 11:18:44.761663: Epoch time: 68.93 s 
2025-07-12 11:18:45.725764:  
2025-07-12 11:18:45.728520: Epoch 962 
2025-07-12 11:18:45.730219: Current learning rate: 0.00053 
2025-07-12 11:19:54.511162: train_loss -0.9837 
2025-07-12 11:19:54.512408: val_loss -0.9529 
2025-07-12 11:19:54.513438: Pseudo dice [np.float32(0.9562)] 
2025-07-12 11:19:54.514685: Epoch time: 68.79 s 
2025-07-12 11:19:55.444791:  
2025-07-12 11:19:55.446916: Epoch 963 
2025-07-12 11:19:55.448082: Current learning rate: 0.00051 
2025-07-12 11:21:04.202509: train_loss -0.9837 
2025-07-12 11:21:04.204052: val_loss -0.9522 
2025-07-12 11:21:04.205479: Pseudo dice [np.float32(0.9546)] 
2025-07-12 11:21:04.207302: Epoch time: 68.76 s 
2025-07-12 11:21:05.138312:  
2025-07-12 11:21:05.140190: Epoch 964 
2025-07-12 11:21:05.141320: Current learning rate: 0.0005 
2025-07-12 11:22:14.065443: train_loss -0.9838 
2025-07-12 11:22:14.066798: val_loss -0.9494 
2025-07-12 11:22:14.067860: Pseudo dice [np.float32(0.9519)] 
2025-07-12 11:22:14.069010: Epoch time: 68.93 s 
2025-07-12 11:22:14.983841:  
2025-07-12 11:22:14.986225: Epoch 965 
2025-07-12 11:22:14.987460: Current learning rate: 0.00049 
2025-07-12 11:23:24.676931: train_loss -0.984 
2025-07-12 11:23:24.678511: val_loss -0.9496 
2025-07-12 11:23:24.679799: Pseudo dice [np.float32(0.9528)] 
2025-07-12 11:23:24.681015: Epoch time: 69.7 s 
2025-07-12 11:23:25.613001:  
2025-07-12 11:23:25.615215: Epoch 966 
2025-07-12 11:23:25.616905: Current learning rate: 0.00048 
2025-07-12 11:24:34.426454: train_loss -0.9837 
2025-07-12 11:24:34.427901: val_loss -0.9524 
2025-07-12 11:24:34.429055: Pseudo dice [np.float32(0.9551)] 
2025-07-12 11:24:34.429996: Epoch time: 68.82 s 
2025-07-12 11:24:35.357417:  
2025-07-12 11:24:35.359712: Epoch 967 
2025-07-12 11:24:35.361181: Current learning rate: 0.00046 
2025-07-12 11:25:44.251015: train_loss -0.9846 
2025-07-12 11:25:44.252702: val_loss -0.9543 
2025-07-12 11:25:44.254264: Pseudo dice [np.float32(0.9569)] 
2025-07-12 11:25:44.255446: Epoch time: 68.9 s 
2025-07-12 11:25:45.176934:  
2025-07-12 11:25:45.178886: Epoch 968 
2025-07-12 11:25:45.179979: Current learning rate: 0.00045 
2025-07-12 11:26:54.073983: train_loss -0.9843 
2025-07-12 11:26:54.075204: val_loss -0.9496 
2025-07-12 11:26:54.076696: Pseudo dice [np.float32(0.9525)] 
2025-07-12 11:26:54.078237: Epoch time: 68.9 s 
2025-07-12 11:26:54.996651:  
2025-07-12 11:26:54.998518: Epoch 969 
2025-07-12 11:26:54.999641: Current learning rate: 0.00044 
2025-07-12 11:28:03.893236: train_loss -0.9839 
2025-07-12 11:28:03.894602: val_loss -0.9531 
2025-07-12 11:28:03.895759: Pseudo dice [np.float32(0.9559)] 
2025-07-12 11:28:03.897199: Epoch time: 68.9 s 
2025-07-12 11:28:04.834832:  
2025-07-12 11:28:04.837274: Epoch 970 
2025-07-12 11:28:04.838658: Current learning rate: 0.00043 
2025-07-12 11:29:13.718688: train_loss -0.9838 
2025-07-12 11:29:13.720015: val_loss -0.9526 
2025-07-12 11:29:13.721151: Pseudo dice [np.float32(0.9547)] 
2025-07-12 11:29:13.722301: Epoch time: 68.89 s 
2025-07-12 11:29:14.655091:  
2025-07-12 11:29:14.656943: Epoch 971 
2025-07-12 11:29:14.658095: Current learning rate: 0.00041 
2025-07-12 11:30:23.560092: train_loss -0.9841 
2025-07-12 11:30:23.561706: val_loss -0.9453 
2025-07-12 11:30:23.563002: Pseudo dice [np.float32(0.9479)] 
2025-07-12 11:30:23.564255: Epoch time: 68.91 s 
2025-07-12 11:30:24.485714:  
2025-07-12 11:30:24.488179: Epoch 972 
2025-07-12 11:30:24.489517: Current learning rate: 0.0004 
2025-07-12 11:31:33.272424: train_loss -0.9843 
2025-07-12 11:31:33.273708: val_loss -0.9484 
2025-07-12 11:31:33.275306: Pseudo dice [np.float32(0.9523)] 
2025-07-12 11:31:33.276260: Epoch time: 68.79 s 
2025-07-12 11:31:34.201140:  
2025-07-12 11:31:34.203283: Epoch 973 
2025-07-12 11:31:34.204855: Current learning rate: 0.00039 
2025-07-12 11:32:43.244733: train_loss -0.9845 
2025-07-12 11:32:43.246110: val_loss -0.9507 
2025-07-12 11:32:43.247292: Pseudo dice [np.float32(0.9538)] 
2025-07-12 11:32:43.248318: Epoch time: 69.05 s 
2025-07-12 11:32:44.186336:  
2025-07-12 11:32:44.188372: Epoch 974 
2025-07-12 11:32:44.189671: Current learning rate: 0.00037 
2025-07-12 11:33:54.090258: train_loss -0.9836 
2025-07-12 11:33:54.091696: val_loss -0.9506 
2025-07-12 11:33:54.093138: Pseudo dice [np.float32(0.9537)] 
2025-07-12 11:33:54.094342: Epoch time: 69.91 s 
2025-07-12 11:33:54.998123:  
2025-07-12 11:33:55.000180: Epoch 975 
2025-07-12 11:33:55.001275: Current learning rate: 0.00036 
2025-07-12 11:35:04.375561: train_loss -0.9834 
2025-07-12 11:35:04.376828: val_loss -0.9488 
2025-07-12 11:35:04.378170: Pseudo dice [np.float32(0.9519)] 
2025-07-12 11:35:04.379574: Epoch time: 69.38 s 
2025-07-12 11:35:05.320099:  
2025-07-12 11:35:05.322117: Epoch 976 
2025-07-12 11:35:05.323472: Current learning rate: 0.00035 
2025-07-12 11:36:14.802334: train_loss -0.9839 
2025-07-12 11:36:14.803683: val_loss -0.9504 
2025-07-12 11:36:14.804927: Pseudo dice [np.float32(0.9535)] 
2025-07-12 11:36:14.806087: Epoch time: 69.49 s 
2025-07-12 11:36:15.725796:  
2025-07-12 11:36:15.728124: Epoch 977 
2025-07-12 11:36:15.729320: Current learning rate: 0.00034 
2025-07-12 11:37:25.151934: train_loss -0.9837 
2025-07-12 11:37:25.153218: val_loss -0.9539 
2025-07-12 11:37:25.154383: Pseudo dice [np.float32(0.9565)] 
2025-07-12 11:37:25.155805: Epoch time: 69.43 s 
2025-07-12 11:37:26.076444:  
2025-07-12 11:37:26.078491: Epoch 978 
2025-07-12 11:37:26.079742: Current learning rate: 0.00032 
2025-07-12 11:38:35.374114: train_loss -0.9845 
2025-07-12 11:38:35.375408: val_loss -0.9505 
2025-07-12 11:38:35.376707: Pseudo dice [np.float32(0.9532)] 
2025-07-12 11:38:35.377918: Epoch time: 69.3 s 
2025-07-12 11:38:36.294755:  
2025-07-12 11:38:36.296760: Epoch 979 
2025-07-12 11:38:36.297970: Current learning rate: 0.00031 
2025-07-12 11:39:45.796722: train_loss -0.9838 
2025-07-12 11:39:45.797879: val_loss -0.9514 
2025-07-12 11:39:45.799006: Pseudo dice [np.float32(0.9536)] 
2025-07-12 11:39:45.800228: Epoch time: 69.51 s 
2025-07-12 11:39:46.728421:  
2025-07-12 11:39:46.730553: Epoch 980 
2025-07-12 11:39:46.731763: Current learning rate: 0.0003 
2025-07-12 11:41:00.947347: train_loss -0.9841 
2025-07-12 11:41:00.948655: val_loss -0.953 
2025-07-12 11:41:00.949555: Pseudo dice [np.float32(0.9554)] 
2025-07-12 11:41:00.950535: Epoch time: 74.22 s 
2025-07-12 11:41:01.874745:  
2025-07-12 11:41:01.876879: Epoch 981 
2025-07-12 11:41:01.878109: Current learning rate: 0.00028 
2025-07-12 11:42:11.534385: train_loss -0.9842 
2025-07-12 11:42:11.535571: val_loss -0.9514 
2025-07-12 11:42:11.536734: Pseudo dice [np.float32(0.9539)] 
2025-07-12 11:42:11.537883: Epoch time: 69.66 s 
2025-07-12 11:42:12.469180:  
2025-07-12 11:42:12.471231: Epoch 982 
2025-07-12 11:42:12.472349: Current learning rate: 0.00027 
2025-07-12 11:43:20.920921: train_loss -0.9843 
2025-07-12 11:43:20.922018: val_loss -0.9502 
2025-07-12 11:43:20.923028: Pseudo dice [np.float32(0.9527)] 
2025-07-12 11:43:20.924639: Epoch time: 68.46 s 
2025-07-12 11:43:21.862329:  
2025-07-12 11:43:21.863961: Epoch 983 
2025-07-12 11:43:21.865225: Current learning rate: 0.00026 
2025-07-12 11:44:31.040578: train_loss -0.9835 
2025-07-12 11:44:31.042037: val_loss -0.9512 
2025-07-12 11:44:31.043010: Pseudo dice [np.float32(0.9535)] 
2025-07-12 11:44:31.044302: Epoch time: 69.18 s 
2025-07-12 11:44:31.935222:  
2025-07-12 11:44:31.937474: Epoch 984 
2025-07-12 11:44:31.938592: Current learning rate: 0.00024 
2025-07-12 11:45:40.225102: train_loss -0.9845 
2025-07-12 11:45:40.226455: val_loss -0.9524 
2025-07-12 11:45:40.227435: Pseudo dice [np.float32(0.9552)] 
2025-07-12 11:45:40.228573: Epoch time: 68.29 s 
2025-07-12 11:45:41.155253:  
2025-07-12 11:45:41.157381: Epoch 985 
2025-07-12 11:45:41.159233: Current learning rate: 0.00023 
2025-07-12 11:46:49.443261: train_loss -0.9842 
2025-07-12 11:46:49.444700: val_loss -0.9554 
2025-07-12 11:46:49.445639: Pseudo dice [np.float32(0.9576)] 
2025-07-12 11:46:49.446742: Epoch time: 68.29 s 
2025-07-12 11:46:50.385010:  
2025-07-12 11:46:50.387016: Epoch 986 
2025-07-12 11:46:50.388314: Current learning rate: 0.00021 
2025-07-12 11:47:58.757402: train_loss -0.9846 
2025-07-12 11:47:58.758549: val_loss -0.9522 
2025-07-12 11:47:58.759421: Pseudo dice [np.float32(0.9545)] 
2025-07-12 11:47:58.760403: Epoch time: 68.38 s 
2025-07-12 11:47:59.657075:  
2025-07-12 11:47:59.659283: Epoch 987 
2025-07-12 11:47:59.660463: Current learning rate: 0.0002 
2025-07-12 11:49:08.095047: train_loss -0.9844 
2025-07-12 11:49:08.096686: val_loss -0.9529 
2025-07-12 11:49:08.097987: Pseudo dice [np.float32(0.956)] 
2025-07-12 11:49:08.099334: Epoch time: 68.44 s 
2025-07-12 11:49:09.035827:  
2025-07-12 11:49:09.038011: Epoch 988 
2025-07-12 11:49:09.039266: Current learning rate: 0.00019 
2025-07-12 11:50:17.731597: train_loss -0.9844 
2025-07-12 11:50:17.732805: val_loss -0.9476 
2025-07-12 11:50:17.734212: Pseudo dice [np.float32(0.9504)] 
2025-07-12 11:50:17.735499: Epoch time: 68.7 s 
2025-07-12 11:50:18.666815:  
2025-07-12 11:50:18.669216: Epoch 989 
2025-07-12 11:50:18.670479: Current learning rate: 0.00017 
2025-07-12 11:51:27.556142: train_loss -0.9838 
2025-07-12 11:51:27.557294: val_loss -0.9504 
2025-07-12 11:51:27.558311: Pseudo dice [np.float32(0.9534)] 
2025-07-12 11:51:27.559791: Epoch time: 68.89 s 
2025-07-12 11:51:28.491569:  
2025-07-12 11:51:28.493130: Epoch 990 
2025-07-12 11:51:28.494198: Current learning rate: 0.00016 
2025-07-12 11:52:37.697908: train_loss -0.9846 
2025-07-12 11:52:37.699407: val_loss -0.9507 
2025-07-12 11:52:37.700497: Pseudo dice [np.float32(0.9536)] 
2025-07-12 11:52:37.701560: Epoch time: 69.21 s 
2025-07-12 11:52:38.651486:  
2025-07-12 11:52:38.653647: Epoch 991 
2025-07-12 11:52:38.654844: Current learning rate: 0.00014 
2025-07-12 11:53:47.934329: train_loss -0.9842 
2025-07-12 11:53:47.936218: val_loss -0.9494 
2025-07-12 11:53:47.937144: Pseudo dice [np.float32(0.9512)] 
2025-07-12 11:53:47.938363: Epoch time: 69.29 s 
2025-07-12 11:53:48.885294:  
2025-07-12 11:53:48.887142: Epoch 992 
2025-07-12 11:53:48.888233: Current learning rate: 0.00013 
2025-07-12 11:54:59.282918: train_loss -0.9844 
2025-07-12 11:54:59.284176: val_loss -0.951 
2025-07-12 11:54:59.285258: Pseudo dice [np.float32(0.9535)] 
2025-07-12 11:54:59.286476: Epoch time: 70.4 s 
2025-07-12 11:55:00.195785:  
2025-07-12 11:55:00.197991: Epoch 993 
2025-07-12 11:55:00.199284: Current learning rate: 0.00011 
2025-07-12 11:56:09.647585: train_loss -0.9845 
2025-07-12 11:56:09.648919: val_loss -0.9507 
2025-07-12 11:56:09.649854: Pseudo dice [np.float32(0.9534)] 
2025-07-12 11:56:09.650798: Epoch time: 69.46 s 
2025-07-12 11:56:10.606367:  
2025-07-12 11:56:10.608525: Epoch 994 
2025-07-12 11:56:10.609701: Current learning rate: 0.0001 
2025-07-12 11:57:19.538693: train_loss -0.9842 
2025-07-12 11:57:19.539820: val_loss -0.9488 
2025-07-12 11:57:19.541004: Pseudo dice [np.float32(0.9517)] 
2025-07-12 11:57:19.542070: Epoch time: 68.94 s 
2025-07-12 11:57:20.457694:  
2025-07-12 11:57:20.459691: Epoch 995 
2025-07-12 11:57:20.460741: Current learning rate: 8e-05 
2025-07-12 11:58:29.601595: train_loss -0.9844 
2025-07-12 11:58:29.603139: val_loss -0.9491 
2025-07-12 11:58:29.604236: Pseudo dice [np.float32(0.9521)] 
2025-07-12 11:58:29.605271: Epoch time: 69.15 s 
2025-07-12 11:58:30.527294:  
2025-07-12 11:58:30.529342: Epoch 996 
2025-07-12 11:58:30.530910: Current learning rate: 7e-05 
2025-07-12 11:59:39.638237: train_loss -0.9841 
2025-07-12 11:59:39.639563: val_loss -0.9538 
2025-07-12 11:59:39.640713: Pseudo dice [np.float32(0.9566)] 
2025-07-12 11:59:39.641683: Epoch time: 69.11 s 
2025-07-12 11:59:40.576499:  
2025-07-12 11:59:40.578277: Epoch 997 
2025-07-12 11:59:40.579340: Current learning rate: 5e-05 
2025-07-12 12:00:49.983407: train_loss -0.9845 
2025-07-12 12:00:49.984690: val_loss -0.9561 
2025-07-12 12:00:49.985899: Pseudo dice [np.float32(0.9585)] 
2025-07-12 12:00:49.987205: Epoch time: 69.41 s 
2025-07-12 12:00:50.871236:  
2025-07-12 12:00:50.873471: Epoch 998 
2025-07-12 12:00:50.874721: Current learning rate: 4e-05 
2025-07-12 12:02:04.781150: train_loss -0.984 
2025-07-12 12:02:04.782690: val_loss -0.951 
2025-07-12 12:02:04.783844: Pseudo dice [np.float32(0.954)] 
2025-07-12 12:02:04.785018: Epoch time: 73.91 s 
2025-07-12 12:02:05.695726:  
2025-07-12 12:02:05.697597: Epoch 999 
2025-07-12 12:02:05.699223: Current learning rate: 2e-05 
2025-07-12 12:03:16.542690: train_loss -0.9842 
2025-07-12 12:03:16.543946: val_loss -0.9492 
2025-07-12 12:03:16.544956: Pseudo dice [np.float32(0.9517)] 
2025-07-12 12:03:16.545991: Epoch time: 70.85 s 
2025-07-12 12:03:18.881042: Training done. 
2025-07-12 12:03:18.916856: Using splits from existing split file: /data/nnUNet_preprocessed/Dataset010_PTB_all_energies_1mm_no_background_alldata/splits_final.json 
2025-07-12 12:03:18.925086: The split file contains 5 splits. 
2025-07-12 12:03:18.926385: Desired fold for training: 0 
2025-07-12 12:03:18.927447: This split has 1440 training and 360 validation cases. 
2025-07-12 12:03:18.937817: predicting PTB_all_energies_1mm_no_background_0001 
2025-07-12 12:03:18.946506: PTB_all_energies_1mm_no_background_0001, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.480278: predicting PTB_all_energies_1mm_no_background_0003 
2025-07-12 12:03:27.488102: PTB_all_energies_1mm_no_background_0003, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.536991: predicting PTB_all_energies_1mm_no_background_0004 
2025-07-12 12:03:27.544390: PTB_all_energies_1mm_no_background_0004, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.595908: predicting PTB_all_energies_1mm_no_background_0009 
2025-07-12 12:03:27.603169: PTB_all_energies_1mm_no_background_0009, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.653908: predicting PTB_all_energies_1mm_no_background_0018 
2025-07-12 12:03:27.662278: PTB_all_energies_1mm_no_background_0018, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.714796: predicting PTB_all_energies_1mm_no_background_0021 
2025-07-12 12:03:27.721357: PTB_all_energies_1mm_no_background_0021, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.771963: predicting PTB_all_energies_1mm_no_background_0023 
2025-07-12 12:03:27.778791: PTB_all_energies_1mm_no_background_0023, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.830139: predicting PTB_all_energies_1mm_no_background_0031 
2025-07-12 12:03:27.838271: PTB_all_energies_1mm_no_background_0031, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.895100: predicting PTB_all_energies_1mm_no_background_0034 
2025-07-12 12:03:27.903422: PTB_all_energies_1mm_no_background_0034, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:27.954497: predicting PTB_all_energies_1mm_no_background_0042 
2025-07-12 12:03:27.961735: PTB_all_energies_1mm_no_background_0042, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.009742: predicting PTB_all_energies_1mm_no_background_0048 
2025-07-12 12:03:28.018769: PTB_all_energies_1mm_no_background_0048, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.079739: predicting PTB_all_energies_1mm_no_background_0057 
2025-07-12 12:03:28.086915: PTB_all_energies_1mm_no_background_0057, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.134906: predicting PTB_all_energies_1mm_no_background_0058 
2025-07-12 12:03:28.141749: PTB_all_energies_1mm_no_background_0058, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.189323: predicting PTB_all_energies_1mm_no_background_0071 
2025-07-12 12:03:28.196212: PTB_all_energies_1mm_no_background_0071, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.242253: predicting PTB_all_energies_1mm_no_background_0073 
2025-07-12 12:03:28.249659: PTB_all_energies_1mm_no_background_0073, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.303690: predicting PTB_all_energies_1mm_no_background_0074 
2025-07-12 12:03:28.310657: PTB_all_energies_1mm_no_background_0074, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.357602: predicting PTB_all_energies_1mm_no_background_0077 
2025-07-12 12:03:28.364202: PTB_all_energies_1mm_no_background_0077, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.411022: predicting PTB_all_energies_1mm_no_background_0093 
2025-07-12 12:03:28.418167: PTB_all_energies_1mm_no_background_0093, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.487913: predicting PTB_all_energies_1mm_no_background_0101 
2025-07-12 12:03:28.495482: PTB_all_energies_1mm_no_background_0101, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.555104: predicting PTB_all_energies_1mm_no_background_0102 
2025-07-12 12:03:28.562190: PTB_all_energies_1mm_no_background_0102, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.610403: predicting PTB_all_energies_1mm_no_background_0105 
2025-07-12 12:03:28.617069: PTB_all_energies_1mm_no_background_0105, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.664219: predicting PTB_all_energies_1mm_no_background_0110 
2025-07-12 12:03:28.671179: PTB_all_energies_1mm_no_background_0110, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.720178: predicting PTB_all_energies_1mm_no_background_0112 
2025-07-12 12:03:28.726701: PTB_all_energies_1mm_no_background_0112, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.776785: predicting PTB_all_energies_1mm_no_background_0116 
2025-07-12 12:03:28.783658: PTB_all_energies_1mm_no_background_0116, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.831693: predicting PTB_all_energies_1mm_no_background_0132 
2025-07-12 12:03:28.838035: PTB_all_energies_1mm_no_background_0132, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.884398: predicting PTB_all_energies_1mm_no_background_0137 
2025-07-12 12:03:28.891229: PTB_all_energies_1mm_no_background_0137, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:28.961690: predicting PTB_all_energies_1mm_no_background_0138 
2025-07-12 12:03:28.969269: PTB_all_energies_1mm_no_background_0138, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.028700: predicting PTB_all_energies_1mm_no_background_0148 
2025-07-12 12:03:29.035520: PTB_all_energies_1mm_no_background_0148, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.084208: predicting PTB_all_energies_1mm_no_background_0149 
2025-07-12 12:03:29.091472: PTB_all_energies_1mm_no_background_0149, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.138979: predicting PTB_all_energies_1mm_no_background_0150 
2025-07-12 12:03:29.146992: PTB_all_energies_1mm_no_background_0150, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.194911: predicting PTB_all_energies_1mm_no_background_0151 
2025-07-12 12:03:29.202237: PTB_all_energies_1mm_no_background_0151, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.252623: predicting PTB_all_energies_1mm_no_background_0152 
2025-07-12 12:03:29.259424: PTB_all_energies_1mm_no_background_0152, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.308639: predicting PTB_all_energies_1mm_no_background_0154 
2025-07-12 12:03:29.315513: PTB_all_energies_1mm_no_background_0154, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.361817: predicting PTB_all_energies_1mm_no_background_0155 
2025-07-12 12:03:29.368493: PTB_all_energies_1mm_no_background_0155, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.415688: predicting PTB_all_energies_1mm_no_background_0163 
2025-07-12 12:03:29.422737: PTB_all_energies_1mm_no_background_0163, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.470400: predicting PTB_all_energies_1mm_no_background_0165 
2025-07-12 12:03:29.477131: PTB_all_energies_1mm_no_background_0165, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.524937: predicting PTB_all_energies_1mm_no_background_0172 
2025-07-12 12:03:29.533083: PTB_all_energies_1mm_no_background_0172, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.581499: predicting PTB_all_energies_1mm_no_background_0179 
2025-07-12 12:03:29.588190: PTB_all_energies_1mm_no_background_0179, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.635569: predicting PTB_all_energies_1mm_no_background_0181 
2025-07-12 12:03:29.642640: PTB_all_energies_1mm_no_background_0181, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.692097: predicting PTB_all_energies_1mm_no_background_0188 
2025-07-12 12:03:29.698991: PTB_all_energies_1mm_no_background_0188, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.746830: predicting PTB_all_energies_1mm_no_background_0189 
2025-07-12 12:03:29.753351: PTB_all_energies_1mm_no_background_0189, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.801032: predicting PTB_all_energies_1mm_no_background_0191 
2025-07-12 12:03:29.808985: PTB_all_energies_1mm_no_background_0191, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.858451: predicting PTB_all_energies_1mm_no_background_0194 
2025-07-12 12:03:29.865450: PTB_all_energies_1mm_no_background_0194, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.935487: predicting PTB_all_energies_1mm_no_background_0200 
2025-07-12 12:03:29.942166: PTB_all_energies_1mm_no_background_0200, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:29.989448: predicting PTB_all_energies_1mm_no_background_0202 
2025-07-12 12:03:29.996042: PTB_all_energies_1mm_no_background_0202, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.048092: predicting PTB_all_energies_1mm_no_background_0207 
2025-07-12 12:03:30.054897: PTB_all_energies_1mm_no_background_0207, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.101637: predicting PTB_all_energies_1mm_no_background_0208 
2025-07-12 12:03:30.109348: PTB_all_energies_1mm_no_background_0208, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.160229: predicting PTB_all_energies_1mm_no_background_0209 
2025-07-12 12:03:30.167261: PTB_all_energies_1mm_no_background_0209, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.217772: predicting PTB_all_energies_1mm_no_background_0210 
2025-07-12 12:03:30.224793: PTB_all_energies_1mm_no_background_0210, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.271276: predicting PTB_all_energies_1mm_no_background_0220 
2025-07-12 12:03:30.278836: PTB_all_energies_1mm_no_background_0220, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.328338: predicting PTB_all_energies_1mm_no_background_0228 
2025-07-12 12:03:30.335652: PTB_all_energies_1mm_no_background_0228, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.382225: predicting PTB_all_energies_1mm_no_background_0230 
2025-07-12 12:03:30.389184: PTB_all_energies_1mm_no_background_0230, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.437754: predicting PTB_all_energies_1mm_no_background_0239 
2025-07-12 12:03:30.444578: PTB_all_energies_1mm_no_background_0239, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.495201: predicting PTB_all_energies_1mm_no_background_0261 
2025-07-12 12:03:30.502120: PTB_all_energies_1mm_no_background_0261, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.548399: predicting PTB_all_energies_1mm_no_background_0263 
2025-07-12 12:03:30.555838: PTB_all_energies_1mm_no_background_0263, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.607547: predicting PTB_all_energies_1mm_no_background_0265 
2025-07-12 12:03:30.615507: PTB_all_energies_1mm_no_background_0265, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.665701: predicting PTB_all_energies_1mm_no_background_0267 
2025-07-12 12:03:30.673128: PTB_all_energies_1mm_no_background_0267, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.720315: predicting PTB_all_energies_1mm_no_background_0269 
2025-07-12 12:03:30.727414: PTB_all_energies_1mm_no_background_0269, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.777367: predicting PTB_all_energies_1mm_no_background_0275 
2025-07-12 12:03:30.786153: PTB_all_energies_1mm_no_background_0275, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.832773: predicting PTB_all_energies_1mm_no_background_0283 
2025-07-12 12:03:30.839415: PTB_all_energies_1mm_no_background_0283, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.886653: predicting PTB_all_energies_1mm_no_background_0284 
2025-07-12 12:03:30.893895: PTB_all_energies_1mm_no_background_0284, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.943604: predicting PTB_all_energies_1mm_no_background_0285 
2025-07-12 12:03:30.950823: PTB_all_energies_1mm_no_background_0285, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:30.998739: predicting PTB_all_energies_1mm_no_background_0288 
2025-07-12 12:03:31.005224: PTB_all_energies_1mm_no_background_0288, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.056104: predicting PTB_all_energies_1mm_no_background_0295 
2025-07-12 12:03:31.063188: PTB_all_energies_1mm_no_background_0295, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.113153: predicting PTB_all_energies_1mm_no_background_0299 
2025-07-12 12:03:31.120865: PTB_all_energies_1mm_no_background_0299, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.168047: predicting PTB_all_energies_1mm_no_background_0301 
2025-07-12 12:03:31.175532: PTB_all_energies_1mm_no_background_0301, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.225350: predicting PTB_all_energies_1mm_no_background_0303 
2025-07-12 12:03:31.232218: PTB_all_energies_1mm_no_background_0303, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.279261: predicting PTB_all_energies_1mm_no_background_0306 
2025-07-12 12:03:31.285599: PTB_all_energies_1mm_no_background_0306, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.333281: predicting PTB_all_energies_1mm_no_background_0312 
2025-07-12 12:03:31.340557: PTB_all_energies_1mm_no_background_0312, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.390757: predicting PTB_all_energies_1mm_no_background_0315 
2025-07-12 12:03:31.399097: PTB_all_energies_1mm_no_background_0315, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.446165: predicting PTB_all_energies_1mm_no_background_0325 
2025-07-12 12:03:31.453989: PTB_all_energies_1mm_no_background_0325, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.503545: predicting PTB_all_energies_1mm_no_background_0329 
2025-07-12 12:03:31.510962: PTB_all_energies_1mm_no_background_0329, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.560556: predicting PTB_all_energies_1mm_no_background_0339 
2025-07-12 12:03:31.567529: PTB_all_energies_1mm_no_background_0339, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.613868: predicting PTB_all_energies_1mm_no_background_0348 
2025-07-12 12:03:31.621896: PTB_all_energies_1mm_no_background_0348, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.671961: predicting PTB_all_energies_1mm_no_background_0358 
2025-07-12 12:03:31.679391: PTB_all_energies_1mm_no_background_0358, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.727711: predicting PTB_all_energies_1mm_no_background_0359 
2025-07-12 12:03:31.736397: PTB_all_energies_1mm_no_background_0359, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.783797: predicting PTB_all_energies_1mm_no_background_0362 
2025-07-12 12:03:31.791736: PTB_all_energies_1mm_no_background_0362, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.839835: predicting PTB_all_energies_1mm_no_background_0363 
2025-07-12 12:03:31.847181: PTB_all_energies_1mm_no_background_0363, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.894142: predicting PTB_all_energies_1mm_no_background_0373 
2025-07-12 12:03:31.900756: PTB_all_energies_1mm_no_background_0373, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:31.951277: predicting PTB_all_energies_1mm_no_background_0375 
2025-07-12 12:03:31.958518: PTB_all_energies_1mm_no_background_0375, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.006644: predicting PTB_all_energies_1mm_no_background_0381 
2025-07-12 12:03:32.015546: PTB_all_energies_1mm_no_background_0381, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.062760: predicting PTB_all_energies_1mm_no_background_0391 
2025-07-12 12:03:32.069633: PTB_all_energies_1mm_no_background_0391, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.118361: predicting PTB_all_energies_1mm_no_background_0392 
2025-07-12 12:03:32.125553: PTB_all_energies_1mm_no_background_0392, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.174964: predicting PTB_all_energies_1mm_no_background_0393 
2025-07-12 12:03:32.181726: PTB_all_energies_1mm_no_background_0393, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.232103: predicting PTB_all_energies_1mm_no_background_0395 
2025-07-12 12:03:32.239484: PTB_all_energies_1mm_no_background_0395, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.287373: predicting PTB_all_energies_1mm_no_background_0396 
2025-07-12 12:03:32.294596: PTB_all_energies_1mm_no_background_0396, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.341501: predicting PTB_all_energies_1mm_no_background_0404 
2025-07-12 12:03:32.349063: PTB_all_energies_1mm_no_background_0404, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.399123: predicting PTB_all_energies_1mm_no_background_0414 
2025-07-12 12:03:32.405846: PTB_all_energies_1mm_no_background_0414, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.453057: predicting PTB_all_energies_1mm_no_background_0419 
2025-07-12 12:03:32.460222: PTB_all_energies_1mm_no_background_0419, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.506834: predicting PTB_all_energies_1mm_no_background_0424 
2025-07-12 12:03:32.513658: PTB_all_energies_1mm_no_background_0424, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.563668: predicting PTB_all_energies_1mm_no_background_0427 
2025-07-12 12:03:32.571092: PTB_all_energies_1mm_no_background_0427, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.620076: predicting PTB_all_energies_1mm_no_background_0428 
2025-07-12 12:03:32.626911: PTB_all_energies_1mm_no_background_0428, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.674097: predicting PTB_all_energies_1mm_no_background_0433 
2025-07-12 12:03:32.682369: PTB_all_energies_1mm_no_background_0433, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.730126: predicting PTB_all_energies_1mm_no_background_0454 
2025-07-12 12:03:32.736711: PTB_all_energies_1mm_no_background_0454, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.788790: predicting PTB_all_energies_1mm_no_background_0457 
2025-07-12 12:03:32.797263: PTB_all_energies_1mm_no_background_0457, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.847238: predicting PTB_all_energies_1mm_no_background_0469 
2025-07-12 12:03:32.854328: PTB_all_energies_1mm_no_background_0469, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.901646: predicting PTB_all_energies_1mm_no_background_0484 
2025-07-12 12:03:32.908416: PTB_all_energies_1mm_no_background_0484, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:32.955258: predicting PTB_all_energies_1mm_no_background_0487 
2025-07-12 12:03:32.961567: PTB_all_energies_1mm_no_background_0487, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.011623: predicting PTB_all_energies_1mm_no_background_0488 
2025-07-12 12:03:33.019321: PTB_all_energies_1mm_no_background_0488, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.068718: predicting PTB_all_energies_1mm_no_background_0489 
2025-07-12 12:03:33.075559: PTB_all_energies_1mm_no_background_0489, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.123002: predicting PTB_all_energies_1mm_no_background_0510 
2025-07-12 12:03:33.129560: PTB_all_energies_1mm_no_background_0510, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.178449: predicting PTB_all_energies_1mm_no_background_0514 
2025-07-12 12:03:33.186181: PTB_all_energies_1mm_no_background_0514, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.233046: predicting PTB_all_energies_1mm_no_background_0523 
2025-07-12 12:03:33.241094: PTB_all_energies_1mm_no_background_0523, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.291293: predicting PTB_all_energies_1mm_no_background_0524 
2025-07-12 12:03:33.298323: PTB_all_energies_1mm_no_background_0524, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.345701: predicting PTB_all_energies_1mm_no_background_0527 
2025-07-12 12:03:33.352724: PTB_all_energies_1mm_no_background_0527, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.400155: predicting PTB_all_energies_1mm_no_background_0529 
2025-07-12 12:03:33.407209: PTB_all_energies_1mm_no_background_0529, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.457023: predicting PTB_all_energies_1mm_no_background_0530 
2025-07-12 12:03:33.464509: PTB_all_energies_1mm_no_background_0530, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.512073: predicting PTB_all_energies_1mm_no_background_0541 
2025-07-12 12:03:33.519767: PTB_all_energies_1mm_no_background_0541, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.567579: predicting PTB_all_energies_1mm_no_background_0545 
2025-07-12 12:03:33.574989: PTB_all_energies_1mm_no_background_0545, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.622512: predicting PTB_all_energies_1mm_no_background_0552 
2025-07-12 12:03:33.629741: PTB_all_energies_1mm_no_background_0552, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.676423: predicting PTB_all_energies_1mm_no_background_0553 
2025-07-12 12:03:33.683281: PTB_all_energies_1mm_no_background_0553, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.733997: predicting PTB_all_energies_1mm_no_background_0564 
2025-07-12 12:03:33.741030: PTB_all_energies_1mm_no_background_0564, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.788069: predicting PTB_all_energies_1mm_no_background_0566 
2025-07-12 12:03:33.794733: PTB_all_energies_1mm_no_background_0566, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.841815: predicting PTB_all_energies_1mm_no_background_0568 
2025-07-12 12:03:33.849012: PTB_all_energies_1mm_no_background_0568, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.898883: predicting PTB_all_energies_1mm_no_background_0569 
2025-07-12 12:03:33.906278: PTB_all_energies_1mm_no_background_0569, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:33.952985: predicting PTB_all_energies_1mm_no_background_0571 
2025-07-12 12:03:33.959989: PTB_all_energies_1mm_no_background_0571, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.008307: predicting PTB_all_energies_1mm_no_background_0572 
2025-07-12 12:03:34.015290: PTB_all_energies_1mm_no_background_0572, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.062704: predicting PTB_all_energies_1mm_no_background_0587 
2025-07-12 12:03:34.069706: PTB_all_energies_1mm_no_background_0587, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.117718: predicting PTB_all_energies_1mm_no_background_0590 
2025-07-12 12:03:34.124429: PTB_all_energies_1mm_no_background_0590, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.174731: predicting PTB_all_energies_1mm_no_background_0599 
2025-07-12 12:03:34.181376: PTB_all_energies_1mm_no_background_0599, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.228330: predicting PTB_all_energies_1mm_no_background_0603 
2025-07-12 12:03:34.235664: PTB_all_energies_1mm_no_background_0603, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.284246: predicting PTB_all_energies_1mm_no_background_0604 
2025-07-12 12:03:34.290958: PTB_all_energies_1mm_no_background_0604, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.341593: predicting PTB_all_energies_1mm_no_background_0605 
2025-07-12 12:03:34.348954: PTB_all_energies_1mm_no_background_0605, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.397908: predicting PTB_all_energies_1mm_no_background_0607 
2025-07-12 12:03:34.404788: PTB_all_energies_1mm_no_background_0607, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.451923: predicting PTB_all_energies_1mm_no_background_0622 
2025-07-12 12:03:34.458678: PTB_all_energies_1mm_no_background_0622, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.506197: predicting PTB_all_energies_1mm_no_background_0625 
2025-07-12 12:03:34.513220: PTB_all_energies_1mm_no_background_0625, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.561060: predicting PTB_all_energies_1mm_no_background_0626 
2025-07-12 12:03:34.567727: PTB_all_energies_1mm_no_background_0626, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.618351: predicting PTB_all_energies_1mm_no_background_0636 
2025-07-12 12:03:34.625795: PTB_all_energies_1mm_no_background_0636, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.673388: predicting PTB_all_energies_1mm_no_background_0638 
2025-07-12 12:03:34.680393: PTB_all_energies_1mm_no_background_0638, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.726973: predicting PTB_all_energies_1mm_no_background_0639 
2025-07-12 12:03:34.734607: PTB_all_energies_1mm_no_background_0639, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.784602: predicting PTB_all_energies_1mm_no_background_0649 
2025-07-12 12:03:34.791665: PTB_all_energies_1mm_no_background_0649, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.838276: predicting PTB_all_energies_1mm_no_background_0659 
2025-07-12 12:03:34.844609: PTB_all_energies_1mm_no_background_0659, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.891906: predicting PTB_all_energies_1mm_no_background_0660 
2025-07-12 12:03:34.898905: PTB_all_energies_1mm_no_background_0660, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:34.947092: predicting PTB_all_energies_1mm_no_background_0669 
2025-07-12 12:03:34.954093: PTB_all_energies_1mm_no_background_0669, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.000710: predicting PTB_all_energies_1mm_no_background_0673 
2025-07-12 12:03:35.008137: PTB_all_energies_1mm_no_background_0673, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.057851: predicting PTB_all_energies_1mm_no_background_0674 
2025-07-12 12:03:35.066202: PTB_all_energies_1mm_no_background_0674, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.114825: predicting PTB_all_energies_1mm_no_background_0678 
2025-07-12 12:03:35.121986: PTB_all_energies_1mm_no_background_0678, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.169022: predicting PTB_all_energies_1mm_no_background_0686 
2025-07-12 12:03:35.176039: PTB_all_energies_1mm_no_background_0686, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.226711: predicting PTB_all_energies_1mm_no_background_0690 
2025-07-12 12:03:35.233901: PTB_all_energies_1mm_no_background_0690, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.280205: predicting PTB_all_energies_1mm_no_background_0693 
2025-07-12 12:03:35.286564: PTB_all_energies_1mm_no_background_0693, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.333776: predicting PTB_all_energies_1mm_no_background_0695 
2025-07-12 12:03:35.342188: PTB_all_energies_1mm_no_background_0695, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.389866: predicting PTB_all_energies_1mm_no_background_0703 
2025-07-12 12:03:35.397007: PTB_all_energies_1mm_no_background_0703, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.444973: predicting PTB_all_energies_1mm_no_background_0706 
2025-07-12 12:03:35.451396: PTB_all_energies_1mm_no_background_0706, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.502943: predicting PTB_all_energies_1mm_no_background_0710 
2025-07-12 12:03:35.509545: PTB_all_energies_1mm_no_background_0710, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.557097: predicting PTB_all_energies_1mm_no_background_0712 
2025-07-12 12:03:35.564044: PTB_all_energies_1mm_no_background_0712, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.610693: predicting PTB_all_energies_1mm_no_background_0715 
2025-07-12 12:03:35.618804: PTB_all_energies_1mm_no_background_0715, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.668242: predicting PTB_all_energies_1mm_no_background_0716 
2025-07-12 12:03:35.675618: PTB_all_energies_1mm_no_background_0716, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.722521: predicting PTB_all_energies_1mm_no_background_0717 
2025-07-12 12:03:35.728804: PTB_all_energies_1mm_no_background_0717, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.774790: predicting PTB_all_energies_1mm_no_background_0719 
2025-07-12 12:03:35.781575: PTB_all_energies_1mm_no_background_0719, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.829475: predicting PTB_all_energies_1mm_no_background_0721 
2025-07-12 12:03:35.836146: PTB_all_energies_1mm_no_background_0721, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.882775: predicting PTB_all_energies_1mm_no_background_0729 
2025-07-12 12:03:35.889334: PTB_all_energies_1mm_no_background_0729, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.940437: predicting PTB_all_energies_1mm_no_background_0734 
2025-07-12 12:03:35.947526: PTB_all_energies_1mm_no_background_0734, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:35.994817: predicting PTB_all_energies_1mm_no_background_0736 
2025-07-12 12:03:36.002733: PTB_all_energies_1mm_no_background_0736, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.050399: predicting PTB_all_energies_1mm_no_background_0737 
2025-07-12 12:03:36.057943: PTB_all_energies_1mm_no_background_0737, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.108627: predicting PTB_all_energies_1mm_no_background_0751 
2025-07-12 12:03:36.115960: PTB_all_energies_1mm_no_background_0751, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.162690: predicting PTB_all_energies_1mm_no_background_0754 
2025-07-12 12:03:36.169712: PTB_all_energies_1mm_no_background_0754, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.216487: predicting PTB_all_energies_1mm_no_background_0769 
2025-07-12 12:03:36.223497: PTB_all_energies_1mm_no_background_0769, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.270573: predicting PTB_all_energies_1mm_no_background_0771 
2025-07-12 12:03:36.277617: PTB_all_energies_1mm_no_background_0771, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.324486: predicting PTB_all_energies_1mm_no_background_0778 
2025-07-12 12:03:36.330965: PTB_all_energies_1mm_no_background_0778, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.380620: predicting PTB_all_energies_1mm_no_background_0785 
2025-07-12 12:03:36.387698: PTB_all_energies_1mm_no_background_0785, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.434799: predicting PTB_all_energies_1mm_no_background_0786 
2025-07-12 12:03:36.442793: PTB_all_energies_1mm_no_background_0786, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.491101: predicting PTB_all_energies_1mm_no_background_0787 
2025-07-12 12:03:36.498463: PTB_all_energies_1mm_no_background_0787, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.550235: predicting PTB_all_energies_1mm_no_background_0793 
2025-07-12 12:03:36.558233: PTB_all_energies_1mm_no_background_0793, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.604776: predicting PTB_all_energies_1mm_no_background_0795 
2025-07-12 12:03:36.612026: PTB_all_energies_1mm_no_background_0795, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.658332: predicting PTB_all_energies_1mm_no_background_0797 
2025-07-12 12:03:36.665211: PTB_all_energies_1mm_no_background_0797, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.712498: predicting PTB_all_energies_1mm_no_background_0799 
2025-07-12 12:03:36.719669: PTB_all_energies_1mm_no_background_0799, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.766248: predicting PTB_all_energies_1mm_no_background_0800 
2025-07-12 12:03:36.773730: PTB_all_energies_1mm_no_background_0800, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.823510: predicting PTB_all_energies_1mm_no_background_0805 
2025-07-12 12:03:36.831139: PTB_all_energies_1mm_no_background_0805, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.879387: predicting PTB_all_energies_1mm_no_background_0810 
2025-07-12 12:03:36.887949: PTB_all_energies_1mm_no_background_0810, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.936408: predicting PTB_all_energies_1mm_no_background_0811 
2025-07-12 12:03:36.946502: PTB_all_energies_1mm_no_background_0811, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:36.996443: predicting PTB_all_energies_1mm_no_background_0812 
2025-07-12 12:03:37.003619: PTB_all_energies_1mm_no_background_0812, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.050815: predicting PTB_all_energies_1mm_no_background_0815 
2025-07-12 12:03:37.057378: PTB_all_energies_1mm_no_background_0815, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.103904: predicting PTB_all_energies_1mm_no_background_0820 
2025-07-12 12:03:37.110849: PTB_all_energies_1mm_no_background_0820, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.159359: predicting PTB_all_energies_1mm_no_background_0821 
2025-07-12 12:03:37.165945: PTB_all_energies_1mm_no_background_0821, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.212547: predicting PTB_all_energies_1mm_no_background_0828 
2025-07-12 12:03:37.219733: PTB_all_energies_1mm_no_background_0828, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.269801: predicting PTB_all_energies_1mm_no_background_0831 
2025-07-12 12:03:37.276764: PTB_all_energies_1mm_no_background_0831, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.325936: predicting PTB_all_energies_1mm_no_background_0838 
2025-07-12 12:03:37.333683: PTB_all_energies_1mm_no_background_0838, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.382502: predicting PTB_all_energies_1mm_no_background_0844 
2025-07-12 12:03:37.389233: PTB_all_energies_1mm_no_background_0844, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.440934: predicting PTB_all_energies_1mm_no_background_0847 
2025-07-12 12:03:37.448723: PTB_all_energies_1mm_no_background_0847, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.496176: predicting PTB_all_energies_1mm_no_background_0848 
2025-07-12 12:03:37.502976: PTB_all_energies_1mm_no_background_0848, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.549136: predicting PTB_all_energies_1mm_no_background_0849 
2025-07-12 12:03:37.556608: PTB_all_energies_1mm_no_background_0849, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.608244: predicting PTB_all_energies_1mm_no_background_0853 
2025-07-12 12:03:37.615834: PTB_all_energies_1mm_no_background_0853, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.663208: predicting PTB_all_energies_1mm_no_background_0855 
2025-07-12 12:03:37.671296: PTB_all_energies_1mm_no_background_0855, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.721382: predicting PTB_all_energies_1mm_no_background_0858 
2025-07-12 12:03:37.728390: PTB_all_energies_1mm_no_background_0858, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.776531: predicting PTB_all_energies_1mm_no_background_0864 
2025-07-12 12:03:37.783659: PTB_all_energies_1mm_no_background_0864, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.831243: predicting PTB_all_energies_1mm_no_background_0870 
2025-07-12 12:03:37.839052: PTB_all_energies_1mm_no_background_0870, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.889704: predicting PTB_all_energies_1mm_no_background_0878 
2025-07-12 12:03:37.897079: PTB_all_energies_1mm_no_background_0878, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.944308: predicting PTB_all_energies_1mm_no_background_0879 
2025-07-12 12:03:37.951961: PTB_all_energies_1mm_no_background_0879, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:37.998417: predicting PTB_all_energies_1mm_no_background_0904 
2025-07-12 12:03:38.005942: PTB_all_energies_1mm_no_background_0904, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.053240: predicting PTB_all_energies_1mm_no_background_0920 
2025-07-12 12:03:38.060009: PTB_all_energies_1mm_no_background_0920, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.106867: predicting PTB_all_energies_1mm_no_background_0926 
2025-07-12 12:03:38.114007: PTB_all_energies_1mm_no_background_0926, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.163552: predicting PTB_all_energies_1mm_no_background_0929 
2025-07-12 12:03:38.171602: PTB_all_energies_1mm_no_background_0929, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.218333: predicting PTB_all_energies_1mm_no_background_0933 
2025-07-12 12:03:38.224960: PTB_all_energies_1mm_no_background_0933, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.272456: predicting PTB_all_energies_1mm_no_background_0939 
2025-07-12 12:03:38.279366: PTB_all_energies_1mm_no_background_0939, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.327246: predicting PTB_all_energies_1mm_no_background_0940 
2025-07-12 12:03:38.333932: PTB_all_energies_1mm_no_background_0940, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.381113: predicting PTB_all_energies_1mm_no_background_0943 
2025-07-12 12:03:38.388035: PTB_all_energies_1mm_no_background_0943, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.434391: predicting PTB_all_energies_1mm_no_background_0957 
2025-07-12 12:03:38.441656: PTB_all_energies_1mm_no_background_0957, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.489240: predicting PTB_all_energies_1mm_no_background_0962 
2025-07-12 12:03:38.496020: PTB_all_energies_1mm_no_background_0962, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.542263: predicting PTB_all_energies_1mm_no_background_0964 
2025-07-12 12:03:38.549814: PTB_all_energies_1mm_no_background_0964, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.598978: predicting PTB_all_energies_1mm_no_background_0975 
2025-07-12 12:03:38.605650: PTB_all_energies_1mm_no_background_0975, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.652102: predicting PTB_all_energies_1mm_no_background_0977 
2025-07-12 12:03:38.659210: PTB_all_energies_1mm_no_background_0977, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.706453: predicting PTB_all_energies_1mm_no_background_0981 
2025-07-12 12:03:38.713300: PTB_all_energies_1mm_no_background_0981, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.760952: predicting PTB_all_energies_1mm_no_background_0992 
2025-07-12 12:03:38.768815: PTB_all_energies_1mm_no_background_0992, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.816490: predicting PTB_all_energies_1mm_no_background_0995 
2025-07-12 12:03:38.823407: PTB_all_energies_1mm_no_background_0995, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.871207: predicting PTB_all_energies_1mm_no_background_0997 
2025-07-12 12:03:38.877763: PTB_all_energies_1mm_no_background_0997, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.924975: predicting PTB_all_energies_1mm_no_background_1000 
2025-07-12 12:03:38.931891: PTB_all_energies_1mm_no_background_1000, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:38.978271: predicting PTB_all_energies_1mm_no_background_1001 
2025-07-12 12:03:38.984976: PTB_all_energies_1mm_no_background_1001, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.035614: predicting PTB_all_energies_1mm_no_background_1003 
2025-07-12 12:03:39.042307: PTB_all_energies_1mm_no_background_1003, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.091289: predicting PTB_all_energies_1mm_no_background_1004 
2025-07-12 12:03:39.098186: PTB_all_energies_1mm_no_background_1004, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.168242: predicting PTB_all_energies_1mm_no_background_1011 
2025-07-12 12:03:39.176034: PTB_all_energies_1mm_no_background_1011, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.240836: predicting PTB_all_energies_1mm_no_background_1021 
2025-07-12 12:03:39.247926: PTB_all_energies_1mm_no_background_1021, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.296268: predicting PTB_all_energies_1mm_no_background_1023 
2025-07-12 12:03:39.303250: PTB_all_energies_1mm_no_background_1023, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.349518: predicting PTB_all_energies_1mm_no_background_1031 
2025-07-12 12:03:39.356806: PTB_all_energies_1mm_no_background_1031, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.404310: predicting PTB_all_energies_1mm_no_background_1035 
2025-07-12 12:03:39.411614: PTB_all_energies_1mm_no_background_1035, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.458179: predicting PTB_all_energies_1mm_no_background_1036 
2025-07-12 12:03:39.466338: PTB_all_energies_1mm_no_background_1036, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.515040: predicting PTB_all_energies_1mm_no_background_1045 
2025-07-12 12:03:39.522959: PTB_all_energies_1mm_no_background_1045, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.572031: predicting PTB_all_energies_1mm_no_background_1047 
2025-07-12 12:03:39.579171: PTB_all_energies_1mm_no_background_1047, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.649212: predicting PTB_all_energies_1mm_no_background_1048 
2025-07-12 12:03:39.657189: PTB_all_energies_1mm_no_background_1048, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.722676: predicting PTB_all_energies_1mm_no_background_1050 
2025-07-12 12:03:39.729941: PTB_all_energies_1mm_no_background_1050, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.779528: predicting PTB_all_energies_1mm_no_background_1055 
2025-07-12 12:03:39.786376: PTB_all_energies_1mm_no_background_1055, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.832796: predicting PTB_all_energies_1mm_no_background_1056 
2025-07-12 12:03:39.840397: PTB_all_energies_1mm_no_background_1056, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.887727: predicting PTB_all_energies_1mm_no_background_1060 
2025-07-12 12:03:39.894992: PTB_all_energies_1mm_no_background_1060, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.941442: predicting PTB_all_energies_1mm_no_background_1066 
2025-07-12 12:03:39.948467: PTB_all_energies_1mm_no_background_1066, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:39.997791: predicting PTB_all_energies_1mm_no_background_1069 
2025-07-12 12:03:40.005308: PTB_all_energies_1mm_no_background_1069, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.053442: predicting PTB_all_energies_1mm_no_background_1073 
2025-07-12 12:03:40.063360: PTB_all_energies_1mm_no_background_1073, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.133939: predicting PTB_all_energies_1mm_no_background_1077 
2025-07-12 12:03:40.144840: PTB_all_energies_1mm_no_background_1077, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.207545: predicting PTB_all_energies_1mm_no_background_1087 
2025-07-12 12:03:40.214690: PTB_all_energies_1mm_no_background_1087, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.264836: predicting PTB_all_energies_1mm_no_background_1093 
2025-07-12 12:03:40.271601: PTB_all_energies_1mm_no_background_1093, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.317718: predicting PTB_all_energies_1mm_no_background_1096 
2025-07-12 12:03:40.325187: PTB_all_energies_1mm_no_background_1096, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.372329: predicting PTB_all_energies_1mm_no_background_1099 
2025-07-12 12:03:40.379729: PTB_all_energies_1mm_no_background_1099, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.426346: predicting PTB_all_energies_1mm_no_background_1100 
2025-07-12 12:03:40.434789: PTB_all_energies_1mm_no_background_1100, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.484045: predicting PTB_all_energies_1mm_no_background_1105 
2025-07-12 12:03:40.491626: PTB_all_energies_1mm_no_background_1105, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.539911: predicting PTB_all_energies_1mm_no_background_1114 
2025-07-12 12:03:40.547730: PTB_all_energies_1mm_no_background_1114, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.617982: predicting PTB_all_energies_1mm_no_background_1119 
2025-07-12 12:03:40.626114: PTB_all_energies_1mm_no_background_1119, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.683359: predicting PTB_all_energies_1mm_no_background_1135 
2025-07-12 12:03:40.690714: PTB_all_energies_1mm_no_background_1135, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.737949: predicting PTB_all_energies_1mm_no_background_1144 
2025-07-12 12:03:40.746192: PTB_all_energies_1mm_no_background_1144, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.792813: predicting PTB_all_energies_1mm_no_background_1154 
2025-07-12 12:03:40.800047: PTB_all_energies_1mm_no_background_1154, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.850801: predicting PTB_all_energies_1mm_no_background_1175 
2025-07-12 12:03:40.857622: PTB_all_energies_1mm_no_background_1175, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.903620: predicting PTB_all_energies_1mm_no_background_1178 
2025-07-12 12:03:40.911733: PTB_all_energies_1mm_no_background_1178, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:40.960871: predicting PTB_all_energies_1mm_no_background_1188 
2025-07-12 12:03:40.967880: PTB_all_energies_1mm_no_background_1188, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.017526: predicting PTB_all_energies_1mm_no_background_1197 
2025-07-12 12:03:41.024513: PTB_all_energies_1mm_no_background_1197, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.074406: predicting PTB_all_energies_1mm_no_background_1206 
2025-07-12 12:03:41.081601: PTB_all_energies_1mm_no_background_1206, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.131465: predicting PTB_all_energies_1mm_no_background_1208 
2025-07-12 12:03:41.138335: PTB_all_energies_1mm_no_background_1208, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.185547: predicting PTB_all_energies_1mm_no_background_1215 
2025-07-12 12:03:41.195068: PTB_all_energies_1mm_no_background_1215, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.241544: predicting PTB_all_energies_1mm_no_background_1219 
2025-07-12 12:03:41.248666: PTB_all_energies_1mm_no_background_1219, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.298323: predicting PTB_all_energies_1mm_no_background_1223 
2025-07-12 12:03:41.305386: PTB_all_energies_1mm_no_background_1223, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.351557: predicting PTB_all_energies_1mm_no_background_1231 
2025-07-12 12:03:41.360362: PTB_all_energies_1mm_no_background_1231, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.409006: predicting PTB_all_energies_1mm_no_background_1237 
2025-07-12 12:03:41.417264: PTB_all_energies_1mm_no_background_1237, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.466965: predicting PTB_all_energies_1mm_no_background_1251 
2025-07-12 12:03:41.473496: PTB_all_energies_1mm_no_background_1251, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.524447: predicting PTB_all_energies_1mm_no_background_1260 
2025-07-12 12:03:41.531671: PTB_all_energies_1mm_no_background_1260, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.581955: predicting PTB_all_energies_1mm_no_background_1277 
2025-07-12 12:03:41.589092: PTB_all_energies_1mm_no_background_1277, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.636338: predicting PTB_all_energies_1mm_no_background_1279 
2025-07-12 12:03:41.643907: PTB_all_energies_1mm_no_background_1279, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.691002: predicting PTB_all_energies_1mm_no_background_1283 
2025-07-12 12:03:41.697800: PTB_all_energies_1mm_no_background_1283, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.747630: predicting PTB_all_energies_1mm_no_background_1287 
2025-07-12 12:03:41.754389: PTB_all_energies_1mm_no_background_1287, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.800653: predicting PTB_all_energies_1mm_no_background_1292 
2025-07-12 12:03:41.807298: PTB_all_energies_1mm_no_background_1292, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.860117: predicting PTB_all_energies_1mm_no_background_1294 
2025-07-12 12:03:41.867647: PTB_all_energies_1mm_no_background_1294, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.916404: predicting PTB_all_energies_1mm_no_background_1298 
2025-07-12 12:03:41.922705: PTB_all_energies_1mm_no_background_1298, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:41.973352: predicting PTB_all_energies_1mm_no_background_1311 
2025-07-12 12:03:41.980897: PTB_all_energies_1mm_no_background_1311, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.030929: predicting PTB_all_energies_1mm_no_background_1315 
2025-07-12 12:03:42.038255: PTB_all_energies_1mm_no_background_1315, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.085365: predicting PTB_all_energies_1mm_no_background_1317 
2025-07-12 12:03:42.092795: PTB_all_energies_1mm_no_background_1317, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.139284: predicting PTB_all_energies_1mm_no_background_1321 
2025-07-12 12:03:42.146670: PTB_all_energies_1mm_no_background_1321, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.196841: predicting PTB_all_energies_1mm_no_background_1325 
2025-07-12 12:03:42.203950: PTB_all_energies_1mm_no_background_1325, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.250100: predicting PTB_all_energies_1mm_no_background_1329 
2025-07-12 12:03:42.257023: PTB_all_energies_1mm_no_background_1329, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.306917: predicting PTB_all_energies_1mm_no_background_1336 
2025-07-12 12:03:42.314169: PTB_all_energies_1mm_no_background_1336, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.363824: predicting PTB_all_energies_1mm_no_background_1339 
2025-07-12 12:03:42.370314: PTB_all_energies_1mm_no_background_1339, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.419974: predicting PTB_all_energies_1mm_no_background_1346 
2025-07-12 12:03:42.428980: PTB_all_energies_1mm_no_background_1346, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.478406: predicting PTB_all_energies_1mm_no_background_1347 
2025-07-12 12:03:42.485330: PTB_all_energies_1mm_no_background_1347, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.533545: predicting PTB_all_energies_1mm_no_background_1348 
2025-07-12 12:03:42.540748: PTB_all_energies_1mm_no_background_1348, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.587287: predicting PTB_all_energies_1mm_no_background_1351 
2025-07-12 12:03:42.594368: PTB_all_energies_1mm_no_background_1351, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.644504: predicting PTB_all_energies_1mm_no_background_1354 
2025-07-12 12:03:42.651352: PTB_all_energies_1mm_no_background_1354, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.698669: predicting PTB_all_energies_1mm_no_background_1356 
2025-07-12 12:03:42.705862: PTB_all_energies_1mm_no_background_1356, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.755451: predicting PTB_all_energies_1mm_no_background_1370 
2025-07-12 12:03:42.762868: PTB_all_energies_1mm_no_background_1370, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.812359: predicting PTB_all_energies_1mm_no_background_1371 
2025-07-12 12:03:42.818839: PTB_all_energies_1mm_no_background_1371, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.868705: predicting PTB_all_energies_1mm_no_background_1372 
2025-07-12 12:03:42.875578: PTB_all_energies_1mm_no_background_1372, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.926102: predicting PTB_all_energies_1mm_no_background_1380 
2025-07-12 12:03:42.933260: PTB_all_energies_1mm_no_background_1380, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:42.980597: predicting PTB_all_energies_1mm_no_background_1381 
2025-07-12 12:03:42.987518: PTB_all_energies_1mm_no_background_1381, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.033889: predicting PTB_all_energies_1mm_no_background_1395 
2025-07-12 12:03:43.040995: PTB_all_energies_1mm_no_background_1395, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.090945: predicting PTB_all_energies_1mm_no_background_1402 
2025-07-12 12:03:43.098411: PTB_all_energies_1mm_no_background_1402, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.144826: predicting PTB_all_energies_1mm_no_background_1405 
2025-07-12 12:03:43.152354: PTB_all_energies_1mm_no_background_1405, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.201789: predicting PTB_all_energies_1mm_no_background_1412 
2025-07-12 12:03:43.208936: PTB_all_energies_1mm_no_background_1412, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.257840: predicting PTB_all_energies_1mm_no_background_1413 
2025-07-12 12:03:43.265219: PTB_all_energies_1mm_no_background_1413, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.314151: predicting PTB_all_energies_1mm_no_background_1415 
2025-07-12 12:03:43.321482: PTB_all_energies_1mm_no_background_1415, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.372191: predicting PTB_all_energies_1mm_no_background_1420 
2025-07-12 12:03:43.380168: PTB_all_energies_1mm_no_background_1420, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.427211: predicting PTB_all_energies_1mm_no_background_1422 
2025-07-12 12:03:43.435042: PTB_all_energies_1mm_no_background_1422, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.481485: predicting PTB_all_energies_1mm_no_background_1428 
2025-07-12 12:03:43.488448: PTB_all_energies_1mm_no_background_1428, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.538429: predicting PTB_all_energies_1mm_no_background_1433 
2025-07-12 12:03:43.545216: PTB_all_energies_1mm_no_background_1433, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.591403: predicting PTB_all_energies_1mm_no_background_1434 
2025-07-12 12:03:43.599025: PTB_all_energies_1mm_no_background_1434, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.648229: predicting PTB_all_energies_1mm_no_background_1441 
2025-07-12 12:03:43.654984: PTB_all_energies_1mm_no_background_1441, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.704072: predicting PTB_all_energies_1mm_no_background_1446 
2025-07-12 12:03:43.711277: PTB_all_energies_1mm_no_background_1446, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.760448: predicting PTB_all_energies_1mm_no_background_1448 
2025-07-12 12:03:43.767759: PTB_all_energies_1mm_no_background_1448, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.818581: predicting PTB_all_energies_1mm_no_background_1452 
2025-07-12 12:03:43.825407: PTB_all_energies_1mm_no_background_1452, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.872405: predicting PTB_all_energies_1mm_no_background_1460 
2025-07-12 12:03:43.881301: PTB_all_energies_1mm_no_background_1460, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.928309: predicting PTB_all_energies_1mm_no_background_1465 
2025-07-12 12:03:43.936344: PTB_all_energies_1mm_no_background_1465, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:43.985648: predicting PTB_all_energies_1mm_no_background_1478 
2025-07-12 12:03:43.992982: PTB_all_energies_1mm_no_background_1478, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.039377: predicting PTB_all_energies_1mm_no_background_1482 
2025-07-12 12:03:44.046089: PTB_all_energies_1mm_no_background_1482, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.095984: predicting PTB_all_energies_1mm_no_background_1483 
2025-07-12 12:03:44.103630: PTB_all_energies_1mm_no_background_1483, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.152332: predicting PTB_all_energies_1mm_no_background_1487 
2025-07-12 12:03:44.158957: PTB_all_energies_1mm_no_background_1487, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.209061: predicting PTB_all_energies_1mm_no_background_1490 
2025-07-12 12:03:44.217421: PTB_all_energies_1mm_no_background_1490, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.267946: predicting PTB_all_energies_1mm_no_background_1495 
2025-07-12 12:03:44.275288: PTB_all_energies_1mm_no_background_1495, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.323356: predicting PTB_all_energies_1mm_no_background_1502 
2025-07-12 12:03:44.331175: PTB_all_energies_1mm_no_background_1502, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.377952: predicting PTB_all_energies_1mm_no_background_1506 
2025-07-12 12:03:44.386204: PTB_all_energies_1mm_no_background_1506, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.435441: predicting PTB_all_energies_1mm_no_background_1508 
2025-07-12 12:03:44.442736: PTB_all_energies_1mm_no_background_1508, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.489204: predicting PTB_all_energies_1mm_no_background_1514 
2025-07-12 12:03:44.496083: PTB_all_energies_1mm_no_background_1514, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.545436: predicting PTB_all_energies_1mm_no_background_1516 
2025-07-12 12:03:44.552521: PTB_all_energies_1mm_no_background_1516, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.601494: predicting PTB_all_energies_1mm_no_background_1523 
2025-07-12 12:03:44.608646: PTB_all_energies_1mm_no_background_1523, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.658940: predicting PTB_all_energies_1mm_no_background_1529 
2025-07-12 12:03:44.665990: PTB_all_energies_1mm_no_background_1529, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.715988: predicting PTB_all_energies_1mm_no_background_1538 
2025-07-12 12:03:44.722677: PTB_all_energies_1mm_no_background_1538, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.769985: predicting PTB_all_energies_1mm_no_background_1540 
2025-07-12 12:03:44.776883: PTB_all_energies_1mm_no_background_1540, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.824834: predicting PTB_all_energies_1mm_no_background_1545 
2025-07-12 12:03:44.832011: PTB_all_energies_1mm_no_background_1545, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.882416: predicting PTB_all_energies_1mm_no_background_1546 
2025-07-12 12:03:44.889339: PTB_all_energies_1mm_no_background_1546, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.935833: predicting PTB_all_energies_1mm_no_background_1547 
2025-07-12 12:03:44.943085: PTB_all_energies_1mm_no_background_1547, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:44.992739: predicting PTB_all_energies_1mm_no_background_1552 
2025-07-12 12:03:44.999919: PTB_all_energies_1mm_no_background_1552, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.048718: predicting PTB_all_energies_1mm_no_background_1554 
2025-07-12 12:03:45.055712: PTB_all_energies_1mm_no_background_1554, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.105713: predicting PTB_all_energies_1mm_no_background_1556 
2025-07-12 12:03:45.112869: PTB_all_energies_1mm_no_background_1556, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.162806: predicting PTB_all_energies_1mm_no_background_1558 
2025-07-12 12:03:45.170395: PTB_all_energies_1mm_no_background_1558, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.217761: predicting PTB_all_energies_1mm_no_background_1562 
2025-07-12 12:03:45.225184: PTB_all_energies_1mm_no_background_1562, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.271543: predicting PTB_all_energies_1mm_no_background_1563 
2025-07-12 12:03:45.279305: PTB_all_energies_1mm_no_background_1563, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.328545: predicting PTB_all_energies_1mm_no_background_1564 
2025-07-12 12:03:45.336728: PTB_all_energies_1mm_no_background_1564, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.384479: predicting PTB_all_energies_1mm_no_background_1568 
2025-07-12 12:03:45.392918: PTB_all_energies_1mm_no_background_1568, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.442264: predicting PTB_all_energies_1mm_no_background_1569 
2025-07-12 12:03:45.449394: PTB_all_energies_1mm_no_background_1569, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.499427: predicting PTB_all_energies_1mm_no_background_1578 
2025-07-12 12:03:45.506520: PTB_all_energies_1mm_no_background_1578, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.555698: predicting PTB_all_energies_1mm_no_background_1583 
2025-07-12 12:03:45.563588: PTB_all_energies_1mm_no_background_1583, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.613248: predicting PTB_all_energies_1mm_no_background_1603 
2025-07-12 12:03:45.620506: PTB_all_energies_1mm_no_background_1603, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.667915: predicting PTB_all_energies_1mm_no_background_1608 
2025-07-12 12:03:45.675442: PTB_all_energies_1mm_no_background_1608, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.721967: predicting PTB_all_energies_1mm_no_background_1635 
2025-07-12 12:03:45.730242: PTB_all_energies_1mm_no_background_1635, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.779032: predicting PTB_all_energies_1mm_no_background_1637 
2025-07-12 12:03:45.786472: PTB_all_energies_1mm_no_background_1637, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.834886: predicting PTB_all_energies_1mm_no_background_1640 
2025-07-12 12:03:45.841890: PTB_all_energies_1mm_no_background_1640, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.891425: predicting PTB_all_energies_1mm_no_background_1647 
2025-07-12 12:03:45.899192: PTB_all_energies_1mm_no_background_1647, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:45.947482: predicting PTB_all_energies_1mm_no_background_1651 
2025-07-12 12:03:45.955282: PTB_all_energies_1mm_no_background_1651, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.004639: predicting PTB_all_energies_1mm_no_background_1655 
2025-07-12 12:03:46.011711: PTB_all_energies_1mm_no_background_1655, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.063141: predicting PTB_all_energies_1mm_no_background_1656 
2025-07-12 12:03:46.070223: PTB_all_energies_1mm_no_background_1656, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.119428: predicting PTB_all_energies_1mm_no_background_1659 
2025-07-12 12:03:46.126865: PTB_all_energies_1mm_no_background_1659, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.174464: predicting PTB_all_energies_1mm_no_background_1660 
2025-07-12 12:03:46.182479: PTB_all_energies_1mm_no_background_1660, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.232582: predicting PTB_all_energies_1mm_no_background_1664 
2025-07-12 12:03:46.239811: PTB_all_energies_1mm_no_background_1664, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.286879: predicting PTB_all_energies_1mm_no_background_1666 
2025-07-12 12:03:46.293515: PTB_all_energies_1mm_no_background_1666, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.343384: predicting PTB_all_energies_1mm_no_background_1668 
2025-07-12 12:03:46.350540: PTB_all_energies_1mm_no_background_1668, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.400660: predicting PTB_all_energies_1mm_no_background_1672 
2025-07-12 12:03:46.407161: PTB_all_energies_1mm_no_background_1672, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.457403: predicting PTB_all_energies_1mm_no_background_1673 
2025-07-12 12:03:46.464731: PTB_all_energies_1mm_no_background_1673, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.514854: predicting PTB_all_energies_1mm_no_background_1685 
2025-07-12 12:03:46.522209: PTB_all_energies_1mm_no_background_1685, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.570135: predicting PTB_all_energies_1mm_no_background_1686 
2025-07-12 12:03:46.577029: PTB_all_energies_1mm_no_background_1686, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.623619: predicting PTB_all_energies_1mm_no_background_1696 
2025-07-12 12:03:46.630716: PTB_all_energies_1mm_no_background_1696, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.680833: predicting PTB_all_energies_1mm_no_background_1697 
2025-07-12 12:03:46.687655: PTB_all_energies_1mm_no_background_1697, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.734163: predicting PTB_all_energies_1mm_no_background_1698 
2025-07-12 12:03:46.742594: PTB_all_energies_1mm_no_background_1698, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.791879: predicting PTB_all_energies_1mm_no_background_1699 
2025-07-12 12:03:46.799953: PTB_all_energies_1mm_no_background_1699, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.848452: predicting PTB_all_energies_1mm_no_background_1704 
2025-07-12 12:03:46.855723: PTB_all_energies_1mm_no_background_1704, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.905532: predicting PTB_all_energies_1mm_no_background_1705 
2025-07-12 12:03:46.912298: PTB_all_energies_1mm_no_background_1705, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:46.963182: predicting PTB_all_energies_1mm_no_background_1707 
2025-07-12 12:03:46.970677: PTB_all_energies_1mm_no_background_1707, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.018268: predicting PTB_all_energies_1mm_no_background_1715 
2025-07-12 12:03:47.026128: PTB_all_energies_1mm_no_background_1715, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.073089: predicting PTB_all_energies_1mm_no_background_1729 
2025-07-12 12:03:47.079904: PTB_all_energies_1mm_no_background_1729, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.129591: predicting PTB_all_energies_1mm_no_background_1732 
2025-07-12 12:03:47.136510: PTB_all_energies_1mm_no_background_1732, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.182863: predicting PTB_all_energies_1mm_no_background_1738 
2025-07-12 12:03:47.190270: PTB_all_energies_1mm_no_background_1738, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.240537: predicting PTB_all_energies_1mm_no_background_1749 
2025-07-12 12:03:47.249593: PTB_all_energies_1mm_no_background_1749, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.297525: predicting PTB_all_energies_1mm_no_background_1762 
2025-07-12 12:03:47.304799: PTB_all_energies_1mm_no_background_1762, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.355287: predicting PTB_all_energies_1mm_no_background_1768 
2025-07-12 12:03:47.361886: PTB_all_energies_1mm_no_background_1768, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.413090: predicting PTB_all_energies_1mm_no_background_1773 
2025-07-12 12:03:47.420321: PTB_all_energies_1mm_no_background_1773, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.468142: predicting PTB_all_energies_1mm_no_background_1775 
2025-07-12 12:03:47.475073: PTB_all_energies_1mm_no_background_1775, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.521833: predicting PTB_all_energies_1mm_no_background_1776 
2025-07-12 12:03:47.529292: PTB_all_energies_1mm_no_background_1776, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.578829: predicting PTB_all_energies_1mm_no_background_1781 
2025-07-12 12:03:47.585449: PTB_all_energies_1mm_no_background_1781, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.631555: predicting PTB_all_energies_1mm_no_background_1793 
2025-07-12 12:03:47.638633: PTB_all_energies_1mm_no_background_1793, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:47.688103: predicting PTB_all_energies_1mm_no_background_1794 
2025-07-12 12:03:47.695651: PTB_all_energies_1mm_no_background_1794, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:03:52.912506: Validation complete 
2025-07-12 12:03:52.914090: Mean Validation Dice:  0.9420512862311742 
