
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-11 16:32:18.600059: Using torch.compile... 
2025-07-11 16:32:19.768018: do_dummy_2d_data_aug: False 
2025-07-11 16:32:19.772723: Using splits from existing split file: /data/nnUNet_preprocessed/Dataset010_PTB_all_energies_1mm_no_background_alldata/splits_final.json 
2025-07-11 16:32:19.776310: The split file contains 5 splits. 
2025-07-11 16:32:19.777570: Desired fold for training: 4 
2025-07-11 16:32:19.779123: This split has 1440 training and 360 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 35, 'patch_size': [512, 512], 'median_image_size_in_voxels': [504.0, 504.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_PTB_all_energies_1mm_no_background_alldata', 'plans_name': 'nnUNetResEncUNetPlans_24G', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 504, 504], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 4282.0, 'mean': 1593.7022300557526, 'median': 1568.0, 'min': 0.0, 'percentile_00_5': 982.0, 'percentile_99_5': 2808.0, 'std': 337.91142407822184}}} 
 
2025-07-11 16:32:23.056515: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-11 16:32:23.106928:  
2025-07-11 16:32:23.117421: Epoch 0 
2025-07-11 16:32:23.128685: Current learning rate: 0.01 
2025-07-11 16:33:49.646035: train_loss -0.0186 
2025-07-11 16:33:49.648445: val_loss -0.3832 
2025-07-11 16:33:49.651301: Pseudo dice [np.float32(0.2709)] 
2025-07-11 16:33:49.653648: Epoch time: 86.55 s 
2025-07-11 16:33:49.655482: Yayy! New best EMA pseudo Dice: 0.27090001106262207 
2025-07-11 16:33:51.690283:  
2025-07-11 16:33:51.692013: Epoch 1 
2025-07-11 16:33:51.693499: Current learning rate: 0.00999 
2025-07-11 16:34:59.600664: train_loss -0.6967 
2025-07-11 16:34:59.603178: val_loss -0.8175 
2025-07-11 16:34:59.605178: Pseudo dice [np.float32(0.8545)] 
2025-07-11 16:34:59.606414: Epoch time: 67.91 s 
2025-07-11 16:34:59.608155: Yayy! New best EMA pseudo Dice: 0.3292999863624573 
2025-07-11 16:35:01.808503:  
2025-07-11 16:35:01.810417: Epoch 2 
2025-07-11 16:35:01.811657: Current learning rate: 0.00998 
2025-07-11 16:36:10.126401: train_loss -0.843 
2025-07-11 16:36:10.127823: val_loss -0.8641 
2025-07-11 16:36:10.128915: Pseudo dice [np.float32(0.8993)] 
2025-07-11 16:36:10.130934: Epoch time: 68.32 s 
2025-07-11 16:36:10.132077: Yayy! New best EMA pseudo Dice: 0.3862999975681305 
2025-07-11 16:36:12.326515:  
2025-07-11 16:36:12.328459: Epoch 3 
2025-07-11 16:36:12.329623: Current learning rate: 0.00997 
2025-07-11 16:37:20.300654: train_loss -0.8728 
2025-07-11 16:37:20.307349: val_loss -0.8763 
2025-07-11 16:37:20.309387: Pseudo dice [np.float32(0.9069)] 
2025-07-11 16:37:20.310477: Epoch time: 67.98 s 
2025-07-11 16:37:20.311525: Yayy! New best EMA pseudo Dice: 0.438400000333786 
2025-07-11 16:37:22.359910:  
2025-07-11 16:37:22.362293: Epoch 4 
2025-07-11 16:37:22.363851: Current learning rate: 0.00996 
2025-07-11 16:38:30.378555: train_loss -0.8896 
2025-07-11 16:38:30.379905: val_loss -0.8908 
2025-07-11 16:38:30.381285: Pseudo dice [np.float32(0.9144)] 
2025-07-11 16:38:30.382313: Epoch time: 68.02 s 
2025-07-11 16:38:30.383376: Yayy! New best EMA pseudo Dice: 0.4860000014305115 
2025-07-11 16:38:32.597814:  
2025-07-11 16:38:32.599705: Epoch 5 
2025-07-11 16:38:32.600962: Current learning rate: 0.00995 
2025-07-11 16:39:40.783274: train_loss -0.9018 
2025-07-11 16:39:40.784834: val_loss -0.9019 
2025-07-11 16:39:40.786190: Pseudo dice [np.float32(0.9226)] 
2025-07-11 16:39:40.787327: Epoch time: 68.19 s 
2025-07-11 16:39:40.788815: Yayy! New best EMA pseudo Dice: 0.5296000242233276 
2025-07-11 16:39:42.987889:  
2025-07-11 16:39:42.989801: Epoch 6 
2025-07-11 16:39:42.991092: Current learning rate: 0.00995 
2025-07-11 16:40:51.011338: train_loss -0.9081 
2025-07-11 16:40:51.012508: val_loss -0.9058 
2025-07-11 16:40:51.013525: Pseudo dice [np.float32(0.9254)] 
2025-07-11 16:40:51.014516: Epoch time: 68.03 s 
2025-07-11 16:40:51.015764: Yayy! New best EMA pseudo Dice: 0.5691999793052673 
2025-07-11 16:40:53.280477:  
2025-07-11 16:40:53.282463: Epoch 7 
2025-07-11 16:40:53.283668: Current learning rate: 0.00994 
2025-07-11 16:42:01.158854: train_loss -0.9134 
2025-07-11 16:42:01.160244: val_loss -0.9076 
2025-07-11 16:42:01.161528: Pseudo dice [np.float32(0.9249)] 
2025-07-11 16:42:01.162811: Epoch time: 67.88 s 
2025-07-11 16:42:01.164116: Yayy! New best EMA pseudo Dice: 0.6047999858856201 
2025-07-11 16:42:03.441147:  
2025-07-11 16:42:03.442632: Epoch 8 
2025-07-11 16:42:03.443685: Current learning rate: 0.00993 
2025-07-11 16:43:11.722959: train_loss -0.9155 
2025-07-11 16:43:11.724368: val_loss -0.9125 
2025-07-11 16:43:11.725716: Pseudo dice [np.float32(0.929)] 
2025-07-11 16:43:11.727565: Epoch time: 68.29 s 
2025-07-11 16:43:11.728922: Yayy! New best EMA pseudo Dice: 0.6371999979019165 
2025-07-11 16:43:13.934771:  
2025-07-11 16:43:13.936805: Epoch 9 
2025-07-11 16:43:13.938056: Current learning rate: 0.00992 
2025-07-11 16:44:22.062747: train_loss -0.92 
2025-07-11 16:44:22.064311: val_loss -0.9144 
2025-07-11 16:44:22.065480: Pseudo dice [np.float32(0.9301)] 
2025-07-11 16:44:22.066561: Epoch time: 68.13 s 
2025-07-11 16:44:22.067687: Yayy! New best EMA pseudo Dice: 0.6664999723434448 
2025-07-11 16:44:24.327586:  
2025-07-11 16:44:24.329243: Epoch 10 
2025-07-11 16:44:24.330382: Current learning rate: 0.00991 
2025-07-11 16:45:32.357640: train_loss -0.9227 
2025-07-11 16:45:32.359600: val_loss -0.9115 
2025-07-11 16:45:32.360587: Pseudo dice [np.float32(0.9253)] 
2025-07-11 16:45:32.361609: Epoch time: 68.03 s 
2025-07-11 16:45:32.362705: Yayy! New best EMA pseudo Dice: 0.6923999786376953 
2025-07-11 16:45:34.571751:  
2025-07-11 16:45:34.573595: Epoch 11 
2025-07-11 16:45:34.575305: Current learning rate: 0.0099 
2025-07-11 16:46:42.717181: train_loss -0.924 
2025-07-11 16:46:42.718286: val_loss -0.9136 
2025-07-11 16:46:42.719524: Pseudo dice [np.float32(0.9286)] 
2025-07-11 16:46:42.720690: Epoch time: 68.15 s 
2025-07-11 16:46:42.722171: Yayy! New best EMA pseudo Dice: 0.7160000205039978 
2025-07-11 16:46:44.924824:  
2025-07-11 16:46:44.926878: Epoch 12 
2025-07-11 16:46:44.928017: Current learning rate: 0.00989 
2025-07-11 16:47:52.787311: train_loss -0.9286 
2025-07-11 16:47:52.788719: val_loss -0.9172 
2025-07-11 16:47:52.789897: Pseudo dice [np.float32(0.9309)] 
2025-07-11 16:47:52.791256: Epoch time: 67.87 s 
2025-07-11 16:47:52.792820: Yayy! New best EMA pseudo Dice: 0.737500011920929 
2025-07-11 16:47:54.997695:  
2025-07-11 16:47:54.999662: Epoch 13 
2025-07-11 16:47:55.001075: Current learning rate: 0.00988 
2025-07-11 16:49:02.926011: train_loss -0.9296 
2025-07-11 16:49:02.927743: val_loss -0.9166 
2025-07-11 16:49:02.929461: Pseudo dice [np.float32(0.9298)] 
2025-07-11 16:49:02.930714: Epoch time: 67.93 s 
2025-07-11 16:49:02.932295: Yayy! New best EMA pseudo Dice: 0.7566999793052673 
2025-07-11 16:49:05.143187:  
2025-07-11 16:49:05.144878: Epoch 14 
2025-07-11 16:49:05.146590: Current learning rate: 0.00987 
2025-07-11 16:50:13.262422: train_loss -0.9307 
2025-07-11 16:50:13.263738: val_loss -0.918 
2025-07-11 16:50:13.265382: Pseudo dice [np.float32(0.9303)] 
2025-07-11 16:50:13.266882: Epoch time: 68.12 s 
2025-07-11 16:50:13.268087: Yayy! New best EMA pseudo Dice: 0.7741000056266785 
2025-07-11 16:50:15.542582:  
2025-07-11 16:50:15.544715: Epoch 15 
2025-07-11 16:50:15.545969: Current learning rate: 0.00986 
2025-07-11 16:51:23.570108: train_loss -0.9325 
2025-07-11 16:51:23.571418: val_loss -0.9133 
2025-07-11 16:51:23.572316: Pseudo dice [np.float32(0.9242)] 
2025-07-11 16:51:23.573726: Epoch time: 68.03 s 
2025-07-11 16:51:23.575218: Yayy! New best EMA pseudo Dice: 0.7890999913215637 
2025-07-11 16:51:25.809363:  
2025-07-11 16:51:25.811452: Epoch 16 
2025-07-11 16:51:25.812882: Current learning rate: 0.00986 
2025-07-11 16:52:33.809941: train_loss -0.933 
2025-07-11 16:52:33.811818: val_loss -0.9229 
2025-07-11 16:52:33.813475: Pseudo dice [np.float32(0.9352)] 
2025-07-11 16:52:33.814825: Epoch time: 68.0 s 
2025-07-11 16:52:33.815632: Yayy! New best EMA pseudo Dice: 0.8036999702453613 
2025-07-11 16:52:36.067940:  
2025-07-11 16:52:36.069760: Epoch 17 
2025-07-11 16:52:36.071247: Current learning rate: 0.00985 
2025-07-11 16:53:44.229187: train_loss -0.9352 
2025-07-11 16:53:44.230877: val_loss -0.9224 
2025-07-11 16:53:44.232061: Pseudo dice [np.float32(0.9334)] 
2025-07-11 16:53:44.233731: Epoch time: 68.16 s 
2025-07-11 16:53:44.235097: Yayy! New best EMA pseudo Dice: 0.8166999816894531 
2025-07-11 16:53:46.481012:  
2025-07-11 16:53:46.483368: Epoch 18 
2025-07-11 16:53:46.484433: Current learning rate: 0.00984 
2025-07-11 16:54:54.499353: train_loss -0.9351 
2025-07-11 16:54:54.501550: val_loss -0.9252 
2025-07-11 16:54:54.502963: Pseudo dice [np.float32(0.9359)] 
2025-07-11 16:54:54.505212: Epoch time: 68.02 s 
2025-07-11 16:54:54.507252: Yayy! New best EMA pseudo Dice: 0.8285999894142151 
2025-07-11 16:54:57.089715:  
2025-07-11 16:54:57.091494: Epoch 19 
2025-07-11 16:54:57.092820: Current learning rate: 0.00983 
2025-07-11 16:56:05.185119: train_loss -0.9382 
2025-07-11 16:56:05.186701: val_loss -0.9222 
2025-07-11 16:56:05.187886: Pseudo dice [np.float32(0.9324)] 
2025-07-11 16:56:05.189205: Epoch time: 68.1 s 
2025-07-11 16:56:05.190581: Yayy! New best EMA pseudo Dice: 0.8389999866485596 
2025-07-11 16:56:07.458182:  
2025-07-11 16:56:07.460045: Epoch 20 
2025-07-11 16:56:07.461129: Current learning rate: 0.00982 
2025-07-11 16:57:15.747293: train_loss -0.9401 
2025-07-11 16:57:15.749099: val_loss -0.926 
2025-07-11 16:57:15.750450: Pseudo dice [np.float32(0.9356)] 
2025-07-11 16:57:15.751833: Epoch time: 68.29 s 
2025-07-11 16:57:15.752855: Yayy! New best EMA pseudo Dice: 0.8485999703407288 
2025-07-11 16:57:18.024403:  
2025-07-11 16:57:18.026094: Epoch 21 
2025-07-11 16:57:18.027302: Current learning rate: 0.00981 
2025-07-11 16:58:26.080884: train_loss -0.94 
2025-07-11 16:58:26.082381: val_loss -0.9254 
2025-07-11 16:58:26.083835: Pseudo dice [np.float32(0.9343)] 
2025-07-11 16:58:26.085376: Epoch time: 68.06 s 
2025-07-11 16:58:26.086542: Yayy! New best EMA pseudo Dice: 0.857200026512146 
2025-07-11 16:58:28.641708:  
2025-07-11 16:58:28.643959: Epoch 22 
2025-07-11 16:58:28.645125: Current learning rate: 0.0098 
2025-07-11 16:59:36.868358: train_loss -0.9415 
2025-07-11 16:59:36.869710: val_loss -0.9238 
2025-07-11 16:59:36.870989: Pseudo dice [np.float32(0.9315)] 
2025-07-11 16:59:36.872347: Epoch time: 68.23 s 
2025-07-11 16:59:36.873931: Yayy! New best EMA pseudo Dice: 0.8646000027656555 
2025-07-11 16:59:39.150356:  
2025-07-11 16:59:39.152639: Epoch 23 
2025-07-11 16:59:39.153621: Current learning rate: 0.00979 
2025-07-11 17:00:47.402357: train_loss -0.9439 
2025-07-11 17:00:47.403848: val_loss -0.9311 
2025-07-11 17:00:47.404875: Pseudo dice [np.float32(0.9405)] 
2025-07-11 17:00:47.406365: Epoch time: 68.26 s 
2025-07-11 17:00:47.408173: Yayy! New best EMA pseudo Dice: 0.8722000122070312 
2025-07-11 17:00:49.618053:  
2025-07-11 17:00:49.620019: Epoch 24 
2025-07-11 17:00:49.621139: Current learning rate: 0.00978 
2025-07-11 17:01:57.796545: train_loss -0.9422 
2025-07-11 17:01:57.797813: val_loss -0.9276 
2025-07-11 17:01:57.798835: Pseudo dice [np.float32(0.9351)] 
2025-07-11 17:01:57.799888: Epoch time: 68.18 s 
2025-07-11 17:01:57.801143: Yayy! New best EMA pseudo Dice: 0.8784999847412109 
2025-07-11 17:02:00.075223:  
2025-07-11 17:02:00.077416: Epoch 25 
2025-07-11 17:02:00.078620: Current learning rate: 0.00977 
2025-07-11 17:03:08.181762: train_loss -0.9422 
2025-07-11 17:03:08.183032: val_loss -0.922 
2025-07-11 17:03:08.184186: Pseudo dice [np.float32(0.9291)] 
2025-07-11 17:03:08.185653: Epoch time: 68.11 s 
2025-07-11 17:03:08.187359: Yayy! New best EMA pseudo Dice: 0.8835999965667725 
2025-07-11 17:03:10.445763:  
2025-07-11 17:03:10.447607: Epoch 26 
2025-07-11 17:03:10.448773: Current learning rate: 0.00977 
2025-07-11 17:04:18.874568: train_loss -0.9442 
2025-07-11 17:04:18.875757: val_loss -0.9293 
2025-07-11 17:04:18.877059: Pseudo dice [np.float32(0.9369)] 
2025-07-11 17:04:18.878490: Epoch time: 68.43 s 
2025-07-11 17:04:18.879699: Yayy! New best EMA pseudo Dice: 0.8888999819755554 
2025-07-11 17:04:21.107374:  
2025-07-11 17:04:21.109312: Epoch 27 
2025-07-11 17:04:21.110398: Current learning rate: 0.00976 
2025-07-11 17:05:29.577935: train_loss -0.9448 
2025-07-11 17:05:29.579507: val_loss -0.9304 
2025-07-11 17:05:29.580525: Pseudo dice [np.float32(0.9382)] 
2025-07-11 17:05:29.581554: Epoch time: 68.47 s 
2025-07-11 17:05:29.582589: Yayy! New best EMA pseudo Dice: 0.8938000202178955 
2025-07-11 17:05:31.835591:  
2025-07-11 17:05:31.837521: Epoch 28 
2025-07-11 17:05:31.838660: Current learning rate: 0.00975 
2025-07-11 17:06:40.221356: train_loss -0.9454 
2025-07-11 17:06:40.223171: val_loss -0.9311 
2025-07-11 17:06:40.224844: Pseudo dice [np.float32(0.9379)] 
2025-07-11 17:06:40.225894: Epoch time: 68.39 s 
2025-07-11 17:06:40.227243: Yayy! New best EMA pseudo Dice: 0.8981999754905701 
2025-07-11 17:06:42.428077:  
2025-07-11 17:06:42.429999: Epoch 29 
2025-07-11 17:06:42.431208: Current learning rate: 0.00974 
2025-07-11 17:07:50.778121: train_loss -0.9462 
2025-07-11 17:07:50.779335: val_loss -0.9261 
2025-07-11 17:07:50.780367: Pseudo dice [np.float32(0.9332)] 
2025-07-11 17:07:50.781487: Epoch time: 68.35 s 
2025-07-11 17:07:50.782681: Yayy! New best EMA pseudo Dice: 0.9017000198364258 
2025-07-11 17:07:53.030998:  
2025-07-11 17:07:53.032718: Epoch 30 
2025-07-11 17:07:53.033864: Current learning rate: 0.00973 
2025-07-11 17:09:01.006356: train_loss -0.9468 
2025-07-11 17:09:01.007731: val_loss -0.9207 
2025-07-11 17:09:01.009224: Pseudo dice [np.float32(0.9266)] 
2025-07-11 17:09:01.010853: Epoch time: 67.98 s 
2025-07-11 17:09:01.012327: Yayy! New best EMA pseudo Dice: 0.90420001745224 
2025-07-11 17:09:03.340102:  
2025-07-11 17:09:03.342216: Epoch 31 
2025-07-11 17:09:03.343231: Current learning rate: 0.00972 
2025-07-11 17:10:11.523376: train_loss -0.9474 
2025-07-11 17:10:11.524621: val_loss -0.9266 
2025-07-11 17:10:11.525654: Pseudo dice [np.float32(0.9346)] 
2025-07-11 17:10:11.526797: Epoch time: 68.19 s 
2025-07-11 17:10:11.528165: Yayy! New best EMA pseudo Dice: 0.9071999788284302 
2025-07-11 17:10:13.792603:  
2025-07-11 17:10:13.794413: Epoch 32 
2025-07-11 17:10:13.795798: Current learning rate: 0.00971 
2025-07-11 17:11:22.215788: train_loss -0.949 
2025-07-11 17:11:22.217310: val_loss -0.9338 
2025-07-11 17:11:22.218447: Pseudo dice [np.float32(0.9401)] 
2025-07-11 17:11:22.219625: Epoch time: 68.43 s 
2025-07-11 17:11:22.221315: Yayy! New best EMA pseudo Dice: 0.9104999899864197 
2025-07-11 17:11:24.509181:  
2025-07-11 17:11:24.511207: Epoch 33 
2025-07-11 17:11:24.512588: Current learning rate: 0.0097 
2025-07-11 17:12:32.789728: train_loss -0.9489 
2025-07-11 17:12:32.790935: val_loss -0.9282 
2025-07-11 17:12:32.792686: Pseudo dice [np.float32(0.9333)] 
2025-07-11 17:12:32.794074: Epoch time: 68.28 s 
2025-07-11 17:12:32.795409: Yayy! New best EMA pseudo Dice: 0.9128000140190125 
2025-07-11 17:12:35.040107:  
2025-07-11 17:12:35.041842: Epoch 34 
2025-07-11 17:12:35.043000: Current learning rate: 0.00969 
2025-07-11 17:13:43.364331: train_loss -0.9512 
2025-07-11 17:13:43.366147: val_loss -0.9285 
2025-07-11 17:13:43.367810: Pseudo dice [np.float32(0.9355)] 
2025-07-11 17:13:43.369750: Epoch time: 68.33 s 
2025-07-11 17:13:43.370814: Yayy! New best EMA pseudo Dice: 0.9150999784469604 
2025-07-11 17:13:45.610194:  
2025-07-11 17:13:45.612315: Epoch 35 
2025-07-11 17:13:45.613448: Current learning rate: 0.00968 
2025-07-11 17:14:54.019491: train_loss -0.9515 
2025-07-11 17:14:54.021168: val_loss -0.9312 
2025-07-11 17:14:54.022301: Pseudo dice [np.float32(0.9389)] 
2025-07-11 17:14:54.023357: Epoch time: 68.41 s 
2025-07-11 17:14:54.024951: Yayy! New best EMA pseudo Dice: 0.9175000190734863 
2025-07-11 17:14:56.295122:  
2025-07-11 17:14:56.297260: Epoch 36 
2025-07-11 17:14:56.299103: Current learning rate: 0.00968 
2025-07-11 17:16:04.507145: train_loss -0.9501 
2025-07-11 17:16:04.508831: val_loss -0.9303 
2025-07-11 17:16:04.511213: Pseudo dice [np.float32(0.9359)] 
2025-07-11 17:16:04.512512: Epoch time: 68.22 s 
2025-07-11 17:16:04.513525: Yayy! New best EMA pseudo Dice: 0.9193000197410583 
2025-07-11 17:16:06.800262:  
2025-07-11 17:16:06.801749: Epoch 37 
2025-07-11 17:16:06.803009: Current learning rate: 0.00967 
2025-07-11 17:17:15.170410: train_loss -0.95 
2025-07-11 17:17:15.172128: val_loss -0.9282 
2025-07-11 17:17:15.173220: Pseudo dice [np.float32(0.9342)] 
2025-07-11 17:17:15.174300: Epoch time: 68.37 s 
2025-07-11 17:17:15.175338: Yayy! New best EMA pseudo Dice: 0.920799970626831 
2025-07-11 17:17:17.423701:  
2025-07-11 17:17:17.425633: Epoch 38 
2025-07-11 17:17:17.426871: Current learning rate: 0.00966 
2025-07-11 17:18:25.987441: train_loss -0.9518 
2025-07-11 17:18:25.989240: val_loss -0.9351 
2025-07-11 17:18:25.990549: Pseudo dice [np.float32(0.9408)] 
2025-07-11 17:18:25.991901: Epoch time: 68.57 s 
2025-07-11 17:18:25.992961: Yayy! New best EMA pseudo Dice: 0.9228000044822693 
2025-07-11 17:18:28.296244:  
2025-07-11 17:18:28.298336: Epoch 39 
2025-07-11 17:18:28.299603: Current learning rate: 0.00965 
2025-07-11 17:19:36.696393: train_loss -0.9501 
2025-07-11 17:19:36.698592: val_loss -0.9244 
2025-07-11 17:19:36.700326: Pseudo dice [np.float32(0.931)] 
2025-07-11 17:19:36.701568: Epoch time: 68.4 s 
2025-07-11 17:19:36.702762: Yayy! New best EMA pseudo Dice: 0.9236000180244446 
2025-07-11 17:19:39.014493:  
2025-07-11 17:19:39.016260: Epoch 40 
2025-07-11 17:19:39.017261: Current learning rate: 0.00964 
2025-07-11 17:20:47.580460: train_loss -0.9532 
2025-07-11 17:20:47.582384: val_loss -0.9232 
2025-07-11 17:20:47.583345: Pseudo dice [np.float32(0.9291)] 
2025-07-11 17:20:47.584187: Epoch time: 68.57 s 
2025-07-11 17:20:47.585335: Yayy! New best EMA pseudo Dice: 0.9241999983787537 
2025-07-11 17:20:49.845031:  
2025-07-11 17:20:49.846665: Epoch 41 
2025-07-11 17:20:49.847798: Current learning rate: 0.00963 
2025-07-11 17:21:58.385937: train_loss -0.9537 
2025-07-11 17:21:58.387279: val_loss -0.93 
2025-07-11 17:21:58.388282: Pseudo dice [np.float32(0.9355)] 
2025-07-11 17:21:58.389465: Epoch time: 68.54 s 
2025-07-11 17:21:58.391404: Yayy! New best EMA pseudo Dice: 0.9253000020980835 
2025-07-11 17:22:00.668991:  
2025-07-11 17:22:00.670941: Epoch 42 
2025-07-11 17:22:00.672029: Current learning rate: 0.00962 
2025-07-11 17:23:08.911759: train_loss -0.9543 
2025-07-11 17:23:08.912871: val_loss -0.9306 
2025-07-11 17:23:08.914087: Pseudo dice [np.float32(0.9366)] 
2025-07-11 17:23:08.915646: Epoch time: 68.25 s 
2025-07-11 17:23:08.917685: Yayy! New best EMA pseudo Dice: 0.9264000058174133 
2025-07-11 17:23:11.151858:  
2025-07-11 17:23:11.153783: Epoch 43 
2025-07-11 17:23:11.155100: Current learning rate: 0.00961 
2025-07-11 17:24:19.387564: train_loss -0.9532 
2025-07-11 17:24:19.389096: val_loss -0.9303 
2025-07-11 17:24:19.390751: Pseudo dice [np.float32(0.9368)] 
2025-07-11 17:24:19.391977: Epoch time: 68.24 s 
2025-07-11 17:24:19.393807: Yayy! New best EMA pseudo Dice: 0.9275000095367432 
2025-07-11 17:24:21.665556:  
2025-07-11 17:24:21.667382: Epoch 44 
2025-07-11 17:24:21.668685: Current learning rate: 0.0096 
2025-07-11 17:25:30.085567: train_loss -0.9548 
2025-07-11 17:25:30.087046: val_loss -0.9288 
2025-07-11 17:25:30.088235: Pseudo dice [np.float32(0.9345)] 
2025-07-11 17:25:30.089191: Epoch time: 68.42 s 
2025-07-11 17:25:30.090422: Yayy! New best EMA pseudo Dice: 0.9282000064849854 
2025-07-11 17:25:32.386018:  
2025-07-11 17:25:32.387713: Epoch 45 
2025-07-11 17:25:32.389133: Current learning rate: 0.00959 
2025-07-11 17:26:40.585915: train_loss -0.9542 
2025-07-11 17:26:40.587181: val_loss -0.932 
2025-07-11 17:26:40.588517: Pseudo dice [np.float32(0.937)] 
2025-07-11 17:26:40.589950: Epoch time: 68.2 s 
2025-07-11 17:26:40.591703: Yayy! New best EMA pseudo Dice: 0.9290000200271606 
2025-07-11 17:26:42.868657:  
2025-07-11 17:26:42.870758: Epoch 46 
2025-07-11 17:26:42.872003: Current learning rate: 0.00959 
2025-07-11 17:27:51.166666: train_loss -0.9564 
2025-07-11 17:27:51.168125: val_loss -0.9316 
2025-07-11 17:27:51.169409: Pseudo dice [np.float32(0.9367)] 
2025-07-11 17:27:51.170381: Epoch time: 68.3 s 
2025-07-11 17:27:51.171621: Yayy! New best EMA pseudo Dice: 0.9297999739646912 
2025-07-11 17:27:53.429333:  
2025-07-11 17:27:53.431568: Epoch 47 
2025-07-11 17:27:53.433269: Current learning rate: 0.00958 
2025-07-11 17:29:01.966945: train_loss -0.9545 
2025-07-11 17:29:01.968583: val_loss -0.932 
2025-07-11 17:29:01.970167: Pseudo dice [np.float32(0.9359)] 
2025-07-11 17:29:01.971131: Epoch time: 68.54 s 
2025-07-11 17:29:01.972189: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2025-07-11 17:29:04.228047:  
2025-07-11 17:29:04.229837: Epoch 48 
2025-07-11 17:29:04.230963: Current learning rate: 0.00957 
2025-07-11 17:30:12.614299: train_loss -0.9558 
2025-07-11 17:30:12.615563: val_loss -0.9334 
2025-07-11 17:30:12.616748: Pseudo dice [np.float32(0.9391)] 
2025-07-11 17:30:12.618720: Epoch time: 68.39 s 
2025-07-11 17:30:12.620061: Yayy! New best EMA pseudo Dice: 0.9312999844551086 
2025-07-11 17:30:14.895601:  
2025-07-11 17:30:14.897465: Epoch 49 
2025-07-11 17:30:14.898701: Current learning rate: 0.00956 
2025-07-11 17:31:23.221156: train_loss -0.9551 
2025-07-11 17:31:23.222610: val_loss -0.9208 
2025-07-11 17:31:23.224186: Pseudo dice [np.float32(0.9246)] 
2025-07-11 17:31:23.225389: Epoch time: 68.33 s 
2025-07-11 17:31:25.279049:  
2025-07-11 17:31:25.280903: Epoch 50 
2025-07-11 17:31:25.282265: Current learning rate: 0.00955 
2025-07-11 17:32:33.930873: train_loss -0.9564 
2025-07-11 17:32:33.932367: val_loss -0.9296 
2025-07-11 17:32:33.934370: Pseudo dice [np.float32(0.9346)] 
2025-07-11 17:32:33.935770: Epoch time: 68.66 s 
2025-07-11 17:32:34.894568:  
2025-07-11 17:32:34.896649: Epoch 51 
2025-07-11 17:32:34.897786: Current learning rate: 0.00954 
2025-07-11 17:33:43.506597: train_loss -0.9572 
2025-07-11 17:33:43.507662: val_loss -0.9339 
2025-07-11 17:33:43.509086: Pseudo dice [np.float32(0.9393)] 
2025-07-11 17:33:43.510378: Epoch time: 68.62 s 
2025-07-11 17:33:43.511665: Yayy! New best EMA pseudo Dice: 0.9318000078201294 
2025-07-11 17:33:45.789213:  
2025-07-11 17:33:45.791401: Epoch 52 
2025-07-11 17:33:45.792510: Current learning rate: 0.00953 
2025-07-11 17:34:54.228081: train_loss -0.9548 
2025-07-11 17:34:54.229342: val_loss -0.9322 
2025-07-11 17:34:54.230748: Pseudo dice [np.float32(0.9381)] 
2025-07-11 17:34:54.232234: Epoch time: 68.44 s 
2025-07-11 17:34:54.233379: Yayy! New best EMA pseudo Dice: 0.9325000047683716 
2025-07-11 17:34:56.521599:  
2025-07-11 17:34:56.523304: Epoch 53 
2025-07-11 17:34:56.524398: Current learning rate: 0.00952 
2025-07-11 17:36:04.879936: train_loss -0.9547 
2025-07-11 17:36:04.881325: val_loss -0.9299 
2025-07-11 17:36:04.882492: Pseudo dice [np.float32(0.9341)] 
2025-07-11 17:36:04.884012: Epoch time: 68.36 s 
2025-07-11 17:36:04.884918: Yayy! New best EMA pseudo Dice: 0.9326000213623047 
2025-07-11 17:36:07.414520:  
2025-07-11 17:36:07.416603: Epoch 54 
2025-07-11 17:36:07.417888: Current learning rate: 0.00951 
2025-07-11 17:37:15.708492: train_loss -0.9559 
2025-07-11 17:37:15.711028: val_loss -0.9223 
2025-07-11 17:37:15.712560: Pseudo dice [np.float32(0.9262)] 
2025-07-11 17:37:15.714153: Epoch time: 68.3 s 
2025-07-11 17:37:16.641628:  
2025-07-11 17:37:16.643751: Epoch 55 
2025-07-11 17:37:16.645286: Current learning rate: 0.0095 
2025-07-11 17:38:24.864289: train_loss -0.9567 
2025-07-11 17:38:24.865882: val_loss -0.9263 
2025-07-11 17:38:24.867132: Pseudo dice [np.float32(0.9316)] 
2025-07-11 17:38:24.868380: Epoch time: 68.23 s 
2025-07-11 17:38:25.809998:  
2025-07-11 17:38:25.811816: Epoch 56 
2025-07-11 17:38:25.812995: Current learning rate: 0.00949 
2025-07-11 17:39:34.091650: train_loss -0.957 
2025-07-11 17:39:34.093144: val_loss -0.9325 
2025-07-11 17:39:34.094320: Pseudo dice [np.float32(0.9359)] 
2025-07-11 17:39:34.095475: Epoch time: 68.29 s 
2025-07-11 17:39:35.020092:  
2025-07-11 17:39:35.021926: Epoch 57 
2025-07-11 17:39:35.023026: Current learning rate: 0.00949 
2025-07-11 17:40:43.669650: train_loss -0.9565 
2025-07-11 17:40:43.671134: val_loss -0.9336 
2025-07-11 17:40:43.672552: Pseudo dice [np.float32(0.9388)] 
2025-07-11 17:40:43.673456: Epoch time: 68.65 s 
2025-07-11 17:40:43.675145: Yayy! New best EMA pseudo Dice: 0.9330000281333923 
2025-07-11 17:40:45.924969:  
2025-07-11 17:40:45.926756: Epoch 58 
2025-07-11 17:40:45.927795: Current learning rate: 0.00948 
2025-07-11 17:41:54.246353: train_loss -0.957 
2025-07-11 17:41:54.247847: val_loss -0.9299 
2025-07-11 17:41:54.249852: Pseudo dice [np.float32(0.9343)] 
2025-07-11 17:41:54.251381: Epoch time: 68.33 s 
2025-07-11 17:41:54.252505: Yayy! New best EMA pseudo Dice: 0.9330999851226807 
2025-07-11 17:41:56.492028:  
2025-07-11 17:41:56.493938: Epoch 59 
2025-07-11 17:41:56.495620: Current learning rate: 0.00947 
2025-07-11 17:43:04.726372: train_loss -0.9575 
2025-07-11 17:43:04.727857: val_loss -0.9305 
2025-07-11 17:43:04.729107: Pseudo dice [np.float32(0.9363)] 
2025-07-11 17:43:04.730215: Epoch time: 68.24 s 
2025-07-11 17:43:04.731308: Yayy! New best EMA pseudo Dice: 0.9333999752998352 
2025-07-11 17:43:07.027384:  
2025-07-11 17:43:07.029526: Epoch 60 
2025-07-11 17:43:07.030721: Current learning rate: 0.00946 
2025-07-11 17:44:15.449871: train_loss -0.959 
2025-07-11 17:44:15.451538: val_loss -0.9385 
2025-07-11 17:44:15.453059: Pseudo dice [np.float32(0.9434)] 
2025-07-11 17:44:15.454135: Epoch time: 68.43 s 
2025-07-11 17:44:15.455867: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-07-11 17:44:17.734793:  
2025-07-11 17:44:17.736685: Epoch 61 
2025-07-11 17:44:17.737921: Current learning rate: 0.00945 
2025-07-11 17:45:26.130369: train_loss -0.9579 
2025-07-11 17:45:26.131669: val_loss -0.9273 
2025-07-11 17:45:26.133094: Pseudo dice [np.float32(0.9308)] 
2025-07-11 17:45:26.134859: Epoch time: 68.4 s 
2025-07-11 17:45:27.064106:  
2025-07-11 17:45:27.065920: Epoch 62 
2025-07-11 17:45:27.066864: Current learning rate: 0.00944 
2025-07-11 17:46:35.383439: train_loss -0.959 
2025-07-11 17:46:35.385556: val_loss -0.9322 
2025-07-11 17:46:35.387007: Pseudo dice [np.float32(0.9379)] 
2025-07-11 17:46:35.388035: Epoch time: 68.32 s 
2025-07-11 17:46:35.390538: Yayy! New best EMA pseudo Dice: 0.934499979019165 
2025-07-11 17:46:37.703900:  
2025-07-11 17:46:37.705934: Epoch 63 
2025-07-11 17:46:37.707189: Current learning rate: 0.00943 
2025-07-11 17:47:46.153042: train_loss -0.959 
2025-07-11 17:47:46.154579: val_loss -0.9211 
2025-07-11 17:47:46.155513: Pseudo dice [np.float32(0.9287)] 
2025-07-11 17:47:46.156749: Epoch time: 68.45 s 
2025-07-11 17:47:47.376938:  
2025-07-11 17:47:47.378894: Epoch 64 
2025-07-11 17:47:47.379827: Current learning rate: 0.00942 
2025-07-11 17:48:55.898405: train_loss -0.9598 
2025-07-11 17:48:55.900374: val_loss -0.9273 
2025-07-11 17:48:55.901502: Pseudo dice [np.float32(0.9316)] 
2025-07-11 17:48:55.902816: Epoch time: 68.53 s 
2025-07-11 17:48:56.839926:  
2025-07-11 17:48:56.842253: Epoch 65 
2025-07-11 17:48:56.843531: Current learning rate: 0.00941 
2025-07-11 17:50:05.397395: train_loss -0.9589 
2025-07-11 17:50:05.398990: val_loss -0.9295 
2025-07-11 17:50:05.400200: Pseudo dice [np.float32(0.9325)] 
2025-07-11 17:50:05.402011: Epoch time: 68.56 s 
2025-07-11 17:50:06.345191:  
2025-07-11 17:50:06.347251: Epoch 66 
2025-07-11 17:50:06.348493: Current learning rate: 0.0094 
2025-07-11 17:51:14.782196: train_loss -0.96 
2025-07-11 17:51:14.783887: val_loss -0.9355 
2025-07-11 17:51:14.784946: Pseudo dice [np.float32(0.9393)] 
2025-07-11 17:51:14.785923: Epoch time: 68.44 s 
2025-07-11 17:51:15.710706:  
2025-07-11 17:51:15.713178: Epoch 67 
2025-07-11 17:51:15.714502: Current learning rate: 0.00939 
2025-07-11 17:52:24.595808: train_loss -0.9596 
2025-07-11 17:52:24.597177: val_loss -0.9251 
2025-07-11 17:52:24.598761: Pseudo dice [np.float32(0.9281)] 
2025-07-11 17:52:24.600863: Epoch time: 68.89 s 
2025-07-11 17:52:25.562017:  
2025-07-11 17:52:25.564186: Epoch 68 
2025-07-11 17:52:25.565611: Current learning rate: 0.00939 
2025-07-11 17:53:34.048040: train_loss -0.9608 
2025-07-11 17:53:34.049562: val_loss -0.937 
2025-07-11 17:53:34.050666: Pseudo dice [np.float32(0.942)] 
2025-07-11 17:53:34.052303: Epoch time: 68.49 s 
2025-07-11 17:53:35.016498:  
2025-07-11 17:53:35.018816: Epoch 69 
2025-07-11 17:53:35.019900: Current learning rate: 0.00938 
2025-07-11 17:54:43.398893: train_loss -0.9598 
2025-07-11 17:54:43.400289: val_loss -0.9265 
2025-07-11 17:54:43.401706: Pseudo dice [np.float32(0.9294)] 
2025-07-11 17:54:43.403306: Epoch time: 68.39 s 
2025-07-11 17:54:44.368815:  
2025-07-11 17:54:44.370653: Epoch 70 
2025-07-11 17:54:44.371768: Current learning rate: 0.00937 
2025-07-11 17:55:52.721523: train_loss -0.9604 
2025-07-11 17:55:52.723384: val_loss -0.9284 
2025-07-11 17:55:52.724766: Pseudo dice [np.float32(0.9321)] 
2025-07-11 17:55:52.725876: Epoch time: 68.36 s 
2025-07-11 17:55:53.913172:  
2025-07-11 17:55:53.914972: Epoch 71 
2025-07-11 17:55:53.916030: Current learning rate: 0.00936 
2025-07-11 17:57:02.301145: train_loss -0.959 
2025-07-11 17:57:02.302355: val_loss -0.9292 
2025-07-11 17:57:02.303588: Pseudo dice [np.float32(0.9326)] 
2025-07-11 17:57:02.304591: Epoch time: 68.39 s 
2025-07-11 17:57:03.255498:  
2025-07-11 17:57:03.257499: Epoch 72 
2025-07-11 17:57:03.259259: Current learning rate: 0.00935 
2025-07-11 17:58:11.839962: train_loss -0.9601 
2025-07-11 17:58:11.841490: val_loss -0.9397 
2025-07-11 17:58:11.842494: Pseudo dice [np.float32(0.944)] 
2025-07-11 17:58:11.843783: Epoch time: 68.59 s 
2025-07-11 17:58:11.845413: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-07-11 17:58:14.194639:  
2025-07-11 17:58:14.196758: Epoch 73 
2025-07-11 17:58:14.198413: Current learning rate: 0.00934 
2025-07-11 17:59:22.694388: train_loss -0.9609 
2025-07-11 17:59:22.695876: val_loss -0.9301 
2025-07-11 17:59:22.696925: Pseudo dice [np.float32(0.9338)] 
2025-07-11 17:59:22.698059: Epoch time: 68.5 s 
2025-07-11 17:59:23.609617:  
2025-07-11 17:59:23.611444: Epoch 74 
2025-07-11 17:59:23.612741: Current learning rate: 0.00933 
2025-07-11 18:00:32.298964: train_loss -0.9614 
2025-07-11 18:00:32.300488: val_loss -0.9314 
2025-07-11 18:00:32.302696: Pseudo dice [np.float32(0.9359)] 
2025-07-11 18:00:32.303786: Epoch time: 68.69 s 
2025-07-11 18:00:32.304988: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2025-07-11 18:00:34.587594:  
2025-07-11 18:00:34.589750: Epoch 75 
2025-07-11 18:00:34.591009: Current learning rate: 0.00932 
2025-07-11 18:01:42.961979: train_loss -0.9597 
2025-07-11 18:01:42.963264: val_loss -0.9271 
2025-07-11 18:01:42.964651: Pseudo dice [np.float32(0.932)] 
2025-07-11 18:01:42.965796: Epoch time: 68.38 s 
2025-07-11 18:01:43.938415:  
2025-07-11 18:01:43.940325: Epoch 76 
2025-07-11 18:01:43.941820: Current learning rate: 0.00931 
2025-07-11 18:02:52.434902: train_loss -0.9612 
2025-07-11 18:02:52.437170: val_loss -0.9348 
2025-07-11 18:02:52.438486: Pseudo dice [np.float32(0.9392)] 
2025-07-11 18:02:52.439684: Epoch time: 68.5 s 
2025-07-11 18:02:52.440752: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-07-11 18:02:54.729582:  
2025-07-11 18:02:54.731654: Epoch 77 
2025-07-11 18:02:54.732897: Current learning rate: 0.0093 
2025-07-11 18:04:03.406173: train_loss -0.9621 
2025-07-11 18:04:03.407582: val_loss -0.9307 
2025-07-11 18:04:03.408979: Pseudo dice [np.float32(0.935)] 
2025-07-11 18:04:03.409951: Epoch time: 68.68 s 
2025-07-11 18:04:03.410983: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-07-11 18:04:05.712182:  
2025-07-11 18:04:05.714062: Epoch 78 
2025-07-11 18:04:05.715282: Current learning rate: 0.0093 
2025-07-11 18:05:14.186674: train_loss -0.9624 
2025-07-11 18:05:14.189162: val_loss -0.9414 
2025-07-11 18:05:14.190534: Pseudo dice [np.float32(0.9449)] 
2025-07-11 18:05:14.191458: Epoch time: 68.48 s 
2025-07-11 18:05:14.192571: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-07-11 18:05:16.512343:  
2025-07-11 18:05:16.514327: Epoch 79 
2025-07-11 18:05:16.515635: Current learning rate: 0.00929 
2025-07-11 18:06:25.213628: train_loss -0.9603 
2025-07-11 18:06:25.214862: val_loss -0.9345 
2025-07-11 18:06:25.216117: Pseudo dice [np.float32(0.9396)] 
2025-07-11 18:06:25.217658: Epoch time: 68.7 s 
2025-07-11 18:06:25.219282: Yayy! New best EMA pseudo Dice: 0.9362999796867371 
2025-07-11 18:06:27.486737:  
2025-07-11 18:06:27.488672: Epoch 80 
2025-07-11 18:06:27.490195: Current learning rate: 0.00928 
2025-07-11 18:07:36.214455: train_loss -0.9606 
2025-07-11 18:07:36.216123: val_loss -0.9324 
2025-07-11 18:07:36.217200: Pseudo dice [np.float32(0.9371)] 
2025-07-11 18:07:36.218644: Epoch time: 68.73 s 
2025-07-11 18:07:36.219701: Yayy! New best EMA pseudo Dice: 0.9363999962806702 
2025-07-11 18:07:38.541365:  
2025-07-11 18:07:38.543260: Epoch 81 
2025-07-11 18:07:38.544557: Current learning rate: 0.00927 
2025-07-11 18:08:46.810714: train_loss -0.9597 
2025-07-11 18:08:46.812501: val_loss -0.9328 
2025-07-11 18:08:46.813628: Pseudo dice [np.float32(0.9369)] 
2025-07-11 18:08:46.814579: Epoch time: 68.27 s 
2025-07-11 18:08:46.815617: Yayy! New best EMA pseudo Dice: 0.9363999962806702 
2025-07-11 18:08:49.106217:  
2025-07-11 18:08:49.108227: Epoch 82 
2025-07-11 18:08:49.109308: Current learning rate: 0.00926 
2025-07-11 18:09:57.457108: train_loss -0.9611 
2025-07-11 18:09:57.458209: val_loss -0.9346 
2025-07-11 18:09:57.459407: Pseudo dice [np.float32(0.9381)] 
2025-07-11 18:09:57.460713: Epoch time: 68.35 s 
2025-07-11 18:09:57.462080: Yayy! New best EMA pseudo Dice: 0.9366000294685364 
2025-07-11 18:09:59.734865:  
2025-07-11 18:09:59.736848: Epoch 83 
2025-07-11 18:09:59.738260: Current learning rate: 0.00925 
2025-07-11 18:11:08.761578: train_loss -0.962 
2025-07-11 18:11:08.763208: val_loss -0.9378 
2025-07-11 18:11:08.764560: Pseudo dice [np.float32(0.9419)] 
2025-07-11 18:11:08.765661: Epoch time: 69.03 s 
2025-07-11 18:11:08.766806: Yayy! New best EMA pseudo Dice: 0.9370999932289124 
2025-07-11 18:11:11.003342:  
2025-07-11 18:11:11.005159: Epoch 84 
2025-07-11 18:11:11.006694: Current learning rate: 0.00924 
2025-07-11 18:12:19.674479: train_loss -0.9624 
2025-07-11 18:12:19.676607: val_loss -0.9336 
2025-07-11 18:12:19.678498: Pseudo dice [np.float32(0.9376)] 
2025-07-11 18:12:19.680318: Epoch time: 68.67 s 
2025-07-11 18:12:19.681359: Yayy! New best EMA pseudo Dice: 0.9372000098228455 
2025-07-11 18:12:21.951617:  
2025-07-11 18:12:21.953418: Epoch 85 
2025-07-11 18:12:21.954820: Current learning rate: 0.00923 
2025-07-11 18:13:30.414937: train_loss -0.9619 
2025-07-11 18:13:30.416581: val_loss -0.9392 
2025-07-11 18:13:30.417600: Pseudo dice [np.float32(0.9435)] 
2025-07-11 18:13:30.418664: Epoch time: 68.47 s 
2025-07-11 18:13:30.419455: Yayy! New best EMA pseudo Dice: 0.9377999901771545 
2025-07-11 18:13:32.913544:  
2025-07-11 18:13:32.915598: Epoch 86 
2025-07-11 18:13:32.916842: Current learning rate: 0.00922 
2025-07-11 18:14:41.275542: train_loss -0.9618 
2025-07-11 18:14:41.276822: val_loss -0.9352 
2025-07-11 18:14:41.278288: Pseudo dice [np.float32(0.9388)] 
2025-07-11 18:14:41.279801: Epoch time: 68.37 s 
2025-07-11 18:14:41.281436: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-07-11 18:14:43.553452:  
2025-07-11 18:14:43.555416: Epoch 87 
2025-07-11 18:14:43.556738: Current learning rate: 0.00921 
2025-07-11 18:15:52.025653: train_loss -0.9618 
2025-07-11 18:15:52.027242: val_loss -0.9317 
2025-07-11 18:15:52.028628: Pseudo dice [np.float32(0.9368)] 
2025-07-11 18:15:52.029799: Epoch time: 68.48 s 
2025-07-11 18:15:52.963442:  
2025-07-11 18:15:52.965726: Epoch 88 
2025-07-11 18:15:52.967712: Current learning rate: 0.0092 
2025-07-11 18:17:01.381472: train_loss -0.9615 
2025-07-11 18:17:01.382915: val_loss -0.9309 
2025-07-11 18:17:01.384581: Pseudo dice [np.float32(0.9343)] 
2025-07-11 18:17:01.385950: Epoch time: 68.42 s 
2025-07-11 18:17:02.309853:  
2025-07-11 18:17:02.312084: Epoch 89 
2025-07-11 18:17:02.313272: Current learning rate: 0.0092 
2025-07-11 18:18:10.732845: train_loss -0.9629 
2025-07-11 18:18:10.735380: val_loss -0.9405 
2025-07-11 18:18:10.736822: Pseudo dice [np.float32(0.9457)] 
2025-07-11 18:18:10.737963: Epoch time: 68.43 s 
2025-07-11 18:18:10.738978: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-07-11 18:18:13.266539:  
2025-07-11 18:18:13.268672: Epoch 90 
2025-07-11 18:18:13.269790: Current learning rate: 0.00919 
2025-07-11 18:19:21.709695: train_loss -0.9629 
2025-07-11 18:19:21.711218: val_loss -0.9392 
2025-07-11 18:19:21.712182: Pseudo dice [np.float32(0.9431)] 
2025-07-11 18:19:21.713585: Epoch time: 68.45 s 
2025-07-11 18:19:21.714756: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-07-11 18:19:24.021915:  
2025-07-11 18:19:24.023961: Epoch 91 
2025-07-11 18:19:24.025031: Current learning rate: 0.00918 
2025-07-11 18:20:32.536304: train_loss -0.9629 
2025-07-11 18:20:32.537667: val_loss -0.9376 
2025-07-11 18:20:32.538680: Pseudo dice [np.float32(0.9411)] 
2025-07-11 18:20:32.539652: Epoch time: 68.52 s 
2025-07-11 18:20:32.540820: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-07-11 18:20:34.820222:  
2025-07-11 18:20:34.822119: Epoch 92 
2025-07-11 18:20:34.823344: Current learning rate: 0.00917 
2025-07-11 18:21:43.240527: train_loss -0.9633 
2025-07-11 18:21:43.242182: val_loss -0.9326 
2025-07-11 18:21:43.243989: Pseudo dice [np.float32(0.9347)] 
2025-07-11 18:21:43.246072: Epoch time: 68.42 s 
2025-07-11 18:21:44.151569:  
2025-07-11 18:21:44.153643: Epoch 93 
2025-07-11 18:21:44.155255: Current learning rate: 0.00916 
2025-07-11 18:22:52.728092: train_loss -0.964 
2025-07-11 18:22:52.729312: val_loss -0.9316 
2025-07-11 18:22:52.730433: Pseudo dice [np.float32(0.9353)] 
2025-07-11 18:22:52.731638: Epoch time: 68.58 s 
2025-07-11 18:22:53.655617:  
2025-07-11 18:22:53.657615: Epoch 94 
2025-07-11 18:22:53.659318: Current learning rate: 0.00915 
2025-07-11 18:24:02.053267: train_loss -0.9632 
2025-07-11 18:24:02.054977: val_loss -0.9383 
2025-07-11 18:24:02.056398: Pseudo dice [np.float32(0.9418)] 
2025-07-11 18:24:02.057817: Epoch time: 68.4 s 
2025-07-11 18:24:02.954526:  
2025-07-11 18:24:02.957144: Epoch 95 
2025-07-11 18:24:02.958801: Current learning rate: 0.00914 
2025-07-11 18:25:11.244468: train_loss -0.9638 
2025-07-11 18:25:11.246638: val_loss -0.9298 
2025-07-11 18:25:11.248344: Pseudo dice [np.float32(0.9349)] 
2025-07-11 18:25:11.249655: Epoch time: 68.29 s 
2025-07-11 18:25:12.172372:  
2025-07-11 18:25:12.174815: Epoch 96 
2025-07-11 18:25:12.176078: Current learning rate: 0.00913 
2025-07-11 18:26:20.614788: train_loss -0.9623 
2025-07-11 18:26:20.616383: val_loss -0.9339 
2025-07-11 18:26:20.617533: Pseudo dice [np.float32(0.9379)] 
2025-07-11 18:26:20.618924: Epoch time: 68.45 s 
2025-07-11 18:26:21.773348:  
2025-07-11 18:26:21.775143: Epoch 97 
2025-07-11 18:26:21.776510: Current learning rate: 0.00912 
2025-07-11 18:27:30.263846: train_loss -0.9631 
2025-07-11 18:27:30.265523: val_loss -0.9381 
2025-07-11 18:27:30.267410: Pseudo dice [np.float32(0.9426)] 
2025-07-11 18:27:30.268358: Epoch time: 68.49 s 
2025-07-11 18:27:31.222463:  
2025-07-11 18:27:31.225358: Epoch 98 
2025-07-11 18:27:31.227253: Current learning rate: 0.00911 
2025-07-11 18:28:39.718676: train_loss -0.9636 
2025-07-11 18:28:39.720062: val_loss -0.9344 
2025-07-11 18:28:39.721215: Pseudo dice [np.float32(0.939)] 
2025-07-11 18:28:39.722556: Epoch time: 68.5 s 
2025-07-11 18:28:40.631598:  
2025-07-11 18:28:40.633915: Epoch 99 
2025-07-11 18:28:40.634958: Current learning rate: 0.0091 
2025-07-11 18:29:49.272098: train_loss -0.964 
2025-07-11 18:29:49.274247: val_loss -0.9341 
2025-07-11 18:29:49.275655: Pseudo dice [np.float32(0.9374)] 
2025-07-11 18:29:49.276798: Epoch time: 68.64 s 
2025-07-11 18:29:51.345311:  
2025-07-11 18:29:51.347246: Epoch 100 
2025-07-11 18:29:51.348491: Current learning rate: 0.0091 
2025-07-11 18:31:00.070294: train_loss -0.9633 
2025-07-11 18:31:00.071706: val_loss -0.9241 
2025-07-11 18:31:00.073042: Pseudo dice [np.float32(0.9276)] 
2025-07-11 18:31:00.074147: Epoch time: 68.73 s 
2025-07-11 18:31:00.999322:  
2025-07-11 18:31:01.001720: Epoch 101 
2025-07-11 18:31:01.003387: Current learning rate: 0.00909 
2025-07-11 18:32:09.416385: train_loss -0.9626 
2025-07-11 18:32:09.418249: val_loss -0.9345 
2025-07-11 18:32:09.419599: Pseudo dice [np.float32(0.9382)] 
2025-07-11 18:32:09.420624: Epoch time: 68.42 s 
2025-07-11 18:32:10.344220:  
2025-07-11 18:32:10.346272: Epoch 102 
2025-07-11 18:32:10.347324: Current learning rate: 0.00908 
2025-07-11 18:33:18.862377: train_loss -0.9634 
2025-07-11 18:33:18.863890: val_loss -0.9396 
2025-07-11 18:33:18.864840: Pseudo dice [np.float32(0.9436)] 
2025-07-11 18:33:18.866348: Epoch time: 68.52 s 
2025-07-11 18:33:19.798766:  
2025-07-11 18:33:19.800823: Epoch 103 
2025-07-11 18:33:19.802043: Current learning rate: 0.00907 
2025-07-11 18:34:28.261299: train_loss -0.9634 
2025-07-11 18:34:28.262497: val_loss -0.9353 
2025-07-11 18:34:28.263725: Pseudo dice [np.float32(0.939)] 
2025-07-11 18:34:28.264817: Epoch time: 68.47 s 
2025-07-11 18:34:29.438418:  
2025-07-11 18:34:29.440664: Epoch 104 
2025-07-11 18:34:29.441577: Current learning rate: 0.00906 
2025-07-11 18:35:37.873303: train_loss -0.9629 
2025-07-11 18:35:37.874755: val_loss -0.9357 
2025-07-11 18:35:37.875808: Pseudo dice [np.float32(0.9402)] 
2025-07-11 18:35:37.877347: Epoch time: 68.44 s 
2025-07-11 18:35:38.805951:  
2025-07-11 18:35:38.807943: Epoch 105 
2025-07-11 18:35:38.809147: Current learning rate: 0.00905 
2025-07-11 18:36:47.266184: train_loss -0.9639 
2025-07-11 18:36:47.267455: val_loss -0.9405 
2025-07-11 18:36:47.268718: Pseudo dice [np.float32(0.945)] 
2025-07-11 18:36:47.269776: Epoch time: 68.46 s 
2025-07-11 18:36:47.271152: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-07-11 18:36:49.500939:  
2025-07-11 18:36:49.502698: Epoch 106 
2025-07-11 18:36:49.503788: Current learning rate: 0.00904 
2025-07-11 18:37:58.016356: train_loss -0.9657 
2025-07-11 18:37:58.017573: val_loss -0.9384 
2025-07-11 18:37:58.019044: Pseudo dice [np.float32(0.9417)] 
2025-07-11 18:37:58.020678: Epoch time: 68.52 s 
2025-07-11 18:37:58.021827: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-07-11 18:38:00.270402:  
2025-07-11 18:38:00.272139: Epoch 107 
2025-07-11 18:38:00.273651: Current learning rate: 0.00903 
2025-07-11 18:39:09.028049: train_loss -0.9647 
2025-07-11 18:39:09.029259: val_loss -0.9349 
2025-07-11 18:39:09.030754: Pseudo dice [np.float32(0.937)] 
2025-07-11 18:39:09.031831: Epoch time: 68.76 s 
2025-07-11 18:39:09.953828:  
2025-07-11 18:39:09.955944: Epoch 108 
2025-07-11 18:39:09.957311: Current learning rate: 0.00902 
2025-07-11 18:40:18.490481: train_loss -0.964 
2025-07-11 18:40:18.491810: val_loss -0.9373 
2025-07-11 18:40:18.493318: Pseudo dice [np.float32(0.9408)] 
2025-07-11 18:40:18.494922: Epoch time: 68.54 s 
2025-07-11 18:40:19.422756:  
2025-07-11 18:40:19.425143: Epoch 109 
2025-07-11 18:40:19.426322: Current learning rate: 0.00901 
2025-07-11 18:41:27.940418: train_loss -0.9629 
2025-07-11 18:41:27.941626: val_loss -0.9317 
2025-07-11 18:41:27.943133: Pseudo dice [np.float32(0.9363)] 
2025-07-11 18:41:27.944279: Epoch time: 68.52 s 
2025-07-11 18:41:28.886188:  
2025-07-11 18:41:28.888105: Epoch 110 
2025-07-11 18:41:28.889274: Current learning rate: 0.009 
2025-07-11 18:42:37.533524: train_loss -0.9636 
2025-07-11 18:42:37.536267: val_loss -0.9287 
2025-07-11 18:42:37.537316: Pseudo dice [np.float32(0.9316)] 
2025-07-11 18:42:37.538429: Epoch time: 68.65 s 
2025-07-11 18:42:38.456999:  
2025-07-11 18:42:38.459091: Epoch 111 
2025-07-11 18:42:38.460258: Current learning rate: 0.009 
2025-07-11 18:43:46.868966: train_loss -0.9647 
2025-07-11 18:43:46.870249: val_loss -0.9363 
2025-07-11 18:43:46.871597: Pseudo dice [np.float32(0.9397)] 
2025-07-11 18:43:46.873606: Epoch time: 68.42 s 
2025-07-11 18:43:47.805088:  
2025-07-11 18:43:47.807592: Epoch 112 
2025-07-11 18:43:47.808832: Current learning rate: 0.00899 
2025-07-11 18:44:56.186823: train_loss -0.9644 
2025-07-11 18:44:56.188537: val_loss -0.9412 
2025-07-11 18:44:56.189917: Pseudo dice [np.float32(0.9434)] 
2025-07-11 18:44:56.191228: Epoch time: 68.39 s 
2025-07-11 18:44:57.129470:  
2025-07-11 18:44:57.131207: Epoch 113 
2025-07-11 18:44:57.133729: Current learning rate: 0.00898 
2025-07-11 18:46:05.512048: train_loss -0.9631 
2025-07-11 18:46:05.513179: val_loss -0.9349 
2025-07-11 18:46:05.514537: Pseudo dice [np.float32(0.9387)] 
2025-07-11 18:46:05.516003: Epoch time: 68.39 s 
2025-07-11 18:46:06.431648:  
2025-07-11 18:46:06.433628: Epoch 114 
2025-07-11 18:46:06.434857: Current learning rate: 0.00897 
2025-07-11 18:47:15.076665: train_loss -0.9636 
2025-07-11 18:47:15.078616: val_loss -0.9392 
2025-07-11 18:47:15.080170: Pseudo dice [np.float32(0.9426)] 
2025-07-11 18:47:15.081584: Epoch time: 68.65 s 
2025-07-11 18:47:15.994233:  
2025-07-11 18:47:15.996040: Epoch 115 
2025-07-11 18:47:15.997144: Current learning rate: 0.00896 
2025-07-11 18:48:24.631100: train_loss -0.9644 
2025-07-11 18:48:24.633427: val_loss -0.931 
2025-07-11 18:48:24.634751: Pseudo dice [np.float32(0.9348)] 
2025-07-11 18:48:24.636713: Epoch time: 68.64 s 
2025-07-11 18:48:25.575858:  
2025-07-11 18:48:25.577746: Epoch 116 
2025-07-11 18:48:25.581129: Current learning rate: 0.00895 
2025-07-11 18:49:34.146620: train_loss -0.9644 
2025-07-11 18:49:34.149706: val_loss -0.9388 
2025-07-11 18:49:34.153049: Pseudo dice [np.float32(0.9424)] 
2025-07-11 18:49:34.155560: Epoch time: 68.57 s 
2025-07-11 18:49:35.096923:  
2025-07-11 18:49:35.099553: Epoch 117 
2025-07-11 18:49:35.101395: Current learning rate: 0.00894 
2025-07-11 18:50:43.749355: train_loss -0.9651 
2025-07-11 18:50:43.751921: val_loss -0.9349 
2025-07-11 18:50:43.754538: Pseudo dice [np.float32(0.9394)] 
2025-07-11 18:50:43.756795: Epoch time: 68.66 s 
2025-07-11 18:50:44.707326:  
2025-07-11 18:50:44.709498: Epoch 118 
2025-07-11 18:50:44.711287: Current learning rate: 0.00893 
2025-07-11 18:51:53.048882: train_loss -0.9627 
2025-07-11 18:51:53.050752: val_loss -0.9307 
2025-07-11 18:51:53.052124: Pseudo dice [np.float32(0.9349)] 
2025-07-11 18:51:53.053664: Epoch time: 68.35 s 
2025-07-11 18:51:53.994003:  
2025-07-11 18:51:53.996443: Epoch 119 
2025-07-11 18:51:53.998806: Current learning rate: 0.00892 
2025-07-11 18:53:02.549219: train_loss -0.9637 
2025-07-11 18:53:02.550908: val_loss -0.9327 
2025-07-11 18:53:02.552103: Pseudo dice [np.float32(0.9371)] 
2025-07-11 18:53:02.553324: Epoch time: 68.56 s 
2025-07-11 18:53:03.448856:  
2025-07-11 18:53:03.451062: Epoch 120 
2025-07-11 18:53:03.452285: Current learning rate: 0.00891 
2025-07-11 18:54:12.094297: train_loss -0.9641 
2025-07-11 18:54:12.095805: val_loss -0.932 
2025-07-11 18:54:12.097367: Pseudo dice [np.float32(0.9348)] 
2025-07-11 18:54:12.098775: Epoch time: 68.65 s 
2025-07-11 18:54:13.030487:  
2025-07-11 18:54:13.032621: Epoch 121 
2025-07-11 18:54:13.033900: Current learning rate: 0.0089 
2025-07-11 18:55:21.516941: train_loss -0.9656 
2025-07-11 18:55:21.518736: val_loss -0.9335 
2025-07-11 18:55:21.519940: Pseudo dice [np.float32(0.9362)] 
2025-07-11 18:55:21.520979: Epoch time: 68.49 s 
2025-07-11 18:55:22.442180:  
2025-07-11 18:55:22.444163: Epoch 122 
2025-07-11 18:55:22.445264: Current learning rate: 0.00889 
2025-07-11 18:56:30.752463: train_loss -0.9644 
2025-07-11 18:56:30.753640: val_loss -0.9354 
2025-07-11 18:56:30.754620: Pseudo dice [np.float32(0.9399)] 
2025-07-11 18:56:30.755615: Epoch time: 68.31 s 
2025-07-11 18:56:31.701088:  
2025-07-11 18:56:31.703549: Epoch 123 
2025-07-11 18:56:31.705297: Current learning rate: 0.00889 
2025-07-11 18:57:40.248039: train_loss -0.9661 
2025-07-11 18:57:40.249562: val_loss -0.9309 
2025-07-11 18:57:40.250677: Pseudo dice [np.float32(0.9338)] 
2025-07-11 18:57:40.251827: Epoch time: 68.55 s 
2025-07-11 18:57:41.189045:  
2025-07-11 18:57:41.191060: Epoch 124 
2025-07-11 18:57:41.192261: Current learning rate: 0.00888 
2025-07-11 18:58:49.950430: train_loss -0.9656 
2025-07-11 18:58:49.952196: val_loss -0.9386 
2025-07-11 18:58:49.953925: Pseudo dice [np.float32(0.9424)] 
2025-07-11 18:58:49.954981: Epoch time: 68.77 s 
2025-07-11 18:58:50.894836:  
2025-07-11 18:58:50.896628: Epoch 125 
2025-07-11 18:58:50.898034: Current learning rate: 0.00887 
2025-07-11 18:59:59.454884: train_loss -0.9654 
2025-07-11 18:59:59.456701: val_loss -0.9332 
2025-07-11 18:59:59.457968: Pseudo dice [np.float32(0.9355)] 
2025-07-11 18:59:59.459442: Epoch time: 68.56 s 
2025-07-11 19:00:00.387284:  
2025-07-11 19:00:00.389264: Epoch 126 
2025-07-11 19:00:00.390386: Current learning rate: 0.00886 
2025-07-11 19:01:08.840936: train_loss -0.9653 
2025-07-11 19:01:08.842526: val_loss -0.9355 
2025-07-11 19:01:08.843574: Pseudo dice [np.float32(0.9386)] 
2025-07-11 19:01:08.844877: Epoch time: 68.46 s 
2025-07-11 19:01:09.766315:  
2025-07-11 19:01:09.768052: Epoch 127 
2025-07-11 19:01:09.769372: Current learning rate: 0.00885 
2025-07-11 19:02:18.309056: train_loss -0.9656 
2025-07-11 19:02:18.310436: val_loss -0.9346 
2025-07-11 19:02:18.311496: Pseudo dice [np.float32(0.9384)] 
2025-07-11 19:02:18.312608: Epoch time: 68.55 s 
2025-07-11 19:02:19.245762:  
2025-07-11 19:02:19.248064: Epoch 128 
2025-07-11 19:02:19.249471: Current learning rate: 0.00884 
2025-07-11 19:03:27.983218: train_loss -0.9642 
2025-07-11 19:03:27.985058: val_loss -0.9371 
2025-07-11 19:03:27.987172: Pseudo dice [np.float32(0.9411)] 
2025-07-11 19:03:27.988312: Epoch time: 68.74 s 
2025-07-11 19:03:28.908516:  
2025-07-11 19:03:28.911174: Epoch 129 
2025-07-11 19:03:28.912728: Current learning rate: 0.00883 
2025-07-11 19:04:37.401196: train_loss -0.9648 
2025-07-11 19:04:37.402525: val_loss -0.9275 
2025-07-11 19:04:37.403963: Pseudo dice [np.float32(0.9315)] 
2025-07-11 19:04:37.405129: Epoch time: 68.5 s 
2025-07-11 19:04:38.352996:  
2025-07-11 19:04:38.355329: Epoch 130 
2025-07-11 19:04:38.356762: Current learning rate: 0.00882 
2025-07-11 19:05:46.794155: train_loss -0.9661 
2025-07-11 19:05:46.795481: val_loss -0.9355 
2025-07-11 19:05:46.796786: Pseudo dice [np.float32(0.9399)] 
2025-07-11 19:05:46.797914: Epoch time: 68.44 s 
2025-07-11 19:05:47.730917:  
2025-07-11 19:05:47.732917: Epoch 131 
2025-07-11 19:05:47.734323: Current learning rate: 0.00881 
2025-07-11 19:06:56.284624: train_loss -0.965 
2025-07-11 19:06:56.285904: val_loss -0.9424 
2025-07-11 19:06:56.287050: Pseudo dice [np.float32(0.946)] 
2025-07-11 19:06:56.289060: Epoch time: 68.56 s 
2025-07-11 19:06:57.241088:  
2025-07-11 19:06:57.243114: Epoch 132 
2025-07-11 19:06:57.244425: Current learning rate: 0.0088 
2025-07-11 19:08:05.764548: train_loss -0.9655 
2025-07-11 19:08:05.765912: val_loss -0.9223 
2025-07-11 19:08:05.766806: Pseudo dice [np.float32(0.9269)] 
2025-07-11 19:08:05.768257: Epoch time: 68.53 s 
2025-07-11 19:08:06.703586:  
2025-07-11 19:08:06.705638: Epoch 133 
2025-07-11 19:08:06.706952: Current learning rate: 0.00879 
2025-07-11 19:09:15.250653: train_loss -0.9663 
2025-07-11 19:09:15.252248: val_loss -0.9376 
2025-07-11 19:09:15.254353: Pseudo dice [np.float32(0.9407)] 
2025-07-11 19:09:15.255878: Epoch time: 68.55 s 
2025-07-11 19:09:16.191931:  
2025-07-11 19:09:16.193864: Epoch 134 
2025-07-11 19:09:16.194915: Current learning rate: 0.00879 
2025-07-11 19:10:24.689520: train_loss -0.967 
2025-07-11 19:10:24.691470: val_loss -0.9396 
2025-07-11 19:10:24.692808: Pseudo dice [np.float32(0.9443)] 
2025-07-11 19:10:24.694234: Epoch time: 68.5 s 
2025-07-11 19:10:25.890350:  
2025-07-11 19:10:25.892347: Epoch 135 
2025-07-11 19:10:25.893605: Current learning rate: 0.00878 
2025-07-11 19:11:34.414984: train_loss -0.9675 
2025-07-11 19:11:34.416299: val_loss -0.9322 
2025-07-11 19:11:34.417461: Pseudo dice [np.float32(0.9348)] 
2025-07-11 19:11:34.418338: Epoch time: 68.53 s 
2025-07-11 19:11:35.338552:  
2025-07-11 19:11:35.341020: Epoch 136 
2025-07-11 19:11:35.342035: Current learning rate: 0.00877 
2025-07-11 19:12:43.796530: train_loss -0.9663 
2025-07-11 19:12:43.797886: val_loss -0.9404 
2025-07-11 19:12:43.799045: Pseudo dice [np.float32(0.9441)] 
2025-07-11 19:12:43.800550: Epoch time: 68.46 s 
2025-07-11 19:12:44.746298:  
2025-07-11 19:12:44.748175: Epoch 137 
2025-07-11 19:12:44.749400: Current learning rate: 0.00876 
2025-07-11 19:13:53.138186: train_loss -0.9649 
2025-07-11 19:13:53.139686: val_loss -0.9337 
2025-07-11 19:13:53.140865: Pseudo dice [np.float32(0.9365)] 
2025-07-11 19:13:53.142010: Epoch time: 68.4 s 
2025-07-11 19:13:54.077034:  
2025-07-11 19:13:54.078951: Epoch 138 
2025-07-11 19:13:54.080295: Current learning rate: 0.00875 
2025-07-11 19:15:02.680100: train_loss -0.9667 
2025-07-11 19:15:02.682066: val_loss -0.9423 
2025-07-11 19:15:02.683333: Pseudo dice [np.float32(0.9459)] 
2025-07-11 19:15:02.684695: Epoch time: 68.61 s 
2025-07-11 19:15:03.706190:  
2025-07-11 19:15:03.708208: Epoch 139 
2025-07-11 19:15:03.709752: Current learning rate: 0.00874 
2025-07-11 19:16:12.071282: train_loss -0.9648 
2025-07-11 19:16:12.073063: val_loss -0.9347 
2025-07-11 19:16:12.074690: Pseudo dice [np.float32(0.9374)] 
2025-07-11 19:16:12.076441: Epoch time: 68.37 s 
2025-07-11 19:16:13.029030:  
2025-07-11 19:16:13.031082: Epoch 140 
2025-07-11 19:16:13.032369: Current learning rate: 0.00873 
2025-07-11 19:17:21.405679: train_loss -0.9659 
2025-07-11 19:17:21.406828: val_loss -0.9252 
2025-07-11 19:17:21.408981: Pseudo dice [np.float32(0.9297)] 
2025-07-11 19:17:21.411252: Epoch time: 68.38 s 
2025-07-11 19:17:22.363223:  
2025-07-11 19:17:22.364948: Epoch 141 
2025-07-11 19:17:22.366521: Current learning rate: 0.00872 
2025-07-11 19:18:30.943473: train_loss -0.9658 
2025-07-11 19:18:30.945323: val_loss -0.9373 
2025-07-11 19:18:30.947159: Pseudo dice [np.float32(0.942)] 
2025-07-11 19:18:30.948488: Epoch time: 68.58 s 
2025-07-11 19:18:32.136279:  
2025-07-11 19:18:32.138460: Epoch 142 
2025-07-11 19:18:32.139495: Current learning rate: 0.00871 
2025-07-11 19:19:40.893921: train_loss -0.9646 
2025-07-11 19:19:40.895331: val_loss -0.9367 
2025-07-11 19:19:40.896562: Pseudo dice [np.float32(0.9418)] 
2025-07-11 19:19:40.898294: Epoch time: 68.76 s 
2025-07-11 19:19:41.856544:  
2025-07-11 19:19:41.858625: Epoch 143 
2025-07-11 19:19:41.859728: Current learning rate: 0.0087 
2025-07-11 19:20:50.504492: train_loss -0.9659 
2025-07-11 19:20:50.506357: val_loss -0.936 
2025-07-11 19:20:50.507503: Pseudo dice [np.float32(0.9393)] 
2025-07-11 19:20:50.508474: Epoch time: 68.65 s 
2025-07-11 19:20:51.403188:  
2025-07-11 19:20:51.405226: Epoch 144 
2025-07-11 19:20:51.406350: Current learning rate: 0.00869 
2025-07-11 19:21:59.953734: train_loss -0.9664 
2025-07-11 19:21:59.955766: val_loss -0.9416 
2025-07-11 19:21:59.957958: Pseudo dice [np.float32(0.9441)] 
2025-07-11 19:21:59.959547: Epoch time: 68.55 s 
2025-07-11 19:21:59.961106: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-07-11 19:22:02.255507:  
2025-07-11 19:22:02.258247: Epoch 145 
2025-07-11 19:22:02.259497: Current learning rate: 0.00868 
2025-07-11 19:23:10.807568: train_loss -0.9667 
2025-07-11 19:23:10.809035: val_loss -0.9366 
2025-07-11 19:23:10.810216: Pseudo dice [np.float32(0.9405)] 
2025-07-11 19:23:10.811348: Epoch time: 68.56 s 
2025-07-11 19:23:10.812528: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-07-11 19:23:13.107736:  
2025-07-11 19:23:13.109993: Epoch 146 
2025-07-11 19:23:13.111190: Current learning rate: 0.00868 
2025-07-11 19:24:21.549494: train_loss -0.9657 
2025-07-11 19:24:21.551214: val_loss -0.9361 
2025-07-11 19:24:21.552285: Pseudo dice [np.float32(0.939)] 
2025-07-11 19:24:21.553491: Epoch time: 68.45 s 
2025-07-11 19:24:22.501654:  
2025-07-11 19:24:22.504186: Epoch 147 
2025-07-11 19:24:22.505880: Current learning rate: 0.00867 
2025-07-11 19:25:30.977657: train_loss -0.9678 
2025-07-11 19:25:30.979146: val_loss -0.9403 
2025-07-11 19:25:30.980581: Pseudo dice [np.float32(0.9434)] 
2025-07-11 19:25:30.982209: Epoch time: 68.48 s 
2025-07-11 19:25:30.984290: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-07-11 19:25:33.305407:  
2025-07-11 19:25:33.307836: Epoch 148 
2025-07-11 19:25:33.309214: Current learning rate: 0.00866 
2025-07-11 19:26:41.941028: train_loss -0.966 
2025-07-11 19:26:41.942277: val_loss -0.9388 
2025-07-11 19:26:41.943494: Pseudo dice [np.float32(0.9415)] 
2025-07-11 19:26:41.944597: Epoch time: 68.64 s 
2025-07-11 19:26:41.946138: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-07-11 19:26:44.482431:  
2025-07-11 19:26:44.484648: Epoch 149 
2025-07-11 19:26:44.485960: Current learning rate: 0.00865 
2025-07-11 19:27:52.996750: train_loss -0.9645 
2025-07-11 19:27:52.998108: val_loss -0.9297 
2025-07-11 19:27:52.999552: Pseudo dice [np.float32(0.9311)] 
2025-07-11 19:27:53.001031: Epoch time: 68.52 s 
2025-07-11 19:27:55.459033:  
2025-07-11 19:27:55.460906: Epoch 150 
2025-07-11 19:27:55.462215: Current learning rate: 0.00864 
2025-07-11 19:29:03.904413: train_loss -0.9655 
2025-07-11 19:29:03.906101: val_loss -0.9296 
2025-07-11 19:29:03.907219: Pseudo dice [np.float32(0.9326)] 
2025-07-11 19:29:03.908858: Epoch time: 68.45 s 
2025-07-11 19:29:04.857309:  
2025-07-11 19:29:04.859501: Epoch 151 
2025-07-11 19:29:04.860841: Current learning rate: 0.00863 
2025-07-11 19:30:13.558651: train_loss -0.9644 
2025-07-11 19:30:13.560586: val_loss -0.9297 
2025-07-11 19:30:13.561819: Pseudo dice [np.float32(0.9329)] 
2025-07-11 19:30:13.563326: Epoch time: 68.7 s 
2025-07-11 19:30:14.515735:  
2025-07-11 19:30:14.517632: Epoch 152 
2025-07-11 19:30:14.518816: Current learning rate: 0.00862 
2025-07-11 19:31:23.018774: train_loss -0.966 
2025-07-11 19:31:23.020313: val_loss -0.9371 
2025-07-11 19:31:23.021485: Pseudo dice [np.float32(0.9411)] 
2025-07-11 19:31:23.023231: Epoch time: 68.51 s 
2025-07-11 19:31:23.989412:  
2025-07-11 19:31:23.991513: Epoch 153 
2025-07-11 19:31:23.992577: Current learning rate: 0.00861 
2025-07-11 19:32:32.508584: train_loss -0.9652 
2025-07-11 19:32:32.510264: val_loss -0.9361 
2025-07-11 19:32:32.511886: Pseudo dice [np.float32(0.9423)] 
2025-07-11 19:32:32.512989: Epoch time: 68.52 s 
2025-07-11 19:32:33.478282:  
2025-07-11 19:32:33.480563: Epoch 154 
2025-07-11 19:32:33.482172: Current learning rate: 0.0086 
2025-07-11 19:33:41.895655: train_loss -0.9629 
2025-07-11 19:33:41.897482: val_loss -0.9341 
2025-07-11 19:33:41.898715: Pseudo dice [np.float32(0.9388)] 
2025-07-11 19:33:41.899784: Epoch time: 68.42 s 
2025-07-11 19:33:42.868152:  
2025-07-11 19:33:42.870249: Epoch 155 
2025-07-11 19:33:42.871539: Current learning rate: 0.00859 
2025-07-11 19:34:51.323586: train_loss -0.9665 
2025-07-11 19:34:51.325017: val_loss -0.9375 
2025-07-11 19:34:51.325980: Pseudo dice [np.float32(0.9404)] 
2025-07-11 19:34:51.327161: Epoch time: 68.46 s 
2025-07-11 19:34:52.301623:  
2025-07-11 19:34:52.303730: Epoch 156 
2025-07-11 19:34:52.305182: Current learning rate: 0.00858 
2025-07-11 19:36:00.528019: train_loss -0.9664 
2025-07-11 19:36:00.531131: val_loss -0.9352 
2025-07-11 19:36:00.532316: Pseudo dice [np.float32(0.9395)] 
2025-07-11 19:36:00.533813: Epoch time: 68.23 s 
2025-07-11 19:36:01.480906:  
2025-07-11 19:36:01.483185: Epoch 157 
2025-07-11 19:36:01.485163: Current learning rate: 0.00858 
2025-07-11 19:37:09.848396: train_loss -0.9665 
2025-07-11 19:37:09.850164: val_loss -0.9369 
2025-07-11 19:37:09.851309: Pseudo dice [np.float32(0.9406)] 
2025-07-11 19:37:09.852480: Epoch time: 68.37 s 
2025-07-11 19:37:10.812090:  
2025-07-11 19:37:10.814208: Epoch 158 
2025-07-11 19:37:10.815757: Current learning rate: 0.00857 
2025-07-11 19:38:19.318079: train_loss -0.9664 
2025-07-11 19:38:19.319679: val_loss -0.9327 
2025-07-11 19:38:19.321291: Pseudo dice [np.float32(0.9359)] 
2025-07-11 19:38:19.323022: Epoch time: 68.51 s 
2025-07-11 19:38:20.265204:  
2025-07-11 19:38:20.267504: Epoch 159 
2025-07-11 19:38:20.268670: Current learning rate: 0.00856 
2025-07-11 19:39:28.785395: train_loss -0.966 
2025-07-11 19:39:28.787169: val_loss -0.941 
2025-07-11 19:39:28.788198: Pseudo dice [np.float32(0.9442)] 
2025-07-11 19:39:28.789509: Epoch time: 68.52 s 
2025-07-11 19:39:29.738684:  
2025-07-11 19:39:29.740858: Epoch 160 
2025-07-11 19:39:29.741999: Current learning rate: 0.00855 
2025-07-11 19:40:38.154869: train_loss -0.9654 
2025-07-11 19:40:38.156628: val_loss -0.9325 
2025-07-11 19:40:38.158064: Pseudo dice [np.float32(0.9358)] 
2025-07-11 19:40:38.159310: Epoch time: 68.42 s 
2025-07-11 19:40:39.100593:  
2025-07-11 19:40:39.102548: Epoch 161 
2025-07-11 19:40:39.103816: Current learning rate: 0.00854 
2025-07-11 19:41:47.502131: train_loss -0.9682 
2025-07-11 19:41:47.503318: val_loss -0.9337 
2025-07-11 19:41:47.504635: Pseudo dice [np.float32(0.9367)] 
2025-07-11 19:41:47.506016: Epoch time: 68.41 s 
2025-07-11 19:41:48.703269:  
2025-07-11 19:41:48.705205: Epoch 162 
2025-07-11 19:41:48.706340: Current learning rate: 0.00853 
2025-07-11 19:42:57.349328: train_loss -0.9689 
2025-07-11 19:42:57.350496: val_loss -0.9411 
2025-07-11 19:42:57.352335: Pseudo dice [np.float32(0.9459)] 
2025-07-11 19:42:57.353665: Epoch time: 68.65 s 
2025-07-11 19:42:58.318263:  
2025-07-11 19:42:58.320336: Epoch 163 
2025-07-11 19:42:58.321497: Current learning rate: 0.00852 
2025-07-11 19:44:06.865668: train_loss -0.9651 
2025-07-11 19:44:06.867157: val_loss -0.9367 
2025-07-11 19:44:06.868143: Pseudo dice [np.float32(0.9404)] 
2025-07-11 19:44:06.869308: Epoch time: 68.55 s 
2025-07-11 19:44:07.829133:  
2025-07-11 19:44:07.831307: Epoch 164 
2025-07-11 19:44:07.832654: Current learning rate: 0.00851 
2025-07-11 19:45:16.291627: train_loss -0.9648 
2025-07-11 19:45:16.293763: val_loss -0.928 
2025-07-11 19:45:16.294857: Pseudo dice [np.float32(0.9319)] 
2025-07-11 19:45:16.295875: Epoch time: 68.47 s 
2025-07-11 19:45:17.259326:  
2025-07-11 19:45:17.261767: Epoch 165 
2025-07-11 19:45:17.263192: Current learning rate: 0.0085 
2025-07-11 19:46:25.878355: train_loss -0.965 
2025-07-11 19:46:25.879553: val_loss -0.9253 
2025-07-11 19:46:25.880768: Pseudo dice [np.float32(0.9302)] 
2025-07-11 19:46:25.881857: Epoch time: 68.62 s 
2025-07-11 19:46:26.823693:  
2025-07-11 19:46:26.825558: Epoch 166 
2025-07-11 19:46:26.826642: Current learning rate: 0.00849 
2025-07-11 19:47:35.364449: train_loss -0.9651 
2025-07-11 19:47:35.367177: val_loss -0.9314 
2025-07-11 19:47:35.368582: Pseudo dice [np.float32(0.9332)] 
2025-07-11 19:47:35.370235: Epoch time: 68.54 s 
2025-07-11 19:47:36.294712:  
2025-07-11 19:47:36.296795: Epoch 167 
2025-07-11 19:47:36.298226: Current learning rate: 0.00848 
2025-07-11 19:48:44.867463: train_loss -0.9668 
2025-07-11 19:48:44.868896: val_loss -0.9353 
2025-07-11 19:48:44.870403: Pseudo dice [np.float32(0.9373)] 
2025-07-11 19:48:44.871898: Epoch time: 68.58 s 
2025-07-11 19:48:45.824617:  
2025-07-11 19:48:45.826754: Epoch 168 
2025-07-11 19:48:45.827883: Current learning rate: 0.00847 
2025-07-11 19:49:54.382378: train_loss -0.9675 
2025-07-11 19:49:54.383985: val_loss -0.9381 
2025-07-11 19:49:54.385423: Pseudo dice [np.float32(0.941)] 
2025-07-11 19:49:54.386496: Epoch time: 68.56 s 
2025-07-11 19:49:55.564660:  
2025-07-11 19:49:55.566482: Epoch 169 
2025-07-11 19:49:55.567834: Current learning rate: 0.00847 
2025-07-11 19:51:04.009134: train_loss -0.9664 
2025-07-11 19:51:04.010492: val_loss -0.9367 
2025-07-11 19:51:04.011684: Pseudo dice [np.float32(0.9396)] 
2025-07-11 19:51:04.012829: Epoch time: 68.45 s 
2025-07-11 19:51:04.981845:  
2025-07-11 19:51:04.983581: Epoch 170 
2025-07-11 19:51:04.984718: Current learning rate: 0.00846 
2025-07-11 19:52:13.286231: train_loss -0.966 
2025-07-11 19:52:13.287675: val_loss -0.9405 
2025-07-11 19:52:13.289228: Pseudo dice [np.float32(0.9415)] 
2025-07-11 19:52:13.290523: Epoch time: 68.31 s 
2025-07-11 19:52:14.240633:  
2025-07-11 19:52:14.242961: Epoch 171 
2025-07-11 19:52:14.244270: Current learning rate: 0.00845 
2025-07-11 19:53:22.545290: train_loss -0.9672 
2025-07-11 19:53:22.546965: val_loss -0.935 
2025-07-11 19:53:22.548794: Pseudo dice [np.float32(0.9375)] 
2025-07-11 19:53:22.550384: Epoch time: 68.31 s 
2025-07-11 19:53:23.521868:  
2025-07-11 19:53:23.523765: Epoch 172 
2025-07-11 19:53:23.525342: Current learning rate: 0.00844 
2025-07-11 19:54:32.204448: train_loss -0.967 
2025-07-11 19:54:32.206164: val_loss -0.9227 
2025-07-11 19:54:32.207646: Pseudo dice [np.float32(0.9269)] 
2025-07-11 19:54:32.208861: Epoch time: 68.69 s 
2025-07-11 19:54:33.183887:  
2025-07-11 19:54:33.186095: Epoch 173 
2025-07-11 19:54:33.187309: Current learning rate: 0.00843 
2025-07-11 19:55:41.782902: train_loss -0.9681 
2025-07-11 19:55:41.784235: val_loss -0.9358 
2025-07-11 19:55:41.785753: Pseudo dice [np.float32(0.9396)] 
2025-07-11 19:55:41.787276: Epoch time: 68.6 s 
2025-07-11 19:55:42.741196:  
2025-07-11 19:55:42.743588: Epoch 174 
2025-07-11 19:55:42.745652: Current learning rate: 0.00842 
2025-07-11 19:56:51.503848: train_loss -0.9661 
2025-07-11 19:56:51.505371: val_loss -0.9334 
2025-07-11 19:56:51.506453: Pseudo dice [np.float32(0.9346)] 
2025-07-11 19:56:51.507607: Epoch time: 68.77 s 
2025-07-11 19:56:52.473054:  
2025-07-11 19:56:52.475122: Epoch 175 
2025-07-11 19:56:52.476214: Current learning rate: 0.00841 
2025-07-11 19:58:01.196254: train_loss -0.9678 
2025-07-11 19:58:01.197643: val_loss -0.9443 
2025-07-11 19:58:01.198957: Pseudo dice [np.float32(0.9476)] 
2025-07-11 19:58:01.201654: Epoch time: 68.73 s 
2025-07-11 19:58:02.397144:  
2025-07-11 19:58:02.398839: Epoch 176 
2025-07-11 19:58:02.400174: Current learning rate: 0.0084 
2025-07-11 19:59:11.143222: train_loss -0.9674 
2025-07-11 19:59:11.144901: val_loss -0.9383 
2025-07-11 19:59:11.146253: Pseudo dice [np.float32(0.9413)] 
2025-07-11 19:59:11.147338: Epoch time: 68.75 s 
2025-07-11 19:59:12.088495:  
2025-07-11 19:59:12.090507: Epoch 177 
2025-07-11 19:59:12.091859: Current learning rate: 0.00839 
2025-07-11 20:00:20.725653: train_loss -0.9675 
2025-07-11 20:00:20.727613: val_loss -0.9256 
2025-07-11 20:00:20.728758: Pseudo dice [np.float32(0.9276)] 
2025-07-11 20:00:20.729931: Epoch time: 68.64 s 
2025-07-11 20:00:21.657849:  
2025-07-11 20:00:21.659868: Epoch 178 
2025-07-11 20:00:21.661036: Current learning rate: 0.00838 
2025-07-11 20:01:30.487901: train_loss -0.9681 
2025-07-11 20:01:30.489796: val_loss -0.9353 
2025-07-11 20:01:30.490988: Pseudo dice [np.float32(0.9395)] 
2025-07-11 20:01:30.492376: Epoch time: 68.83 s 
2025-07-11 20:01:31.433290:  
2025-07-11 20:01:31.435269: Epoch 179 
2025-07-11 20:01:31.436588: Current learning rate: 0.00837 
2025-07-11 20:02:40.019351: train_loss -0.9665 
2025-07-11 20:02:40.021124: val_loss -0.9303 
2025-07-11 20:02:40.022511: Pseudo dice [np.float32(0.934)] 
2025-07-11 20:02:40.023970: Epoch time: 68.59 s 
2025-07-11 20:02:40.980845:  
2025-07-11 20:02:40.983197: Epoch 180 
2025-07-11 20:02:40.985189: Current learning rate: 0.00836 
2025-07-11 20:03:49.490593: train_loss -0.9666 
2025-07-11 20:03:49.492209: val_loss -0.9384 
2025-07-11 20:03:49.493570: Pseudo dice [np.float32(0.9405)] 
2025-07-11 20:03:49.494820: Epoch time: 68.51 s 
2025-07-11 20:03:50.422466:  
2025-07-11 20:03:50.424646: Epoch 181 
2025-07-11 20:03:50.426209: Current learning rate: 0.00836 
2025-07-11 20:04:58.909603: train_loss -0.9675 
2025-07-11 20:04:58.910872: val_loss -0.9412 
2025-07-11 20:04:58.912269: Pseudo dice [np.float32(0.9445)] 
2025-07-11 20:04:58.914186: Epoch time: 68.49 s 
2025-07-11 20:04:59.896043:  
2025-07-11 20:04:59.898394: Epoch 182 
2025-07-11 20:04:59.900258: Current learning rate: 0.00835 
2025-07-11 20:06:08.614940: train_loss -0.9665 
2025-07-11 20:06:08.616332: val_loss -0.9358 
2025-07-11 20:06:08.617623: Pseudo dice [np.float32(0.9389)] 
2025-07-11 20:06:08.618515: Epoch time: 68.72 s 
2025-07-11 20:06:09.555056:  
2025-07-11 20:06:09.556969: Epoch 183 
2025-07-11 20:06:09.558024: Current learning rate: 0.00834 
2025-07-11 20:07:17.975728: train_loss -0.9663 
2025-07-11 20:07:17.976944: val_loss -0.9395 
2025-07-11 20:07:17.979114: Pseudo dice [np.float32(0.9436)] 
2025-07-11 20:07:17.980362: Epoch time: 68.42 s 
2025-07-11 20:07:18.936228:  
2025-07-11 20:07:18.938850: Epoch 184 
2025-07-11 20:07:18.940042: Current learning rate: 0.00833 
2025-07-11 20:08:27.306051: train_loss -0.9677 
2025-07-11 20:08:27.307863: val_loss -0.9472 
2025-07-11 20:08:27.309142: Pseudo dice [np.float32(0.9503)] 
2025-07-11 20:08:27.310690: Epoch time: 68.37 s 
2025-07-11 20:08:28.271804:  
2025-07-11 20:08:28.273753: Epoch 185 
2025-07-11 20:08:28.274813: Current learning rate: 0.00832 
2025-07-11 20:09:36.709189: train_loss -0.9683 
2025-07-11 20:09:36.710513: val_loss -0.9377 
2025-07-11 20:09:36.712253: Pseudo dice [np.float32(0.9403)] 
2025-07-11 20:09:36.713170: Epoch time: 68.44 s 
2025-07-11 20:09:37.671153:  
2025-07-11 20:09:37.673250: Epoch 186 
2025-07-11 20:09:37.674708: Current learning rate: 0.00831 
2025-07-11 20:10:46.248900: train_loss -0.9669 
2025-07-11 20:10:46.250626: val_loss -0.9397 
2025-07-11 20:10:46.251752: Pseudo dice [np.float32(0.944)] 
2025-07-11 20:10:46.253509: Epoch time: 68.58 s 
2025-07-11 20:10:46.254697: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-07-11 20:10:48.594815:  
2025-07-11 20:10:48.596857: Epoch 187 
2025-07-11 20:10:48.598201: Current learning rate: 0.0083 
2025-07-11 20:11:56.953213: train_loss -0.9674 
2025-07-11 20:11:56.954568: val_loss -0.9428 
2025-07-11 20:11:56.956245: Pseudo dice [np.float32(0.9455)] 
2025-07-11 20:11:56.957515: Epoch time: 68.36 s 
2025-07-11 20:11:56.958622: Yayy! New best EMA pseudo Dice: 0.9409000277519226 
2025-07-11 20:11:59.263175:  
2025-07-11 20:11:59.265297: Epoch 188 
2025-07-11 20:11:59.266592: Current learning rate: 0.00829 
2025-07-11 20:13:07.634201: train_loss -0.9671 
2025-07-11 20:13:07.635404: val_loss -0.9379 
2025-07-11 20:13:07.636507: Pseudo dice [np.float32(0.9417)] 
2025-07-11 20:13:07.637341: Epoch time: 68.37 s 
2025-07-11 20:13:07.638527: Yayy! New best EMA pseudo Dice: 0.9409999847412109 
2025-07-11 20:13:09.963210:  
2025-07-11 20:13:09.964945: Epoch 189 
2025-07-11 20:13:09.966292: Current learning rate: 0.00828 
2025-07-11 20:14:18.608630: train_loss -0.9675 
2025-07-11 20:14:18.610243: val_loss -0.941 
2025-07-11 20:14:18.611132: Pseudo dice [np.float32(0.9445)] 
2025-07-11 20:14:18.612316: Epoch time: 68.65 s 
2025-07-11 20:14:18.614068: Yayy! New best EMA pseudo Dice: 0.9413999915122986 
2025-07-11 20:14:20.945857:  
2025-07-11 20:14:20.947839: Epoch 190 
2025-07-11 20:14:20.949029: Current learning rate: 0.00827 
2025-07-11 20:15:29.434094: train_loss -0.9668 
2025-07-11 20:15:29.435537: val_loss -0.9358 
2025-07-11 20:15:29.437217: Pseudo dice [np.float32(0.9381)] 
2025-07-11 20:15:29.438475: Epoch time: 68.49 s 
2025-07-11 20:15:30.397926:  
2025-07-11 20:15:30.400012: Epoch 191 
2025-07-11 20:15:30.401212: Current learning rate: 0.00826 
2025-07-11 20:16:39.012184: train_loss -0.9685 
2025-07-11 20:16:39.013408: val_loss -0.9337 
2025-07-11 20:16:39.014616: Pseudo dice [np.float32(0.9365)] 
2025-07-11 20:16:39.015796: Epoch time: 68.62 s 
2025-07-11 20:16:39.980722:  
2025-07-11 20:16:39.983076: Epoch 192 
2025-07-11 20:16:39.984302: Current learning rate: 0.00825 
2025-07-11 20:17:48.508012: train_loss -0.9675 
2025-07-11 20:17:48.509409: val_loss -0.9356 
2025-07-11 20:17:48.511023: Pseudo dice [np.float32(0.9394)] 
2025-07-11 20:17:48.512271: Epoch time: 68.53 s 
2025-07-11 20:17:49.479007:  
2025-07-11 20:17:49.481220: Epoch 193 
2025-07-11 20:17:49.482687: Current learning rate: 0.00824 
2025-07-11 20:18:57.933519: train_loss -0.9673 
2025-07-11 20:18:57.935008: val_loss -0.9435 
2025-07-11 20:18:57.936184: Pseudo dice [np.float32(0.9477)] 
2025-07-11 20:18:57.937495: Epoch time: 68.46 s 
2025-07-11 20:18:58.926543:  
2025-07-11 20:18:58.929058: Epoch 194 
2025-07-11 20:18:58.930180: Current learning rate: 0.00824 
2025-07-11 20:20:07.284833: train_loss -0.9678 
2025-07-11 20:20:07.285991: val_loss -0.9395 
2025-07-11 20:20:07.287189: Pseudo dice [np.float32(0.9434)] 
2025-07-11 20:20:07.288785: Epoch time: 68.36 s 
2025-07-11 20:20:07.290262: Yayy! New best EMA pseudo Dice: 0.9413999915122986 
2025-07-11 20:20:09.804650:  
2025-07-11 20:20:09.806893: Epoch 195 
2025-07-11 20:20:09.808018: Current learning rate: 0.00823 
2025-07-11 20:21:18.185442: train_loss -0.9686 
2025-07-11 20:21:18.186892: val_loss -0.9425 
2025-07-11 20:21:18.188193: Pseudo dice [np.float32(0.946)] 
2025-07-11 20:21:18.189663: Epoch time: 68.38 s 
2025-07-11 20:21:18.191698: Yayy! New best EMA pseudo Dice: 0.9419000148773193 
2025-07-11 20:21:20.952092:  
2025-07-11 20:21:20.954328: Epoch 196 
2025-07-11 20:21:20.956039: Current learning rate: 0.00822 
2025-07-11 20:22:29.243168: train_loss -0.9687 
2025-07-11 20:22:29.245083: val_loss -0.9426 
2025-07-11 20:22:29.247143: Pseudo dice [np.float32(0.9455)] 
2025-07-11 20:22:29.249172: Epoch time: 68.29 s 
2025-07-11 20:22:29.252471: Yayy! New best EMA pseudo Dice: 0.9422000050544739 
2025-07-11 20:22:31.623049:  
2025-07-11 20:22:31.625044: Epoch 197 
2025-07-11 20:22:31.626441: Current learning rate: 0.00821 
2025-07-11 20:23:39.888950: train_loss -0.9682 
2025-07-11 20:23:39.891395: val_loss -0.9383 
2025-07-11 20:23:39.893651: Pseudo dice [np.float32(0.9404)] 
2025-07-11 20:23:39.895940: Epoch time: 68.27 s 
2025-07-11 20:23:40.850079:  
2025-07-11 20:23:40.852138: Epoch 198 
2025-07-11 20:23:40.853440: Current learning rate: 0.0082 
2025-07-11 20:24:49.166074: train_loss -0.9683 
2025-07-11 20:24:49.167581: val_loss -0.9384 
2025-07-11 20:24:49.169624: Pseudo dice [np.float32(0.942)] 
2025-07-11 20:24:49.171621: Epoch time: 68.32 s 
2025-07-11 20:24:50.159173:  
2025-07-11 20:24:50.160393: Epoch 199 
2025-07-11 20:24:50.161641: Current learning rate: 0.00819 
2025-07-11 20:25:58.773292: train_loss -0.9688 
2025-07-11 20:25:58.775793: val_loss -0.9387 
2025-07-11 20:25:58.777196: Pseudo dice [np.float32(0.9415)] 
2025-07-11 20:25:58.778712: Epoch time: 68.62 s 
2025-07-11 20:26:01.250582:  
2025-07-11 20:26:01.252577: Epoch 200 
2025-07-11 20:26:01.254029: Current learning rate: 0.00818 
2025-07-11 20:27:09.745639: train_loss -0.9687 
2025-07-11 20:27:09.747367: val_loss -0.9428 
2025-07-11 20:27:09.748669: Pseudo dice [np.float32(0.946)] 
2025-07-11 20:27:09.749875: Epoch time: 68.5 s 
2025-07-11 20:27:09.750859: Yayy! New best EMA pseudo Dice: 0.9423999786376953 
2025-07-11 20:27:12.069977:  
2025-07-11 20:27:12.072065: Epoch 201 
2025-07-11 20:27:12.073073: Current learning rate: 0.00817 
2025-07-11 20:28:20.427024: train_loss -0.9686 
2025-07-11 20:28:20.428917: val_loss -0.9363 
2025-07-11 20:28:20.430116: Pseudo dice [np.float32(0.9395)] 
2025-07-11 20:28:20.431362: Epoch time: 68.36 s 
2025-07-11 20:28:21.392171:  
2025-07-11 20:28:21.394190: Epoch 202 
2025-07-11 20:28:21.396460: Current learning rate: 0.00816 
2025-07-11 20:29:29.839074: train_loss -0.9691 
2025-07-11 20:29:29.840909: val_loss -0.931 
2025-07-11 20:29:29.842950: Pseudo dice [np.float32(0.9315)] 
2025-07-11 20:29:29.844198: Epoch time: 68.45 s 
2025-07-11 20:29:30.819514:  
2025-07-11 20:29:30.821517: Epoch 203 
2025-07-11 20:29:30.822866: Current learning rate: 0.00815 
2025-07-11 20:30:39.315925: train_loss -0.9683 
2025-07-11 20:30:39.317643: val_loss -0.9417 
2025-07-11 20:30:39.318712: Pseudo dice [np.float32(0.946)] 
2025-07-11 20:30:39.320046: Epoch time: 68.5 s 
2025-07-11 20:30:40.265756:  
2025-07-11 20:30:40.268126: Epoch 204 
2025-07-11 20:30:40.269421: Current learning rate: 0.00814 
2025-07-11 20:31:48.922734: train_loss -0.9673 
2025-07-11 20:31:48.924265: val_loss -0.9318 
2025-07-11 20:31:48.925449: Pseudo dice [np.float32(0.9351)] 
2025-07-11 20:31:48.927268: Epoch time: 68.66 s 
2025-07-11 20:31:49.897857:  
2025-07-11 20:31:49.900185: Epoch 205 
2025-07-11 20:31:49.901380: Current learning rate: 0.00813 
2025-07-11 20:32:58.720472: train_loss -0.9681 
2025-07-11 20:32:58.722236: val_loss -0.9313 
2025-07-11 20:32:58.723598: Pseudo dice [np.float32(0.9338)] 
2025-07-11 20:32:58.724845: Epoch time: 68.83 s 
2025-07-11 20:32:59.646137:  
2025-07-11 20:32:59.648483: Epoch 206 
2025-07-11 20:32:59.650020: Current learning rate: 0.00813 
2025-07-11 20:34:08.165221: train_loss -0.966 
2025-07-11 20:34:08.166532: val_loss -0.9403 
2025-07-11 20:34:08.167893: Pseudo dice [np.float32(0.9429)] 
2025-07-11 20:34:08.169029: Epoch time: 68.52 s 
2025-07-11 20:34:09.093284:  
2025-07-11 20:34:09.095567: Epoch 207 
2025-07-11 20:34:09.096658: Current learning rate: 0.00812 
2025-07-11 20:35:17.867454: train_loss -0.9672 
2025-07-11 20:35:17.868620: val_loss -0.9381 
2025-07-11 20:35:17.869607: Pseudo dice [np.float32(0.9394)] 
2025-07-11 20:35:17.870527: Epoch time: 68.78 s 
2025-07-11 20:35:18.805731:  
2025-07-11 20:35:18.807599: Epoch 208 
2025-07-11 20:35:18.808938: Current learning rate: 0.00811 
2025-07-11 20:36:27.544543: train_loss -0.968 
2025-07-11 20:36:27.546323: val_loss -0.932 
2025-07-11 20:36:27.547510: Pseudo dice [np.float32(0.9362)] 
2025-07-11 20:36:27.549115: Epoch time: 68.74 s 
2025-07-11 20:36:28.480459:  
2025-07-11 20:36:28.483010: Epoch 209 
2025-07-11 20:36:28.484376: Current learning rate: 0.0081 
2025-07-11 20:37:37.361631: train_loss -0.9697 
2025-07-11 20:37:37.363251: val_loss -0.9334 
2025-07-11 20:37:37.364453: Pseudo dice [np.float32(0.9363)] 
2025-07-11 20:37:37.366045: Epoch time: 68.88 s 
2025-07-11 20:37:38.293109:  
2025-07-11 20:37:38.295235: Epoch 210 
2025-07-11 20:37:38.296318: Current learning rate: 0.00809 
2025-07-11 20:38:46.656847: train_loss -0.9685 
2025-07-11 20:38:46.658399: val_loss -0.9398 
2025-07-11 20:38:46.659692: Pseudo dice [np.float32(0.9428)] 
2025-07-11 20:38:46.661145: Epoch time: 68.37 s 
2025-07-11 20:38:47.601012:  
2025-07-11 20:38:47.602830: Epoch 211 
2025-07-11 20:38:47.604016: Current learning rate: 0.00808 
2025-07-11 20:39:55.988178: train_loss -0.9673 
2025-07-11 20:39:55.989592: val_loss -0.9409 
2025-07-11 20:39:55.991089: Pseudo dice [np.float32(0.9431)] 
2025-07-11 20:39:55.993151: Epoch time: 68.39 s 
2025-07-11 20:39:56.939274:  
2025-07-11 20:39:56.941479: Epoch 212 
2025-07-11 20:39:56.942803: Current learning rate: 0.00807 
2025-07-11 20:41:05.740157: train_loss -0.9688 
2025-07-11 20:41:05.741244: val_loss -0.9415 
2025-07-11 20:41:05.742424: Pseudo dice [np.float32(0.9443)] 
2025-07-11 20:41:05.743788: Epoch time: 68.8 s 
2025-07-11 20:41:06.676928:  
2025-07-11 20:41:06.679185: Epoch 213 
2025-07-11 20:41:06.680438: Current learning rate: 0.00806 
2025-07-11 20:42:15.335604: train_loss -0.9691 
2025-07-11 20:42:15.338018: val_loss -0.9391 
2025-07-11 20:42:15.339107: Pseudo dice [np.float32(0.9418)] 
2025-07-11 20:42:15.340605: Epoch time: 68.66 s 
2025-07-11 20:42:16.263756:  
2025-07-11 20:42:16.265937: Epoch 214 
2025-07-11 20:42:16.267162: Current learning rate: 0.00805 
2025-07-11 20:43:24.823346: train_loss -0.9688 
2025-07-11 20:43:24.825018: val_loss -0.9337 
2025-07-11 20:43:24.826174: Pseudo dice [np.float32(0.9367)] 
2025-07-11 20:43:24.828095: Epoch time: 68.56 s 
2025-07-11 20:43:26.063117:  
2025-07-11 20:43:26.065386: Epoch 215 
2025-07-11 20:43:26.066736: Current learning rate: 0.00804 
2025-07-11 20:44:34.654130: train_loss -0.9693 
2025-07-11 20:44:34.655398: val_loss -0.9356 
2025-07-11 20:44:34.656570: Pseudo dice [np.float32(0.9393)] 
2025-07-11 20:44:34.657755: Epoch time: 68.59 s 
2025-07-11 20:44:35.580898:  
2025-07-11 20:44:35.583565: Epoch 216 
2025-07-11 20:44:35.584606: Current learning rate: 0.00803 
2025-07-11 20:45:44.263593: train_loss -0.9675 
2025-07-11 20:45:44.265017: val_loss -0.9333 
2025-07-11 20:45:44.266634: Pseudo dice [np.float32(0.9355)] 
2025-07-11 20:45:44.268935: Epoch time: 68.69 s 
2025-07-11 20:45:45.204173:  
2025-07-11 20:45:45.206580: Epoch 217 
2025-07-11 20:45:45.207829: Current learning rate: 0.00802 
2025-07-11 20:46:53.650483: train_loss -0.9677 
2025-07-11 20:46:53.651957: val_loss -0.9407 
2025-07-11 20:46:53.652944: Pseudo dice [np.float32(0.944)] 
2025-07-11 20:46:53.654833: Epoch time: 68.45 s 
2025-07-11 20:46:54.579840:  
2025-07-11 20:46:54.581890: Epoch 218 
2025-07-11 20:46:54.583117: Current learning rate: 0.00801 
2025-07-11 20:48:03.063980: train_loss -0.9676 
2025-07-11 20:48:03.065154: val_loss -0.9318 
2025-07-11 20:48:03.066224: Pseudo dice [np.float32(0.9358)] 
2025-07-11 20:48:03.067876: Epoch time: 68.49 s 
2025-07-11 20:48:04.006913:  
2025-07-11 20:48:04.009274: Epoch 219 
2025-07-11 20:48:04.011234: Current learning rate: 0.00801 
2025-07-11 20:49:12.800985: train_loss -0.9686 
2025-07-11 20:49:12.803474: val_loss -0.9348 
2025-07-11 20:49:12.805216: Pseudo dice [np.float32(0.9367)] 
2025-07-11 20:49:12.806400: Epoch time: 68.8 s 
2025-07-11 20:49:13.765135:  
2025-07-11 20:49:13.766885: Epoch 220 
2025-07-11 20:49:13.768677: Current learning rate: 0.008 
2025-07-11 20:50:22.328965: train_loss -0.9681 
2025-07-11 20:50:22.330266: val_loss -0.9267 
2025-07-11 20:50:22.331332: Pseudo dice [np.float32(0.9304)] 
2025-07-11 20:50:22.332937: Epoch time: 68.57 s 
2025-07-11 20:50:23.269746:  
2025-07-11 20:50:23.271802: Epoch 221 
2025-07-11 20:50:23.273430: Current learning rate: 0.00799 
2025-07-11 20:51:31.893194: train_loss -0.9669 
2025-07-11 20:51:31.894422: val_loss -0.9349 
2025-07-11 20:51:31.895595: Pseudo dice [np.float32(0.9381)] 
2025-07-11 20:51:31.896958: Epoch time: 68.63 s 
2025-07-11 20:51:32.838189:  
2025-07-11 20:51:32.840577: Epoch 222 
2025-07-11 20:51:32.842358: Current learning rate: 0.00798 
2025-07-11 20:52:41.340041: train_loss -0.9675 
2025-07-11 20:52:41.342876: val_loss -0.9373 
2025-07-11 20:52:41.344275: Pseudo dice [np.float32(0.9422)] 
2025-07-11 20:52:41.345733: Epoch time: 68.51 s 
2025-07-11 20:52:42.274979:  
2025-07-11 20:52:42.277666: Epoch 223 
2025-07-11 20:52:42.279174: Current learning rate: 0.00797 
2025-07-11 20:53:51.079897: train_loss -0.9671 
2025-07-11 20:53:51.081597: val_loss -0.941 
2025-07-11 20:53:51.082718: Pseudo dice [np.float32(0.9447)] 
2025-07-11 20:53:51.084430: Epoch time: 68.81 s 
2025-07-11 20:53:52.015273:  
2025-07-11 20:53:52.017173: Epoch 224 
2025-07-11 20:53:52.018275: Current learning rate: 0.00796 
2025-07-11 20:55:00.501112: train_loss -0.9659 
2025-07-11 20:55:00.502866: val_loss -0.9386 
2025-07-11 20:55:00.503889: Pseudo dice [np.float32(0.9424)] 
2025-07-11 20:55:00.505829: Epoch time: 68.49 s 
2025-07-11 20:55:01.420283:  
2025-07-11 20:55:01.422144: Epoch 225 
2025-07-11 20:55:01.423404: Current learning rate: 0.00795 
2025-07-11 20:56:09.978729: train_loss -0.967 
2025-07-11 20:56:09.980182: val_loss -0.9402 
2025-07-11 20:56:09.981218: Pseudo dice [np.float32(0.9452)] 
2025-07-11 20:56:09.982123: Epoch time: 68.56 s 
2025-07-11 20:56:10.914418:  
2025-07-11 20:56:10.917177: Epoch 226 
2025-07-11 20:56:10.919216: Current learning rate: 0.00794 
2025-07-11 20:57:19.884859: train_loss -0.9678 
2025-07-11 20:57:19.886301: val_loss -0.9393 
2025-07-11 20:57:19.887345: Pseudo dice [np.float32(0.9431)] 
2025-07-11 20:57:19.888520: Epoch time: 68.97 s 
2025-07-11 20:57:20.789102:  
2025-07-11 20:57:20.791039: Epoch 227 
2025-07-11 20:57:20.792268: Current learning rate: 0.00793 
2025-07-11 20:58:29.473433: train_loss -0.9672 
2025-07-11 20:58:29.475250: val_loss -0.9385 
2025-07-11 20:58:29.476401: Pseudo dice [np.float32(0.9425)] 
2025-07-11 20:58:29.477773: Epoch time: 68.69 s 
2025-07-11 20:58:30.390072:  
2025-07-11 20:58:30.392107: Epoch 228 
2025-07-11 20:58:30.393459: Current learning rate: 0.00792 
2025-07-11 20:59:39.034671: train_loss -0.9686 
2025-07-11 20:59:39.036189: val_loss -0.9404 
2025-07-11 20:59:39.037289: Pseudo dice [np.float32(0.9447)] 
2025-07-11 20:59:39.039354: Epoch time: 68.65 s 
2025-07-11 20:59:39.940280:  
2025-07-11 20:59:39.942312: Epoch 229 
2025-07-11 20:59:39.943473: Current learning rate: 0.00791 
2025-07-11 21:00:48.403490: train_loss -0.9681 
2025-07-11 21:00:48.405187: val_loss -0.9402 
2025-07-11 21:00:48.406966: Pseudo dice [np.float32(0.942)] 
2025-07-11 21:00:48.408109: Epoch time: 68.47 s 
2025-07-11 21:00:49.326500:  
2025-07-11 21:00:49.328822: Epoch 230 
2025-07-11 21:00:49.330040: Current learning rate: 0.0079 
2025-07-11 21:01:57.980156: train_loss -0.969 
2025-07-11 21:01:57.981400: val_loss -0.9415 
2025-07-11 21:01:57.982619: Pseudo dice [np.float32(0.9452)] 
2025-07-11 21:01:57.984270: Epoch time: 68.66 s 
2025-07-11 21:01:58.900233:  
2025-07-11 21:01:58.902249: Epoch 231 
2025-07-11 21:01:58.903391: Current learning rate: 0.00789 
2025-07-11 21:03:07.230740: train_loss -0.9698 
2025-07-11 21:03:07.232159: val_loss -0.9318 
2025-07-11 21:03:07.233561: Pseudo dice [np.float32(0.934)] 
2025-07-11 21:03:07.235127: Epoch time: 68.33 s 
2025-07-11 21:03:08.143375:  
2025-07-11 21:03:08.145454: Epoch 232 
2025-07-11 21:03:08.147329: Current learning rate: 0.00789 
2025-07-11 21:04:16.594422: train_loss -0.9693 
2025-07-11 21:04:16.595561: val_loss -0.9409 
2025-07-11 21:04:16.596788: Pseudo dice [np.float32(0.943)] 
2025-07-11 21:04:16.598710: Epoch time: 68.45 s 
2025-07-11 21:04:17.509568:  
2025-07-11 21:04:17.512212: Epoch 233 
2025-07-11 21:04:17.513366: Current learning rate: 0.00788 
2025-07-11 21:05:26.363348: train_loss -0.9709 
2025-07-11 21:05:26.365043: val_loss -0.9433 
2025-07-11 21:05:26.366280: Pseudo dice [np.float32(0.9472)] 
2025-07-11 21:05:26.367427: Epoch time: 68.86 s 
2025-07-11 21:05:27.267196:  
2025-07-11 21:05:27.269461: Epoch 234 
2025-07-11 21:05:27.270776: Current learning rate: 0.00787 
2025-07-11 21:06:35.961877: train_loss -0.9666 
2025-07-11 21:06:35.963381: val_loss -0.9349 
2025-07-11 21:06:35.964373: Pseudo dice [np.float32(0.9377)] 
2025-07-11 21:06:35.966022: Epoch time: 68.7 s 
2025-07-11 21:06:36.852598:  
2025-07-11 21:06:36.854802: Epoch 235 
2025-07-11 21:06:36.856219: Current learning rate: 0.00786 
2025-07-11 21:07:45.484260: train_loss -0.9679 
2025-07-11 21:07:45.485661: val_loss -0.9346 
2025-07-11 21:07:45.487231: Pseudo dice [np.float32(0.938)] 
2025-07-11 21:07:45.488421: Epoch time: 68.64 s 
2025-07-11 21:07:46.387810:  
2025-07-11 21:07:46.389993: Epoch 236 
2025-07-11 21:07:46.391685: Current learning rate: 0.00785 
2025-07-11 21:08:54.800655: train_loss -0.9701 
2025-07-11 21:08:54.801811: val_loss -0.9416 
2025-07-11 21:08:54.802878: Pseudo dice [np.float32(0.9447)] 
2025-07-11 21:08:54.803993: Epoch time: 68.42 s 
2025-07-11 21:08:55.713250:  
2025-07-11 21:08:55.715291: Epoch 237 
2025-07-11 21:08:55.716718: Current learning rate: 0.00784 
2025-07-11 21:10:04.279638: train_loss -0.9701 
2025-07-11 21:10:04.281618: val_loss -0.937 
2025-07-11 21:10:04.283205: Pseudo dice [np.float32(0.9391)] 
2025-07-11 21:10:04.284689: Epoch time: 68.57 s 
2025-07-11 21:10:05.179389:  
2025-07-11 21:10:05.181455: Epoch 238 
2025-07-11 21:10:05.182612: Current learning rate: 0.00783 
2025-07-11 21:11:13.582961: train_loss -0.9697 
2025-07-11 21:11:13.584643: val_loss -0.9427 
2025-07-11 21:11:13.586084: Pseudo dice [np.float32(0.9468)] 
2025-07-11 21:11:13.587293: Epoch time: 68.41 s 
2025-07-11 21:11:14.513040:  
2025-07-11 21:11:14.514997: Epoch 239 
2025-07-11 21:11:14.516346: Current learning rate: 0.00782 
2025-07-11 21:12:22.837367: train_loss -0.9691 
2025-07-11 21:12:22.838698: val_loss -0.9397 
2025-07-11 21:12:22.840770: Pseudo dice [np.float32(0.9424)] 
2025-07-11 21:12:22.842186: Epoch time: 68.33 s 
2025-07-11 21:12:23.733560:  
2025-07-11 21:12:23.736298: Epoch 240 
2025-07-11 21:12:23.737582: Current learning rate: 0.00781 
2025-07-11 21:13:32.433853: train_loss -0.969 
2025-07-11 21:13:32.435321: val_loss -0.9382 
2025-07-11 21:13:32.436512: Pseudo dice [np.float32(0.942)] 
2025-07-11 21:13:32.437845: Epoch time: 68.7 s 
2025-07-11 21:13:33.351118:  
2025-07-11 21:13:33.353147: Epoch 241 
2025-07-11 21:13:33.354364: Current learning rate: 0.0078 
2025-07-11 21:14:41.866954: train_loss -0.9702 
2025-07-11 21:14:41.868226: val_loss -0.9387 
2025-07-11 21:14:41.869632: Pseudo dice [np.float32(0.9429)] 
2025-07-11 21:14:41.871498: Epoch time: 68.52 s 
2025-07-11 21:14:42.785322:  
2025-07-11 21:14:42.787193: Epoch 242 
2025-07-11 21:14:42.788276: Current learning rate: 0.00779 
2025-07-11 21:15:51.406595: train_loss -0.9707 
2025-07-11 21:15:51.408445: val_loss -0.9351 
2025-07-11 21:15:51.409927: Pseudo dice [np.float32(0.9383)] 
2025-07-11 21:15:51.411187: Epoch time: 68.62 s 
2025-07-11 21:15:52.333471:  
2025-07-11 21:15:52.336404: Epoch 243 
2025-07-11 21:15:52.337766: Current learning rate: 0.00778 
2025-07-11 21:17:00.870564: train_loss -0.9702 
2025-07-11 21:17:00.872650: val_loss -0.9365 
2025-07-11 21:17:00.874134: Pseudo dice [np.float32(0.9392)] 
2025-07-11 21:17:00.875292: Epoch time: 68.54 s 
2025-07-11 21:17:01.801831:  
2025-07-11 21:17:01.804034: Epoch 244 
2025-07-11 21:17:01.805291: Current learning rate: 0.00777 
2025-07-11 21:18:10.536497: train_loss -0.97 
2025-07-11 21:18:10.537756: val_loss -0.9365 
2025-07-11 21:18:10.539499: Pseudo dice [np.float32(0.939)] 
2025-07-11 21:18:10.541329: Epoch time: 68.74 s 
2025-07-11 21:18:11.471903:  
2025-07-11 21:18:11.473803: Epoch 245 
2025-07-11 21:18:11.474844: Current learning rate: 0.00777 
2025-07-11 21:19:19.961626: train_loss -0.9688 
2025-07-11 21:19:19.963605: val_loss -0.9382 
2025-07-11 21:19:19.964954: Pseudo dice [np.float32(0.9397)] 
2025-07-11 21:19:19.966289: Epoch time: 68.49 s 
2025-07-11 21:19:20.896964:  
2025-07-11 21:19:20.899520: Epoch 246 
2025-07-11 21:19:20.900726: Current learning rate: 0.00776 
2025-07-11 21:20:29.307577: train_loss -0.969 
2025-07-11 21:20:29.309286: val_loss -0.9413 
2025-07-11 21:20:29.310648: Pseudo dice [np.float32(0.9455)] 
2025-07-11 21:20:29.311746: Epoch time: 68.41 s 
2025-07-11 21:20:30.233256:  
2025-07-11 21:20:30.235355: Epoch 247 
2025-07-11 21:20:30.236750: Current learning rate: 0.00775 
2025-07-11 21:21:38.814587: train_loss -0.9711 
2025-07-11 21:21:38.816213: val_loss -0.9379 
2025-07-11 21:21:38.817433: Pseudo dice [np.float32(0.9409)] 
2025-07-11 21:21:38.818897: Epoch time: 68.58 s 
2025-07-11 21:21:39.733835:  
2025-07-11 21:21:39.736011: Epoch 248 
2025-07-11 21:21:39.737073: Current learning rate: 0.00774 
2025-07-11 21:22:48.053136: train_loss -0.9688 
2025-07-11 21:22:48.054426: val_loss -0.9362 
2025-07-11 21:22:48.055416: Pseudo dice [np.float32(0.939)] 
2025-07-11 21:22:48.056496: Epoch time: 68.32 s 
2025-07-11 21:22:48.936998:  
2025-07-11 21:22:48.938992: Epoch 249 
2025-07-11 21:22:48.940333: Current learning rate: 0.00773 
2025-07-11 21:23:57.354859: train_loss -0.9698 
2025-07-11 21:23:57.356155: val_loss -0.9285 
2025-07-11 21:23:57.357710: Pseudo dice [np.float32(0.9313)] 
2025-07-11 21:23:57.358952: Epoch time: 68.42 s 
2025-07-11 21:23:59.438832:  
2025-07-11 21:23:59.440726: Epoch 250 
2025-07-11 21:23:59.442064: Current learning rate: 0.00772 
2025-07-11 21:25:07.905107: train_loss -0.9693 
2025-07-11 21:25:07.906234: val_loss -0.9356 
2025-07-11 21:25:07.907200: Pseudo dice [np.float32(0.9392)] 
2025-07-11 21:25:07.908694: Epoch time: 68.47 s 
2025-07-11 21:25:09.075066:  
2025-07-11 21:25:09.077055: Epoch 251 
2025-07-11 21:25:09.078206: Current learning rate: 0.00771 
2025-07-11 21:26:17.619529: train_loss -0.9705 
2025-07-11 21:26:17.621002: val_loss -0.9361 
2025-07-11 21:26:17.622418: Pseudo dice [np.float32(0.9395)] 
2025-07-11 21:26:17.623656: Epoch time: 68.55 s 
2025-07-11 21:26:18.539468:  
2025-07-11 21:26:18.541624: Epoch 252 
2025-07-11 21:26:18.542677: Current learning rate: 0.0077 
2025-07-11 21:27:26.860409: train_loss -0.9691 
2025-07-11 21:27:26.862179: val_loss -0.9379 
2025-07-11 21:27:26.863806: Pseudo dice [np.float32(0.9395)] 
2025-07-11 21:27:26.865033: Epoch time: 68.32 s 
2025-07-11 21:27:27.789848:  
2025-07-11 21:27:27.792237: Epoch 253 
2025-07-11 21:27:27.793529: Current learning rate: 0.00769 
2025-07-11 21:28:36.288569: train_loss -0.9704 
2025-07-11 21:28:36.290488: val_loss -0.9388 
2025-07-11 21:28:36.292293: Pseudo dice [np.float32(0.942)] 
2025-07-11 21:28:36.293610: Epoch time: 68.5 s 
2025-07-11 21:28:37.203189:  
2025-07-11 21:28:37.206188: Epoch 254 
2025-07-11 21:28:37.207423: Current learning rate: 0.00768 
2025-07-11 21:29:45.701545: train_loss -0.9708 
2025-07-11 21:29:45.702718: val_loss -0.943 
2025-07-11 21:29:45.703977: Pseudo dice [np.float32(0.9452)] 
2025-07-11 21:29:45.705237: Epoch time: 68.5 s 
2025-07-11 21:29:46.604628:  
2025-07-11 21:29:46.606687: Epoch 255 
2025-07-11 21:29:46.607872: Current learning rate: 0.00767 
2025-07-11 21:30:54.946125: train_loss -0.9686 
2025-07-11 21:30:54.947677: val_loss -0.933 
2025-07-11 21:30:54.949191: Pseudo dice [np.float32(0.9348)] 
2025-07-11 21:30:54.950767: Epoch time: 68.35 s 
2025-07-11 21:30:55.866550:  
2025-07-11 21:30:55.868615: Epoch 256 
2025-07-11 21:30:55.870142: Current learning rate: 0.00766 
2025-07-11 21:32:04.122115: train_loss -0.9691 
2025-07-11 21:32:04.123753: val_loss -0.94 
2025-07-11 21:32:04.125356: Pseudo dice [np.float32(0.9424)] 
2025-07-11 21:32:04.126610: Epoch time: 68.26 s 
2025-07-11 21:32:05.053553:  
2025-07-11 21:32:05.055557: Epoch 257 
2025-07-11 21:32:05.056874: Current learning rate: 0.00765 
2025-07-11 21:33:13.278934: train_loss -0.9682 
2025-07-11 21:33:13.280384: val_loss -0.9321 
2025-07-11 21:33:13.281953: Pseudo dice [np.float32(0.935)] 
2025-07-11 21:33:13.283372: Epoch time: 68.23 s 
2025-07-11 21:33:14.208213:  
2025-07-11 21:33:14.210340: Epoch 258 
2025-07-11 21:33:14.211493: Current learning rate: 0.00764 
2025-07-11 21:34:22.731547: train_loss -0.97 
2025-07-11 21:34:22.732668: val_loss -0.9346 
2025-07-11 21:34:22.733531: Pseudo dice [np.float32(0.9378)] 
2025-07-11 21:34:22.734811: Epoch time: 68.53 s 
2025-07-11 21:34:23.661203:  
2025-07-11 21:34:23.663433: Epoch 259 
2025-07-11 21:34:23.665268: Current learning rate: 0.00764 
2025-07-11 21:35:32.188528: train_loss -0.9719 
2025-07-11 21:35:32.190042: val_loss -0.9359 
2025-07-11 21:35:32.191725: Pseudo dice [np.float32(0.9392)] 
2025-07-11 21:35:32.193388: Epoch time: 68.53 s 
2025-07-11 21:35:33.111366:  
2025-07-11 21:35:33.114406: Epoch 260 
2025-07-11 21:35:33.115857: Current learning rate: 0.00763 
2025-07-11 21:36:41.613690: train_loss -0.969 
2025-07-11 21:36:41.614908: val_loss -0.9385 
2025-07-11 21:36:41.616489: Pseudo dice [np.float32(0.9412)] 
2025-07-11 21:36:41.618527: Epoch time: 68.51 s 
2025-07-11 21:36:42.523880:  
2025-07-11 21:36:42.525771: Epoch 261 
2025-07-11 21:36:42.526970: Current learning rate: 0.00762 
2025-07-11 21:37:50.999447: train_loss -0.9689 
2025-07-11 21:37:51.000978: val_loss -0.9416 
2025-07-11 21:37:51.002652: Pseudo dice [np.float32(0.9442)] 
2025-07-11 21:37:51.003654: Epoch time: 68.48 s 
2025-07-11 21:37:51.943748:  
2025-07-11 21:37:51.945591: Epoch 262 
2025-07-11 21:37:51.946729: Current learning rate: 0.00761 
2025-07-11 21:39:00.217220: train_loss -0.9691 
2025-07-11 21:39:00.218689: val_loss -0.9339 
2025-07-11 21:39:00.220175: Pseudo dice [np.float32(0.9367)] 
2025-07-11 21:39:00.221844: Epoch time: 68.28 s 
2025-07-11 21:39:01.132604:  
2025-07-11 21:39:01.135210: Epoch 263 
2025-07-11 21:39:01.137165: Current learning rate: 0.0076 
2025-07-11 21:40:09.491731: train_loss -0.9698 
2025-07-11 21:40:09.493021: val_loss -0.9397 
2025-07-11 21:40:09.493977: Pseudo dice [np.float32(0.9429)] 
2025-07-11 21:40:09.495335: Epoch time: 68.36 s 
2025-07-11 21:40:10.416095:  
2025-07-11 21:40:10.417979: Epoch 264 
2025-07-11 21:40:10.419030: Current learning rate: 0.00759 
2025-07-11 21:41:18.825061: train_loss -0.9697 
2025-07-11 21:41:18.829329: val_loss -0.9336 
2025-07-11 21:41:18.830869: Pseudo dice [np.float32(0.9357)] 
2025-07-11 21:41:18.832483: Epoch time: 68.41 s 
2025-07-11 21:41:19.748255:  
2025-07-11 21:41:19.750113: Epoch 265 
2025-07-11 21:41:19.751403: Current learning rate: 0.00758 
2025-07-11 21:42:28.409323: train_loss -0.969 
2025-07-11 21:42:28.411675: val_loss -0.9439 
2025-07-11 21:42:28.414686: Pseudo dice [np.float32(0.9465)] 
2025-07-11 21:42:28.417049: Epoch time: 68.66 s 
2025-07-11 21:42:29.335532:  
2025-07-11 21:42:29.338432: Epoch 266 
2025-07-11 21:42:29.339794: Current learning rate: 0.00757 
2025-07-11 21:43:37.770353: train_loss -0.9687 
2025-07-11 21:43:37.772413: val_loss -0.9417 
2025-07-11 21:43:37.774066: Pseudo dice [np.float32(0.9441)] 
2025-07-11 21:43:37.776195: Epoch time: 68.44 s 
2025-07-11 21:43:38.710678:  
2025-07-11 21:43:38.713752: Epoch 267 
2025-07-11 21:43:38.715477: Current learning rate: 0.00756 
2025-07-11 21:44:47.145308: train_loss -0.9697 
2025-07-11 21:44:47.147270: val_loss -0.9372 
2025-07-11 21:44:47.149498: Pseudo dice [np.float32(0.9408)] 
2025-07-11 21:44:47.152128: Epoch time: 68.44 s 
2025-07-11 21:44:48.077309:  
2025-07-11 21:44:48.079332: Epoch 268 
2025-07-11 21:44:48.080607: Current learning rate: 0.00755 
2025-07-11 21:45:56.455909: train_loss -0.9711 
2025-07-11 21:45:56.457689: val_loss -0.9374 
2025-07-11 21:45:56.459297: Pseudo dice [np.float32(0.9418)] 
2025-07-11 21:45:56.461024: Epoch time: 68.38 s 
2025-07-11 21:45:57.366237:  
2025-07-11 21:45:57.368622: Epoch 269 
2025-07-11 21:45:57.369645: Current learning rate: 0.00754 
2025-07-11 21:47:05.534361: train_loss -0.9704 
2025-07-11 21:47:05.536876: val_loss -0.9333 
2025-07-11 21:47:05.538719: Pseudo dice [np.float32(0.9368)] 
2025-07-11 21:47:05.541545: Epoch time: 68.17 s 
2025-07-11 21:47:06.474091:  
2025-07-11 21:47:06.475769: Epoch 270 
2025-07-11 21:47:06.476830: Current learning rate: 0.00753 
2025-07-11 21:48:14.848204: train_loss -0.9702 
2025-07-11 21:48:14.850529: val_loss -0.9319 
2025-07-11 21:48:14.853479: Pseudo dice [np.float32(0.9356)] 
2025-07-11 21:48:14.856373: Epoch time: 68.38 s 
2025-07-11 21:48:15.783930:  
2025-07-11 21:48:15.786108: Epoch 271 
2025-07-11 21:48:15.787511: Current learning rate: 0.00752 
2025-07-11 21:49:24.224472: train_loss -0.9717 
2025-07-11 21:49:24.227172: val_loss -0.9405 
2025-07-11 21:49:24.229544: Pseudo dice [np.float32(0.9429)] 
2025-07-11 21:49:24.231641: Epoch time: 68.44 s 
2025-07-11 21:49:25.157298:  
2025-07-11 21:49:25.159730: Epoch 272 
2025-07-11 21:49:25.161540: Current learning rate: 0.00751 
2025-07-11 21:50:33.724727: train_loss -0.9711 
2025-07-11 21:50:33.726707: val_loss -0.9329 
2025-07-11 21:50:33.729292: Pseudo dice [np.float32(0.9355)] 
2025-07-11 21:50:33.731545: Epoch time: 68.57 s 
2025-07-11 21:50:34.659381:  
2025-07-11 21:50:34.661361: Epoch 273 
2025-07-11 21:50:34.662608: Current learning rate: 0.00751 
2025-07-11 21:51:42.901421: train_loss -0.9709 
2025-07-11 21:51:42.903406: val_loss -0.9335 
2025-07-11 21:51:42.904867: Pseudo dice [np.float32(0.9365)] 
2025-07-11 21:51:42.907248: Epoch time: 68.25 s 
2025-07-11 21:51:43.838634:  
2025-07-11 21:51:43.840660: Epoch 274 
2025-07-11 21:51:43.842452: Current learning rate: 0.0075 
2025-07-11 21:52:51.955647: train_loss -0.9685 
2025-07-11 21:52:51.957340: val_loss -0.9301 
2025-07-11 21:52:51.959065: Pseudo dice [np.float32(0.9329)] 
2025-07-11 21:52:51.961369: Epoch time: 68.12 s 
2025-07-11 21:52:52.892384:  
2025-07-11 21:52:52.894701: Epoch 275 
2025-07-11 21:52:52.896577: Current learning rate: 0.00749 
2025-07-11 21:54:01.266456: train_loss -0.9701 
2025-07-11 21:54:01.267896: val_loss -0.9423 
2025-07-11 21:54:01.269393: Pseudo dice [np.float32(0.9449)] 
2025-07-11 21:54:01.270385: Epoch time: 68.38 s 
2025-07-11 21:54:02.151730:  
2025-07-11 21:54:02.153766: Epoch 276 
2025-07-11 21:54:02.155277: Current learning rate: 0.00748 
2025-07-11 21:55:10.640261: train_loss -0.9701 
2025-07-11 21:55:10.641751: val_loss -0.9404 
2025-07-11 21:55:10.643325: Pseudo dice [np.float32(0.9438)] 
2025-07-11 21:55:10.644704: Epoch time: 68.49 s 
2025-07-11 21:55:11.573970:  
2025-07-11 21:55:11.576291: Epoch 277 
2025-07-11 21:55:11.577358: Current learning rate: 0.00747 
2025-07-11 21:56:20.072239: train_loss -0.9706 
2025-07-11 21:56:20.073820: val_loss -0.9341 
2025-07-11 21:56:20.075361: Pseudo dice [np.float32(0.9361)] 
2025-07-11 21:56:20.077219: Epoch time: 68.5 s 
2025-07-11 21:56:20.989764:  
2025-07-11 21:56:20.991734: Epoch 278 
2025-07-11 21:56:20.993398: Current learning rate: 0.00746 
2025-07-11 21:57:29.443567: train_loss -0.9713 
2025-07-11 21:57:29.449421: val_loss -0.9448 
2025-07-11 21:57:29.450615: Pseudo dice [np.float32(0.9484)] 
2025-07-11 21:57:29.452068: Epoch time: 68.46 s 
2025-07-11 21:57:30.377487:  
2025-07-11 21:57:30.379954: Epoch 279 
2025-07-11 21:57:30.381143: Current learning rate: 0.00745 
2025-07-11 21:58:39.062244: train_loss -0.9706 
2025-07-11 21:58:39.065274: val_loss -0.9426 
2025-07-11 21:58:39.066598: Pseudo dice [np.float32(0.9469)] 
2025-07-11 21:58:39.067946: Epoch time: 68.69 s 
2025-07-11 21:58:39.995555:  
2025-07-11 21:58:39.997605: Epoch 280 
2025-07-11 21:58:39.999326: Current learning rate: 0.00744 
2025-07-11 21:59:48.697446: train_loss -0.9709 
2025-07-11 21:59:48.698958: val_loss -0.9442 
2025-07-11 21:59:48.700033: Pseudo dice [np.float32(0.9466)] 
2025-07-11 21:59:48.701516: Epoch time: 68.71 s 
2025-07-11 21:59:49.618413:  
2025-07-11 21:59:49.620746: Epoch 281 
2025-07-11 21:59:49.621858: Current learning rate: 0.00743 
2025-07-11 22:00:58.276132: train_loss -0.9704 
2025-07-11 22:00:58.277444: val_loss -0.9361 
2025-07-11 22:00:58.278503: Pseudo dice [np.float32(0.94)] 
2025-07-11 22:00:58.279655: Epoch time: 68.66 s 
2025-07-11 22:00:59.186783:  
2025-07-11 22:00:59.188457: Epoch 282 
2025-07-11 22:00:59.189516: Current learning rate: 0.00742 
2025-07-11 22:02:07.752494: train_loss -0.9713 
2025-07-11 22:02:07.753682: val_loss -0.9337 
2025-07-11 22:02:07.754817: Pseudo dice [np.float32(0.9381)] 
2025-07-11 22:02:07.756504: Epoch time: 68.57 s 
2025-07-11 22:02:08.701550:  
2025-07-11 22:02:08.704292: Epoch 283 
2025-07-11 22:02:08.705826: Current learning rate: 0.00741 
2025-07-11 22:03:17.138718: train_loss -0.971 
2025-07-11 22:03:17.140331: val_loss -0.9434 
2025-07-11 22:03:17.141974: Pseudo dice [np.float32(0.9464)] 
2025-07-11 22:03:17.143360: Epoch time: 68.44 s 
2025-07-11 22:03:18.060705:  
2025-07-11 22:03:18.062605: Epoch 284 
2025-07-11 22:03:18.063851: Current learning rate: 0.0074 
2025-07-11 22:04:26.555011: train_loss -0.9705 
2025-07-11 22:04:26.556619: val_loss -0.9444 
2025-07-11 22:04:26.557847: Pseudo dice [np.float32(0.9468)] 
2025-07-11 22:04:26.559289: Epoch time: 68.5 s 
2025-07-11 22:04:27.490080:  
2025-07-11 22:04:27.492172: Epoch 285 
2025-07-11 22:04:27.493356: Current learning rate: 0.00739 
2025-07-11 22:05:35.963999: train_loss -0.9716 
2025-07-11 22:05:35.965526: val_loss -0.9412 
2025-07-11 22:05:35.966953: Pseudo dice [np.float32(0.9449)] 
2025-07-11 22:05:35.968370: Epoch time: 68.48 s 
2025-07-11 22:05:35.969467: Yayy! New best EMA pseudo Dice: 0.9423999786376953 
2025-07-11 22:05:38.278305:  
2025-07-11 22:05:38.280236: Epoch 286 
2025-07-11 22:05:38.281326: Current learning rate: 0.00738 
2025-07-11 22:06:46.897799: train_loss -0.9704 
2025-07-11 22:06:46.899485: val_loss -0.9401 
2025-07-11 22:06:46.900953: Pseudo dice [np.float32(0.9433)] 
2025-07-11 22:06:46.902312: Epoch time: 68.62 s 
2025-07-11 22:06:46.903813: Yayy! New best EMA pseudo Dice: 0.9424999952316284 
2025-07-11 22:06:49.359571:  
2025-07-11 22:06:49.361679: Epoch 287 
2025-07-11 22:06:49.362587: Current learning rate: 0.00738 
2025-07-11 22:07:57.979605: train_loss -0.9694 
2025-07-11 22:07:57.980877: val_loss -0.9403 
2025-07-11 22:07:57.982085: Pseudo dice [np.float32(0.9432)] 
2025-07-11 22:07:57.983306: Epoch time: 68.62 s 
2025-07-11 22:07:57.984510: Yayy! New best EMA pseudo Dice: 0.9426000118255615 
2025-07-11 22:08:00.183896:  
2025-07-11 22:08:00.185819: Epoch 288 
2025-07-11 22:08:00.186967: Current learning rate: 0.00737 
2025-07-11 22:09:08.781023: train_loss -0.971 
2025-07-11 22:09:08.782486: val_loss -0.9393 
2025-07-11 22:09:08.783916: Pseudo dice [np.float32(0.9417)] 
2025-07-11 22:09:08.785218: Epoch time: 68.6 s 
2025-07-11 22:09:09.765055:  
2025-07-11 22:09:09.766919: Epoch 289 
2025-07-11 22:09:09.767945: Current learning rate: 0.00736 
2025-07-11 22:10:18.160046: train_loss -0.9716 
2025-07-11 22:10:18.161578: val_loss -0.9409 
2025-07-11 22:10:18.163055: Pseudo dice [np.float32(0.9442)] 
2025-07-11 22:10:18.164352: Epoch time: 68.4 s 
2025-07-11 22:10:18.165480: Yayy! New best EMA pseudo Dice: 0.9426000118255615 
2025-07-11 22:10:20.440058:  
2025-07-11 22:10:20.442206: Epoch 290 
2025-07-11 22:10:20.443688: Current learning rate: 0.00735 
2025-07-11 22:11:28.686930: train_loss -0.9698 
2025-07-11 22:11:28.688151: val_loss -0.9387 
2025-07-11 22:11:28.689129: Pseudo dice [np.float32(0.9422)] 
2025-07-11 22:11:28.690140: Epoch time: 68.25 s 
2025-07-11 22:11:29.624712:  
2025-07-11 22:11:29.627337: Epoch 291 
2025-07-11 22:11:29.628574: Current learning rate: 0.00734 
2025-07-11 22:12:37.855622: train_loss -0.9699 
2025-07-11 22:12:37.856794: val_loss -0.9423 
2025-07-11 22:12:37.859002: Pseudo dice [np.float32(0.9449)] 
2025-07-11 22:12:37.860868: Epoch time: 68.23 s 
2025-07-11 22:12:37.862538: Yayy! New best EMA pseudo Dice: 0.942799985408783 
2025-07-11 22:12:40.120863:  
2025-07-11 22:12:40.122428: Epoch 292 
2025-07-11 22:12:40.123468: Current learning rate: 0.00733 
2025-07-11 22:13:48.542749: train_loss -0.9696 
2025-07-11 22:13:48.544428: val_loss -0.9387 
2025-07-11 22:13:48.545586: Pseudo dice [np.float32(0.9425)] 
2025-07-11 22:13:48.546704: Epoch time: 68.43 s 
2025-07-11 22:13:49.476171:  
2025-07-11 22:13:49.478327: Epoch 293 
2025-07-11 22:13:49.479806: Current learning rate: 0.00732 
2025-07-11 22:14:57.743316: train_loss -0.9696 
2025-07-11 22:14:57.744808: val_loss -0.94 
2025-07-11 22:14:57.745827: Pseudo dice [np.float32(0.9433)] 
2025-07-11 22:14:57.746728: Epoch time: 68.27 s 
2025-07-11 22:14:57.748256: Yayy! New best EMA pseudo Dice: 0.942799985408783 
2025-07-11 22:15:00.191367:  
2025-07-11 22:15:00.193277: Epoch 294 
2025-07-11 22:15:00.194692: Current learning rate: 0.00731 
2025-07-11 22:16:08.491165: train_loss -0.9703 
2025-07-11 22:16:08.492469: val_loss -0.9401 
2025-07-11 22:16:08.494005: Pseudo dice [np.float32(0.9419)] 
2025-07-11 22:16:08.495528: Epoch time: 68.3 s 
2025-07-11 22:16:09.431895:  
2025-07-11 22:16:09.433799: Epoch 295 
2025-07-11 22:16:09.435353: Current learning rate: 0.0073 
2025-07-11 22:17:17.811024: train_loss -0.9701 
2025-07-11 22:17:17.812852: val_loss -0.9384 
2025-07-11 22:17:17.814270: Pseudo dice [np.float32(0.941)] 
2025-07-11 22:17:17.815483: Epoch time: 68.38 s 
2025-07-11 22:17:18.771879:  
2025-07-11 22:17:18.773755: Epoch 296 
2025-07-11 22:17:18.774754: Current learning rate: 0.00729 
2025-07-11 22:18:26.955810: train_loss -0.9709 
2025-07-11 22:18:26.957442: val_loss -0.9473 
2025-07-11 22:18:26.958573: Pseudo dice [np.float32(0.9505)] 
2025-07-11 22:18:26.959594: Epoch time: 68.19 s 
2025-07-11 22:18:26.961330: Yayy! New best EMA pseudo Dice: 0.9434000253677368 
2025-07-11 22:18:29.407808:  
2025-07-11 22:18:29.409815: Epoch 297 
2025-07-11 22:18:29.410970: Current learning rate: 0.00728 
2025-07-11 22:19:37.741408: train_loss -0.9707 
2025-07-11 22:19:37.743535: val_loss -0.9428 
2025-07-11 22:19:37.745009: Pseudo dice [np.float32(0.9471)] 
2025-07-11 22:19:37.746294: Epoch time: 68.34 s 
2025-07-11 22:19:37.748021: Yayy! New best EMA pseudo Dice: 0.9437000155448914 
2025-07-11 22:19:40.187453:  
2025-07-11 22:19:40.189329: Epoch 298 
2025-07-11 22:19:40.190574: Current learning rate: 0.00727 
2025-07-11 22:20:48.586009: train_loss -0.9707 
2025-07-11 22:20:48.587536: val_loss -0.9406 
2025-07-11 22:20:48.589444: Pseudo dice [np.float32(0.9433)] 
2025-07-11 22:20:48.590948: Epoch time: 68.4 s 
2025-07-11 22:20:49.757867:  
2025-07-11 22:20:49.759908: Epoch 299 
2025-07-11 22:20:49.761275: Current learning rate: 0.00726 
2025-07-11 22:21:58.207833: train_loss -0.9685 
2025-07-11 22:21:58.209137: val_loss -0.9415 
2025-07-11 22:21:58.210299: Pseudo dice [np.float32(0.9452)] 
2025-07-11 22:21:58.211688: Epoch time: 68.45 s 
2025-07-11 22:21:59.406071: Yayy! New best EMA pseudo Dice: 0.9438999891281128 
2025-07-11 22:22:01.705425:  
2025-07-11 22:22:01.707523: Epoch 300 
2025-07-11 22:22:01.709258: Current learning rate: 0.00725 
2025-07-11 22:23:10.083654: train_loss -0.9696 
2025-07-11 22:23:10.085106: val_loss -0.9375 
2025-07-11 22:23:10.086626: Pseudo dice [np.float32(0.9402)] 
2025-07-11 22:23:10.089705: Epoch time: 68.38 s 
2025-07-11 22:23:11.018641:  
2025-07-11 22:23:11.021461: Epoch 301 
2025-07-11 22:23:11.022752: Current learning rate: 0.00724 
2025-07-11 22:24:19.373832: train_loss -0.9696 
2025-07-11 22:24:19.375705: val_loss -0.9351 
2025-07-11 22:24:19.377049: Pseudo dice [np.float32(0.9374)] 
2025-07-11 22:24:19.378218: Epoch time: 68.36 s 
2025-07-11 22:24:20.300880:  
2025-07-11 22:24:20.303245: Epoch 302 
2025-07-11 22:24:20.304222: Current learning rate: 0.00724 
2025-07-11 22:25:29.129879: train_loss -0.972 
2025-07-11 22:25:29.131280: val_loss -0.944 
2025-07-11 22:25:29.132810: Pseudo dice [np.float32(0.9468)] 
2025-07-11 22:25:29.133852: Epoch time: 68.83 s 
2025-07-11 22:25:30.087797:  
2025-07-11 22:25:30.089728: Epoch 303 
2025-07-11 22:25:30.091164: Current learning rate: 0.00723 
2025-07-11 22:26:38.824450: train_loss -0.9705 
2025-07-11 22:26:38.825660: val_loss -0.9441 
2025-07-11 22:26:38.827075: Pseudo dice [np.float32(0.9462)] 
2025-07-11 22:26:38.829241: Epoch time: 68.74 s 
2025-07-11 22:26:39.754908:  
2025-07-11 22:26:39.757103: Epoch 304 
2025-07-11 22:26:39.758790: Current learning rate: 0.00722 
2025-07-11 22:27:48.256033: train_loss -0.9702 
2025-07-11 22:27:48.257542: val_loss -0.9362 
2025-07-11 22:27:48.258603: Pseudo dice [np.float32(0.9394)] 
2025-07-11 22:27:48.259624: Epoch time: 68.5 s 
2025-07-11 22:27:49.187334:  
2025-07-11 22:27:49.189600: Epoch 305 
2025-07-11 22:27:49.191417: Current learning rate: 0.00721 
2025-07-11 22:28:57.695863: train_loss -0.97 
2025-07-11 22:28:57.697365: val_loss -0.9341 
2025-07-11 22:28:57.698646: Pseudo dice [np.float32(0.9359)] 
2025-07-11 22:28:57.699956: Epoch time: 68.51 s 
2025-07-11 22:28:58.638701:  
2025-07-11 22:28:58.640898: Epoch 306 
2025-07-11 22:28:58.642212: Current learning rate: 0.0072 
2025-07-11 22:30:07.058840: train_loss -0.9711 
2025-07-11 22:30:07.060427: val_loss -0.9412 
2025-07-11 22:30:07.061867: Pseudo dice [np.float32(0.9444)] 
2025-07-11 22:30:07.063446: Epoch time: 68.42 s 
2025-07-11 22:30:07.983054:  
2025-07-11 22:30:07.985436: Epoch 307 
2025-07-11 22:30:07.986492: Current learning rate: 0.00719 
2025-07-11 22:31:16.613328: train_loss -0.9712 
2025-07-11 22:31:16.614923: val_loss -0.9378 
2025-07-11 22:31:16.615902: Pseudo dice [np.float32(0.9379)] 
2025-07-11 22:31:16.617266: Epoch time: 68.63 s 
2025-07-11 22:31:17.567327:  
2025-07-11 22:31:17.569692: Epoch 308 
2025-07-11 22:31:17.571123: Current learning rate: 0.00718 
2025-07-11 22:32:26.101129: train_loss -0.9717 
2025-07-11 22:32:26.102444: val_loss -0.9427 
2025-07-11 22:32:26.103461: Pseudo dice [np.float32(0.946)] 
2025-07-11 22:32:26.104662: Epoch time: 68.54 s 
2025-07-11 22:32:27.030091:  
2025-07-11 22:32:27.031905: Epoch 309 
2025-07-11 22:32:27.033153: Current learning rate: 0.00717 
2025-07-11 22:33:35.784270: train_loss -0.9713 
2025-07-11 22:33:35.785829: val_loss -0.9378 
2025-07-11 22:33:35.787138: Pseudo dice [np.float32(0.9407)] 
2025-07-11 22:33:35.788056: Epoch time: 68.76 s 
2025-07-11 22:33:36.714057:  
2025-07-11 22:33:36.715769: Epoch 310 
2025-07-11 22:33:36.717284: Current learning rate: 0.00716 
2025-07-11 22:34:45.241382: train_loss -0.9716 
2025-07-11 22:34:45.242556: val_loss -0.9353 
2025-07-11 22:34:45.243358: Pseudo dice [np.float32(0.9398)] 
2025-07-11 22:34:45.244412: Epoch time: 68.53 s 
2025-07-11 22:34:46.186066:  
2025-07-11 22:34:46.188377: Epoch 311 
2025-07-11 22:34:46.190262: Current learning rate: 0.00715 
2025-07-11 22:35:54.612423: train_loss -0.9713 
2025-07-11 22:35:54.614133: val_loss -0.9386 
2025-07-11 22:35:54.616066: Pseudo dice [np.float32(0.9414)] 
2025-07-11 22:35:54.617358: Epoch time: 68.43 s 
2025-07-11 22:35:55.554168:  
2025-07-11 22:35:55.556550: Epoch 312 
2025-07-11 22:35:55.557738: Current learning rate: 0.00714 
2025-07-11 22:37:03.974509: train_loss -0.9716 
2025-07-11 22:37:03.975951: val_loss -0.9363 
2025-07-11 22:37:03.977188: Pseudo dice [np.float32(0.9365)] 
2025-07-11 22:37:03.978886: Epoch time: 68.42 s 
2025-07-11 22:37:04.906857:  
2025-07-11 22:37:04.909273: Epoch 313 
2025-07-11 22:37:04.910621: Current learning rate: 0.00713 
2025-07-11 22:38:13.518792: train_loss -0.9719 
2025-07-11 22:38:13.520474: val_loss -0.937 
2025-07-11 22:38:13.521857: Pseudo dice [np.float32(0.9395)] 
2025-07-11 22:38:13.523309: Epoch time: 68.62 s 
2025-07-11 22:38:14.454436:  
2025-07-11 22:38:14.456503: Epoch 314 
2025-07-11 22:38:14.457559: Current learning rate: 0.00712 
2025-07-11 22:39:23.096070: train_loss -0.9714 
2025-07-11 22:39:23.097799: val_loss -0.9399 
2025-07-11 22:39:23.099078: Pseudo dice [np.float32(0.9429)] 
2025-07-11 22:39:23.100800: Epoch time: 68.65 s 
2025-07-11 22:39:24.014254:  
2025-07-11 22:39:24.016715: Epoch 315 
2025-07-11 22:39:24.017720: Current learning rate: 0.00711 
2025-07-11 22:40:32.298234: train_loss -0.9718 
2025-07-11 22:40:32.299456: val_loss -0.9354 
2025-07-11 22:40:32.300415: Pseudo dice [np.float32(0.9387)] 
2025-07-11 22:40:32.301316: Epoch time: 68.29 s 
2025-07-11 22:40:33.212635:  
2025-07-11 22:40:33.214807: Epoch 316 
2025-07-11 22:40:33.215824: Current learning rate: 0.0071 
2025-07-11 22:41:41.763218: train_loss -0.9715 
2025-07-11 22:41:41.764696: val_loss -0.9357 
2025-07-11 22:41:41.766399: Pseudo dice [np.float32(0.9344)] 
2025-07-11 22:41:41.767596: Epoch time: 68.55 s 
2025-07-11 22:41:42.687968:  
2025-07-11 22:41:42.689996: Epoch 317 
2025-07-11 22:41:42.691488: Current learning rate: 0.0071 
2025-07-11 22:42:51.111124: train_loss -0.9715 
2025-07-11 22:42:51.112627: val_loss -0.9379 
2025-07-11 22:42:51.113819: Pseudo dice [np.float32(0.9399)] 
2025-07-11 22:42:51.114755: Epoch time: 68.43 s 
2025-07-11 22:42:52.042672:  
2025-07-11 22:42:52.044919: Epoch 318 
2025-07-11 22:42:52.046017: Current learning rate: 0.00709 
2025-07-11 22:44:00.466940: train_loss -0.972 
2025-07-11 22:44:00.468658: val_loss -0.9336 
2025-07-11 22:44:00.469846: Pseudo dice [np.float32(0.9354)] 
2025-07-11 22:44:00.471292: Epoch time: 68.43 s 
2025-07-11 22:44:01.413398:  
2025-07-11 22:44:01.415722: Epoch 319 
2025-07-11 22:44:01.417283: Current learning rate: 0.00708 
2025-07-11 22:45:09.882309: train_loss -0.9699 
2025-07-11 22:45:09.883680: val_loss -0.9447 
2025-07-11 22:45:09.884724: Pseudo dice [np.float32(0.9469)] 
2025-07-11 22:45:09.886519: Epoch time: 68.47 s 
2025-07-11 22:45:10.840377:  
2025-07-11 22:45:10.842793: Epoch 320 
2025-07-11 22:45:10.844294: Current learning rate: 0.00707 
2025-07-11 22:46:19.306690: train_loss -0.9706 
2025-07-11 22:46:19.308008: val_loss -0.9382 
2025-07-11 22:46:19.309047: Pseudo dice [np.float32(0.9402)] 
2025-07-11 22:46:19.310192: Epoch time: 68.47 s 
2025-07-11 22:46:20.259281:  
2025-07-11 22:46:20.261760: Epoch 321 
2025-07-11 22:46:20.263158: Current learning rate: 0.00706 
2025-07-11 22:47:28.668761: train_loss -0.9713 
2025-07-11 22:47:28.670219: val_loss -0.9353 
2025-07-11 22:47:28.671743: Pseudo dice [np.float32(0.9379)] 
2025-07-11 22:47:28.673285: Epoch time: 68.41 s 
2025-07-11 22:47:29.627089:  
2025-07-11 22:47:29.628866: Epoch 322 
2025-07-11 22:47:29.629968: Current learning rate: 0.00705 
2025-07-11 22:48:38.178515: train_loss -0.9712 
2025-07-11 22:48:38.180181: val_loss -0.9302 
2025-07-11 22:48:38.181186: Pseudo dice [np.float32(0.9313)] 
2025-07-11 22:48:38.182260: Epoch time: 68.56 s 
2025-07-11 22:48:39.367951:  
2025-07-11 22:48:39.370178: Epoch 323 
2025-07-11 22:48:39.371365: Current learning rate: 0.00704 
2025-07-11 22:49:47.875021: train_loss -0.9725 
2025-07-11 22:49:47.876327: val_loss -0.9381 
2025-07-11 22:49:47.877535: Pseudo dice [np.float32(0.9413)] 
2025-07-11 22:49:47.878905: Epoch time: 68.51 s 
2025-07-11 22:49:48.815067:  
2025-07-11 22:49:48.817052: Epoch 324 
2025-07-11 22:49:48.818224: Current learning rate: 0.00703 
2025-07-11 22:50:57.432387: train_loss -0.9726 
2025-07-11 22:50:57.434149: val_loss -0.9379 
2025-07-11 22:50:57.435185: Pseudo dice [np.float32(0.9403)] 
2025-07-11 22:50:57.436854: Epoch time: 68.62 s 
2025-07-11 22:50:58.387117:  
2025-07-11 22:50:58.388942: Epoch 325 
2025-07-11 22:50:58.389910: Current learning rate: 0.00702 
2025-07-11 22:52:06.974428: train_loss -0.9707 
2025-07-11 22:52:06.975868: val_loss -0.9458 
2025-07-11 22:52:06.977266: Pseudo dice [np.float32(0.949)] 
2025-07-11 22:52:06.978160: Epoch time: 68.59 s 
2025-07-11 22:52:07.921839:  
2025-07-11 22:52:07.924298: Epoch 326 
2025-07-11 22:52:07.925702: Current learning rate: 0.00701 
2025-07-11 22:53:16.625822: train_loss -0.9706 
2025-07-11 22:53:16.627336: val_loss -0.9446 
2025-07-11 22:53:16.628767: Pseudo dice [np.float32(0.9481)] 
2025-07-11 22:53:16.629908: Epoch time: 68.71 s 
2025-07-11 22:53:17.559126:  
2025-07-11 22:53:17.561594: Epoch 327 
2025-07-11 22:53:17.563182: Current learning rate: 0.007 
2025-07-11 22:54:26.166212: train_loss -0.9707 
2025-07-11 22:54:26.167808: val_loss -0.946 
2025-07-11 22:54:26.169166: Pseudo dice [np.float32(0.9496)] 
2025-07-11 22:54:26.170819: Epoch time: 68.61 s 
2025-07-11 22:54:27.085542:  
2025-07-11 22:54:27.087797: Epoch 328 
2025-07-11 22:54:27.089671: Current learning rate: 0.00699 
2025-07-11 22:55:35.650356: train_loss -0.971 
2025-07-11 22:55:35.651931: val_loss -0.9369 
2025-07-11 22:55:35.653856: Pseudo dice [np.float32(0.9405)] 
2025-07-11 22:55:35.655530: Epoch time: 68.57 s 
2025-07-11 22:55:36.540243:  
2025-07-11 22:55:36.542400: Epoch 329 
2025-07-11 22:55:36.543684: Current learning rate: 0.00698 
2025-07-11 22:56:45.084755: train_loss -0.9713 
2025-07-11 22:56:45.086209: val_loss -0.9397 
2025-07-11 22:56:45.087160: Pseudo dice [np.float32(0.9416)] 
2025-07-11 22:56:45.088675: Epoch time: 68.55 s 
2025-07-11 22:56:46.006214:  
2025-07-11 22:56:46.007983: Epoch 330 
2025-07-11 22:56:46.009037: Current learning rate: 0.00697 
2025-07-11 22:57:54.638060: train_loss -0.9705 
2025-07-11 22:57:54.639661: val_loss -0.9368 
2025-07-11 22:57:54.640860: Pseudo dice [np.float32(0.9392)] 
2025-07-11 22:57:54.643049: Epoch time: 68.64 s 
2025-07-11 22:57:55.578555:  
2025-07-11 22:57:55.580456: Epoch 331 
2025-07-11 22:57:55.582180: Current learning rate: 0.00696 
2025-07-11 22:59:04.041100: train_loss -0.971 
2025-07-11 22:59:04.043260: val_loss -0.9389 
2025-07-11 22:59:04.044718: Pseudo dice [np.float32(0.9419)] 
2025-07-11 22:59:04.045785: Epoch time: 68.47 s 
2025-07-11 22:59:04.942334:  
2025-07-11 22:59:04.944387: Epoch 332 
2025-07-11 22:59:04.945567: Current learning rate: 0.00696 
2025-07-11 23:00:13.585180: train_loss -0.9713 
2025-07-11 23:00:13.586682: val_loss -0.9376 
2025-07-11 23:00:13.587741: Pseudo dice [np.float32(0.9404)] 
2025-07-11 23:00:13.588774: Epoch time: 68.65 s 
2025-07-11 23:00:14.506194:  
2025-07-11 23:00:14.508108: Epoch 333 
2025-07-11 23:00:14.509408: Current learning rate: 0.00695 
2025-07-11 23:01:23.156485: train_loss -0.9717 
2025-07-11 23:01:23.158668: val_loss -0.9382 
2025-07-11 23:01:23.160231: Pseudo dice [np.float32(0.9417)] 
2025-07-11 23:01:23.161744: Epoch time: 68.65 s 
2025-07-11 23:01:24.083292:  
2025-07-11 23:01:24.084932: Epoch 334 
2025-07-11 23:01:24.086185: Current learning rate: 0.00694 
2025-07-11 23:02:32.686739: train_loss -0.9701 
2025-07-11 23:02:32.688527: val_loss -0.9309 
2025-07-11 23:02:32.689742: Pseudo dice [np.float32(0.9315)] 
2025-07-11 23:02:32.691084: Epoch time: 68.61 s 
2025-07-11 23:02:33.655692:  
2025-07-11 23:02:33.658190: Epoch 335 
2025-07-11 23:02:33.659487: Current learning rate: 0.00693 
2025-07-11 23:03:42.575911: train_loss -0.9711 
2025-07-11 23:03:42.578661: val_loss -0.9418 
2025-07-11 23:03:42.579675: Pseudo dice [np.float32(0.9436)] 
2025-07-11 23:03:42.581163: Epoch time: 68.92 s 
2025-07-11 23:03:43.562650:  
2025-07-11 23:03:43.564751: Epoch 336 
2025-07-11 23:03:43.565845: Current learning rate: 0.00692 
2025-07-11 23:04:52.377298: train_loss -0.9691 
2025-07-11 23:04:52.378891: val_loss -0.9378 
2025-07-11 23:04:52.380242: Pseudo dice [np.float32(0.9401)] 
2025-07-11 23:04:52.381333: Epoch time: 68.82 s 
2025-07-11 23:04:53.352096:  
2025-07-11 23:04:53.354342: Epoch 337 
2025-07-11 23:04:53.355601: Current learning rate: 0.00691 
2025-07-11 23:06:02.335071: train_loss -0.9717 
2025-07-11 23:06:02.336201: val_loss -0.941 
2025-07-11 23:06:02.337386: Pseudo dice [np.float32(0.9445)] 
2025-07-11 23:06:02.338893: Epoch time: 68.99 s 
2025-07-11 23:06:03.294176:  
2025-07-11 23:06:03.296429: Epoch 338 
2025-07-11 23:06:03.297718: Current learning rate: 0.0069 
2025-07-11 23:07:11.770837: train_loss -0.972 
2025-07-11 23:07:11.772296: val_loss -0.9478 
2025-07-11 23:07:11.773229: Pseudo dice [np.float32(0.9515)] 
2025-07-11 23:07:11.774453: Epoch time: 68.48 s 
2025-07-11 23:07:12.726114:  
2025-07-11 23:07:12.728465: Epoch 339 
2025-07-11 23:07:12.729713: Current learning rate: 0.00689 
2025-07-11 23:08:21.376213: train_loss -0.9714 
2025-07-11 23:08:21.377757: val_loss -0.9449 
2025-07-11 23:08:21.379251: Pseudo dice [np.float32(0.9484)] 
2025-07-11 23:08:21.381108: Epoch time: 68.65 s 
2025-07-11 23:08:22.336456:  
2025-07-11 23:08:22.339422: Epoch 340 
2025-07-11 23:08:22.340921: Current learning rate: 0.00688 
2025-07-11 23:09:31.477450: train_loss -0.9698 
2025-07-11 23:09:31.479227: val_loss -0.9306 
2025-07-11 23:09:31.480708: Pseudo dice [np.float32(0.9329)] 
2025-07-11 23:09:31.481792: Epoch time: 69.14 s 
2025-07-11 23:09:32.454081:  
2025-07-11 23:09:32.456515: Epoch 341 
2025-07-11 23:09:32.457844: Current learning rate: 0.00687 
2025-07-11 23:10:41.739152: train_loss -0.9713 
2025-07-11 23:10:41.740468: val_loss -0.9386 
2025-07-11 23:10:41.741693: Pseudo dice [np.float32(0.9427)] 
2025-07-11 23:10:41.742903: Epoch time: 69.29 s 
2025-07-11 23:10:42.755097:  
2025-07-11 23:10:42.757316: Epoch 342 
2025-07-11 23:10:42.758467: Current learning rate: 0.00686 
2025-07-11 23:11:51.798128: train_loss -0.9712 
2025-07-11 23:11:51.799343: val_loss -0.9329 
2025-07-11 23:11:51.800358: Pseudo dice [np.float32(0.9356)] 
2025-07-11 23:11:51.801516: Epoch time: 69.05 s 
2025-07-11 23:11:52.764470:  
2025-07-11 23:11:52.766790: Epoch 343 
2025-07-11 23:11:52.768257: Current learning rate: 0.00685 
2025-07-11 23:13:01.684258: train_loss -0.9722 
2025-07-11 23:13:01.685491: val_loss -0.9392 
2025-07-11 23:13:01.687099: Pseudo dice [np.float32(0.9419)] 
2025-07-11 23:13:01.688548: Epoch time: 68.92 s 
2025-07-11 23:13:02.873829:  
2025-07-11 23:13:02.876393: Epoch 344 
2025-07-11 23:13:02.877838: Current learning rate: 0.00684 
2025-07-11 23:14:11.734530: train_loss -0.9721 
2025-07-11 23:14:11.736348: val_loss -0.9425 
2025-07-11 23:14:11.738193: Pseudo dice [np.float32(0.9468)] 
2025-07-11 23:14:11.739727: Epoch time: 68.86 s 
2025-07-11 23:14:12.691213:  
2025-07-11 23:14:12.693733: Epoch 345 
2025-07-11 23:14:12.695216: Current learning rate: 0.00683 
2025-07-11 23:15:21.683702: train_loss -0.9718 
2025-07-11 23:15:21.685615: val_loss -0.9373 
2025-07-11 23:15:21.687281: Pseudo dice [np.float32(0.9407)] 
2025-07-11 23:15:21.688587: Epoch time: 69.0 s 
2025-07-11 23:15:22.634956:  
2025-07-11 23:15:22.636969: Epoch 346 
2025-07-11 23:15:22.638351: Current learning rate: 0.00682 
2025-07-11 23:16:31.608242: train_loss -0.9721 
2025-07-11 23:16:31.609713: val_loss -0.9283 
2025-07-11 23:16:31.610998: Pseudo dice [np.float32(0.9311)] 
2025-07-11 23:16:31.612641: Epoch time: 68.98 s 
2025-07-11 23:16:32.598141:  
2025-07-11 23:16:32.600282: Epoch 347 
2025-07-11 23:16:32.601288: Current learning rate: 0.00681 
2025-07-11 23:17:41.910528: train_loss -0.9723 
2025-07-11 23:17:41.911637: val_loss -0.9401 
2025-07-11 23:17:41.912643: Pseudo dice [np.float32(0.9433)] 
2025-07-11 23:17:41.913697: Epoch time: 69.32 s 
2025-07-11 23:17:42.867720:  
2025-07-11 23:17:42.869967: Epoch 348 
2025-07-11 23:17:42.871227: Current learning rate: 0.0068 
2025-07-11 23:18:51.948441: train_loss -0.9708 
2025-07-11 23:18:51.949890: val_loss -0.9431 
2025-07-11 23:18:51.951347: Pseudo dice [np.float32(0.9466)] 
2025-07-11 23:18:51.953266: Epoch time: 69.08 s 
2025-07-11 23:18:52.911649:  
2025-07-11 23:18:52.914079: Epoch 349 
2025-07-11 23:18:52.915621: Current learning rate: 0.0068 
2025-07-11 23:20:01.960901: train_loss -0.9723 
2025-07-11 23:20:01.962157: val_loss -0.9379 
2025-07-11 23:20:01.963539: Pseudo dice [np.float32(0.9411)] 
2025-07-11 23:20:01.964720: Epoch time: 69.05 s 
2025-07-11 23:20:04.377038:  
2025-07-11 23:20:04.379569: Epoch 350 
2025-07-11 23:20:04.380768: Current learning rate: 0.00679 
2025-07-11 23:21:13.435823: train_loss -0.9729 
2025-07-11 23:21:13.437135: val_loss -0.9342 
2025-07-11 23:21:13.438200: Pseudo dice [np.float32(0.9378)] 
2025-07-11 23:21:13.439937: Epoch time: 69.06 s 
2025-07-11 23:21:14.380989:  
2025-07-11 23:21:14.383568: Epoch 351 
2025-07-11 23:21:14.385404: Current learning rate: 0.00678 
2025-07-11 23:22:23.144294: train_loss -0.9728 
2025-07-11 23:22:23.146007: val_loss -0.9408 
2025-07-11 23:22:23.147235: Pseudo dice [np.float32(0.944)] 
2025-07-11 23:22:23.148314: Epoch time: 68.77 s 
2025-07-11 23:22:24.128028:  
2025-07-11 23:22:24.130216: Epoch 352 
2025-07-11 23:22:24.131912: Current learning rate: 0.00677 
2025-07-11 23:23:33.005921: train_loss -0.9725 
2025-07-11 23:23:33.007695: val_loss -0.9396 
2025-07-11 23:23:33.009114: Pseudo dice [np.float32(0.9446)] 
2025-07-11 23:23:33.011232: Epoch time: 68.88 s 
2025-07-11 23:23:33.970878:  
2025-07-11 23:23:33.973310: Epoch 353 
2025-07-11 23:23:33.974475: Current learning rate: 0.00676 
2025-07-11 23:24:42.712978: train_loss -0.9716 
2025-07-11 23:24:42.715005: val_loss -0.929 
2025-07-11 23:24:42.716319: Pseudo dice [np.float32(0.9304)] 
2025-07-11 23:24:42.717520: Epoch time: 68.75 s 
2025-07-11 23:24:43.713418:  
2025-07-11 23:24:43.715722: Epoch 354 
2025-07-11 23:24:43.716855: Current learning rate: 0.00675 
2025-07-11 23:25:52.783129: train_loss -0.9726 
2025-07-11 23:25:52.784619: val_loss -0.935 
2025-07-11 23:25:52.785704: Pseudo dice [np.float32(0.9383)] 
2025-07-11 23:25:52.786998: Epoch time: 69.07 s 
2025-07-11 23:25:53.751349:  
2025-07-11 23:25:53.753832: Epoch 355 
2025-07-11 23:25:53.755188: Current learning rate: 0.00674 
2025-07-11 23:27:02.727856: train_loss -0.9727 
2025-07-11 23:27:02.729280: val_loss -0.9385 
2025-07-11 23:27:02.731261: Pseudo dice [np.float32(0.9406)] 
2025-07-11 23:27:02.732766: Epoch time: 68.98 s 
2025-07-11 23:27:03.688102:  
2025-07-11 23:27:03.690037: Epoch 356 
2025-07-11 23:27:03.691324: Current learning rate: 0.00673 
2025-07-11 23:28:12.574680: train_loss -0.9726 
2025-07-11 23:28:12.575925: val_loss -0.9387 
2025-07-11 23:28:12.577318: Pseudo dice [np.float32(0.9426)] 
2025-07-11 23:28:12.578563: Epoch time: 68.89 s 
2025-07-11 23:28:13.528553:  
2025-07-11 23:28:13.531284: Epoch 357 
2025-07-11 23:28:13.533230: Current learning rate: 0.00672 
2025-07-11 23:29:22.524277: train_loss -0.9724 
2025-07-11 23:29:22.525519: val_loss -0.9366 
2025-07-11 23:29:22.527057: Pseudo dice [np.float32(0.9394)] 
2025-07-11 23:29:22.528837: Epoch time: 69.0 s 
2025-07-11 23:29:23.495941:  
2025-07-11 23:29:23.498487: Epoch 358 
2025-07-11 23:29:23.499791: Current learning rate: 0.00671 
2025-07-11 23:30:32.353525: train_loss -0.9721 
2025-07-11 23:30:32.354852: val_loss -0.9408 
2025-07-11 23:30:32.356030: Pseudo dice [np.float32(0.9447)] 
2025-07-11 23:30:32.357419: Epoch time: 68.86 s 
2025-07-11 23:30:33.309401:  
2025-07-11 23:30:33.311503: Epoch 359 
2025-07-11 23:30:33.312734: Current learning rate: 0.0067 
2025-07-11 23:31:42.031447: train_loss -0.9733 
2025-07-11 23:31:42.032884: val_loss -0.9436 
2025-07-11 23:31:42.034016: Pseudo dice [np.float32(0.9468)] 
2025-07-11 23:31:42.035603: Epoch time: 68.73 s 
2025-07-11 23:31:42.994114:  
2025-07-11 23:31:42.996446: Epoch 360 
2025-07-11 23:31:42.998015: Current learning rate: 0.00669 
2025-07-11 23:32:51.835962: train_loss -0.9718 
2025-07-11 23:32:51.837242: val_loss -0.9416 
2025-07-11 23:32:51.838495: Pseudo dice [np.float32(0.9447)] 
2025-07-11 23:32:51.839720: Epoch time: 68.85 s 
2025-07-11 23:32:52.782649:  
2025-07-11 23:32:52.785191: Epoch 361 
2025-07-11 23:32:52.786497: Current learning rate: 0.00668 
2025-07-11 23:34:01.575824: train_loss -0.9724 
2025-07-11 23:34:01.577380: val_loss -0.9375 
2025-07-11 23:34:01.578233: Pseudo dice [np.float32(0.9403)] 
2025-07-11 23:34:01.579381: Epoch time: 68.8 s 
2025-07-11 23:34:02.506336:  
2025-07-11 23:34:02.508535: Epoch 362 
2025-07-11 23:34:02.509862: Current learning rate: 0.00667 
2025-07-11 23:35:11.145642: train_loss -0.9723 
2025-07-11 23:35:11.147452: val_loss -0.936 
2025-07-11 23:35:11.148787: Pseudo dice [np.float32(0.9406)] 
2025-07-11 23:35:11.150051: Epoch time: 68.64 s 
2025-07-11 23:35:12.120005:  
2025-07-11 23:35:12.122190: Epoch 363 
2025-07-11 23:35:12.123404: Current learning rate: 0.00666 
2025-07-11 23:36:20.945806: train_loss -0.9717 
2025-07-11 23:36:20.947100: val_loss -0.9331 
2025-07-11 23:36:20.948435: Pseudo dice [np.float32(0.9366)] 
2025-07-11 23:36:20.949965: Epoch time: 68.83 s 
2025-07-11 23:36:21.921224:  
2025-07-11 23:36:21.923496: Epoch 364 
2025-07-11 23:36:21.925496: Current learning rate: 0.00665 
2025-07-11 23:37:30.916082: train_loss -0.9729 
2025-07-11 23:37:30.917805: val_loss -0.9401 
2025-07-11 23:37:30.919022: Pseudo dice [np.float32(0.9441)] 
2025-07-11 23:37:30.920537: Epoch time: 69.0 s 
2025-07-11 23:37:31.886585:  
2025-07-11 23:37:31.888828: Epoch 365 
2025-07-11 23:37:31.890096: Current learning rate: 0.00665 
2025-07-11 23:38:40.807679: train_loss -0.9724 
2025-07-11 23:38:40.809236: val_loss -0.9351 
2025-07-11 23:38:40.810656: Pseudo dice [np.float32(0.9362)] 
2025-07-11 23:38:40.811646: Epoch time: 68.92 s 
2025-07-11 23:38:41.757202:  
2025-07-11 23:38:41.759387: Epoch 366 
2025-07-11 23:38:41.761302: Current learning rate: 0.00664 
2025-07-11 23:39:50.470115: train_loss -0.9717 
2025-07-11 23:39:50.472209: val_loss -0.9291 
2025-07-11 23:39:50.473981: Pseudo dice [np.float32(0.9305)] 
2025-07-11 23:39:50.475992: Epoch time: 68.72 s 
2025-07-11 23:39:51.446796:  
2025-07-11 23:39:51.448942: Epoch 367 
2025-07-11 23:39:51.450175: Current learning rate: 0.00663 
2025-07-11 23:41:00.015873: train_loss -0.9709 
2025-07-11 23:41:00.017680: val_loss -0.9366 
2025-07-11 23:41:00.019360: Pseudo dice [np.float32(0.9397)] 
2025-07-11 23:41:00.020321: Epoch time: 68.57 s 
2025-07-11 23:41:00.963826:  
2025-07-11 23:41:00.966200: Epoch 368 
2025-07-11 23:41:00.967551: Current learning rate: 0.00662 
2025-07-11 23:42:09.725066: train_loss -0.9713 
2025-07-11 23:42:09.726504: val_loss -0.941 
2025-07-11 23:42:09.727809: Pseudo dice [np.float32(0.944)] 
2025-07-11 23:42:09.729342: Epoch time: 68.76 s 
2025-07-11 23:42:10.703238:  
2025-07-11 23:42:10.705371: Epoch 369 
2025-07-11 23:42:10.706519: Current learning rate: 0.00661 
2025-07-11 23:43:19.400158: train_loss -0.9713 
2025-07-11 23:43:19.401580: val_loss -0.9448 
2025-07-11 23:43:19.403344: Pseudo dice [np.float32(0.9475)] 
2025-07-11 23:43:19.404580: Epoch time: 68.7 s 
2025-07-11 23:43:20.372043:  
2025-07-11 23:43:20.374104: Epoch 370 
2025-07-11 23:43:20.375488: Current learning rate: 0.0066 
2025-07-11 23:44:29.039813: train_loss -0.9719 
2025-07-11 23:44:29.041414: val_loss -0.9415 
2025-07-11 23:44:29.042607: Pseudo dice [np.float32(0.9446)] 
2025-07-11 23:44:29.043989: Epoch time: 68.67 s 
2025-07-11 23:44:30.006732:  
2025-07-11 23:44:30.008770: Epoch 371 
2025-07-11 23:44:30.009963: Current learning rate: 0.00659 
2025-07-11 23:45:38.678374: train_loss -0.9738 
2025-07-11 23:45:38.680179: val_loss -0.9402 
2025-07-11 23:45:38.681448: Pseudo dice [np.float32(0.9426)] 
2025-07-11 23:45:38.682999: Epoch time: 68.68 s 
2025-07-11 23:45:39.664667:  
2025-07-11 23:45:39.667481: Epoch 372 
2025-07-11 23:45:39.669226: Current learning rate: 0.00658 
2025-07-11 23:46:48.338421: train_loss -0.9727 
2025-07-11 23:46:48.340164: val_loss -0.946 
2025-07-11 23:46:48.341116: Pseudo dice [np.float32(0.949)] 
2025-07-11 23:46:48.342511: Epoch time: 68.68 s 
2025-07-11 23:46:49.282764:  
2025-07-11 23:46:49.284758: Epoch 373 
2025-07-11 23:46:49.285894: Current learning rate: 0.00657 
2025-07-11 23:47:57.933940: train_loss -0.9731 
2025-07-11 23:47:57.935416: val_loss -0.9428 
2025-07-11 23:47:57.936549: Pseudo dice [np.float32(0.9469)] 
2025-07-11 23:47:57.937648: Epoch time: 68.65 s 
2025-07-11 23:47:58.918473:  
2025-07-11 23:47:58.920845: Epoch 374 
2025-07-11 23:47:58.922030: Current learning rate: 0.00656 
2025-07-11 23:49:07.498314: train_loss -0.9727 
2025-07-11 23:49:07.499443: val_loss -0.9409 
2025-07-11 23:49:07.501441: Pseudo dice [np.float32(0.9441)] 
2025-07-11 23:49:07.502687: Epoch time: 68.58 s 
2025-07-11 23:49:08.704700:  
2025-07-11 23:49:08.707220: Epoch 375 
2025-07-11 23:49:08.708567: Current learning rate: 0.00655 
2025-07-11 23:50:17.467479: train_loss -0.9724 
2025-07-11 23:50:17.469178: val_loss -0.9357 
2025-07-11 23:50:17.470260: Pseudo dice [np.float32(0.9393)] 
2025-07-11 23:50:17.471410: Epoch time: 68.77 s 
2025-07-11 23:50:18.393213:  
2025-07-11 23:50:18.395408: Epoch 376 
2025-07-11 23:50:18.397017: Current learning rate: 0.00654 
2025-07-11 23:51:27.173045: train_loss -0.9714 
2025-07-11 23:51:27.174424: val_loss -0.9339 
2025-07-11 23:51:27.175937: Pseudo dice [np.float32(0.9367)] 
2025-07-11 23:51:27.177832: Epoch time: 68.78 s 
2025-07-11 23:51:28.103096:  
2025-07-11 23:51:28.105010: Epoch 377 
2025-07-11 23:51:28.106315: Current learning rate: 0.00653 
2025-07-11 23:52:36.842310: train_loss -0.9729 
2025-07-11 23:52:36.843933: val_loss -0.9423 
2025-07-11 23:52:36.845284: Pseudo dice [np.float32(0.9446)] 
2025-07-11 23:52:36.846827: Epoch time: 68.74 s 
2025-07-11 23:52:37.791118:  
2025-07-11 23:52:37.793675: Epoch 378 
2025-07-11 23:52:37.794824: Current learning rate: 0.00652 
2025-07-11 23:53:46.526560: train_loss -0.9732 
2025-07-11 23:53:46.529141: val_loss -0.9385 
2025-07-11 23:53:46.530823: Pseudo dice [np.float32(0.942)] 
2025-07-11 23:53:46.532006: Epoch time: 68.74 s 
2025-07-11 23:53:47.485241:  
2025-07-11 23:53:47.487405: Epoch 379 
2025-07-11 23:53:47.488392: Current learning rate: 0.00651 
2025-07-11 23:54:56.137998: train_loss -0.9726 
2025-07-11 23:54:56.140237: val_loss -0.9374 
2025-07-11 23:54:56.142274: Pseudo dice [np.float32(0.9405)] 
2025-07-11 23:54:56.143953: Epoch time: 68.66 s 
2025-07-11 23:54:57.088161:  
2025-07-11 23:54:57.090789: Epoch 380 
2025-07-11 23:54:57.092410: Current learning rate: 0.0065 
2025-07-11 23:56:05.791995: train_loss -0.9725 
2025-07-11 23:56:05.793715: val_loss -0.944 
2025-07-11 23:56:05.795612: Pseudo dice [np.float32(0.9467)] 
2025-07-11 23:56:05.796873: Epoch time: 68.71 s 
2025-07-11 23:56:06.764665:  
2025-07-11 23:56:06.767411: Epoch 381 
2025-07-11 23:56:06.768768: Current learning rate: 0.00649 
2025-07-11 23:57:15.465559: train_loss -0.9735 
2025-07-11 23:57:15.467627: val_loss -0.9437 
2025-07-11 23:57:15.469408: Pseudo dice [np.float32(0.9468)] 
2025-07-11 23:57:15.470834: Epoch time: 68.7 s 
2025-07-11 23:57:16.673389:  
2025-07-11 23:57:16.675641: Epoch 382 
2025-07-11 23:57:16.676899: Current learning rate: 0.00648 
2025-07-11 23:58:25.252032: train_loss -0.9726 
2025-07-11 23:58:25.254432: val_loss -0.9428 
2025-07-11 23:58:25.255348: Pseudo dice [np.float32(0.945)] 
2025-07-11 23:58:25.256711: Epoch time: 68.58 s 
2025-07-11 23:58:26.223939:  
2025-07-11 23:58:26.226408: Epoch 383 
2025-07-11 23:58:26.227802: Current learning rate: 0.00648 
2025-07-11 23:59:34.932888: train_loss -0.9734 
2025-07-11 23:59:34.934182: val_loss -0.9395 
2025-07-11 23:59:34.935569: Pseudo dice [np.float32(0.942)] 
2025-07-11 23:59:34.936841: Epoch time: 68.71 s 
2025-07-11 23:59:35.889125:  
2025-07-11 23:59:35.891153: Epoch 384 
2025-07-11 23:59:35.892306: Current learning rate: 0.00647 
2025-07-12 00:00:44.606963: train_loss -0.9715 
2025-07-12 00:00:44.608224: val_loss -0.9408 
2025-07-12 00:00:44.609240: Pseudo dice [np.float32(0.944)] 
2025-07-12 00:00:44.610610: Epoch time: 68.72 s 
2025-07-12 00:00:45.559964:  
2025-07-12 00:00:45.561711: Epoch 385 
2025-07-12 00:00:45.562887: Current learning rate: 0.00646 
2025-07-12 00:01:54.590490: train_loss -0.9729 
2025-07-12 00:01:54.592393: val_loss -0.9385 
2025-07-12 00:01:54.594224: Pseudo dice [np.float32(0.941)] 
2025-07-12 00:01:54.595346: Epoch time: 69.03 s 
2025-07-12 00:01:55.564930:  
2025-07-12 00:01:55.567377: Epoch 386 
2025-07-12 00:01:55.568627: Current learning rate: 0.00645 
2025-07-12 00:03:04.338330: train_loss -0.9729 
2025-07-12 00:03:04.340089: val_loss -0.9343 
2025-07-12 00:03:04.341534: Pseudo dice [np.float32(0.9374)] 
2025-07-12 00:03:04.342577: Epoch time: 68.78 s 
2025-07-12 00:03:05.340683:  
2025-07-12 00:03:05.342759: Epoch 387 
2025-07-12 00:03:05.344108: Current learning rate: 0.00644 
2025-07-12 00:04:13.965455: train_loss -0.9737 
2025-07-12 00:04:13.967326: val_loss -0.9447 
2025-07-12 00:04:13.969640: Pseudo dice [np.float32(0.9474)] 
2025-07-12 00:04:13.971418: Epoch time: 68.63 s 
2025-07-12 00:04:14.941750:  
2025-07-12 00:04:14.944026: Epoch 388 
2025-07-12 00:04:14.945182: Current learning rate: 0.00643 
2025-07-12 00:05:23.662899: train_loss -0.9738 
2025-07-12 00:05:23.664563: val_loss -0.9395 
2025-07-12 00:05:23.665792: Pseudo dice [np.float32(0.9411)] 
2025-07-12 00:05:23.668019: Epoch time: 68.72 s 
2025-07-12 00:05:24.855861:  
2025-07-12 00:05:24.858124: Epoch 389 
2025-07-12 00:05:24.859592: Current learning rate: 0.00642 
2025-07-12 00:06:33.596993: train_loss -0.9719 
2025-07-12 00:06:33.598216: val_loss -0.9415 
2025-07-12 00:06:33.599325: Pseudo dice [np.float32(0.9449)] 
2025-07-12 00:06:33.600533: Epoch time: 68.75 s 
2025-07-12 00:06:34.640913:  
2025-07-12 00:06:34.643213: Epoch 390 
2025-07-12 00:06:34.644215: Current learning rate: 0.00641 
2025-07-12 00:07:43.413852: train_loss -0.971 
2025-07-12 00:07:43.415097: val_loss -0.9425 
2025-07-12 00:07:43.416539: Pseudo dice [np.float32(0.9458)] 
2025-07-12 00:07:43.417952: Epoch time: 68.78 s 
2025-07-12 00:07:44.372325:  
2025-07-12 00:07:44.375423: Epoch 391 
2025-07-12 00:07:44.377326: Current learning rate: 0.0064 
2025-07-12 00:08:53.152218: train_loss -0.9734 
2025-07-12 00:08:53.155111: val_loss -0.9368 
2025-07-12 00:08:53.156567: Pseudo dice [np.float32(0.9378)] 
2025-07-12 00:08:53.157983: Epoch time: 68.78 s 
2025-07-12 00:08:54.131716:  
2025-07-12 00:08:54.133502: Epoch 392 
2025-07-12 00:08:54.134628: Current learning rate: 0.00639 
2025-07-12 00:10:03.003867: train_loss -0.9725 
2025-07-12 00:10:03.005697: val_loss -0.9401 
2025-07-12 00:10:03.006950: Pseudo dice [np.float32(0.9426)] 
2025-07-12 00:10:03.008560: Epoch time: 68.88 s 
2025-07-12 00:10:03.983187:  
2025-07-12 00:10:03.985389: Epoch 393 
2025-07-12 00:10:03.986843: Current learning rate: 0.00638 
2025-07-12 00:11:12.709224: train_loss -0.9724 
2025-07-12 00:11:12.710558: val_loss -0.9432 
2025-07-12 00:11:12.712344: Pseudo dice [np.float32(0.9463)] 
2025-07-12 00:11:12.713504: Epoch time: 68.73 s 
2025-07-12 00:11:13.667749:  
2025-07-12 00:11:13.670184: Epoch 394 
2025-07-12 00:11:13.671468: Current learning rate: 0.00637 
2025-07-12 00:12:22.170367: train_loss -0.9721 
2025-07-12 00:12:22.172313: val_loss -0.9463 
2025-07-12 00:12:22.173487: Pseudo dice [np.float32(0.9489)] 
2025-07-12 00:12:22.175162: Epoch time: 68.51 s 
2025-07-12 00:12:23.169782:  
2025-07-12 00:12:23.172003: Epoch 395 
2025-07-12 00:12:23.173037: Current learning rate: 0.00636 
2025-07-12 00:13:31.863529: train_loss -0.9736 
2025-07-12 00:13:31.864908: val_loss -0.9396 
2025-07-12 00:13:31.866324: Pseudo dice [np.float32(0.9419)] 
2025-07-12 00:13:31.867786: Epoch time: 68.7 s 
2025-07-12 00:13:33.077905:  
2025-07-12 00:13:33.080186: Epoch 396 
2025-07-12 00:13:33.081581: Current learning rate: 0.00635 
2025-07-12 00:14:41.690856: train_loss -0.9741 
2025-07-12 00:14:41.692721: val_loss -0.9318 
2025-07-12 00:14:41.693803: Pseudo dice [np.float32(0.9357)] 
2025-07-12 00:14:41.695348: Epoch time: 68.62 s 
2025-07-12 00:14:42.686617:  
2025-07-12 00:14:42.689180: Epoch 397 
2025-07-12 00:14:42.691201: Current learning rate: 0.00634 
2025-07-12 00:15:51.317796: train_loss -0.9728 
2025-07-12 00:15:51.319178: val_loss -0.9414 
2025-07-12 00:15:51.320248: Pseudo dice [np.float32(0.9449)] 
2025-07-12 00:15:51.321644: Epoch time: 68.63 s 
2025-07-12 00:15:52.303755:  
2025-07-12 00:15:52.306298: Epoch 398 
2025-07-12 00:15:52.308276: Current learning rate: 0.00633 
2025-07-12 00:17:00.973297: train_loss -0.9723 
2025-07-12 00:17:00.974674: val_loss -0.9442 
2025-07-12 00:17:00.975983: Pseudo dice [np.float32(0.948)] 
2025-07-12 00:17:00.977464: Epoch time: 68.67 s 
2025-07-12 00:17:01.946588:  
2025-07-12 00:17:01.948229: Epoch 399 
2025-07-12 00:17:01.949389: Current learning rate: 0.00632 
2025-07-12 00:18:10.838448: train_loss -0.9727 
2025-07-12 00:18:10.840551: val_loss -0.9362 
2025-07-12 00:18:10.841662: Pseudo dice [np.float32(0.9396)] 
2025-07-12 00:18:10.843157: Epoch time: 68.9 s 
2025-07-12 00:18:13.256150:  
2025-07-12 00:18:13.258297: Epoch 400 
2025-07-12 00:18:13.259302: Current learning rate: 0.00631 
2025-07-12 00:19:21.785134: train_loss -0.973 
2025-07-12 00:19:21.786579: val_loss -0.9389 
2025-07-12 00:19:21.787740: Pseudo dice [np.float32(0.943)] 
2025-07-12 00:19:21.788864: Epoch time: 68.53 s 
2025-07-12 00:19:22.745923:  
2025-07-12 00:19:22.748060: Epoch 401 
2025-07-12 00:19:22.749316: Current learning rate: 0.0063 
2025-07-12 00:20:31.227676: train_loss -0.973 
2025-07-12 00:20:31.228922: val_loss -0.938 
2025-07-12 00:20:31.231323: Pseudo dice [np.float32(0.9405)] 
2025-07-12 00:20:31.232588: Epoch time: 68.49 s 
2025-07-12 00:20:32.209114:  
2025-07-12 00:20:32.210892: Epoch 402 
2025-07-12 00:20:32.212454: Current learning rate: 0.0063 
2025-07-12 00:21:40.946546: train_loss -0.9736 
2025-07-12 00:21:40.948519: val_loss -0.9379 
2025-07-12 00:21:40.949949: Pseudo dice [np.float32(0.9419)] 
2025-07-12 00:21:40.951345: Epoch time: 68.74 s 
2025-07-12 00:21:41.909789:  
2025-07-12 00:21:41.912484: Epoch 403 
2025-07-12 00:21:41.913639: Current learning rate: 0.00629 
2025-07-12 00:22:50.485454: train_loss -0.973 
2025-07-12 00:22:50.487732: val_loss -0.9407 
2025-07-12 00:22:50.489456: Pseudo dice [np.float32(0.9433)] 
2025-07-12 00:22:50.490588: Epoch time: 68.58 s 
2025-07-12 00:22:51.478556:  
2025-07-12 00:22:51.480504: Epoch 404 
2025-07-12 00:22:51.481828: Current learning rate: 0.00628 
2025-07-12 00:24:00.005439: train_loss -0.9735 
2025-07-12 00:24:00.007267: val_loss -0.9407 
2025-07-12 00:24:00.008429: Pseudo dice [np.float32(0.9447)] 
2025-07-12 00:24:00.009623: Epoch time: 68.53 s 
2025-07-12 00:24:00.995955:  
2025-07-12 00:24:00.998146: Epoch 405 
2025-07-12 00:24:00.999706: Current learning rate: 0.00627 
2025-07-12 00:25:09.664858: train_loss -0.9732 
2025-07-12 00:25:09.666823: val_loss -0.9456 
2025-07-12 00:25:09.667913: Pseudo dice [np.float32(0.9487)] 
2025-07-12 00:25:09.669065: Epoch time: 68.67 s 
2025-07-12 00:25:10.621012:  
2025-07-12 00:25:10.623307: Epoch 406 
2025-07-12 00:25:10.624498: Current learning rate: 0.00626 
2025-07-12 00:26:19.453119: train_loss -0.9734 
2025-07-12 00:26:19.454921: val_loss -0.9419 
2025-07-12 00:26:19.456651: Pseudo dice [np.float32(0.945)] 
2025-07-12 00:26:19.458177: Epoch time: 68.84 s 
2025-07-12 00:26:20.426414:  
2025-07-12 00:26:20.429228: Epoch 407 
2025-07-12 00:26:20.430212: Current learning rate: 0.00625 
2025-07-12 00:27:29.070319: train_loss -0.9734 
2025-07-12 00:27:29.072179: val_loss -0.9368 
2025-07-12 00:27:29.074108: Pseudo dice [np.float32(0.9395)] 
2025-07-12 00:27:29.076613: Epoch time: 68.65 s 
2025-07-12 00:27:30.049528:  
2025-07-12 00:27:30.051716: Epoch 408 
2025-07-12 00:27:30.052766: Current learning rate: 0.00624 
2025-07-12 00:28:38.651048: train_loss -0.9749 
2025-07-12 00:28:38.652594: val_loss -0.9455 
2025-07-12 00:28:38.654106: Pseudo dice [np.float32(0.9484)] 
2025-07-12 00:28:38.655186: Epoch time: 68.61 s 
2025-07-12 00:28:39.632402:  
2025-07-12 00:28:39.634927: Epoch 409 
2025-07-12 00:28:39.636290: Current learning rate: 0.00623 
2025-07-12 00:29:48.446069: train_loss -0.9741 
2025-07-12 00:29:48.447607: val_loss -0.9446 
2025-07-12 00:29:48.448695: Pseudo dice [np.float32(0.9481)] 
2025-07-12 00:29:48.449995: Epoch time: 68.82 s 
2025-07-12 00:29:48.451422: Yayy! New best EMA pseudo Dice: 0.9441999793052673 
2025-07-12 00:29:50.640973:  
2025-07-12 00:29:50.643216: Epoch 410 
2025-07-12 00:29:50.644545: Current learning rate: 0.00622 
2025-07-12 00:30:59.069201: train_loss -0.9734 
2025-07-12 00:30:59.070684: val_loss -0.9442 
2025-07-12 00:30:59.071868: Pseudo dice [np.float32(0.9474)] 
2025-07-12 00:30:59.073557: Epoch time: 68.43 s 
2025-07-12 00:30:59.074867: Yayy! New best EMA pseudo Dice: 0.9445000290870667 
2025-07-12 00:31:01.361069:  
2025-07-12 00:31:01.363209: Epoch 411 
2025-07-12 00:31:01.364409: Current learning rate: 0.00621 
2025-07-12 00:32:09.775644: train_loss -0.9725 
2025-07-12 00:32:09.777557: val_loss -0.9397 
2025-07-12 00:32:09.778697: Pseudo dice [np.float32(0.9434)] 
2025-07-12 00:32:09.780273: Epoch time: 68.42 s 
2025-07-12 00:32:10.706701:  
2025-07-12 00:32:10.708935: Epoch 412 
2025-07-12 00:32:10.710585: Current learning rate: 0.0062 
2025-07-12 00:33:19.416148: train_loss -0.9731 
2025-07-12 00:33:19.417513: val_loss -0.9369 
2025-07-12 00:33:19.418617: Pseudo dice [np.float32(0.9382)] 
2025-07-12 00:33:19.420383: Epoch time: 68.71 s 
2025-07-12 00:33:20.358130:  
2025-07-12 00:33:20.360403: Epoch 413 
2025-07-12 00:33:20.361951: Current learning rate: 0.00619 
2025-07-12 00:34:28.916492: train_loss -0.9731 
2025-07-12 00:34:28.918861: val_loss -0.9408 
2025-07-12 00:34:28.920818: Pseudo dice [np.float32(0.9454)] 
2025-07-12 00:34:28.922260: Epoch time: 68.56 s 
2025-07-12 00:34:29.860485:  
2025-07-12 00:34:29.862652: Epoch 414 
2025-07-12 00:34:29.864229: Current learning rate: 0.00618 
2025-07-12 00:35:38.545624: train_loss -0.9731 
2025-07-12 00:35:38.547059: val_loss -0.94 
2025-07-12 00:35:38.548935: Pseudo dice [np.float32(0.9428)] 
2025-07-12 00:35:38.551306: Epoch time: 68.69 s 
2025-07-12 00:35:39.496090:  
2025-07-12 00:35:39.498429: Epoch 415 
2025-07-12 00:35:39.500393: Current learning rate: 0.00617 
2025-07-12 00:36:48.172087: train_loss -0.9746 
2025-07-12 00:36:48.173355: val_loss -0.9425 
2025-07-12 00:36:48.174825: Pseudo dice [np.float32(0.946)] 
2025-07-12 00:36:48.176140: Epoch time: 68.68 s 
2025-07-12 00:36:49.120654:  
2025-07-12 00:36:49.122734: Epoch 416 
2025-07-12 00:36:49.124326: Current learning rate: 0.00616 
2025-07-12 00:37:57.946112: train_loss -0.9745 
2025-07-12 00:37:57.947333: val_loss -0.9387 
2025-07-12 00:37:57.948233: Pseudo dice [np.float32(0.9417)] 
2025-07-12 00:37:57.949531: Epoch time: 68.83 s 
2025-07-12 00:37:58.851413:  
2025-07-12 00:37:58.853395: Epoch 417 
2025-07-12 00:37:58.854523: Current learning rate: 0.00615 
2025-07-12 00:39:07.408908: train_loss -0.9725 
2025-07-12 00:39:07.410151: val_loss -0.9319 
2025-07-12 00:39:07.411855: Pseudo dice [np.float32(0.936)] 
2025-07-12 00:39:07.413520: Epoch time: 68.56 s 
2025-07-12 00:39:08.343002:  
2025-07-12 00:39:08.345258: Epoch 418 
2025-07-12 00:39:08.346498: Current learning rate: 0.00614 
2025-07-12 00:40:16.880067: train_loss -0.9727 
2025-07-12 00:40:16.881236: val_loss -0.9392 
2025-07-12 00:40:16.882200: Pseudo dice [np.float32(0.9425)] 
2025-07-12 00:40:16.883652: Epoch time: 68.54 s 
2025-07-12 00:40:17.813865:  
2025-07-12 00:40:17.816319: Epoch 419 
2025-07-12 00:40:17.817829: Current learning rate: 0.00613 
2025-07-12 00:41:26.555578: train_loss -0.9731 
2025-07-12 00:41:26.557014: val_loss -0.9435 
2025-07-12 00:41:26.558183: Pseudo dice [np.float32(0.9463)] 
2025-07-12 00:41:26.560084: Epoch time: 68.75 s 
2025-07-12 00:41:27.511917:  
2025-07-12 00:41:27.513883: Epoch 420 
2025-07-12 00:41:27.514925: Current learning rate: 0.00612 
2025-07-12 00:42:36.065135: train_loss -0.9735 
2025-07-12 00:42:36.066726: val_loss -0.9423 
2025-07-12 00:42:36.067857: Pseudo dice [np.float32(0.9458)] 
2025-07-12 00:42:36.068957: Epoch time: 68.56 s 
2025-07-12 00:42:36.996982:  
2025-07-12 00:42:36.999171: Epoch 421 
2025-07-12 00:42:37.000180: Current learning rate: 0.00612 
2025-07-12 00:43:45.496871: train_loss -0.9734 
2025-07-12 00:43:45.498265: val_loss -0.9316 
2025-07-12 00:43:45.499548: Pseudo dice [np.float32(0.935)] 
2025-07-12 00:43:45.501015: Epoch time: 68.5 s 
2025-07-12 00:43:46.439373:  
2025-07-12 00:43:46.441622: Epoch 422 
2025-07-12 00:43:46.442800: Current learning rate: 0.00611 
2025-07-12 00:44:54.882842: train_loss -0.9729 
2025-07-12 00:44:54.884278: val_loss -0.9306 
2025-07-12 00:44:54.885432: Pseudo dice [np.float32(0.932)] 
2025-07-12 00:44:54.886598: Epoch time: 68.45 s 
2025-07-12 00:44:55.819574:  
2025-07-12 00:44:55.821552: Epoch 423 
2025-07-12 00:44:55.822642: Current learning rate: 0.0061 
2025-07-12 00:46:04.440160: train_loss -0.9739 
2025-07-12 00:46:04.441920: val_loss -0.9272 
2025-07-12 00:46:04.443182: Pseudo dice [np.float32(0.9284)] 
2025-07-12 00:46:04.444127: Epoch time: 68.62 s 
2025-07-12 00:46:05.371133:  
2025-07-12 00:46:05.373176: Epoch 424 
2025-07-12 00:46:05.374358: Current learning rate: 0.00609 
2025-07-12 00:47:13.877071: train_loss -0.9731 
2025-07-12 00:47:13.878222: val_loss -0.931 
2025-07-12 00:47:13.879543: Pseudo dice [np.float32(0.9336)] 
2025-07-12 00:47:13.880732: Epoch time: 68.51 s 
2025-07-12 00:47:14.818692:  
2025-07-12 00:47:14.820895: Epoch 425 
2025-07-12 00:47:14.822169: Current learning rate: 0.00608 
2025-07-12 00:48:23.356586: train_loss -0.9733 
2025-07-12 00:48:23.358439: val_loss -0.9402 
2025-07-12 00:48:23.360130: Pseudo dice [np.float32(0.9436)] 
2025-07-12 00:48:23.361242: Epoch time: 68.54 s 
2025-07-12 00:48:24.293080:  
2025-07-12 00:48:24.295285: Epoch 426 
2025-07-12 00:48:24.296535: Current learning rate: 0.00607 
2025-07-12 00:49:32.905809: train_loss -0.974 
2025-07-12 00:49:32.907490: val_loss -0.9438 
2025-07-12 00:49:32.908635: Pseudo dice [np.float32(0.9442)] 
2025-07-12 00:49:32.909641: Epoch time: 68.62 s 
2025-07-12 00:49:33.837163:  
2025-07-12 00:49:33.839522: Epoch 427 
2025-07-12 00:49:33.840936: Current learning rate: 0.00606 
2025-07-12 00:50:42.491911: train_loss -0.9738 
2025-07-12 00:50:42.493538: val_loss -0.9353 
2025-07-12 00:50:42.495298: Pseudo dice [np.float32(0.9379)] 
2025-07-12 00:50:42.496913: Epoch time: 68.66 s 
2025-07-12 00:50:43.434640:  
2025-07-12 00:50:43.436787: Epoch 428 
2025-07-12 00:50:43.438201: Current learning rate: 0.00605 
2025-07-12 00:51:51.957369: train_loss -0.9738 
2025-07-12 00:51:51.958656: val_loss -0.9266 
2025-07-12 00:51:51.959672: Pseudo dice [np.float32(0.9302)] 
2025-07-12 00:51:51.960877: Epoch time: 68.53 s 
2025-07-12 00:51:52.904189:  
2025-07-12 00:51:52.906258: Epoch 429 
2025-07-12 00:51:52.907550: Current learning rate: 0.00604 
2025-07-12 00:53:01.389486: train_loss -0.9736 
2025-07-12 00:53:01.391090: val_loss -0.9437 
2025-07-12 00:53:01.392675: Pseudo dice [np.float32(0.9461)] 
2025-07-12 00:53:01.394065: Epoch time: 68.49 s 
2025-07-12 00:53:02.333964:  
2025-07-12 00:53:02.335850: Epoch 430 
2025-07-12 00:53:02.336905: Current learning rate: 0.00603 
2025-07-12 00:54:11.181326: train_loss -0.9741 
2025-07-12 00:54:11.182766: val_loss -0.9375 
2025-07-12 00:54:11.183816: Pseudo dice [np.float32(0.9389)] 
2025-07-12 00:54:11.185346: Epoch time: 68.85 s 
2025-07-12 00:54:12.123097:  
2025-07-12 00:54:12.125153: Epoch 431 
2025-07-12 00:54:12.126301: Current learning rate: 0.00602 
2025-07-12 00:55:20.693495: train_loss -0.9738 
2025-07-12 00:55:20.695183: val_loss -0.9418 
2025-07-12 00:55:20.697036: Pseudo dice [np.float32(0.9432)] 
2025-07-12 00:55:20.698528: Epoch time: 68.57 s 
2025-07-12 00:55:21.640349:  
2025-07-12 00:55:21.643191: Epoch 432 
2025-07-12 00:55:21.645186: Current learning rate: 0.00601 
2025-07-12 00:56:30.181622: train_loss -0.9743 
2025-07-12 00:56:30.183204: val_loss -0.9437 
2025-07-12 00:56:30.184871: Pseudo dice [np.float32(0.9463)] 
2025-07-12 00:56:30.186392: Epoch time: 68.54 s 
2025-07-12 00:56:31.128284:  
2025-07-12 00:56:31.130540: Epoch 433 
2025-07-12 00:56:31.131737: Current learning rate: 0.006 
2025-07-12 00:57:39.971325: train_loss -0.9743 
2025-07-12 00:57:39.973256: val_loss -0.945 
2025-07-12 00:57:39.974647: Pseudo dice [np.float32(0.9479)] 
2025-07-12 00:57:39.975811: Epoch time: 68.85 s 
2025-07-12 00:57:40.895566:  
2025-07-12 00:57:40.897564: Epoch 434 
2025-07-12 00:57:40.898749: Current learning rate: 0.00599 
2025-07-12 00:58:49.607738: train_loss -0.9744 
2025-07-12 00:58:49.609127: val_loss -0.9347 
2025-07-12 00:58:49.610276: Pseudo dice [np.float32(0.9371)] 
2025-07-12 00:58:49.611275: Epoch time: 68.72 s 
2025-07-12 00:58:50.556762:  
2025-07-12 00:58:50.558854: Epoch 435 
2025-07-12 00:58:50.560238: Current learning rate: 0.00598 
2025-07-12 00:59:59.168042: train_loss -0.9743 
2025-07-12 00:59:59.169344: val_loss -0.9389 
2025-07-12 00:59:59.170359: Pseudo dice [np.float32(0.9421)] 
2025-07-12 00:59:59.171361: Epoch time: 68.61 s 
2025-07-12 01:00:00.093868:  
2025-07-12 01:00:00.095964: Epoch 436 
2025-07-12 01:00:00.097174: Current learning rate: 0.00597 
2025-07-12 01:01:08.684136: train_loss -0.9744 
2025-07-12 01:01:08.685637: val_loss -0.9408 
2025-07-12 01:01:08.687444: Pseudo dice [np.float32(0.9449)] 
2025-07-12 01:01:08.689103: Epoch time: 68.59 s 
2025-07-12 01:01:09.653276:  
2025-07-12 01:01:09.655102: Epoch 437 
2025-07-12 01:01:09.656219: Current learning rate: 0.00596 
2025-07-12 01:02:18.390792: train_loss -0.974 
2025-07-12 01:02:18.392204: val_loss -0.9438 
2025-07-12 01:02:18.394159: Pseudo dice [np.float32(0.9463)] 
2025-07-12 01:02:18.395808: Epoch time: 68.74 s 
2025-07-12 01:02:19.329224:  
2025-07-12 01:02:19.331239: Epoch 438 
2025-07-12 01:02:19.332445: Current learning rate: 0.00595 
2025-07-12 01:03:27.823469: train_loss -0.975 
2025-07-12 01:03:27.824987: val_loss -0.9408 
2025-07-12 01:03:27.826057: Pseudo dice [np.float32(0.9425)] 
2025-07-12 01:03:27.827057: Epoch time: 68.5 s 
2025-07-12 01:03:28.779062:  
2025-07-12 01:03:28.781723: Epoch 439 
2025-07-12 01:03:28.783252: Current learning rate: 0.00594 
2025-07-12 01:04:37.535925: train_loss -0.9733 
2025-07-12 01:04:37.537892: val_loss -0.9385 
2025-07-12 01:04:37.538879: Pseudo dice [np.float32(0.9427)] 
2025-07-12 01:04:37.540284: Epoch time: 68.76 s 
2025-07-12 01:04:38.486236:  
2025-07-12 01:04:38.488443: Epoch 440 
2025-07-12 01:04:38.489527: Current learning rate: 0.00593 
2025-07-12 01:05:47.226383: train_loss -0.9736 
2025-07-12 01:05:47.228129: val_loss -0.946 
2025-07-12 01:05:47.229644: Pseudo dice [np.float32(0.9497)] 
2025-07-12 01:05:47.230628: Epoch time: 68.74 s 
2025-07-12 01:05:48.163306:  
2025-07-12 01:05:48.165410: Epoch 441 
2025-07-12 01:05:48.166635: Current learning rate: 0.00592 
2025-07-12 01:06:56.751741: train_loss -0.9746 
2025-07-12 01:06:56.753544: val_loss -0.9445 
2025-07-12 01:06:56.755179: Pseudo dice [np.float32(0.9474)] 
2025-07-12 01:06:56.756271: Epoch time: 68.59 s 
2025-07-12 01:06:57.654463:  
2025-07-12 01:06:57.657318: Epoch 442 
2025-07-12 01:06:57.658688: Current learning rate: 0.00592 
2025-07-12 01:08:06.335953: train_loss -0.9741 
2025-07-12 01:08:06.337800: val_loss -0.9417 
2025-07-12 01:08:06.339453: Pseudo dice [np.float32(0.9443)] 
2025-07-12 01:08:06.340334: Epoch time: 68.69 s 
2025-07-12 01:08:07.278112:  
2025-07-12 01:08:07.280304: Epoch 443 
2025-07-12 01:08:07.281393: Current learning rate: 0.00591 
2025-07-12 01:09:15.946814: train_loss -0.9751 
2025-07-12 01:09:15.948606: val_loss -0.9423 
2025-07-12 01:09:15.949712: Pseudo dice [np.float32(0.9451)] 
2025-07-12 01:09:15.950788: Epoch time: 68.67 s 
2025-07-12 01:09:16.847735:  
2025-07-12 01:09:16.849887: Epoch 444 
2025-07-12 01:09:16.851342: Current learning rate: 0.0059 
2025-07-12 01:10:25.858030: train_loss -0.9745 
2025-07-12 01:10:25.859378: val_loss -0.9397 
2025-07-12 01:10:25.860483: Pseudo dice [np.float32(0.9419)] 
2025-07-12 01:10:25.861822: Epoch time: 69.01 s 
2025-07-12 01:10:26.795607:  
2025-07-12 01:10:26.797744: Epoch 445 
2025-07-12 01:10:26.799304: Current learning rate: 0.00589 
2025-07-12 01:11:35.634518: train_loss -0.9737 
2025-07-12 01:11:35.636041: val_loss -0.9423 
2025-07-12 01:11:35.637554: Pseudo dice [np.float32(0.9466)] 
2025-07-12 01:11:35.638968: Epoch time: 68.84 s 
2025-07-12 01:11:36.574451:  
2025-07-12 01:11:36.577183: Epoch 446 
2025-07-12 01:11:36.578290: Current learning rate: 0.00588 
2025-07-12 01:12:45.194840: train_loss -0.9742 
2025-07-12 01:12:45.196483: val_loss -0.9436 
2025-07-12 01:12:45.198247: Pseudo dice [np.float32(0.9468)] 
2025-07-12 01:12:45.199696: Epoch time: 68.62 s 
2025-07-12 01:12:46.111170:  
2025-07-12 01:12:46.113129: Epoch 447 
2025-07-12 01:12:46.114231: Current learning rate: 0.00587 
2025-07-12 01:13:54.748038: train_loss -0.9747 
2025-07-12 01:13:54.750134: val_loss -0.9464 
2025-07-12 01:13:54.751199: Pseudo dice [np.float32(0.9493)] 
2025-07-12 01:13:54.752153: Epoch time: 68.64 s 
2025-07-12 01:13:54.754018: Yayy! New best EMA pseudo Dice: 0.944599986076355 
2025-07-12 01:13:56.888245:  
2025-07-12 01:13:56.890583: Epoch 448 
2025-07-12 01:13:56.891871: Current learning rate: 0.00586 
2025-07-12 01:15:05.567559: train_loss -0.9735 
2025-07-12 01:15:05.569119: val_loss -0.9376 
2025-07-12 01:15:05.570080: Pseudo dice [np.float32(0.9399)] 
2025-07-12 01:15:05.571218: Epoch time: 68.68 s 
2025-07-12 01:15:06.505173:  
2025-07-12 01:15:06.506812: Epoch 449 
2025-07-12 01:15:06.507907: Current learning rate: 0.00585 
2025-07-12 01:16:15.421141: train_loss -0.9739 
2025-07-12 01:16:15.422410: val_loss -0.9469 
2025-07-12 01:16:15.423649: Pseudo dice [np.float32(0.9492)] 
2025-07-12 01:16:15.425088: Epoch time: 68.92 s 
2025-07-12 01:16:16.637919: Yayy! New best EMA pseudo Dice: 0.944599986076355 
2025-07-12 01:16:18.977976:  
2025-07-12 01:16:18.980048: Epoch 450 
2025-07-12 01:16:18.981313: Current learning rate: 0.00584 
2025-07-12 01:17:27.645237: train_loss -0.9742 
2025-07-12 01:17:27.646470: val_loss -0.9324 
2025-07-12 01:17:27.647592: Pseudo dice [np.float32(0.9321)] 
2025-07-12 01:17:27.648947: Epoch time: 68.67 s 
2025-07-12 01:17:28.551153:  
2025-07-12 01:17:28.553626: Epoch 451 
2025-07-12 01:17:28.554904: Current learning rate: 0.00583 
2025-07-12 01:18:37.235550: train_loss -0.9748 
2025-07-12 01:18:37.236959: val_loss -0.9403 
2025-07-12 01:18:37.238095: Pseudo dice [np.float32(0.943)] 
2025-07-12 01:18:37.239340: Epoch time: 68.69 s 
2025-07-12 01:18:38.161585:  
2025-07-12 01:18:38.163691: Epoch 452 
2025-07-12 01:18:38.165161: Current learning rate: 0.00582 
2025-07-12 01:19:46.644904: train_loss -0.9758 
2025-07-12 01:19:46.647130: val_loss -0.9406 
2025-07-12 01:19:46.649038: Pseudo dice [np.float32(0.9434)] 
2025-07-12 01:19:46.650882: Epoch time: 68.49 s 
2025-07-12 01:19:47.570009:  
2025-07-12 01:19:47.572421: Epoch 453 
2025-07-12 01:19:47.573724: Current learning rate: 0.00581 
2025-07-12 01:20:56.237987: train_loss -0.9734 
2025-07-12 01:20:56.239368: val_loss -0.9451 
2025-07-12 01:20:56.240732: Pseudo dice [np.float32(0.9478)] 
2025-07-12 01:20:56.242652: Epoch time: 68.67 s 
2025-07-12 01:20:57.187653:  
2025-07-12 01:20:57.190122: Epoch 454 
2025-07-12 01:20:57.191465: Current learning rate: 0.0058 
2025-07-12 01:22:05.977945: train_loss -0.9751 
2025-07-12 01:22:05.979160: val_loss -0.9465 
2025-07-12 01:22:05.980247: Pseudo dice [np.float32(0.9492)] 
2025-07-12 01:22:05.981686: Epoch time: 68.79 s 
2025-07-12 01:22:06.890273:  
2025-07-12 01:22:06.892337: Epoch 455 
2025-07-12 01:22:06.893571: Current learning rate: 0.00579 
2025-07-12 01:23:15.615541: train_loss -0.974 
2025-07-12 01:23:15.617234: val_loss -0.943 
2025-07-12 01:23:15.619034: Pseudo dice [np.float32(0.9467)] 
2025-07-12 01:23:15.620916: Epoch time: 68.73 s 
2025-07-12 01:23:16.527188:  
2025-07-12 01:23:16.529346: Epoch 456 
2025-07-12 01:23:16.530766: Current learning rate: 0.00578 
2025-07-12 01:24:25.198946: train_loss -0.9736 
2025-07-12 01:24:25.200229: val_loss -0.9405 
2025-07-12 01:24:25.201396: Pseudo dice [np.float32(0.9441)] 
2025-07-12 01:24:25.202847: Epoch time: 68.68 s 
2025-07-12 01:24:26.126382:  
2025-07-12 01:24:26.128497: Epoch 457 
2025-07-12 01:24:26.129688: Current learning rate: 0.00577 
2025-07-12 01:25:34.957582: train_loss -0.9714 
2025-07-12 01:25:34.958958: val_loss -0.9416 
2025-07-12 01:25:34.960116: Pseudo dice [np.float32(0.944)] 
2025-07-12 01:25:34.961129: Epoch time: 68.83 s 
2025-07-12 01:25:35.896323:  
2025-07-12 01:25:35.898579: Epoch 458 
2025-07-12 01:25:35.899852: Current learning rate: 0.00576 
2025-07-12 01:26:44.832335: train_loss -0.9728 
2025-07-12 01:26:44.833771: val_loss -0.9408 
2025-07-12 01:26:44.834889: Pseudo dice [np.float32(0.9441)] 
2025-07-12 01:26:44.836109: Epoch time: 68.94 s 
2025-07-12 01:26:45.768992:  
2025-07-12 01:26:45.770897: Epoch 459 
2025-07-12 01:26:45.772150: Current learning rate: 0.00575 
2025-07-12 01:27:54.813796: train_loss -0.9742 
2025-07-12 01:27:54.815751: val_loss -0.943 
2025-07-12 01:27:54.817252: Pseudo dice [np.float32(0.9456)] 
2025-07-12 01:27:54.818434: Epoch time: 69.05 s 
2025-07-12 01:27:55.749879:  
2025-07-12 01:27:55.752115: Epoch 460 
2025-07-12 01:27:55.753621: Current learning rate: 0.00574 
2025-07-12 01:29:04.733256: train_loss -0.9745 
2025-07-12 01:29:04.735430: val_loss -0.9419 
2025-07-12 01:29:04.737463: Pseudo dice [np.float32(0.9446)] 
2025-07-12 01:29:04.738458: Epoch time: 68.99 s 
2025-07-12 01:29:05.663979:  
2025-07-12 01:29:05.666151: Epoch 461 
2025-07-12 01:29:05.667417: Current learning rate: 0.00573 
2025-07-12 01:30:14.540444: train_loss -0.9749 
2025-07-12 01:30:14.542480: val_loss -0.9468 
2025-07-12 01:30:14.543582: Pseudo dice [np.float32(0.9499)] 
2025-07-12 01:30:14.544939: Epoch time: 68.88 s 
2025-07-12 01:30:14.546332: Yayy! New best EMA pseudo Dice: 0.9451000094413757 
2025-07-12 01:30:16.818549:  
2025-07-12 01:30:16.820648: Epoch 462 
2025-07-12 01:30:16.822644: Current learning rate: 0.00572 
2025-07-12 01:31:25.680505: train_loss -0.9747 
2025-07-12 01:31:25.681973: val_loss -0.9399 
2025-07-12 01:31:25.683153: Pseudo dice [np.float32(0.9435)] 
2025-07-12 01:31:25.684405: Epoch time: 68.87 s 
2025-07-12 01:31:26.595617:  
2025-07-12 01:31:26.598275: Epoch 463 
2025-07-12 01:31:26.599397: Current learning rate: 0.00571 
2025-07-12 01:32:35.411340: train_loss -0.9734 
2025-07-12 01:32:35.412631: val_loss -0.9431 
2025-07-12 01:32:35.413675: Pseudo dice [np.float32(0.947)] 
2025-07-12 01:32:35.415217: Epoch time: 68.82 s 
2025-07-12 01:32:35.417383: Yayy! New best EMA pseudo Dice: 0.9451000094413757 
2025-07-12 01:32:37.694923:  
2025-07-12 01:32:37.697281: Epoch 464 
2025-07-12 01:32:37.698883: Current learning rate: 0.0057 
2025-07-12 01:33:46.497419: train_loss -0.9735 
2025-07-12 01:33:46.498796: val_loss -0.9414 
2025-07-12 01:33:46.499837: Pseudo dice [np.float32(0.9457)] 
2025-07-12 01:33:46.501594: Epoch time: 68.81 s 
2025-07-12 01:33:46.504984: Yayy! New best EMA pseudo Dice: 0.9452000260353088 
2025-07-12 01:33:48.796540:  
2025-07-12 01:33:48.798428: Epoch 465 
2025-07-12 01:33:48.799838: Current learning rate: 0.0057 
2025-07-12 01:34:57.495519: train_loss -0.9742 
2025-07-12 01:34:57.497288: val_loss -0.9399 
2025-07-12 01:34:57.499645: Pseudo dice [np.float32(0.9443)] 
2025-07-12 01:34:57.503339: Epoch time: 68.7 s 
2025-07-12 01:34:58.404151:  
2025-07-12 01:34:58.406389: Epoch 466 
2025-07-12 01:34:58.407991: Current learning rate: 0.00569 
2025-07-12 01:36:07.241503: train_loss -0.973 
2025-07-12 01:36:07.242988: val_loss -0.9368 
2025-07-12 01:36:07.245037: Pseudo dice [np.float32(0.941)] 
2025-07-12 01:36:07.247265: Epoch time: 68.84 s 
2025-07-12 01:36:08.177554:  
2025-07-12 01:36:08.180713: Epoch 467 
2025-07-12 01:36:08.181985: Current learning rate: 0.00568 
2025-07-12 01:37:16.616819: train_loss -0.9735 
2025-07-12 01:37:16.619183: val_loss -0.9474 
2025-07-12 01:37:16.621417: Pseudo dice [np.float32(0.9506)] 
2025-07-12 01:37:16.624010: Epoch time: 68.44 s 
2025-07-12 01:37:16.625419: Yayy! New best EMA pseudo Dice: 0.9452999830245972 
2025-07-12 01:37:19.166716:  
2025-07-12 01:37:19.168795: Epoch 468 
2025-07-12 01:37:19.170035: Current learning rate: 0.00567 
2025-07-12 01:38:27.858269: train_loss -0.9743 
2025-07-12 01:38:27.860492: val_loss -0.9316 
2025-07-12 01:38:27.862838: Pseudo dice [np.float32(0.934)] 
2025-07-12 01:38:27.865294: Epoch time: 68.7 s 
2025-07-12 01:38:28.804238:  
2025-07-12 01:38:28.806291: Epoch 469 
2025-07-12 01:38:28.807503: Current learning rate: 0.00566 
2025-07-12 01:39:37.505727: train_loss -0.9728 
2025-07-12 01:39:37.507477: val_loss -0.9308 
2025-07-12 01:39:37.509114: Pseudo dice [np.float32(0.9346)] 
2025-07-12 01:39:37.511054: Epoch time: 68.71 s 
2025-07-12 01:39:38.435096:  
2025-07-12 01:39:38.437414: Epoch 470 
2025-07-12 01:39:38.438654: Current learning rate: 0.00565 
2025-07-12 01:40:47.219162: train_loss -0.9746 
2025-07-12 01:40:47.220654: val_loss -0.9314 
2025-07-12 01:40:47.222134: Pseudo dice [np.float32(0.9343)] 
2025-07-12 01:40:47.224243: Epoch time: 68.79 s 
2025-07-12 01:40:48.140745:  
2025-07-12 01:40:48.142884: Epoch 471 
2025-07-12 01:40:48.144361: Current learning rate: 0.00564 
2025-07-12 01:41:56.778382: train_loss -0.9747 
2025-07-12 01:41:56.780360: val_loss -0.9353 
2025-07-12 01:41:56.783404: Pseudo dice [np.float32(0.9354)] 
2025-07-12 01:41:56.785491: Epoch time: 68.64 s 
2025-07-12 01:41:57.737382:  
2025-07-12 01:41:57.739965: Epoch 472 
2025-07-12 01:41:57.741287: Current learning rate: 0.00563 
2025-07-12 01:43:06.405405: train_loss -0.9731 
2025-07-12 01:43:06.407746: val_loss -0.9359 
2025-07-12 01:43:06.409675: Pseudo dice [np.float32(0.9405)] 
2025-07-12 01:43:06.411765: Epoch time: 68.67 s 
2025-07-12 01:43:07.356739:  
2025-07-12 01:43:07.359173: Epoch 473 
2025-07-12 01:43:07.360612: Current learning rate: 0.00562 
2025-07-12 01:44:16.059644: train_loss -0.97 
2025-07-12 01:44:16.061072: val_loss -0.9389 
2025-07-12 01:44:16.062882: Pseudo dice [np.float32(0.942)] 
2025-07-12 01:44:16.064995: Epoch time: 68.71 s 
2025-07-12 01:44:16.998749:  
2025-07-12 01:44:17.000746: Epoch 474 
2025-07-12 01:44:17.001717: Current learning rate: 0.00561 
2025-07-12 01:45:25.792686: train_loss -0.9704 
2025-07-12 01:45:25.795293: val_loss -0.9407 
2025-07-12 01:45:25.797683: Pseudo dice [np.float32(0.9437)] 
2025-07-12 01:45:25.801662: Epoch time: 68.8 s 
2025-07-12 01:45:26.958205:  
2025-07-12 01:45:26.960799: Epoch 475 
2025-07-12 01:45:26.961797: Current learning rate: 0.0056 
2025-07-12 01:46:35.673522: train_loss -0.9735 
2025-07-12 01:46:35.675101: val_loss -0.9376 
2025-07-12 01:46:35.676478: Pseudo dice [np.float32(0.9399)] 
2025-07-12 01:46:35.678379: Epoch time: 68.72 s 
2025-07-12 01:46:36.611447:  
2025-07-12 01:46:36.613669: Epoch 476 
2025-07-12 01:46:36.615355: Current learning rate: 0.00559 
2025-07-12 01:47:45.444815: train_loss -0.9746 
2025-07-12 01:47:45.447490: val_loss -0.9416 
2025-07-12 01:47:45.449168: Pseudo dice [np.float32(0.9437)] 
2025-07-12 01:47:45.451221: Epoch time: 68.84 s 
2025-07-12 01:47:46.371794:  
2025-07-12 01:47:46.374149: Epoch 477 
2025-07-12 01:47:46.375394: Current learning rate: 0.00558 
2025-07-12 01:48:54.901114: train_loss -0.9744 
2025-07-12 01:48:54.902914: val_loss -0.945 
2025-07-12 01:48:54.904533: Pseudo dice [np.float32(0.9481)] 
2025-07-12 01:48:54.905709: Epoch time: 68.53 s 
2025-07-12 01:48:55.852426:  
2025-07-12 01:48:55.854472: Epoch 478 
2025-07-12 01:48:55.855844: Current learning rate: 0.00557 
2025-07-12 01:50:04.501998: train_loss -0.975 
2025-07-12 01:50:04.504204: val_loss -0.9477 
2025-07-12 01:50:04.507317: Pseudo dice [np.float32(0.9499)] 
2025-07-12 01:50:04.509722: Epoch time: 68.65 s 
2025-07-12 01:50:05.403511:  
2025-07-12 01:50:05.406211: Epoch 479 
2025-07-12 01:50:05.408360: Current learning rate: 0.00556 
2025-07-12 01:51:14.150669: train_loss -0.9757 
2025-07-12 01:51:14.152461: val_loss -0.944 
2025-07-12 01:51:14.155016: Pseudo dice [np.float32(0.9477)] 
2025-07-12 01:51:14.157623: Epoch time: 68.75 s 
2025-07-12 01:51:15.090285:  
2025-07-12 01:51:15.092529: Epoch 480 
2025-07-12 01:51:15.093740: Current learning rate: 0.00555 
2025-07-12 01:52:24.003163: train_loss -0.9741 
2025-07-12 01:52:24.005509: val_loss -0.9409 
2025-07-12 01:52:24.007519: Pseudo dice [np.float32(0.9441)] 
2025-07-12 01:52:24.010681: Epoch time: 68.92 s 
2025-07-12 01:52:24.916570:  
2025-07-12 01:52:24.918788: Epoch 481 
2025-07-12 01:52:24.920153: Current learning rate: 0.00554 
2025-07-12 01:53:33.829291: train_loss -0.9734 
2025-07-12 01:53:33.832272: val_loss -0.9435 
2025-07-12 01:53:33.834864: Pseudo dice [np.float32(0.9471)] 
2025-07-12 01:53:33.837284: Epoch time: 68.92 s 
2025-07-12 01:53:34.800448:  
2025-07-12 01:53:34.803225: Epoch 482 
2025-07-12 01:53:34.804637: Current learning rate: 0.00553 
2025-07-12 01:54:43.939269: train_loss -0.9747 
2025-07-12 01:54:43.941726: val_loss -0.9332 
2025-07-12 01:54:43.943560: Pseudo dice [np.float32(0.938)] 
2025-07-12 01:54:43.945399: Epoch time: 69.14 s 
2025-07-12 01:54:44.935592:  
2025-07-12 01:54:44.937511: Epoch 483 
2025-07-12 01:54:44.938608: Current learning rate: 0.00552 
2025-07-12 01:55:53.504555: train_loss -0.9747 
2025-07-12 01:55:53.507466: val_loss -0.937 
2025-07-12 01:55:53.509877: Pseudo dice [np.float32(0.9406)] 
2025-07-12 01:55:53.511618: Epoch time: 68.57 s 
2025-07-12 01:55:54.428267:  
2025-07-12 01:55:54.430648: Epoch 484 
2025-07-12 01:55:54.432273: Current learning rate: 0.00551 
2025-07-12 01:57:02.925864: train_loss -0.9749 
2025-07-12 01:57:02.927550: val_loss -0.9428 
2025-07-12 01:57:02.929374: Pseudo dice [np.float32(0.9456)] 
2025-07-12 01:57:02.931353: Epoch time: 68.5 s 
2025-07-12 01:57:03.873804:  
2025-07-12 01:57:03.875584: Epoch 485 
2025-07-12 01:57:03.876832: Current learning rate: 0.0055 
2025-07-12 01:58:12.594659: train_loss -0.974 
2025-07-12 01:58:12.598323: val_loss -0.9416 
2025-07-12 01:58:12.600667: Pseudo dice [np.float32(0.9458)] 
2025-07-12 01:58:12.602205: Epoch time: 68.72 s 
2025-07-12 01:58:13.611219:  
2025-07-12 01:58:13.613718: Epoch 486 
2025-07-12 01:58:13.615205: Current learning rate: 0.00549 
2025-07-12 01:59:22.291051: train_loss -0.9756 
2025-07-12 01:59:22.293581: val_loss -0.9387 
2025-07-12 01:59:22.295339: Pseudo dice [np.float32(0.9423)] 
2025-07-12 01:59:22.297591: Epoch time: 68.68 s 
2025-07-12 01:59:23.226650:  
2025-07-12 01:59:23.229164: Epoch 487 
2025-07-12 01:59:23.230311: Current learning rate: 0.00548 
2025-07-12 02:00:31.981219: train_loss -0.9744 
2025-07-12 02:00:31.983545: val_loss -0.9429 
2025-07-12 02:00:31.985667: Pseudo dice [np.float32(0.946)] 
2025-07-12 02:00:31.987838: Epoch time: 68.76 s 
2025-07-12 02:00:32.951632:  
2025-07-12 02:00:32.952835: Epoch 488 
2025-07-12 02:00:32.954648: Current learning rate: 0.00547 
2025-07-12 02:01:41.580245: train_loss -0.9744 
2025-07-12 02:01:41.582132: val_loss -0.9375 
2025-07-12 02:01:41.583443: Pseudo dice [np.float32(0.9387)] 
2025-07-12 02:01:41.584825: Epoch time: 68.63 s 
2025-07-12 02:01:42.515120:  
2025-07-12 02:01:42.517206: Epoch 489 
2025-07-12 02:01:42.518791: Current learning rate: 0.00546 
2025-07-12 02:02:51.384391: train_loss -0.9749 
2025-07-12 02:02:51.385955: val_loss -0.9398 
2025-07-12 02:02:51.387154: Pseudo dice [np.float32(0.9431)] 
2025-07-12 02:02:51.388371: Epoch time: 68.87 s 
2025-07-12 02:02:52.305943:  
2025-07-12 02:02:52.308230: Epoch 490 
2025-07-12 02:02:52.309317: Current learning rate: 0.00546 
2025-07-12 02:04:00.948732: train_loss -0.9753 
2025-07-12 02:04:00.950315: val_loss -0.936 
2025-07-12 02:04:00.951514: Pseudo dice [np.float32(0.9399)] 
2025-07-12 02:04:00.952343: Epoch time: 68.65 s 
2025-07-12 02:04:01.867192:  
2025-07-12 02:04:01.869200: Epoch 491 
2025-07-12 02:04:01.870544: Current learning rate: 0.00545 
2025-07-12 02:05:10.587385: train_loss -0.9752 
2025-07-12 02:05:10.588699: val_loss -0.9371 
2025-07-12 02:05:10.589678: Pseudo dice [np.float32(0.9393)] 
2025-07-12 02:05:10.590696: Epoch time: 68.72 s 
2025-07-12 02:05:11.524835:  
2025-07-12 02:05:11.526773: Epoch 492 
2025-07-12 02:05:11.527886: Current learning rate: 0.00544 
2025-07-12 02:06:20.347991: train_loss -0.9762 
2025-07-12 02:06:20.349747: val_loss -0.9418 
2025-07-12 02:06:20.351166: Pseudo dice [np.float32(0.9447)] 
2025-07-12 02:06:20.352379: Epoch time: 68.83 s 
2025-07-12 02:06:21.276994:  
2025-07-12 02:06:21.279146: Epoch 493 
2025-07-12 02:06:21.280430: Current learning rate: 0.00543 
2025-07-12 02:07:29.912517: train_loss -0.9752 
2025-07-12 02:07:29.914181: val_loss -0.9372 
2025-07-12 02:07:29.915609: Pseudo dice [np.float32(0.9393)] 
2025-07-12 02:07:29.916902: Epoch time: 68.64 s 
2025-07-12 02:07:30.842864:  
2025-07-12 02:07:30.844927: Epoch 494 
2025-07-12 02:07:30.846257: Current learning rate: 0.00542 
2025-07-12 02:08:39.462598: train_loss -0.9751 
2025-07-12 02:08:39.463732: val_loss -0.936 
2025-07-12 02:08:39.464858: Pseudo dice [np.float32(0.9394)] 
2025-07-12 02:08:39.467027: Epoch time: 68.62 s 
2025-07-12 02:08:40.393885:  
2025-07-12 02:08:40.396364: Epoch 495 
2025-07-12 02:08:40.397876: Current learning rate: 0.00541 
2025-07-12 02:09:48.962528: train_loss -0.9748 
2025-07-12 02:09:48.963814: val_loss -0.9402 
2025-07-12 02:09:48.965063: Pseudo dice [np.float32(0.9435)] 
2025-07-12 02:09:48.967153: Epoch time: 68.57 s 
2025-07-12 02:09:49.927239:  
2025-07-12 02:09:49.929242: Epoch 496 
2025-07-12 02:09:49.930572: Current learning rate: 0.0054 
2025-07-12 02:10:58.635093: train_loss -0.9747 
2025-07-12 02:10:58.636357: val_loss -0.9442 
2025-07-12 02:10:58.637727: Pseudo dice [np.float32(0.9477)] 
2025-07-12 02:10:58.639098: Epoch time: 68.71 s 
2025-07-12 02:10:59.567237:  
2025-07-12 02:10:59.569566: Epoch 497 
2025-07-12 02:10:59.571472: Current learning rate: 0.00539 
2025-07-12 02:12:08.138980: train_loss -0.9737 
2025-07-12 02:12:08.140466: val_loss -0.9362 
2025-07-12 02:12:08.141526: Pseudo dice [np.float32(0.9389)] 
2025-07-12 02:12:08.143261: Epoch time: 68.58 s 
2025-07-12 02:12:09.083351:  
2025-07-12 02:12:09.085299: Epoch 498 
2025-07-12 02:12:09.086535: Current learning rate: 0.00538 
2025-07-12 02:13:17.757114: train_loss -0.9737 
2025-07-12 02:13:17.758571: val_loss -0.9436 
2025-07-12 02:13:17.759694: Pseudo dice [np.float32(0.9478)] 
2025-07-12 02:13:17.761148: Epoch time: 68.68 s 
2025-07-12 02:13:18.711458:  
2025-07-12 02:13:18.713840: Epoch 499 
2025-07-12 02:13:18.715215: Current learning rate: 0.00537 
2025-07-12 02:14:27.455914: train_loss -0.9742 
2025-07-12 02:14:27.457516: val_loss -0.9368 
2025-07-12 02:14:27.459156: Pseudo dice [np.float32(0.9408)] 
2025-07-12 02:14:27.460537: Epoch time: 68.75 s 
2025-07-12 02:14:29.580301:  
2025-07-12 02:14:29.582595: Epoch 500 
2025-07-12 02:14:29.584036: Current learning rate: 0.00536 
2025-07-12 02:15:38.283199: train_loss -0.9738 
2025-07-12 02:15:38.285320: val_loss -0.9391 
2025-07-12 02:15:38.287340: Pseudo dice [np.float32(0.9424)] 
2025-07-12 02:15:38.288735: Epoch time: 68.71 s 
2025-07-12 02:15:39.309368:  
2025-07-12 02:15:39.311658: Epoch 501 
2025-07-12 02:15:39.312882: Current learning rate: 0.00535 
2025-07-12 02:16:48.096764: train_loss -0.9748 
2025-07-12 02:16:48.098130: val_loss -0.9425 
2025-07-12 02:16:48.099592: Pseudo dice [np.float32(0.9457)] 
2025-07-12 02:16:48.100661: Epoch time: 68.79 s 
2025-07-12 02:16:49.035228:  
2025-07-12 02:16:49.037748: Epoch 502 
2025-07-12 02:16:49.038928: Current learning rate: 0.00534 
2025-07-12 02:17:57.787387: train_loss -0.9738 
2025-07-12 02:17:57.789084: val_loss -0.9386 
2025-07-12 02:17:57.790231: Pseudo dice [np.float32(0.9427)] 
2025-07-12 02:17:57.791427: Epoch time: 68.76 s 
2025-07-12 02:17:58.966252:  
2025-07-12 02:17:58.969311: Epoch 503 
2025-07-12 02:17:58.971163: Current learning rate: 0.00533 
2025-07-12 02:19:07.696994: train_loss -0.975 
2025-07-12 02:19:07.699044: val_loss -0.9387 
2025-07-12 02:19:07.700351: Pseudo dice [np.float32(0.942)] 
2025-07-12 02:19:07.702647: Epoch time: 68.73 s 
2025-07-12 02:19:08.644331:  
2025-07-12 02:19:08.646660: Epoch 504 
2025-07-12 02:19:08.648347: Current learning rate: 0.00532 
2025-07-12 02:20:17.284159: train_loss -0.976 
2025-07-12 02:20:17.286649: val_loss -0.943 
2025-07-12 02:20:17.288373: Pseudo dice [np.float32(0.9453)] 
2025-07-12 02:20:17.289602: Epoch time: 68.64 s 
2025-07-12 02:20:18.202285:  
2025-07-12 02:20:18.204529: Epoch 505 
2025-07-12 02:20:18.205626: Current learning rate: 0.00531 
2025-07-12 02:21:26.759159: train_loss -0.9761 
2025-07-12 02:21:26.761189: val_loss -0.9427 
2025-07-12 02:21:26.762975: Pseudo dice [np.float32(0.9457)] 
2025-07-12 02:21:26.764361: Epoch time: 68.56 s 
2025-07-12 02:21:27.694112:  
2025-07-12 02:21:27.696685: Epoch 506 
2025-07-12 02:21:27.698034: Current learning rate: 0.0053 
2025-07-12 02:22:36.415785: train_loss -0.9761 
2025-07-12 02:22:36.417651: val_loss -0.9427 
2025-07-12 02:22:36.418578: Pseudo dice [np.float32(0.9451)] 
2025-07-12 02:22:36.419672: Epoch time: 68.73 s 
2025-07-12 02:22:37.362862:  
2025-07-12 02:22:37.365359: Epoch 507 
2025-07-12 02:22:37.367448: Current learning rate: 0.00529 
2025-07-12 02:23:45.941647: train_loss -0.9745 
2025-07-12 02:23:45.942852: val_loss -0.9416 
2025-07-12 02:23:45.944176: Pseudo dice [np.float32(0.945)] 
2025-07-12 02:23:45.946258: Epoch time: 68.58 s 
2025-07-12 02:23:46.908514:  
2025-07-12 02:23:46.910863: Epoch 508 
2025-07-12 02:23:46.912027: Current learning rate: 0.00528 
2025-07-12 02:24:55.391409: train_loss -0.9754 
2025-07-12 02:24:55.393047: val_loss -0.9474 
2025-07-12 02:24:55.394315: Pseudo dice [np.float32(0.9497)] 
2025-07-12 02:24:55.395674: Epoch time: 68.49 s 
2025-07-12 02:24:56.311501:  
2025-07-12 02:24:56.313793: Epoch 509 
2025-07-12 02:24:56.315324: Current learning rate: 0.00527 
2025-07-12 02:26:04.863350: train_loss -0.9768 
2025-07-12 02:26:04.865244: val_loss -0.9388 
2025-07-12 02:26:04.866378: Pseudo dice [np.float32(0.9419)] 
2025-07-12 02:26:04.867762: Epoch time: 68.56 s 
2025-07-12 02:26:05.783211:  
2025-07-12 02:26:05.785533: Epoch 510 
2025-07-12 02:26:05.787160: Current learning rate: 0.00526 
2025-07-12 02:27:14.649336: train_loss -0.9764 
2025-07-12 02:27:14.650682: val_loss -0.9429 
2025-07-12 02:27:14.651857: Pseudo dice [np.float32(0.9456)] 
2025-07-12 02:27:14.653352: Epoch time: 68.87 s 
2025-07-12 02:27:15.566905:  
2025-07-12 02:27:15.569376: Epoch 511 
2025-07-12 02:27:15.570491: Current learning rate: 0.00525 
2025-07-12 02:28:24.257742: train_loss -0.9763 
2025-07-12 02:28:24.259005: val_loss -0.9396 
2025-07-12 02:28:24.260301: Pseudo dice [np.float32(0.9419)] 
2025-07-12 02:28:24.261275: Epoch time: 68.69 s 
2025-07-12 02:28:25.164317:  
2025-07-12 02:28:25.166839: Epoch 512 
2025-07-12 02:28:25.168208: Current learning rate: 0.00524 
2025-07-12 02:29:33.912938: train_loss -0.9754 
2025-07-12 02:29:33.914267: val_loss -0.9272 
2025-07-12 02:29:33.915362: Pseudo dice [np.float32(0.9254)] 
2025-07-12 02:29:33.916408: Epoch time: 68.75 s 
2025-07-12 02:29:34.830917:  
2025-07-12 02:29:34.833148: Epoch 513 
2025-07-12 02:29:34.834868: Current learning rate: 0.00523 
2025-07-12 02:30:43.596663: train_loss -0.9745 
2025-07-12 02:30:43.597909: val_loss -0.9429 
2025-07-12 02:30:43.599032: Pseudo dice [np.float32(0.9463)] 
2025-07-12 02:30:43.599990: Epoch time: 68.77 s 
2025-07-12 02:30:44.500472:  
2025-07-12 02:30:44.502757: Epoch 514 
2025-07-12 02:30:44.504114: Current learning rate: 0.00522 
2025-07-12 02:31:53.138859: train_loss -0.9746 
2025-07-12 02:31:53.140091: val_loss -0.9378 
2025-07-12 02:31:53.141738: Pseudo dice [np.float32(0.9374)] 
2025-07-12 02:31:53.142712: Epoch time: 68.64 s 
2025-07-12 02:31:54.073889:  
2025-07-12 02:31:54.076050: Epoch 515 
2025-07-12 02:31:54.077313: Current learning rate: 0.00521 
2025-07-12 02:33:02.689283: train_loss -0.9747 
2025-07-12 02:33:02.690466: val_loss -0.9447 
2025-07-12 02:33:02.691444: Pseudo dice [np.float32(0.9479)] 
2025-07-12 02:33:02.692597: Epoch time: 68.62 s 
2025-07-12 02:33:03.629900:  
2025-07-12 02:33:03.631730: Epoch 516 
2025-07-12 02:33:03.633040: Current learning rate: 0.0052 
2025-07-12 02:34:12.358524: train_loss -0.975 
2025-07-12 02:34:12.359909: val_loss -0.943 
2025-07-12 02:34:12.361389: Pseudo dice [np.float32(0.9456)] 
2025-07-12 02:34:12.362537: Epoch time: 68.73 s 
2025-07-12 02:34:13.296686:  
2025-07-12 02:34:13.298975: Epoch 517 
2025-07-12 02:34:13.300395: Current learning rate: 0.00519 
2025-07-12 02:35:22.276908: train_loss -0.9757 
2025-07-12 02:35:22.278478: val_loss -0.9399 
2025-07-12 02:35:22.280184: Pseudo dice [np.float32(0.9434)] 
2025-07-12 02:35:22.281229: Epoch time: 68.98 s 
2025-07-12 02:35:23.201861:  
2025-07-12 02:35:23.203595: Epoch 518 
2025-07-12 02:35:23.204848: Current learning rate: 0.00518 
2025-07-12 02:36:32.074054: train_loss -0.9747 
2025-07-12 02:36:32.075500: val_loss -0.9444 
2025-07-12 02:36:32.076628: Pseudo dice [np.float32(0.9472)] 
2025-07-12 02:36:32.077686: Epoch time: 68.88 s 
2025-07-12 02:36:33.015284:  
2025-07-12 02:36:33.016837: Epoch 519 
2025-07-12 02:36:33.018275: Current learning rate: 0.00518 
2025-07-12 02:37:41.965124: train_loss -0.9758 
2025-07-12 02:37:41.966351: val_loss -0.939 
2025-07-12 02:37:41.967471: Pseudo dice [np.float32(0.9419)] 
2025-07-12 02:37:41.968453: Epoch time: 68.95 s 
2025-07-12 02:37:42.910087:  
2025-07-12 02:37:42.912580: Epoch 520 
2025-07-12 02:37:42.914318: Current learning rate: 0.00517 
2025-07-12 02:38:51.769678: train_loss -0.9763 
2025-07-12 02:38:51.770961: val_loss -0.9339 
2025-07-12 02:38:51.772289: Pseudo dice [np.float32(0.9341)] 
2025-07-12 02:38:51.773659: Epoch time: 68.86 s 
2025-07-12 02:38:53.551677:  
2025-07-12 02:38:53.554032: Epoch 521 
2025-07-12 02:38:53.555444: Current learning rate: 0.00516 
2025-07-12 02:40:02.062913: train_loss -0.9765 
2025-07-12 02:40:02.064026: val_loss -0.9417 
2025-07-12 02:40:02.065206: Pseudo dice [np.float32(0.9443)] 
2025-07-12 02:40:02.067067: Epoch time: 68.51 s 
2025-07-12 02:40:02.979378:  
2025-07-12 02:40:02.981735: Epoch 522 
2025-07-12 02:40:02.983246: Current learning rate: 0.00515 
2025-07-12 02:41:11.727258: train_loss -0.975 
2025-07-12 02:41:11.728643: val_loss -0.9364 
2025-07-12 02:41:11.729919: Pseudo dice [np.float32(0.9391)] 
2025-07-12 02:41:11.730997: Epoch time: 68.75 s 
2025-07-12 02:41:12.656091:  
2025-07-12 02:41:12.658270: Epoch 523 
2025-07-12 02:41:12.659460: Current learning rate: 0.00514 
2025-07-12 02:42:21.433599: train_loss -0.975 
2025-07-12 02:42:21.435209: val_loss -0.9461 
2025-07-12 02:42:21.436849: Pseudo dice [np.float32(0.9493)] 
2025-07-12 02:42:21.438337: Epoch time: 68.78 s 
2025-07-12 02:42:22.361594:  
2025-07-12 02:42:22.363802: Epoch 524 
2025-07-12 02:42:22.365131: Current learning rate: 0.00513 
2025-07-12 02:43:31.166525: train_loss -0.9755 
2025-07-12 02:43:31.167986: val_loss -0.9419 
2025-07-12 02:43:31.169075: Pseudo dice [np.float32(0.9438)] 
2025-07-12 02:43:31.170472: Epoch time: 68.81 s 
2025-07-12 02:43:32.090960:  
2025-07-12 02:43:32.093046: Epoch 525 
2025-07-12 02:43:32.094165: Current learning rate: 0.00512 
2025-07-12 02:44:40.553819: train_loss -0.9754 
2025-07-12 02:44:40.555138: val_loss -0.9414 
2025-07-12 02:44:40.556308: Pseudo dice [np.float32(0.9442)] 
2025-07-12 02:44:40.557426: Epoch time: 68.47 s 
2025-07-12 02:44:41.471741:  
2025-07-12 02:44:41.473897: Epoch 526 
2025-07-12 02:44:41.475174: Current learning rate: 0.00511 
2025-07-12 02:45:50.055080: train_loss -0.976 
2025-07-12 02:45:50.056483: val_loss -0.9403 
2025-07-12 02:45:50.057558: Pseudo dice [np.float32(0.944)] 
2025-07-12 02:45:50.058656: Epoch time: 68.59 s 
2025-07-12 02:45:50.978870:  
2025-07-12 02:45:50.981142: Epoch 527 
2025-07-12 02:45:50.982403: Current learning rate: 0.0051 
2025-07-12 02:46:59.794159: train_loss -0.9764 
2025-07-12 02:46:59.795654: val_loss -0.9408 
2025-07-12 02:46:59.797403: Pseudo dice [np.float32(0.9432)] 
2025-07-12 02:46:59.798599: Epoch time: 68.82 s 
2025-07-12 02:47:00.719337:  
2025-07-12 02:47:00.721772: Epoch 528 
2025-07-12 02:47:00.723146: Current learning rate: 0.00509 
2025-07-12 02:48:09.488756: train_loss -0.977 
2025-07-12 02:48:09.490499: val_loss -0.9432 
2025-07-12 02:48:09.491515: Pseudo dice [np.float32(0.9468)] 
2025-07-12 02:48:09.492595: Epoch time: 68.77 s 
2025-07-12 02:48:10.408111:  
2025-07-12 02:48:10.410395: Epoch 529 
2025-07-12 02:48:10.412133: Current learning rate: 0.00508 
2025-07-12 02:49:19.146425: train_loss -0.9765 
2025-07-12 02:49:19.147833: val_loss -0.9412 
2025-07-12 02:49:19.148958: Pseudo dice [np.float32(0.944)] 
2025-07-12 02:49:19.150518: Epoch time: 68.74 s 
2025-07-12 02:49:20.075752:  
2025-07-12 02:49:20.077958: Epoch 530 
2025-07-12 02:49:20.079333: Current learning rate: 0.00507 
2025-07-12 02:50:28.789879: train_loss -0.9768 
2025-07-12 02:50:28.791116: val_loss -0.9474 
2025-07-12 02:50:28.792338: Pseudo dice [np.float32(0.9496)] 
2025-07-12 02:50:28.793308: Epoch time: 68.72 s 
2025-07-12 02:50:29.689812:  
2025-07-12 02:50:29.691974: Epoch 531 
2025-07-12 02:50:29.693189: Current learning rate: 0.00506 
2025-07-12 02:51:38.680913: train_loss -0.9763 
2025-07-12 02:51:38.682579: val_loss -0.9411 
2025-07-12 02:51:38.684056: Pseudo dice [np.float32(0.9432)] 
2025-07-12 02:51:38.685409: Epoch time: 68.99 s 
2025-07-12 02:51:39.607257:  
2025-07-12 02:51:39.609390: Epoch 532 
2025-07-12 02:51:39.610731: Current learning rate: 0.00505 
2025-07-12 02:52:48.507306: train_loss -0.9764 
2025-07-12 02:52:48.508515: val_loss -0.9468 
2025-07-12 02:52:48.509688: Pseudo dice [np.float32(0.95)] 
2025-07-12 02:52:48.510884: Epoch time: 68.9 s 
2025-07-12 02:52:49.446123:  
2025-07-12 02:52:49.448087: Epoch 533 
2025-07-12 02:52:49.449204: Current learning rate: 0.00504 
2025-07-12 02:53:58.336071: train_loss -0.9762 
2025-07-12 02:53:58.337644: val_loss -0.9444 
2025-07-12 02:53:58.338753: Pseudo dice [np.float32(0.9479)] 
2025-07-12 02:53:58.339885: Epoch time: 68.89 s 
2025-07-12 02:53:59.261843:  
2025-07-12 02:53:59.264177: Epoch 534 
2025-07-12 02:53:59.265462: Current learning rate: 0.00503 
2025-07-12 02:55:08.191396: train_loss -0.9761 
2025-07-12 02:55:08.192479: val_loss -0.9404 
2025-07-12 02:55:08.194140: Pseudo dice [np.float32(0.9433)] 
2025-07-12 02:55:08.195228: Epoch time: 68.93 s 
2025-07-12 02:55:09.118156:  
2025-07-12 02:55:09.120348: Epoch 535 
2025-07-12 02:55:09.121712: Current learning rate: 0.00502 
2025-07-12 02:56:17.977866: train_loss -0.9763 
2025-07-12 02:56:17.979599: val_loss -0.9425 
2025-07-12 02:56:17.980776: Pseudo dice [np.float32(0.9456)] 
2025-07-12 02:56:17.981907: Epoch time: 68.86 s 
2025-07-12 02:56:18.933966:  
2025-07-12 02:56:18.936211: Epoch 536 
2025-07-12 02:56:18.937413: Current learning rate: 0.00501 
2025-07-12 02:57:27.847608: train_loss -0.9769 
2025-07-12 02:57:27.849092: val_loss -0.9452 
2025-07-12 02:57:27.850195: Pseudo dice [np.float32(0.9486)] 
2025-07-12 02:57:27.851322: Epoch time: 68.92 s 
2025-07-12 02:57:27.852411: Yayy! New best EMA pseudo Dice: 0.9452999830245972 
2025-07-12 02:57:29.981938:  
2025-07-12 02:57:29.984015: Epoch 537 
2025-07-12 02:57:29.985329: Current learning rate: 0.005 
2025-07-12 02:58:38.689652: train_loss -0.9759 
2025-07-12 02:58:38.690932: val_loss -0.9454 
2025-07-12 02:58:38.692283: Pseudo dice [np.float32(0.9485)] 
2025-07-12 02:58:38.693736: Epoch time: 68.71 s 
2025-07-12 02:58:38.694946: Yayy! New best EMA pseudo Dice: 0.9455999732017517 
2025-07-12 02:58:41.260162:  
2025-07-12 02:58:41.262162: Epoch 538 
2025-07-12 02:58:41.263353: Current learning rate: 0.00499 
2025-07-12 02:59:49.920853: train_loss -0.9757 
2025-07-12 02:59:49.922201: val_loss -0.942 
2025-07-12 02:59:49.923424: Pseudo dice [np.float32(0.9455)] 
2025-07-12 02:59:49.924618: Epoch time: 68.66 s 
2025-07-12 02:59:50.833738:  
2025-07-12 02:59:50.835775: Epoch 539 
2025-07-12 02:59:50.836859: Current learning rate: 0.00498 
2025-07-12 03:00:59.523910: train_loss -0.976 
2025-07-12 03:00:59.525188: val_loss -0.938 
2025-07-12 03:00:59.526253: Pseudo dice [np.float32(0.937)] 
2025-07-12 03:00:59.527189: Epoch time: 68.69 s 
2025-07-12 03:01:00.431113:  
2025-07-12 03:01:00.432922: Epoch 540 
2025-07-12 03:01:00.433897: Current learning rate: 0.00497 
2025-07-12 03:02:09.216707: train_loss -0.9758 
2025-07-12 03:02:09.218271: val_loss -0.9412 
2025-07-12 03:02:09.219457: Pseudo dice [np.float32(0.9436)] 
2025-07-12 03:02:09.220702: Epoch time: 68.79 s 
2025-07-12 03:02:10.149234:  
2025-07-12 03:02:10.151160: Epoch 541 
2025-07-12 03:02:10.152367: Current learning rate: 0.00496 
2025-07-12 03:03:19.221233: train_loss -0.9769 
2025-07-12 03:03:19.222690: val_loss -0.9451 
2025-07-12 03:03:19.223691: Pseudo dice [np.float32(0.9483)] 
2025-07-12 03:03:19.225162: Epoch time: 69.08 s 
2025-07-12 03:03:20.143803:  
2025-07-12 03:03:20.146234: Epoch 542 
2025-07-12 03:03:20.147522: Current learning rate: 0.00495 
2025-07-12 03:04:29.015073: train_loss -0.9771 
2025-07-12 03:04:29.016656: val_loss -0.9398 
2025-07-12 03:04:29.018221: Pseudo dice [np.float32(0.9415)] 
2025-07-12 03:04:29.019271: Epoch time: 68.88 s 
2025-07-12 03:04:29.956923:  
2025-07-12 03:04:29.959024: Epoch 543 
2025-07-12 03:04:29.960298: Current learning rate: 0.00494 
2025-07-12 03:05:38.682491: train_loss -0.9754 
2025-07-12 03:05:38.684161: val_loss -0.9457 
2025-07-12 03:05:38.685133: Pseudo dice [np.float32(0.9476)] 
2025-07-12 03:05:38.686394: Epoch time: 68.73 s 
2025-07-12 03:05:39.612772:  
2025-07-12 03:05:39.614746: Epoch 544 
2025-07-12 03:05:39.616144: Current learning rate: 0.00493 
2025-07-12 03:06:48.269260: train_loss -0.9759 
2025-07-12 03:06:48.271052: val_loss -0.9403 
2025-07-12 03:06:48.272059: Pseudo dice [np.float32(0.9428)] 
2025-07-12 03:06:48.273115: Epoch time: 68.66 s 
2025-07-12 03:06:49.416838:  
2025-07-12 03:06:49.418560: Epoch 545 
2025-07-12 03:06:49.419814: Current learning rate: 0.00492 
2025-07-12 03:07:58.263475: train_loss -0.9755 
2025-07-12 03:07:58.265476: val_loss -0.9364 
2025-07-12 03:07:58.267256: Pseudo dice [np.float32(0.9398)] 
2025-07-12 03:07:58.268295: Epoch time: 68.85 s 
2025-07-12 03:07:59.211326:  
2025-07-12 03:07:59.213706: Epoch 546 
2025-07-12 03:07:59.214888: Current learning rate: 0.00491 
2025-07-12 03:09:07.981827: train_loss -0.9752 
2025-07-12 03:09:07.983095: val_loss -0.9406 
2025-07-12 03:09:07.984555: Pseudo dice [np.float32(0.9441)] 
2025-07-12 03:09:07.985621: Epoch time: 68.77 s 
2025-07-12 03:09:08.911487:  
2025-07-12 03:09:08.913787: Epoch 547 
2025-07-12 03:09:08.915318: Current learning rate: 0.0049 
2025-07-12 03:10:17.673100: train_loss -0.9762 
2025-07-12 03:10:17.674311: val_loss -0.937 
2025-07-12 03:10:17.675749: Pseudo dice [np.float32(0.9392)] 
2025-07-12 03:10:17.676841: Epoch time: 68.77 s 
2025-07-12 03:10:18.594102:  
2025-07-12 03:10:18.596236: Epoch 548 
2025-07-12 03:10:18.597845: Current learning rate: 0.00489 
2025-07-12 03:11:27.650527: train_loss -0.9758 
2025-07-12 03:11:27.652097: val_loss -0.9432 
2025-07-12 03:11:27.653333: Pseudo dice [np.float32(0.9466)] 
2025-07-12 03:11:27.654436: Epoch time: 69.06 s 
2025-07-12 03:11:28.573050:  
2025-07-12 03:11:28.575339: Epoch 549 
2025-07-12 03:11:28.576665: Current learning rate: 0.00488 
2025-07-12 03:12:37.212356: train_loss -0.9753 
2025-07-12 03:12:37.213627: val_loss -0.9409 
2025-07-12 03:12:37.214803: Pseudo dice [np.float32(0.9432)] 
2025-07-12 03:12:37.216369: Epoch time: 68.64 s 
2025-07-12 03:12:39.348151:  
2025-07-12 03:12:39.350261: Epoch 550 
2025-07-12 03:12:39.351639: Current learning rate: 0.00487 
2025-07-12 03:13:48.068057: train_loss -0.9748 
2025-07-12 03:13:48.069836: val_loss -0.9426 
2025-07-12 03:13:48.071023: Pseudo dice [np.float32(0.9453)] 
2025-07-12 03:13:48.072156: Epoch time: 68.72 s 
2025-07-12 03:13:48.964464:  
2025-07-12 03:13:48.966913: Epoch 551 
2025-07-12 03:13:48.968393: Current learning rate: 0.00486 
2025-07-12 03:14:57.796983: train_loss -0.9753 
2025-07-12 03:14:57.798200: val_loss -0.9458 
2025-07-12 03:14:57.799388: Pseudo dice [np.float32(0.9489)] 
2025-07-12 03:14:57.800590: Epoch time: 68.84 s 
2025-07-12 03:14:58.957957:  
2025-07-12 03:14:58.960282: Epoch 552 
2025-07-12 03:14:58.961682: Current learning rate: 0.00485 
2025-07-12 03:16:07.656653: train_loss -0.9765 
2025-07-12 03:16:07.658147: val_loss -0.9448 
2025-07-12 03:16:07.659184: Pseudo dice [np.float32(0.9474)] 
2025-07-12 03:16:07.660268: Epoch time: 68.7 s 
2025-07-12 03:16:08.593165:  
2025-07-12 03:16:08.595374: Epoch 553 
2025-07-12 03:16:08.596528: Current learning rate: 0.00484 
2025-07-12 03:17:17.223064: train_loss -0.9763 
2025-07-12 03:17:17.224379: val_loss -0.9341 
2025-07-12 03:17:17.225806: Pseudo dice [np.float32(0.9361)] 
2025-07-12 03:17:17.227031: Epoch time: 68.63 s 
2025-07-12 03:17:18.139214:  
2025-07-12 03:17:18.141230: Epoch 554 
2025-07-12 03:17:18.142500: Current learning rate: 0.00484 
2025-07-12 03:18:26.893430: train_loss -0.9761 
2025-07-12 03:18:26.895241: val_loss -0.9477 
2025-07-12 03:18:26.896330: Pseudo dice [np.float32(0.9503)] 
2025-07-12 03:18:26.897383: Epoch time: 68.76 s 
2025-07-12 03:18:27.820633:  
2025-07-12 03:18:27.822195: Epoch 555 
2025-07-12 03:18:27.823414: Current learning rate: 0.00483 
2025-07-12 03:19:36.790120: train_loss -0.9761 
2025-07-12 03:19:36.791925: val_loss -0.9466 
2025-07-12 03:19:36.793640: Pseudo dice [np.float32(0.9492)] 
2025-07-12 03:19:36.795423: Epoch time: 68.97 s 
2025-07-12 03:19:37.723148:  
2025-07-12 03:19:37.725100: Epoch 556 
2025-07-12 03:19:37.726305: Current learning rate: 0.00482 
2025-07-12 03:20:46.559045: train_loss -0.9765 
2025-07-12 03:20:46.560269: val_loss -0.9392 
2025-07-12 03:20:46.561246: Pseudo dice [np.float32(0.9433)] 
2025-07-12 03:20:46.562407: Epoch time: 68.84 s 
2025-07-12 03:20:47.471300:  
2025-07-12 03:20:47.473690: Epoch 557 
2025-07-12 03:20:47.475507: Current learning rate: 0.00481 
2025-07-12 03:21:56.127223: train_loss -0.9762 
2025-07-12 03:21:56.128587: val_loss -0.9388 
2025-07-12 03:21:56.129618: Pseudo dice [np.float32(0.9419)] 
2025-07-12 03:21:56.130584: Epoch time: 68.66 s 
2025-07-12 03:21:57.051954:  
2025-07-12 03:21:57.053527: Epoch 558 
2025-07-12 03:21:57.054707: Current learning rate: 0.0048 
2025-07-12 03:23:05.666687: train_loss -0.976 
2025-07-12 03:23:05.668154: val_loss -0.9428 
2025-07-12 03:23:05.669168: Pseudo dice [np.float32(0.9469)] 
2025-07-12 03:23:05.670329: Epoch time: 68.62 s 
2025-07-12 03:23:06.815073:  
2025-07-12 03:23:06.817683: Epoch 559 
2025-07-12 03:23:06.819031: Current learning rate: 0.00479 
2025-07-12 03:24:15.702233: train_loss -0.9756 
2025-07-12 03:24:15.704530: val_loss -0.943 
2025-07-12 03:24:15.705708: Pseudo dice [np.float32(0.9446)] 
2025-07-12 03:24:15.706892: Epoch time: 68.89 s 
2025-07-12 03:24:16.635393:  
2025-07-12 03:24:16.637549: Epoch 560 
2025-07-12 03:24:16.638633: Current learning rate: 0.00478 
2025-07-12 03:25:25.383828: train_loss -0.9755 
2025-07-12 03:25:25.385833: val_loss -0.9404 
2025-07-12 03:25:25.387260: Pseudo dice [np.float32(0.9417)] 
2025-07-12 03:25:25.388243: Epoch time: 68.75 s 
2025-07-12 03:25:26.312288:  
2025-07-12 03:25:26.314535: Epoch 561 
2025-07-12 03:25:26.315798: Current learning rate: 0.00477 
2025-07-12 03:26:35.151356: train_loss -0.9754 
2025-07-12 03:26:35.152674: val_loss -0.9452 
2025-07-12 03:26:35.153718: Pseudo dice [np.float32(0.9476)] 
2025-07-12 03:26:35.154621: Epoch time: 68.84 s 
2025-07-12 03:26:36.071190:  
2025-07-12 03:26:36.073194: Epoch 562 
2025-07-12 03:26:36.074317: Current learning rate: 0.00476 
2025-07-12 03:27:45.244810: train_loss -0.9764 
2025-07-12 03:27:45.246299: val_loss -0.9417 
2025-07-12 03:27:45.247364: Pseudo dice [np.float32(0.9449)] 
2025-07-12 03:27:45.248442: Epoch time: 69.18 s 
2025-07-12 03:27:46.158763:  
2025-07-12 03:27:46.161003: Epoch 563 
2025-07-12 03:27:46.162174: Current learning rate: 0.00475 
2025-07-12 03:28:54.736501: train_loss -0.9759 
2025-07-12 03:28:54.737826: val_loss -0.9464 
2025-07-12 03:28:54.738977: Pseudo dice [np.float32(0.9501)] 
2025-07-12 03:28:54.740031: Epoch time: 68.58 s 
2025-07-12 03:28:55.648444:  
2025-07-12 03:28:55.650087: Epoch 564 
2025-07-12 03:28:55.651087: Current learning rate: 0.00474 
2025-07-12 03:30:04.267347: train_loss -0.9768 
2025-07-12 03:30:04.268584: val_loss -0.9406 
2025-07-12 03:30:04.270440: Pseudo dice [np.float32(0.944)] 
2025-07-12 03:30:04.271611: Epoch time: 68.62 s 
2025-07-12 03:30:05.189656:  
2025-07-12 03:30:05.191705: Epoch 565 
2025-07-12 03:30:05.192773: Current learning rate: 0.00473 
2025-07-12 03:31:13.783858: train_loss -0.9775 
2025-07-12 03:31:13.784957: val_loss -0.9384 
2025-07-12 03:31:13.785834: Pseudo dice [np.float32(0.9429)] 
2025-07-12 03:31:13.786863: Epoch time: 68.6 s 
2025-07-12 03:31:14.716461:  
2025-07-12 03:31:14.718982: Epoch 566 
2025-07-12 03:31:14.720046: Current learning rate: 0.00472 
2025-07-12 03:32:23.569183: train_loss -0.9761 
2025-07-12 03:32:23.570559: val_loss -0.9436 
2025-07-12 03:32:23.571646: Pseudo dice [np.float32(0.9461)] 
2025-07-12 03:32:23.572815: Epoch time: 68.86 s 
2025-07-12 03:32:24.469008:  
2025-07-12 03:32:24.471075: Epoch 567 
2025-07-12 03:32:24.472301: Current learning rate: 0.00471 
2025-07-12 03:33:33.104488: train_loss -0.9775 
2025-07-12 03:33:33.105776: val_loss -0.9371 
2025-07-12 03:33:33.106769: Pseudo dice [np.float32(0.9386)] 
2025-07-12 03:33:33.107787: Epoch time: 68.64 s 
2025-07-12 03:33:34.025959:  
2025-07-12 03:33:34.028003: Epoch 568 
2025-07-12 03:33:34.029114: Current learning rate: 0.0047 
2025-07-12 03:34:42.807299: train_loss -0.9767 
2025-07-12 03:34:42.808560: val_loss -0.9422 
2025-07-12 03:34:42.809638: Pseudo dice [np.float32(0.9452)] 
2025-07-12 03:34:42.810616: Epoch time: 68.79 s 
2025-07-12 03:34:43.728621:  
2025-07-12 03:34:43.730657: Epoch 569 
2025-07-12 03:34:43.731721: Current learning rate: 0.00469 
2025-07-12 03:35:52.539532: train_loss -0.9769 
2025-07-12 03:35:52.540816: val_loss -0.9413 
2025-07-12 03:35:52.542123: Pseudo dice [np.float32(0.9423)] 
2025-07-12 03:35:52.543442: Epoch time: 68.81 s 
2025-07-12 03:35:53.462326:  
2025-07-12 03:35:53.464353: Epoch 570 
2025-07-12 03:35:53.465653: Current learning rate: 0.00468 
2025-07-12 03:37:02.051293: train_loss -0.9765 
2025-07-12 03:37:02.052678: val_loss -0.942 
2025-07-12 03:37:02.053993: Pseudo dice [np.float32(0.9437)] 
2025-07-12 03:37:02.055130: Epoch time: 68.59 s 
2025-07-12 03:37:02.972114:  
2025-07-12 03:37:02.974202: Epoch 571 
2025-07-12 03:37:02.975254: Current learning rate: 0.00467 
2025-07-12 03:38:11.757129: train_loss -0.9774 
2025-07-12 03:38:11.758432: val_loss -0.9443 
2025-07-12 03:38:11.759444: Pseudo dice [np.float32(0.9472)] 
2025-07-12 03:38:11.760534: Epoch time: 68.79 s 
2025-07-12 03:38:12.667303:  
2025-07-12 03:38:12.669146: Epoch 572 
2025-07-12 03:38:12.670102: Current learning rate: 0.00466 
2025-07-12 03:39:21.481485: train_loss -0.9769 
2025-07-12 03:39:21.482669: val_loss -0.9408 
2025-07-12 03:39:21.484175: Pseudo dice [np.float32(0.9432)] 
2025-07-12 03:39:21.485176: Epoch time: 68.82 s 
2025-07-12 03:39:22.420658:  
2025-07-12 03:39:22.422388: Epoch 573 
2025-07-12 03:39:22.423373: Current learning rate: 0.00465 
2025-07-12 03:40:31.386225: train_loss -0.9776 
2025-07-12 03:40:31.387659: val_loss -0.9379 
2025-07-12 03:40:31.389485: Pseudo dice [np.float32(0.9412)] 
2025-07-12 03:40:31.390561: Epoch time: 68.97 s 
2025-07-12 03:40:32.321824:  
2025-07-12 03:40:32.323554: Epoch 574 
2025-07-12 03:40:32.324753: Current learning rate: 0.00464 
2025-07-12 03:41:41.463466: train_loss -0.976 
2025-07-12 03:41:41.464845: val_loss -0.9456 
2025-07-12 03:41:41.465786: Pseudo dice [np.float32(0.9485)] 
2025-07-12 03:41:41.466825: Epoch time: 69.15 s 
2025-07-12 03:41:42.375105:  
2025-07-12 03:41:42.376739: Epoch 575 
2025-07-12 03:41:42.378213: Current learning rate: 0.00463 
2025-07-12 03:42:51.471346: train_loss -0.9761 
2025-07-12 03:42:51.472593: val_loss -0.9432 
2025-07-12 03:42:51.473537: Pseudo dice [np.float32(0.946)] 
2025-07-12 03:42:51.474870: Epoch time: 69.1 s 
2025-07-12 03:42:52.396684:  
2025-07-12 03:42:52.398442: Epoch 576 
2025-07-12 03:42:52.399474: Current learning rate: 0.00462 
2025-07-12 03:44:01.593038: train_loss -0.9778 
2025-07-12 03:44:01.594194: val_loss -0.9469 
2025-07-12 03:44:01.595347: Pseudo dice [np.float32(0.9494)] 
2025-07-12 03:44:01.596380: Epoch time: 69.2 s 
2025-07-12 03:44:02.504285:  
2025-07-12 03:44:02.506482: Epoch 577 
2025-07-12 03:44:02.507699: Current learning rate: 0.00461 
2025-07-12 03:45:11.647942: train_loss -0.9771 
2025-07-12 03:45:11.649569: val_loss -0.9429 
2025-07-12 03:45:11.650615: Pseudo dice [np.float32(0.9461)] 
2025-07-12 03:45:11.652076: Epoch time: 69.15 s 
2025-07-12 03:45:12.583293:  
2025-07-12 03:45:12.585169: Epoch 578 
2025-07-12 03:45:12.586291: Current learning rate: 0.0046 
2025-07-12 03:46:21.764995: train_loss -0.9767 
2025-07-12 03:46:21.766384: val_loss -0.9405 
2025-07-12 03:46:21.767367: Pseudo dice [np.float32(0.9438)] 
2025-07-12 03:46:21.768534: Epoch time: 69.19 s 
2025-07-12 03:46:22.696780:  
2025-07-12 03:46:22.698691: Epoch 579 
2025-07-12 03:46:22.700261: Current learning rate: 0.00459 
2025-07-12 03:47:32.043641: train_loss -0.9767 
2025-07-12 03:47:32.045280: val_loss -0.9363 
2025-07-12 03:47:32.046194: Pseudo dice [np.float32(0.9384)] 
2025-07-12 03:47:32.047254: Epoch time: 69.35 s 
2025-07-12 03:47:33.303021:  
2025-07-12 03:47:33.305057: Epoch 580 
2025-07-12 03:47:33.306311: Current learning rate: 0.00458 
2025-07-12 03:48:42.741750: train_loss -0.9765 
2025-07-12 03:48:42.743257: val_loss -0.9406 
2025-07-12 03:48:42.744543: Pseudo dice [np.float32(0.9427)] 
2025-07-12 03:48:42.745648: Epoch time: 69.44 s 
2025-07-12 03:48:43.709360:  
2025-07-12 03:48:43.711840: Epoch 581 
2025-07-12 03:48:43.713020: Current learning rate: 0.00457 
2025-07-12 03:49:53.282020: train_loss -0.977 
2025-07-12 03:49:53.283465: val_loss -0.9433 
2025-07-12 03:49:53.284636: Pseudo dice [np.float32(0.9468)] 
2025-07-12 03:49:53.285708: Epoch time: 69.58 s 
2025-07-12 03:49:54.225810:  
2025-07-12 03:49:54.228090: Epoch 582 
2025-07-12 03:49:54.229277: Current learning rate: 0.00456 
2025-07-12 03:51:03.863646: train_loss -0.977 
2025-07-12 03:51:03.865604: val_loss -0.9418 
2025-07-12 03:51:03.866745: Pseudo dice [np.float32(0.9448)] 
2025-07-12 03:51:03.867828: Epoch time: 69.64 s 
2025-07-12 03:51:04.769427:  
2025-07-12 03:51:04.771469: Epoch 583 
2025-07-12 03:51:04.772717: Current learning rate: 0.00455 
2025-07-12 03:52:13.882434: train_loss -0.9765 
2025-07-12 03:52:13.883927: val_loss -0.935 
2025-07-12 03:52:13.885208: Pseudo dice [np.float32(0.938)] 
2025-07-12 03:52:13.886320: Epoch time: 69.12 s 
2025-07-12 03:52:14.816265:  
2025-07-12 03:52:14.817892: Epoch 584 
2025-07-12 03:52:14.819128: Current learning rate: 0.00454 
2025-07-12 03:53:23.792363: train_loss -0.9761 
2025-07-12 03:53:23.793810: val_loss -0.9423 
2025-07-12 03:53:23.794977: Pseudo dice [np.float32(0.945)] 
2025-07-12 03:53:23.796206: Epoch time: 68.98 s 
2025-07-12 03:53:24.725421:  
2025-07-12 03:53:24.727505: Epoch 585 
2025-07-12 03:53:24.728752: Current learning rate: 0.00453 
2025-07-12 03:54:33.671168: train_loss -0.9761 
2025-07-12 03:54:33.672375: val_loss -0.9446 
2025-07-12 03:54:33.673367: Pseudo dice [np.float32(0.9476)] 
2025-07-12 03:54:33.674525: Epoch time: 68.95 s 
2025-07-12 03:54:34.593335:  
2025-07-12 03:54:34.595367: Epoch 586 
2025-07-12 03:54:34.596680: Current learning rate: 0.00452 
2025-07-12 03:55:43.647101: train_loss -0.9757 
2025-07-12 03:55:43.648458: val_loss -0.939 
2025-07-12 03:55:43.649550: Pseudo dice [np.float32(0.9413)] 
2025-07-12 03:55:43.650733: Epoch time: 69.06 s 
2025-07-12 03:55:44.569057:  
2025-07-12 03:55:44.571311: Epoch 587 
2025-07-12 03:55:44.572794: Current learning rate: 0.00451 
2025-07-12 03:56:53.893950: train_loss -0.9755 
2025-07-12 03:56:53.895346: val_loss -0.9417 
2025-07-12 03:56:53.896640: Pseudo dice [np.float32(0.9447)] 
2025-07-12 03:56:53.898173: Epoch time: 69.33 s 
2025-07-12 03:56:54.816738:  
2025-07-12 03:56:54.818645: Epoch 588 
2025-07-12 03:56:54.819646: Current learning rate: 0.0045 
2025-07-12 03:58:04.001922: train_loss -0.9763 
2025-07-12 03:58:04.003446: val_loss -0.9418 
2025-07-12 03:58:04.004585: Pseudo dice [np.float32(0.9439)] 
2025-07-12 03:58:04.005828: Epoch time: 69.19 s 
2025-07-12 03:58:04.930643:  
2025-07-12 03:58:04.932685: Epoch 589 
2025-07-12 03:58:04.933890: Current learning rate: 0.00449 
2025-07-12 03:59:14.192884: train_loss -0.9759 
2025-07-12 03:59:14.194126: val_loss -0.9428 
2025-07-12 03:59:14.195812: Pseudo dice [np.float32(0.9467)] 
2025-07-12 03:59:14.196893: Epoch time: 69.27 s 
2025-07-12 03:59:15.105612:  
2025-07-12 03:59:15.107630: Epoch 590 
2025-07-12 03:59:15.108852: Current learning rate: 0.00448 
2025-07-12 04:00:24.449922: train_loss -0.9768 
2025-07-12 04:00:24.451270: val_loss -0.9478 
2025-07-12 04:00:24.452321: Pseudo dice [np.float32(0.9508)] 
2025-07-12 04:00:24.453444: Epoch time: 69.35 s 
2025-07-12 04:00:25.380271:  
2025-07-12 04:00:25.382433: Epoch 591 
2025-07-12 04:00:25.383813: Current learning rate: 0.00447 
2025-07-12 04:01:34.514509: train_loss -0.9766 
2025-07-12 04:01:34.515862: val_loss -0.936 
2025-07-12 04:01:34.516979: Pseudo dice [np.float32(0.94)] 
2025-07-12 04:01:34.518216: Epoch time: 69.14 s 
2025-07-12 04:01:35.421716:  
2025-07-12 04:01:35.423736: Epoch 592 
2025-07-12 04:01:35.424910: Current learning rate: 0.00446 
2025-07-12 04:02:44.609089: train_loss -0.9752 
2025-07-12 04:02:44.610789: val_loss -0.9404 
2025-07-12 04:02:44.611940: Pseudo dice [np.float32(0.9429)] 
2025-07-12 04:02:44.613191: Epoch time: 69.19 s 
2025-07-12 04:02:45.496819:  
2025-07-12 04:02:45.498770: Epoch 593 
2025-07-12 04:02:45.499785: Current learning rate: 0.00445 
2025-07-12 04:03:54.824273: train_loss -0.9753 
2025-07-12 04:03:54.825853: val_loss -0.9376 
2025-07-12 04:03:54.827036: Pseudo dice [np.float32(0.9398)] 
2025-07-12 04:03:54.828091: Epoch time: 69.33 s 
2025-07-12 04:03:55.731265:  
2025-07-12 04:03:55.733103: Epoch 594 
2025-07-12 04:03:55.734189: Current learning rate: 0.00444 
2025-07-12 04:05:05.281291: train_loss -0.9765 
2025-07-12 04:05:05.282614: val_loss -0.9457 
2025-07-12 04:05:05.283641: Pseudo dice [np.float32(0.9485)] 
2025-07-12 04:05:05.284587: Epoch time: 69.55 s 
2025-07-12 04:05:06.211009:  
2025-07-12 04:05:06.213027: Epoch 595 
2025-07-12 04:05:06.214341: Current learning rate: 0.00443 
2025-07-12 04:06:15.434168: train_loss -0.9773 
2025-07-12 04:06:15.435436: val_loss -0.9351 
2025-07-12 04:06:15.436491: Pseudo dice [np.float32(0.9367)] 
2025-07-12 04:06:15.437931: Epoch time: 69.23 s 
2025-07-12 04:06:16.370017:  
2025-07-12 04:06:16.371844: Epoch 596 
2025-07-12 04:06:16.372894: Current learning rate: 0.00442 
2025-07-12 04:07:25.687757: train_loss -0.9771 
2025-07-12 04:07:25.689489: val_loss -0.9449 
2025-07-12 04:07:25.690794: Pseudo dice [np.float32(0.9481)] 
2025-07-12 04:07:25.691972: Epoch time: 69.32 s 
2025-07-12 04:07:26.606607:  
2025-07-12 04:07:26.608511: Epoch 597 
2025-07-12 04:07:26.609601: Current learning rate: 0.00441 
2025-07-12 04:08:35.997663: train_loss -0.9774 
2025-07-12 04:08:35.998916: val_loss -0.9407 
2025-07-12 04:08:35.999928: Pseudo dice [np.float32(0.9436)] 
2025-07-12 04:08:36.000891: Epoch time: 69.39 s 
2025-07-12 04:08:36.925850:  
2025-07-12 04:08:36.927564: Epoch 598 
2025-07-12 04:08:36.928691: Current learning rate: 0.0044 
2025-07-12 04:09:46.315181: train_loss -0.9775 
2025-07-12 04:09:46.316422: val_loss -0.946 
2025-07-12 04:09:46.317514: Pseudo dice [np.float32(0.9493)] 
2025-07-12 04:09:46.319038: Epoch time: 69.39 s 
2025-07-12 04:09:47.245972:  
2025-07-12 04:09:47.247710: Epoch 599 
2025-07-12 04:09:47.248843: Current learning rate: 0.00439 
2025-07-12 04:11:02.653797: train_loss -0.976 
2025-07-12 04:11:02.655099: val_loss -0.9306 
2025-07-12 04:11:02.656231: Pseudo dice [np.float32(0.9321)] 
2025-07-12 04:11:02.657324: Epoch time: 75.41 s 
2025-07-12 04:11:05.017635:  
2025-07-12 04:11:05.019397: Epoch 600 
2025-07-12 04:11:05.020367: Current learning rate: 0.00438 
2025-07-12 04:12:17.303005: train_loss -0.9777 
2025-07-12 04:12:17.304289: val_loss -0.9418 
2025-07-12 04:12:17.305265: Pseudo dice [np.float32(0.9433)] 
2025-07-12 04:12:17.306382: Epoch time: 72.29 s 
2025-07-12 04:12:18.439278:  
2025-07-12 04:12:18.441406: Epoch 601 
2025-07-12 04:12:18.442462: Current learning rate: 0.00437 
2025-07-12 04:13:27.581603: train_loss -0.9766 
2025-07-12 04:13:27.582850: val_loss -0.941 
2025-07-12 04:13:27.584200: Pseudo dice [np.float32(0.9438)] 
2025-07-12 04:13:27.585581: Epoch time: 69.15 s 
2025-07-12 04:13:28.494364:  
2025-07-12 04:13:28.496325: Epoch 602 
2025-07-12 04:13:28.497437: Current learning rate: 0.00436 
2025-07-12 04:14:37.399332: train_loss -0.9764 
2025-07-12 04:14:37.400599: val_loss -0.939 
2025-07-12 04:14:37.401685: Pseudo dice [np.float32(0.9409)] 
2025-07-12 04:14:37.402998: Epoch time: 68.91 s 
2025-07-12 04:14:38.324473:  
2025-07-12 04:14:38.326375: Epoch 603 
2025-07-12 04:14:38.327580: Current learning rate: 0.00435 
2025-07-12 04:15:47.381756: train_loss -0.9767 
2025-07-12 04:15:47.382898: val_loss -0.9374 
2025-07-12 04:15:47.383893: Pseudo dice [np.float32(0.9391)] 
2025-07-12 04:15:47.385409: Epoch time: 69.06 s 
2025-07-12 04:15:48.365005:  
2025-07-12 04:15:48.366973: Epoch 604 
2025-07-12 04:15:48.368042: Current learning rate: 0.00434 
2025-07-12 04:16:57.602484: train_loss -0.9773 
2025-07-12 04:16:57.604160: val_loss -0.9404 
2025-07-12 04:16:57.605136: Pseudo dice [np.float32(0.9428)] 
2025-07-12 04:16:57.606092: Epoch time: 69.24 s 
2025-07-12 04:16:58.523253:  
2025-07-12 04:16:58.525033: Epoch 605 
2025-07-12 04:16:58.525935: Current learning rate: 0.00433 
2025-07-12 04:18:07.725315: train_loss -0.9755 
2025-07-12 04:18:07.726512: val_loss -0.9341 
2025-07-12 04:18:07.727793: Pseudo dice [np.float32(0.9361)] 
2025-07-12 04:18:07.728906: Epoch time: 69.21 s 
2025-07-12 04:18:08.643047:  
2025-07-12 04:18:08.645080: Epoch 606 
2025-07-12 04:18:08.646376: Current learning rate: 0.00432 
2025-07-12 04:19:17.892304: train_loss -0.9765 
2025-07-12 04:19:17.893507: val_loss -0.9387 
2025-07-12 04:19:17.894578: Pseudo dice [np.float32(0.9405)] 
2025-07-12 04:19:17.895676: Epoch time: 69.25 s 
2025-07-12 04:19:18.798575:  
2025-07-12 04:19:18.800239: Epoch 607 
2025-07-12 04:19:18.801417: Current learning rate: 0.00431 
2025-07-12 04:20:28.173620: train_loss -0.9761 
2025-07-12 04:20:28.174718: val_loss -0.9415 
2025-07-12 04:20:28.175661: Pseudo dice [np.float32(0.9444)] 
2025-07-12 04:20:28.176623: Epoch time: 69.38 s 
2025-07-12 04:20:29.313605:  
2025-07-12 04:20:29.315039: Epoch 608 
2025-07-12 04:20:29.316103: Current learning rate: 0.0043 
2025-07-12 04:21:38.832236: train_loss -0.977 
2025-07-12 04:21:38.833401: val_loss -0.9421 
2025-07-12 04:21:38.834625: Pseudo dice [np.float32(0.944)] 
2025-07-12 04:21:38.835725: Epoch time: 69.52 s 
2025-07-12 04:21:39.733620:  
2025-07-12 04:21:39.735237: Epoch 609 
2025-07-12 04:21:39.736325: Current learning rate: 0.00429 
2025-07-12 04:22:50.536046: train_loss -0.9777 
2025-07-12 04:22:50.537472: val_loss -0.9355 
2025-07-12 04:22:50.538512: Pseudo dice [np.float32(0.9342)] 
2025-07-12 04:22:50.539504: Epoch time: 70.81 s 
2025-07-12 04:22:51.452285:  
2025-07-12 04:22:51.454029: Epoch 610 
2025-07-12 04:22:51.455462: Current learning rate: 0.00429 
2025-07-12 04:24:04.267717: train_loss -0.978 
2025-07-12 04:24:04.269174: val_loss -0.9392 
2025-07-12 04:24:04.271118: Pseudo dice [np.float32(0.9396)] 
2025-07-12 04:24:04.273272: Epoch time: 72.82 s 
2025-07-12 04:24:05.197015:  
2025-07-12 04:24:05.199026: Epoch 611 
2025-07-12 04:24:05.200084: Current learning rate: 0.00428 
2025-07-12 04:25:14.350207: train_loss -0.9777 
2025-07-12 04:25:14.351511: val_loss -0.9459 
2025-07-12 04:25:14.352619: Pseudo dice [np.float32(0.9493)] 
2025-07-12 04:25:14.353838: Epoch time: 69.16 s 
2025-07-12 04:25:15.272262:  
2025-07-12 04:25:15.274010: Epoch 612 
2025-07-12 04:25:15.274985: Current learning rate: 0.00427 
2025-07-12 04:26:24.376170: train_loss -0.9775 
2025-07-12 04:26:24.377811: val_loss -0.945 
2025-07-12 04:26:24.379568: Pseudo dice [np.float32(0.9472)] 
2025-07-12 04:26:24.381022: Epoch time: 69.11 s 
2025-07-12 04:26:25.311312:  
2025-07-12 04:26:25.313197: Epoch 613 
2025-07-12 04:26:25.314196: Current learning rate: 0.00426 
2025-07-12 04:27:34.486387: train_loss -0.9775 
2025-07-12 04:27:34.487831: val_loss -0.944 
2025-07-12 04:27:34.489321: Pseudo dice [np.float32(0.9479)] 
2025-07-12 04:27:34.490444: Epoch time: 69.18 s 
2025-07-12 04:27:35.411187:  
2025-07-12 04:27:35.413044: Epoch 614 
2025-07-12 04:27:35.414079: Current learning rate: 0.00425 
2025-07-12 04:28:51.508367: train_loss -0.978 
2025-07-12 04:28:51.510120: val_loss -0.9414 
2025-07-12 04:28:51.511125: Pseudo dice [np.float32(0.9431)] 
2025-07-12 04:28:51.512127: Epoch time: 76.1 s 
2025-07-12 04:28:52.683838:  
2025-07-12 04:28:52.685654: Epoch 615 
2025-07-12 04:28:52.686722: Current learning rate: 0.00424 
2025-07-12 04:30:06.007946: train_loss -0.9772 
2025-07-12 04:30:06.011440: val_loss -0.9481 
2025-07-12 04:30:06.012352: Pseudo dice [np.float32(0.9492)] 
2025-07-12 04:30:06.013313: Epoch time: 73.33 s 
2025-07-12 04:30:06.927808:  
2025-07-12 04:30:06.929297: Epoch 616 
2025-07-12 04:30:06.930450: Current learning rate: 0.00423 
2025-07-12 04:31:15.907741: train_loss -0.9782 
2025-07-12 04:31:15.909332: val_loss -0.9495 
2025-07-12 04:31:15.910534: Pseudo dice [np.float32(0.9524)] 
2025-07-12 04:31:15.911530: Epoch time: 68.98 s 
2025-07-12 04:31:16.834941:  
2025-07-12 04:31:16.836977: Epoch 617 
2025-07-12 04:31:16.838082: Current learning rate: 0.00422 
2025-07-12 04:32:26.031431: train_loss -0.9774 
2025-07-12 04:32:26.033155: val_loss -0.9461 
2025-07-12 04:32:26.034553: Pseudo dice [np.float32(0.9494)] 
2025-07-12 04:32:26.035656: Epoch time: 69.2 s 
2025-07-12 04:32:26.955492:  
2025-07-12 04:32:26.957546: Epoch 618 
2025-07-12 04:32:26.958712: Current learning rate: 0.00421 
2025-07-12 04:33:36.401207: train_loss -0.9764 
2025-07-12 04:33:36.402455: val_loss -0.9434 
2025-07-12 04:33:36.403805: Pseudo dice [np.float32(0.9469)] 
2025-07-12 04:33:36.405256: Epoch time: 69.45 s 
2025-07-12 04:33:37.304509:  
2025-07-12 04:33:37.309796: Epoch 619 
2025-07-12 04:33:37.311314: Current learning rate: 0.0042 
2025-07-12 04:34:46.602068: train_loss -0.976 
2025-07-12 04:34:46.603333: val_loss -0.9394 
2025-07-12 04:34:46.604285: Pseudo dice [np.float32(0.9413)] 
2025-07-12 04:34:46.605357: Epoch time: 69.3 s 
2025-07-12 04:34:47.523210:  
2025-07-12 04:34:47.525321: Epoch 620 
2025-07-12 04:34:47.526563: Current learning rate: 0.00419 
2025-07-12 04:35:56.832122: train_loss -0.9777 
2025-07-12 04:35:56.833376: val_loss -0.9398 
2025-07-12 04:35:56.834443: Pseudo dice [np.float32(0.9425)] 
2025-07-12 04:35:56.835966: Epoch time: 69.31 s 
2025-07-12 04:35:57.759230:  
2025-07-12 04:35:57.761156: Epoch 621 
2025-07-12 04:35:57.762134: Current learning rate: 0.00418 
2025-07-12 04:37:07.037809: train_loss -0.9757 
2025-07-12 04:37:07.039140: val_loss -0.9402 
2025-07-12 04:37:07.040151: Pseudo dice [np.float32(0.9429)] 
2025-07-12 04:37:07.041084: Epoch time: 69.28 s 
2025-07-12 04:37:07.973929:  
2025-07-12 04:37:07.975566: Epoch 622 
2025-07-12 04:37:07.976962: Current learning rate: 0.00417 
2025-07-12 04:38:24.363666: train_loss -0.9759 
2025-07-12 04:38:24.365026: val_loss -0.9375 
2025-07-12 04:38:24.366163: Pseudo dice [np.float32(0.9397)] 
2025-07-12 04:38:24.367198: Epoch time: 76.39 s 
2025-07-12 04:38:25.268270:  
2025-07-12 04:38:25.270032: Epoch 623 
2025-07-12 04:38:25.271137: Current learning rate: 0.00416 
2025-07-12 04:39:38.853765: train_loss -0.9758 
2025-07-12 04:39:38.855234: val_loss -0.9406 
2025-07-12 04:39:38.856440: Pseudo dice [np.float32(0.943)] 
2025-07-12 04:39:38.857658: Epoch time: 73.59 s 
2025-07-12 04:39:39.786417:  
2025-07-12 04:39:39.788352: Epoch 624 
2025-07-12 04:39:39.789393: Current learning rate: 0.00415 
2025-07-12 04:40:48.865924: train_loss -0.9774 
2025-07-12 04:40:48.867542: val_loss -0.9471 
2025-07-12 04:40:48.868697: Pseudo dice [np.float32(0.951)] 
2025-07-12 04:40:48.870146: Epoch time: 69.08 s 
2025-07-12 04:40:49.796127:  
2025-07-12 04:40:49.798128: Epoch 625 
2025-07-12 04:40:49.799239: Current learning rate: 0.00414 
2025-07-12 04:41:59.321862: train_loss -0.9769 
2025-07-12 04:41:59.323061: val_loss -0.9427 
2025-07-12 04:41:59.324599: Pseudo dice [np.float32(0.9472)] 
2025-07-12 04:41:59.325526: Epoch time: 69.53 s 
2025-07-12 04:42:00.260188:  
2025-07-12 04:42:00.261801: Epoch 626 
2025-07-12 04:42:00.263170: Current learning rate: 0.00413 
2025-07-12 04:43:09.525949: train_loss -0.9779 
2025-07-12 04:43:09.527297: val_loss -0.9446 
2025-07-12 04:43:09.528280: Pseudo dice [np.float32(0.9469)] 
2025-07-12 04:43:09.529282: Epoch time: 69.27 s 
2025-07-12 04:43:10.468903:  
2025-07-12 04:43:10.470407: Epoch 627 
2025-07-12 04:43:10.471370: Current learning rate: 0.00412 
2025-07-12 04:44:19.999416: train_loss -0.9784 
2025-07-12 04:44:20.001014: val_loss -0.945 
2025-07-12 04:44:20.002316: Pseudo dice [np.float32(0.9481)] 
2025-07-12 04:44:20.003793: Epoch time: 69.53 s 
2025-07-12 04:44:20.933649:  
2025-07-12 04:44:20.935318: Epoch 628 
2025-07-12 04:44:20.936810: Current learning rate: 0.00411 
2025-07-12 04:45:38.094125: train_loss -0.9777 
2025-07-12 04:45:38.095285: val_loss -0.9465 
2025-07-12 04:45:38.096477: Pseudo dice [np.float32(0.9503)] 
2025-07-12 04:45:38.097592: Epoch time: 77.16 s 
2025-07-12 04:45:38.098856: Yayy! New best EMA pseudo Dice: 0.945900022983551 
2025-07-12 04:45:40.515560:  
2025-07-12 04:45:40.517157: Epoch 629 
2025-07-12 04:45:40.518176: Current learning rate: 0.0041 
2025-07-12 04:46:53.164234: train_loss -0.9782 
2025-07-12 04:46:53.165576: val_loss -0.9404 
2025-07-12 04:46:53.166559: Pseudo dice [np.float32(0.9435)] 
2025-07-12 04:46:53.167545: Epoch time: 72.65 s 
2025-07-12 04:46:54.077489:  
2025-07-12 04:46:54.079456: Epoch 630 
2025-07-12 04:46:54.080457: Current learning rate: 0.00409 
2025-07-12 04:48:03.389736: train_loss -0.9779 
2025-07-12 04:48:03.391065: val_loss -0.9467 
2025-07-12 04:48:03.392234: Pseudo dice [np.float32(0.9506)] 
2025-07-12 04:48:03.393370: Epoch time: 69.32 s 
2025-07-12 04:48:03.394609: Yayy! New best EMA pseudo Dice: 0.9460999965667725 
2025-07-12 04:48:05.830282:  
2025-07-12 04:48:05.831916: Epoch 631 
2025-07-12 04:48:05.833056: Current learning rate: 0.00408 
2025-07-12 04:49:15.235785: train_loss -0.979 
2025-07-12 04:49:15.237112: val_loss -0.9468 
2025-07-12 04:49:15.238386: Pseudo dice [np.float32(0.9492)] 
2025-07-12 04:49:15.240138: Epoch time: 69.41 s 
2025-07-12 04:49:15.241226: Yayy! New best EMA pseudo Dice: 0.946399986743927 
2025-07-12 04:49:17.687696:  
2025-07-12 04:49:17.689609: Epoch 632 
2025-07-12 04:49:17.690900: Current learning rate: 0.00407 
2025-07-12 04:50:27.019539: train_loss -0.9786 
2025-07-12 04:50:27.021106: val_loss -0.9442 
2025-07-12 04:50:27.022234: Pseudo dice [np.float32(0.9478)] 
2025-07-12 04:50:27.023252: Epoch time: 69.34 s 
2025-07-12 04:50:27.024269: Yayy! New best EMA pseudo Dice: 0.9466000199317932 
2025-07-12 04:50:29.250557:  
2025-07-12 04:50:29.252434: Epoch 633 
2025-07-12 04:50:29.253505: Current learning rate: 0.00406 
2025-07-12 04:51:38.688959: train_loss -0.9782 
2025-07-12 04:51:38.690380: val_loss -0.9398 
2025-07-12 04:51:38.691417: Pseudo dice [np.float32(0.9428)] 
2025-07-12 04:51:38.692626: Epoch time: 69.44 s 
2025-07-12 04:51:39.599846:  
2025-07-12 04:51:39.601853: Epoch 634 
2025-07-12 04:51:39.602981: Current learning rate: 0.00405 
2025-07-12 04:52:48.849048: train_loss -0.9778 
2025-07-12 04:52:48.850722: val_loss -0.9471 
2025-07-12 04:52:48.851980: Pseudo dice [np.float32(0.9498)] 
2025-07-12 04:52:48.853062: Epoch time: 69.25 s 
2025-07-12 04:52:49.774465:  
2025-07-12 04:52:49.776407: Epoch 635 
2025-07-12 04:52:49.777404: Current learning rate: 0.00404 
2025-07-12 04:53:59.253220: train_loss -0.9787 
2025-07-12 04:53:59.254875: val_loss -0.9421 
2025-07-12 04:53:59.256124: Pseudo dice [np.float32(0.9441)] 
2025-07-12 04:53:59.257560: Epoch time: 69.48 s 
2025-07-12 04:54:00.182678:  
2025-07-12 04:54:00.184495: Epoch 636 
2025-07-12 04:54:00.185565: Current learning rate: 0.00403 
2025-07-12 04:55:09.580138: train_loss -0.979 
2025-07-12 04:55:09.581326: val_loss -0.9448 
2025-07-12 04:55:09.582470: Pseudo dice [np.float32(0.9467)] 
2025-07-12 04:55:09.583898: Epoch time: 69.4 s 
2025-07-12 04:55:10.482378:  
2025-07-12 04:55:10.484267: Epoch 637 
2025-07-12 04:55:10.485393: Current learning rate: 0.00402 
2025-07-12 04:56:20.126515: train_loss -0.9794 
2025-07-12 04:56:20.127813: val_loss -0.9334 
2025-07-12 04:56:20.128800: Pseudo dice [np.float32(0.9355)] 
2025-07-12 04:56:20.130216: Epoch time: 69.65 s 
2025-07-12 04:56:21.064134:  
2025-07-12 04:56:21.066267: Epoch 638 
2025-07-12 04:56:21.067271: Current learning rate: 0.00401 
2025-07-12 04:57:30.605439: train_loss -0.9779 
2025-07-12 04:57:30.606676: val_loss -0.9423 
2025-07-12 04:57:30.607935: Pseudo dice [np.float32(0.9451)] 
2025-07-12 04:57:30.608784: Epoch time: 69.54 s 
2025-07-12 04:57:31.760360:  
2025-07-12 04:57:31.762274: Epoch 639 
2025-07-12 04:57:31.763533: Current learning rate: 0.004 
2025-07-12 04:58:41.217927: train_loss -0.9784 
2025-07-12 04:58:41.219307: val_loss -0.9426 
2025-07-12 04:58:41.220346: Pseudo dice [np.float32(0.9447)] 
2025-07-12 04:58:41.221431: Epoch time: 69.46 s 
2025-07-12 04:58:42.145851:  
2025-07-12 04:58:42.147351: Epoch 640 
2025-07-12 04:58:42.148468: Current learning rate: 0.00399 
2025-07-12 04:59:51.546677: train_loss -0.9787 
2025-07-12 04:59:51.548077: val_loss -0.939 
2025-07-12 04:59:51.549195: Pseudo dice [np.float32(0.941)] 
2025-07-12 04:59:51.550415: Epoch time: 69.4 s 
2025-07-12 04:59:52.467216:  
2025-07-12 04:59:52.469210: Epoch 641 
2025-07-12 04:59:52.470268: Current learning rate: 0.00398 
2025-07-12 05:01:02.085887: train_loss -0.9768 
2025-07-12 05:01:02.087072: val_loss -0.9419 
2025-07-12 05:01:02.088090: Pseudo dice [np.float32(0.9455)] 
2025-07-12 05:01:02.089141: Epoch time: 69.62 s 
2025-07-12 05:01:03.024082:  
2025-07-12 05:01:03.026295: Epoch 642 
2025-07-12 05:01:03.027383: Current learning rate: 0.00397 
2025-07-12 05:02:12.560462: train_loss -0.9768 
2025-07-12 05:02:12.561742: val_loss -0.9312 
2025-07-12 05:02:12.562805: Pseudo dice [np.float32(0.9342)] 
2025-07-12 05:02:12.563855: Epoch time: 69.54 s 
2025-07-12 05:02:13.493974:  
2025-07-12 05:02:13.495902: Epoch 643 
2025-07-12 05:02:13.497012: Current learning rate: 0.00396 
2025-07-12 05:03:22.903983: train_loss -0.978 
2025-07-12 05:03:22.905674: val_loss -0.9459 
2025-07-12 05:03:22.906832: Pseudo dice [np.float32(0.9496)] 
2025-07-12 05:03:22.907835: Epoch time: 69.41 s 
2025-07-12 05:03:23.831673:  
2025-07-12 05:03:23.833240: Epoch 644 
2025-07-12 05:03:23.834654: Current learning rate: 0.00395 
2025-07-12 05:04:33.311646: train_loss -0.9777 
2025-07-12 05:04:33.313115: val_loss -0.9382 
2025-07-12 05:04:33.314201: Pseudo dice [np.float32(0.9414)] 
2025-07-12 05:04:33.315430: Epoch time: 69.48 s 
2025-07-12 05:04:34.283095:  
2025-07-12 05:04:34.284879: Epoch 645 
2025-07-12 05:04:34.286217: Current learning rate: 0.00394 
2025-07-12 05:05:43.669570: train_loss -0.9784 
2025-07-12 05:05:43.670938: val_loss -0.9456 
2025-07-12 05:05:43.672247: Pseudo dice [np.float32(0.9487)] 
2025-07-12 05:05:43.673232: Epoch time: 69.39 s 
2025-07-12 05:05:44.802825:  
2025-07-12 05:05:44.804862: Epoch 646 
2025-07-12 05:05:44.805952: Current learning rate: 0.00393 
2025-07-12 05:06:54.208535: train_loss -0.9783 
2025-07-12 05:06:54.210019: val_loss -0.9462 
2025-07-12 05:06:54.210976: Pseudo dice [np.float32(0.9489)] 
2025-07-12 05:06:54.212082: Epoch time: 69.41 s 
2025-07-12 05:06:55.132241:  
2025-07-12 05:06:55.133870: Epoch 647 
2025-07-12 05:06:55.135005: Current learning rate: 0.00392 
2025-07-12 05:08:04.450684: train_loss -0.9786 
2025-07-12 05:08:04.451994: val_loss -0.9458 
2025-07-12 05:08:04.452894: Pseudo dice [np.float32(0.9488)] 
2025-07-12 05:08:04.454119: Epoch time: 69.32 s 
2025-07-12 05:08:05.350093:  
2025-07-12 05:08:05.351948: Epoch 648 
2025-07-12 05:08:05.353200: Current learning rate: 0.00391 
2025-07-12 05:09:14.891617: train_loss -0.9789 
2025-07-12 05:09:14.892862: val_loss -0.945 
2025-07-12 05:09:14.894349: Pseudo dice [np.float32(0.9477)] 
2025-07-12 05:09:14.895658: Epoch time: 69.55 s 
2025-07-12 05:09:15.822345:  
2025-07-12 05:09:15.823949: Epoch 649 
2025-07-12 05:09:15.824911: Current learning rate: 0.0039 
2025-07-12 05:10:25.542063: train_loss -0.9778 
2025-07-12 05:10:25.543246: val_loss -0.9425 
2025-07-12 05:10:25.544374: Pseudo dice [np.float32(0.9453)] 
2025-07-12 05:10:25.545660: Epoch time: 69.72 s 
2025-07-12 05:10:27.603498:  
2025-07-12 05:10:27.605011: Epoch 650 
2025-07-12 05:10:27.606140: Current learning rate: 0.00389 
2025-07-12 05:11:36.932398: train_loss -0.9786 
2025-07-12 05:11:36.933621: val_loss -0.9431 
2025-07-12 05:11:36.934632: Pseudo dice [np.float32(0.9456)] 
2025-07-12 05:11:36.935640: Epoch time: 69.33 s 
2025-07-12 05:11:37.858819:  
2025-07-12 05:11:37.860869: Epoch 651 
2025-07-12 05:11:37.861962: Current learning rate: 0.00388 
2025-07-12 05:12:47.257890: train_loss -0.978 
2025-07-12 05:12:47.259625: val_loss -0.9386 
2025-07-12 05:12:47.260938: Pseudo dice [np.float32(0.9413)] 
2025-07-12 05:12:47.262238: Epoch time: 69.4 s 
2025-07-12 05:12:48.236053:  
2025-07-12 05:12:48.238157: Epoch 652 
2025-07-12 05:12:48.239372: Current learning rate: 0.00387 
2025-07-12 05:13:57.552567: train_loss -0.978 
2025-07-12 05:13:57.553802: val_loss -0.9397 
2025-07-12 05:13:57.555117: Pseudo dice [np.float32(0.9429)] 
2025-07-12 05:13:57.556775: Epoch time: 69.32 s 
2025-07-12 05:13:58.719731:  
2025-07-12 05:13:58.721425: Epoch 653 
2025-07-12 05:13:58.722436: Current learning rate: 0.00386 
2025-07-12 05:15:08.100748: train_loss -0.9782 
2025-07-12 05:15:08.102350: val_loss -0.9352 
2025-07-12 05:15:08.103615: Pseudo dice [np.float32(0.9382)] 
2025-07-12 05:15:08.104749: Epoch time: 69.38 s 
2025-07-12 05:15:09.012770:  
2025-07-12 05:15:09.014693: Epoch 654 
2025-07-12 05:15:09.015913: Current learning rate: 0.00385 
2025-07-12 05:16:18.206507: train_loss -0.9781 
2025-07-12 05:16:18.207804: val_loss -0.9429 
2025-07-12 05:16:18.209343: Pseudo dice [np.float32(0.9455)] 
2025-07-12 05:16:18.210308: Epoch time: 69.2 s 
2025-07-12 05:16:19.138359:  
2025-07-12 05:16:19.140385: Epoch 655 
2025-07-12 05:16:19.141623: Current learning rate: 0.00384 
2025-07-12 05:17:28.534402: train_loss -0.9765 
2025-07-12 05:17:28.535715: val_loss -0.9459 
2025-07-12 05:17:28.537205: Pseudo dice [np.float32(0.9491)] 
2025-07-12 05:17:28.538254: Epoch time: 69.4 s 
2025-07-12 05:17:29.467403:  
2025-07-12 05:17:29.469454: Epoch 656 
2025-07-12 05:17:29.470631: Current learning rate: 0.00383 
2025-07-12 05:18:38.782457: train_loss -0.9771 
2025-07-12 05:18:38.783941: val_loss -0.945 
2025-07-12 05:18:38.785464: Pseudo dice [np.float32(0.9478)] 
2025-07-12 05:18:38.786542: Epoch time: 69.32 s 
2025-07-12 05:18:39.756138:  
2025-07-12 05:18:39.757850: Epoch 657 
2025-07-12 05:18:39.759008: Current learning rate: 0.00382 
2025-07-12 05:19:49.035551: train_loss -0.9775 
2025-07-12 05:19:49.036870: val_loss -0.9423 
2025-07-12 05:19:49.037924: Pseudo dice [np.float32(0.9456)] 
2025-07-12 05:19:49.039021: Epoch time: 69.28 s 
2025-07-12 05:19:49.975466:  
2025-07-12 05:19:49.977626: Epoch 658 
2025-07-12 05:19:49.978744: Current learning rate: 0.00381 
2025-07-12 05:20:59.438632: train_loss -0.9765 
2025-07-12 05:20:59.439833: val_loss -0.939 
2025-07-12 05:20:59.440893: Pseudo dice [np.float32(0.9411)] 
2025-07-12 05:20:59.441989: Epoch time: 69.47 s 
2025-07-12 05:21:00.367338:  
2025-07-12 05:21:00.369457: Epoch 659 
2025-07-12 05:21:00.370714: Current learning rate: 0.0038 
2025-07-12 05:22:09.605212: train_loss -0.9777 
2025-07-12 05:22:09.606489: val_loss -0.9465 
2025-07-12 05:22:09.607752: Pseudo dice [np.float32(0.9495)] 
2025-07-12 05:22:09.608803: Epoch time: 69.24 s 
2025-07-12 05:22:10.761483:  
2025-07-12 05:22:10.763441: Epoch 660 
2025-07-12 05:22:10.764794: Current learning rate: 0.00379 
2025-07-12 05:23:20.053427: train_loss -0.9775 
2025-07-12 05:23:20.054662: val_loss -0.9483 
2025-07-12 05:23:20.055997: Pseudo dice [np.float32(0.952)] 
2025-07-12 05:23:20.056964: Epoch time: 69.3 s 
2025-07-12 05:23:20.986207:  
2025-07-12 05:23:20.987819: Epoch 661 
2025-07-12 05:23:20.988900: Current learning rate: 0.00378 
2025-07-12 05:24:30.314254: train_loss -0.9786 
2025-07-12 05:24:30.315810: val_loss -0.9461 
2025-07-12 05:24:30.317161: Pseudo dice [np.float32(0.9484)] 
2025-07-12 05:24:30.318027: Epoch time: 69.33 s 
2025-07-12 05:24:31.238696:  
2025-07-12 05:24:31.240704: Epoch 662 
2025-07-12 05:24:31.241716: Current learning rate: 0.00377 
2025-07-12 05:25:40.801140: train_loss -0.9785 
2025-07-12 05:25:40.802449: val_loss -0.9388 
2025-07-12 05:25:40.803553: Pseudo dice [np.float32(0.943)] 
2025-07-12 05:25:40.804621: Epoch time: 69.57 s 
2025-07-12 05:25:41.742291:  
2025-07-12 05:25:41.744412: Epoch 663 
2025-07-12 05:25:41.745603: Current learning rate: 0.00376 
2025-07-12 05:26:51.404263: train_loss -0.9785 
2025-07-12 05:26:51.405546: val_loss -0.9445 
2025-07-12 05:26:51.406537: Pseudo dice [np.float32(0.9478)] 
2025-07-12 05:26:51.407522: Epoch time: 69.67 s 
2025-07-12 05:26:52.325912:  
2025-07-12 05:26:52.328152: Epoch 664 
2025-07-12 05:26:52.329153: Current learning rate: 0.00375 
2025-07-12 05:28:01.206320: train_loss -0.9783 
2025-07-12 05:28:01.207524: val_loss -0.9438 
2025-07-12 05:28:01.208578: Pseudo dice [np.float32(0.947)] 
2025-07-12 05:28:01.209947: Epoch time: 68.88 s 
2025-07-12 05:28:02.143394:  
2025-07-12 05:28:02.145092: Epoch 665 
2025-07-12 05:28:02.146373: Current learning rate: 0.00374 
2025-07-12 05:29:11.236161: train_loss -0.9778 
2025-07-12 05:29:11.237467: val_loss -0.9475 
2025-07-12 05:29:11.238636: Pseudo dice [np.float32(0.951)] 
2025-07-12 05:29:11.239725: Epoch time: 69.1 s 
2025-07-12 05:29:11.240816: Yayy! New best EMA pseudo Dice: 0.9466000199317932 
2025-07-12 05:29:13.273277:  
2025-07-12 05:29:13.275155: Epoch 666 
2025-07-12 05:29:13.276214: Current learning rate: 0.00373 
2025-07-12 05:30:22.727297: train_loss -0.9779 
2025-07-12 05:30:22.728689: val_loss -0.9458 
2025-07-12 05:30:22.729628: Pseudo dice [np.float32(0.949)] 
2025-07-12 05:30:22.731298: Epoch time: 69.46 s 
2025-07-12 05:30:22.732537: Yayy! New best EMA pseudo Dice: 0.9469000101089478 
2025-07-12 05:30:24.979595:  
2025-07-12 05:30:24.981515: Epoch 667 
2025-07-12 05:30:24.982596: Current learning rate: 0.00372 
2025-07-12 05:31:34.268350: train_loss -0.9788 
2025-07-12 05:31:34.269575: val_loss -0.9453 
2025-07-12 05:31:34.270840: Pseudo dice [np.float32(0.9482)] 
2025-07-12 05:31:34.271966: Epoch time: 69.29 s 
2025-07-12 05:31:34.273348: Yayy! New best EMA pseudo Dice: 0.9470000267028809 
2025-07-12 05:31:36.464740:  
2025-07-12 05:31:36.466629: Epoch 668 
2025-07-12 05:31:36.467840: Current learning rate: 0.00371 
2025-07-12 05:32:45.698745: train_loss -0.9788 
2025-07-12 05:32:45.700044: val_loss -0.9474 
2025-07-12 05:32:45.701193: Pseudo dice [np.float32(0.9498)] 
2025-07-12 05:32:45.702513: Epoch time: 69.24 s 
2025-07-12 05:32:45.703764: Yayy! New best EMA pseudo Dice: 0.9473000168800354 
2025-07-12 05:32:47.949977:  
2025-07-12 05:32:47.951704: Epoch 669 
2025-07-12 05:32:47.952746: Current learning rate: 0.0037 
2025-07-12 05:33:57.339183: train_loss -0.9785 
2025-07-12 05:33:57.340393: val_loss -0.9431 
2025-07-12 05:33:57.341366: Pseudo dice [np.float32(0.9466)] 
2025-07-12 05:33:57.342451: Epoch time: 69.39 s 
2025-07-12 05:33:58.280941:  
2025-07-12 05:33:58.282963: Epoch 670 
2025-07-12 05:33:58.284051: Current learning rate: 0.00369 
2025-07-12 05:35:07.574287: train_loss -0.9786 
2025-07-12 05:35:07.576364: val_loss -0.9423 
2025-07-12 05:35:07.577357: Pseudo dice [np.float32(0.945)] 
2025-07-12 05:35:07.578605: Epoch time: 69.3 s 
2025-07-12 05:35:08.510339:  
2025-07-12 05:35:08.512349: Epoch 671 
2025-07-12 05:35:08.513377: Current learning rate: 0.00368 
2025-07-12 05:36:17.701052: train_loss -0.9788 
2025-07-12 05:36:17.702342: val_loss -0.945 
2025-07-12 05:36:17.703682: Pseudo dice [np.float32(0.9483)] 
2025-07-12 05:36:17.705211: Epoch time: 69.19 s 
2025-07-12 05:36:18.638300:  
2025-07-12 05:36:18.640135: Epoch 672 
2025-07-12 05:36:18.641637: Current learning rate: 0.00367 
2025-07-12 05:37:27.801035: train_loss -0.9794 
2025-07-12 05:37:27.802226: val_loss -0.9405 
2025-07-12 05:37:27.803245: Pseudo dice [np.float32(0.9438)] 
2025-07-12 05:37:27.804636: Epoch time: 69.17 s 
2025-07-12 05:37:28.741061:  
2025-07-12 05:37:28.742881: Epoch 673 
2025-07-12 05:37:28.744336: Current learning rate: 0.00366 
2025-07-12 05:38:38.236712: train_loss -0.9794 
2025-07-12 05:38:38.238142: val_loss -0.9428 
2025-07-12 05:38:38.239027: Pseudo dice [np.float32(0.9458)] 
2025-07-12 05:38:38.239850: Epoch time: 69.5 s 
2025-07-12 05:38:39.172909:  
2025-07-12 05:38:39.175075: Epoch 674 
2025-07-12 05:38:39.176253: Current learning rate: 0.00365 
2025-07-12 05:39:48.551481: train_loss -0.9792 
2025-07-12 05:39:48.552777: val_loss -0.9416 
2025-07-12 05:39:48.553852: Pseudo dice [np.float32(0.9434)] 
2025-07-12 05:39:48.554760: Epoch time: 69.38 s 
2025-07-12 05:39:49.481453:  
2025-07-12 05:39:49.483210: Epoch 675 
2025-07-12 05:39:49.484224: Current learning rate: 0.00364 
2025-07-12 05:40:59.532278: train_loss -0.9789 
2025-07-12 05:40:59.533665: val_loss -0.9408 
2025-07-12 05:40:59.534678: Pseudo dice [np.float32(0.9434)] 
2025-07-12 05:40:59.536204: Epoch time: 70.05 s 
2025-07-12 05:41:00.460658:  
2025-07-12 05:41:00.462702: Epoch 676 
2025-07-12 05:41:00.463999: Current learning rate: 0.00363 
2025-07-12 05:42:10.171573: train_loss -0.9781 
2025-07-12 05:42:10.172786: val_loss -0.9316 
2025-07-12 05:42:10.173820: Pseudo dice [np.float32(0.932)] 
2025-07-12 05:42:10.174836: Epoch time: 69.71 s 
2025-07-12 05:42:11.101510:  
2025-07-12 05:42:11.103336: Epoch 677 
2025-07-12 05:42:11.104343: Current learning rate: 0.00362 
2025-07-12 05:43:20.165591: train_loss -0.9772 
2025-07-12 05:43:20.166758: val_loss -0.9346 
2025-07-12 05:43:20.167800: Pseudo dice [np.float32(0.9377)] 
2025-07-12 05:43:20.169209: Epoch time: 69.07 s 
2025-07-12 05:43:21.100680:  
2025-07-12 05:43:21.102477: Epoch 678 
2025-07-12 05:43:21.103568: Current learning rate: 0.00361 
2025-07-12 05:44:30.192329: train_loss -0.9774 
2025-07-12 05:44:30.194119: val_loss -0.9333 
2025-07-12 05:44:30.195520: Pseudo dice [np.float32(0.9359)] 
2025-07-12 05:44:30.196512: Epoch time: 69.1 s 
2025-07-12 05:44:31.132230:  
2025-07-12 05:44:31.133861: Epoch 679 
2025-07-12 05:44:31.135055: Current learning rate: 0.0036 
2025-07-12 05:45:40.208142: train_loss -0.9782 
2025-07-12 05:45:40.209414: val_loss -0.9386 
2025-07-12 05:45:40.210350: Pseudo dice [np.float32(0.9422)] 
2025-07-12 05:45:40.211411: Epoch time: 69.08 s 
2025-07-12 05:45:41.371923:  
2025-07-12 05:45:41.373734: Epoch 680 
2025-07-12 05:45:41.374906: Current learning rate: 0.00359 
2025-07-12 05:46:50.413405: train_loss -0.9792 
2025-07-12 05:46:50.414868: val_loss -0.9432 
2025-07-12 05:46:50.415754: Pseudo dice [np.float32(0.9452)] 
2025-07-12 05:46:50.416792: Epoch time: 69.05 s 
2025-07-12 05:46:51.341447:  
2025-07-12 05:46:51.343446: Epoch 681 
2025-07-12 05:46:51.344745: Current learning rate: 0.00358 
2025-07-12 05:48:00.541157: train_loss -0.9786 
2025-07-12 05:48:00.542497: val_loss -0.9407 
2025-07-12 05:48:00.543552: Pseudo dice [np.float32(0.9429)] 
2025-07-12 05:48:00.544808: Epoch time: 69.2 s 
2025-07-12 05:48:01.443440:  
2025-07-12 05:48:01.445192: Epoch 682 
2025-07-12 05:48:01.446447: Current learning rate: 0.00357 
2025-07-12 05:49:10.726064: train_loss -0.9783 
2025-07-12 05:49:10.727475: val_loss -0.9437 
2025-07-12 05:49:10.728458: Pseudo dice [np.float32(0.945)] 
2025-07-12 05:49:10.729537: Epoch time: 69.29 s 
2025-07-12 05:49:11.645597:  
2025-07-12 05:49:11.647676: Epoch 683 
2025-07-12 05:49:11.648792: Current learning rate: 0.00356 
2025-07-12 05:50:20.953311: train_loss -0.9786 
2025-07-12 05:50:20.954519: val_loss -0.9411 
2025-07-12 05:50:20.955637: Pseudo dice [np.float32(0.9444)] 
2025-07-12 05:50:20.956741: Epoch time: 69.31 s 
2025-07-12 05:50:21.874541:  
2025-07-12 05:50:21.876409: Epoch 684 
2025-07-12 05:50:21.877429: Current learning rate: 0.00355 
2025-07-12 05:51:31.135581: train_loss -0.9776 
2025-07-12 05:51:31.137059: val_loss -0.9357 
2025-07-12 05:51:31.138347: Pseudo dice [np.float32(0.9373)] 
2025-07-12 05:51:31.139373: Epoch time: 69.26 s 
2025-07-12 05:51:32.069692:  
2025-07-12 05:51:32.071258: Epoch 685 
2025-07-12 05:51:32.072279: Current learning rate: 0.00354 
2025-07-12 05:52:41.394286: train_loss -0.9784 
2025-07-12 05:52:41.395750: val_loss -0.9382 
2025-07-12 05:52:41.396655: Pseudo dice [np.float32(0.9394)] 
2025-07-12 05:52:41.397657: Epoch time: 69.33 s 
2025-07-12 05:52:42.341971:  
2025-07-12 05:52:42.344086: Epoch 686 
2025-07-12 05:52:42.345036: Current learning rate: 0.00353 
2025-07-12 05:53:51.808942: train_loss -0.9795 
2025-07-12 05:53:51.810281: val_loss -0.9404 
2025-07-12 05:53:51.811345: Pseudo dice [np.float32(0.9411)] 
2025-07-12 05:53:51.812344: Epoch time: 69.47 s 
2025-07-12 05:53:52.966146:  
2025-07-12 05:53:52.968197: Epoch 687 
2025-07-12 05:53:52.969360: Current learning rate: 0.00352 
2025-07-12 05:55:02.251625: train_loss -0.979 
2025-07-12 05:55:02.253043: val_loss -0.943 
2025-07-12 05:55:02.253969: Pseudo dice [np.float32(0.946)] 
2025-07-12 05:55:02.254899: Epoch time: 69.29 s 
2025-07-12 05:55:03.178722:  
2025-07-12 05:55:03.180703: Epoch 688 
2025-07-12 05:55:03.181871: Current learning rate: 0.00351 
2025-07-12 05:56:17.854628: train_loss -0.9789 
2025-07-12 05:56:17.855959: val_loss -0.9407 
2025-07-12 05:56:17.856918: Pseudo dice [np.float32(0.9444)] 
2025-07-12 05:56:17.857875: Epoch time: 74.68 s 
2025-07-12 05:56:18.781936:  
2025-07-12 05:56:18.783439: Epoch 689 
2025-07-12 05:56:18.785218: Current learning rate: 0.0035 
2025-07-12 05:57:31.856357: train_loss -0.9798 
2025-07-12 05:57:31.857595: val_loss -0.9427 
2025-07-12 05:57:31.859330: Pseudo dice [np.float32(0.946)] 
2025-07-12 05:57:31.860324: Epoch time: 73.08 s 
2025-07-12 05:57:32.775806:  
2025-07-12 05:57:32.777689: Epoch 690 
2025-07-12 05:57:32.778757: Current learning rate: 0.00349 
2025-07-12 05:58:41.367299: train_loss -0.9788 
2025-07-12 05:58:41.368796: val_loss -0.9411 
2025-07-12 05:58:41.370104: Pseudo dice [np.float32(0.9424)] 
2025-07-12 05:58:41.371171: Epoch time: 68.6 s 
2025-07-12 05:58:42.302776:  
2025-07-12 05:58:42.304620: Epoch 691 
2025-07-12 05:58:42.305596: Current learning rate: 0.00348 
2025-07-12 05:59:50.956249: train_loss -0.9795 
2025-07-12 05:59:50.957474: val_loss -0.9347 
2025-07-12 05:59:50.958387: Pseudo dice [np.float32(0.9372)] 
2025-07-12 05:59:50.959872: Epoch time: 68.66 s 
2025-07-12 05:59:51.885695:  
2025-07-12 05:59:51.887452: Epoch 692 
2025-07-12 05:59:51.889013: Current learning rate: 0.00346 
2025-07-12 06:01:00.929030: train_loss -0.9793 
2025-07-12 06:01:00.930698: val_loss -0.9412 
2025-07-12 06:01:00.932113: Pseudo dice [np.float32(0.944)] 
2025-07-12 06:01:00.933222: Epoch time: 69.05 s 
2025-07-12 06:01:01.867377:  
2025-07-12 06:01:01.869054: Epoch 693 
2025-07-12 06:01:01.870043: Current learning rate: 0.00345 
2025-07-12 06:02:10.908620: train_loss -0.9795 
2025-07-12 06:02:10.910388: val_loss -0.9385 
2025-07-12 06:02:10.911442: Pseudo dice [np.float32(0.9389)] 
2025-07-12 06:02:10.912638: Epoch time: 69.04 s 
2025-07-12 06:02:12.063714:  
2025-07-12 06:02:12.065718: Epoch 694 
2025-07-12 06:02:12.066783: Current learning rate: 0.00344 
2025-07-12 06:03:21.180355: train_loss -0.9789 
2025-07-12 06:03:21.181830: val_loss -0.942 
2025-07-12 06:03:21.183036: Pseudo dice [np.float32(0.9447)] 
2025-07-12 06:03:21.184196: Epoch time: 69.12 s 
2025-07-12 06:03:22.121410:  
2025-07-12 06:03:22.123746: Epoch 695 
2025-07-12 06:03:22.125127: Current learning rate: 0.00343 
2025-07-12 06:04:31.240828: train_loss -0.9792 
2025-07-12 06:04:31.242263: val_loss -0.9412 
2025-07-12 06:04:31.243150: Pseudo dice [np.float32(0.9441)] 
2025-07-12 06:04:31.244501: Epoch time: 69.12 s 
2025-07-12 06:04:32.173150:  
2025-07-12 06:04:32.174527: Epoch 696 
2025-07-12 06:04:32.175581: Current learning rate: 0.00342 
2025-07-12 06:05:41.488333: train_loss -0.9789 
2025-07-12 06:05:41.489815: val_loss -0.9467 
2025-07-12 06:05:41.491010: Pseudo dice [np.float32(0.9504)] 
2025-07-12 06:05:41.492060: Epoch time: 69.32 s 
2025-07-12 06:05:42.407251:  
2025-07-12 06:05:42.408977: Epoch 697 
2025-07-12 06:05:42.410001: Current learning rate: 0.00341 
2025-07-12 06:06:51.857728: train_loss -0.9794 
2025-07-12 06:06:51.859110: val_loss -0.9445 
2025-07-12 06:06:51.860160: Pseudo dice [np.float32(0.9471)] 
2025-07-12 06:06:51.861259: Epoch time: 69.45 s 
2025-07-12 06:06:52.790785:  
2025-07-12 06:06:52.792793: Epoch 698 
2025-07-12 06:06:52.793979: Current learning rate: 0.0034 
2025-07-12 06:08:02.120689: train_loss -0.9795 
2025-07-12 06:08:02.122046: val_loss -0.9418 
2025-07-12 06:08:02.123596: Pseudo dice [np.float32(0.9444)] 
2025-07-12 06:08:02.125183: Epoch time: 69.33 s 
2025-07-12 06:08:03.074249:  
2025-07-12 06:08:03.076257: Epoch 699 
2025-07-12 06:08:03.077348: Current learning rate: 0.00339 
2025-07-12 06:09:12.258567: train_loss -0.9794 
2025-07-12 06:09:12.259769: val_loss -0.9452 
2025-07-12 06:09:12.260929: Pseudo dice [np.float32(0.9471)] 
2025-07-12 06:09:12.261855: Epoch time: 69.19 s 
2025-07-12 06:09:14.438339:  
2025-07-12 06:09:14.439756: Epoch 700 
2025-07-12 06:09:14.440795: Current learning rate: 0.00338 
2025-07-12 06:10:23.925601: train_loss -0.9791 
2025-07-12 06:10:23.927139: val_loss -0.9407 
2025-07-12 06:10:23.928155: Pseudo dice [np.float32(0.9422)] 
2025-07-12 06:10:23.929123: Epoch time: 69.49 s 
2025-07-12 06:10:24.857309:  
2025-07-12 06:10:24.859214: Epoch 701 
2025-07-12 06:10:24.860212: Current learning rate: 0.00337 
2025-07-12 06:11:33.980118: train_loss -0.9789 
2025-07-12 06:11:33.981553: val_loss -0.9392 
2025-07-12 06:11:33.982901: Pseudo dice [np.float32(0.9416)] 
2025-07-12 06:11:33.984279: Epoch time: 69.13 s 
2025-07-12 06:11:34.911541:  
2025-07-12 06:11:34.913303: Epoch 702 
2025-07-12 06:11:34.914442: Current learning rate: 0.00336 
2025-07-12 06:12:44.130265: train_loss -0.978 
2025-07-12 06:12:44.131835: val_loss -0.9379 
2025-07-12 06:12:44.132864: Pseudo dice [np.float32(0.94)] 
2025-07-12 06:12:44.134082: Epoch time: 69.22 s 
2025-07-12 06:12:45.077333:  
2025-07-12 06:12:45.079096: Epoch 703 
2025-07-12 06:12:45.080231: Current learning rate: 0.00335 
2025-07-12 06:13:54.098917: train_loss -0.9776 
2025-07-12 06:13:54.100121: val_loss -0.9432 
2025-07-12 06:13:54.101419: Pseudo dice [np.float32(0.946)] 
2025-07-12 06:13:54.102494: Epoch time: 69.03 s 
2025-07-12 06:13:55.024342:  
2025-07-12 06:13:55.025852: Epoch 704 
2025-07-12 06:13:55.026897: Current learning rate: 0.00334 
2025-07-12 06:15:04.389575: train_loss -0.9785 
2025-07-12 06:15:04.390857: val_loss -0.9477 
2025-07-12 06:15:04.392139: Pseudo dice [np.float32(0.9503)] 
2025-07-12 06:15:04.393124: Epoch time: 69.37 s 
2025-07-12 06:15:05.343827:  
2025-07-12 06:15:05.345684: Epoch 705 
2025-07-12 06:15:05.346911: Current learning rate: 0.00333 
2025-07-12 06:16:14.579439: train_loss -0.9778 
2025-07-12 06:16:14.580765: val_loss -0.9361 
2025-07-12 06:16:14.581814: Pseudo dice [np.float32(0.9391)] 
2025-07-12 06:16:14.583108: Epoch time: 69.24 s 
2025-07-12 06:16:15.536572:  
2025-07-12 06:16:15.538423: Epoch 706 
2025-07-12 06:16:15.539440: Current learning rate: 0.00332 
2025-07-12 06:17:24.824166: train_loss -0.9782 
2025-07-12 06:17:24.825266: val_loss -0.9427 
2025-07-12 06:17:24.826206: Pseudo dice [np.float32(0.9449)] 
2025-07-12 06:17:24.827112: Epoch time: 69.29 s 
2025-07-12 06:17:25.735700:  
2025-07-12 06:17:25.737171: Epoch 707 
2025-07-12 06:17:25.738299: Current learning rate: 0.00331 
2025-07-12 06:18:35.058680: train_loss -0.9788 
2025-07-12 06:18:35.059854: val_loss -0.9389 
2025-07-12 06:18:35.060887: Pseudo dice [np.float32(0.9418)] 
2025-07-12 06:18:35.062182: Epoch time: 69.33 s 
2025-07-12 06:18:36.006179:  
2025-07-12 06:18:36.008294: Epoch 708 
2025-07-12 06:18:36.009387: Current learning rate: 0.0033 
2025-07-12 06:19:45.184345: train_loss -0.9801 
2025-07-12 06:19:45.185467: val_loss -0.9338 
2025-07-12 06:19:45.186506: Pseudo dice [np.float32(0.936)] 
2025-07-12 06:19:45.187447: Epoch time: 69.18 s 
2025-07-12 06:19:46.123391:  
2025-07-12 06:19:46.125418: Epoch 709 
2025-07-12 06:19:46.126522: Current learning rate: 0.00329 
2025-07-12 06:20:55.445924: train_loss -0.98 
2025-07-12 06:20:55.447716: val_loss -0.9488 
2025-07-12 06:20:55.448861: Pseudo dice [np.float32(0.9505)] 
2025-07-12 06:20:55.450103: Epoch time: 69.33 s 
2025-07-12 06:20:56.401917:  
2025-07-12 06:20:56.403762: Epoch 710 
2025-07-12 06:20:56.404825: Current learning rate: 0.00328 
2025-07-12 06:22:05.770372: train_loss -0.9794 
2025-07-12 06:22:05.771706: val_loss -0.9381 
2025-07-12 06:22:05.773267: Pseudo dice [np.float32(0.9416)] 
2025-07-12 06:22:05.774592: Epoch time: 69.37 s 
2025-07-12 06:22:06.718554:  
2025-07-12 06:22:06.720536: Epoch 711 
2025-07-12 06:22:06.721731: Current learning rate: 0.00327 
2025-07-12 06:23:16.102678: train_loss -0.9797 
2025-07-12 06:23:16.103958: val_loss -0.9465 
2025-07-12 06:23:16.105008: Pseudo dice [np.float32(0.9494)] 
2025-07-12 06:23:16.106207: Epoch time: 69.39 s 
2025-07-12 06:23:17.030731:  
2025-07-12 06:23:17.032454: Epoch 712 
2025-07-12 06:23:17.033458: Current learning rate: 0.00326 
2025-07-12 06:24:26.422457: train_loss -0.9799 
2025-07-12 06:24:26.423643: val_loss -0.9413 
2025-07-12 06:24:26.424816: Pseudo dice [np.float32(0.943)] 
2025-07-12 06:24:26.426009: Epoch time: 69.4 s 
2025-07-12 06:24:27.369205:  
2025-07-12 06:24:27.371239: Epoch 713 
2025-07-12 06:24:27.372655: Current learning rate: 0.00325 
2025-07-12 06:25:37.544941: train_loss -0.9795 
2025-07-12 06:25:37.546183: val_loss -0.9437 
2025-07-12 06:25:37.547496: Pseudo dice [np.float32(0.9467)] 
2025-07-12 06:25:37.548743: Epoch time: 70.18 s 
2025-07-12 06:25:38.480158:  
2025-07-12 06:25:38.482269: Epoch 714 
2025-07-12 06:25:38.483340: Current learning rate: 0.00324 
2025-07-12 06:26:48.514977: train_loss -0.9798 
2025-07-12 06:26:48.516248: val_loss -0.935 
2025-07-12 06:26:48.517447: Pseudo dice [np.float32(0.9387)] 
2025-07-12 06:26:48.518774: Epoch time: 70.04 s 
2025-07-12 06:26:49.499731:  
2025-07-12 06:26:49.501734: Epoch 715 
2025-07-12 06:26:49.503233: Current learning rate: 0.00323 
2025-07-12 06:27:58.014379: train_loss -0.9789 
2025-07-12 06:27:58.015737: val_loss -0.9336 
2025-07-12 06:27:58.016777: Pseudo dice [np.float32(0.9356)] 
2025-07-12 06:27:58.018195: Epoch time: 68.52 s 
2025-07-12 06:27:58.958773:  
2025-07-12 06:27:58.960369: Epoch 716 
2025-07-12 06:27:58.961612: Current learning rate: 0.00322 
2025-07-12 06:29:07.565088: train_loss -0.9789 
2025-07-12 06:29:07.571469: val_loss -0.9437 
2025-07-12 06:29:07.572602: Pseudo dice [np.float32(0.9466)] 
2025-07-12 06:29:07.573866: Epoch time: 68.61 s 
2025-07-12 06:29:08.497775:  
2025-07-12 06:29:08.499633: Epoch 717 
2025-07-12 06:29:08.500823: Current learning rate: 0.00321 
2025-07-12 06:30:17.541018: train_loss -0.9785 
2025-07-12 06:30:17.542191: val_loss -0.9441 
2025-07-12 06:30:17.543164: Pseudo dice [np.float32(0.947)] 
2025-07-12 06:30:17.544096: Epoch time: 69.05 s 
2025-07-12 06:30:18.705748:  
2025-07-12 06:30:18.707755: Epoch 718 
2025-07-12 06:30:18.709158: Current learning rate: 0.0032 
2025-07-12 06:31:27.874659: train_loss -0.9791 
2025-07-12 06:31:27.876142: val_loss -0.9347 
2025-07-12 06:31:27.877123: Pseudo dice [np.float32(0.9372)] 
2025-07-12 06:31:27.878435: Epoch time: 69.17 s 
2025-07-12 06:31:28.806644:  
2025-07-12 06:31:28.808414: Epoch 719 
2025-07-12 06:31:28.809533: Current learning rate: 0.00319 
2025-07-12 06:32:38.051330: train_loss -0.9787 
2025-07-12 06:32:38.052533: val_loss -0.943 
2025-07-12 06:32:38.053624: Pseudo dice [np.float32(0.9455)] 
2025-07-12 06:32:38.054891: Epoch time: 69.25 s 
2025-07-12 06:32:38.981125:  
2025-07-12 06:32:38.983078: Epoch 720 
2025-07-12 06:32:38.984392: Current learning rate: 0.00318 
2025-07-12 06:33:48.177874: train_loss -0.9798 
2025-07-12 06:33:48.179021: val_loss -0.9394 
2025-07-12 06:33:48.180340: Pseudo dice [np.float32(0.9415)] 
2025-07-12 06:33:48.181796: Epoch time: 69.2 s 
2025-07-12 06:33:49.103009:  
2025-07-12 06:33:49.104529: Epoch 721 
2025-07-12 06:33:49.105828: Current learning rate: 0.00317 
2025-07-12 06:34:58.418507: train_loss -0.9797 
2025-07-12 06:34:58.419798: val_loss -0.9449 
2025-07-12 06:34:58.420731: Pseudo dice [np.float32(0.9478)] 
2025-07-12 06:34:58.421676: Epoch time: 69.32 s 
2025-07-12 06:34:59.368033:  
2025-07-12 06:34:59.369720: Epoch 722 
2025-07-12 06:34:59.370835: Current learning rate: 0.00316 
2025-07-12 06:36:08.618711: train_loss -0.9795 
2025-07-12 06:36:08.619980: val_loss -0.936 
2025-07-12 06:36:08.620868: Pseudo dice [np.float32(0.9389)] 
2025-07-12 06:36:08.621796: Epoch time: 69.25 s 
2025-07-12 06:36:09.550619:  
2025-07-12 06:36:09.552701: Epoch 723 
2025-07-12 06:36:09.553644: Current learning rate: 0.00315 
2025-07-12 06:37:18.766606: train_loss -0.9805 
2025-07-12 06:37:18.768371: val_loss -0.9465 
2025-07-12 06:37:18.769592: Pseudo dice [np.float32(0.9497)] 
2025-07-12 06:37:18.770793: Epoch time: 69.22 s 
2025-07-12 06:37:19.711008:  
2025-07-12 06:37:19.713102: Epoch 724 
2025-07-12 06:37:19.714089: Current learning rate: 0.00314 
2025-07-12 06:38:28.956231: train_loss -0.98 
2025-07-12 06:38:28.957677: val_loss -0.9437 
2025-07-12 06:38:28.958714: Pseudo dice [np.float32(0.9463)] 
2025-07-12 06:38:28.959697: Epoch time: 69.25 s 
2025-07-12 06:38:29.898397:  
2025-07-12 06:38:29.900155: Epoch 725 
2025-07-12 06:38:29.901390: Current learning rate: 0.00313 
2025-07-12 06:39:39.363989: train_loss -0.979 
2025-07-12 06:39:39.366100: val_loss -0.9439 
2025-07-12 06:39:39.367148: Pseudo dice [np.float32(0.9469)] 
2025-07-12 06:39:39.368171: Epoch time: 69.47 s 
2025-07-12 06:39:40.314163:  
2025-07-12 06:39:40.315979: Epoch 726 
2025-07-12 06:39:40.317113: Current learning rate: 0.00312 
2025-07-12 06:40:52.290345: train_loss -0.9798 
2025-07-12 06:40:52.291639: val_loss -0.9438 
2025-07-12 06:40:52.292672: Pseudo dice [np.float32(0.947)] 
2025-07-12 06:40:52.293604: Epoch time: 71.98 s 
2025-07-12 06:40:53.222604:  
2025-07-12 06:40:53.224562: Epoch 727 
2025-07-12 06:40:53.225590: Current learning rate: 0.00311 
2025-07-12 06:42:05.382831: train_loss -0.9783 
2025-07-12 06:42:05.384138: val_loss -0.9326 
2025-07-12 06:42:05.385181: Pseudo dice [np.float32(0.9359)] 
2025-07-12 06:42:05.386505: Epoch time: 72.16 s 
2025-07-12 06:42:06.340619:  
2025-07-12 06:42:06.342487: Epoch 728 
2025-07-12 06:42:06.343510: Current learning rate: 0.0031 
2025-07-12 06:43:15.502925: train_loss -0.9787 
2025-07-12 06:43:15.504134: val_loss -0.9472 
2025-07-12 06:43:15.505160: Pseudo dice [np.float32(0.9497)] 
2025-07-12 06:43:15.506061: Epoch time: 69.17 s 
2025-07-12 06:43:16.426162:  
2025-07-12 06:43:16.427957: Epoch 729 
2025-07-12 06:43:16.429126: Current learning rate: 0.00309 
2025-07-12 06:44:25.417544: train_loss -0.98 
2025-07-12 06:44:25.418815: val_loss -0.9441 
2025-07-12 06:44:25.419990: Pseudo dice [np.float32(0.9463)] 
2025-07-12 06:44:25.420991: Epoch time: 69.0 s 
2025-07-12 06:44:26.369037:  
2025-07-12 06:44:26.371094: Epoch 730 
2025-07-12 06:44:26.372245: Current learning rate: 0.00308 
2025-07-12 06:45:35.444599: train_loss -0.9797 
2025-07-12 06:45:35.445916: val_loss -0.9428 
2025-07-12 06:45:35.446950: Pseudo dice [np.float32(0.9447)] 
2025-07-12 06:45:35.447983: Epoch time: 69.08 s 
2025-07-12 06:45:36.398559:  
2025-07-12 06:45:36.400068: Epoch 731 
2025-07-12 06:45:36.401237: Current learning rate: 0.00307 
2025-07-12 06:46:45.579212: train_loss -0.9797 
2025-07-12 06:46:45.580325: val_loss -0.9424 
2025-07-12 06:46:45.581550: Pseudo dice [np.float32(0.9452)] 
2025-07-12 06:46:45.582682: Epoch time: 69.18 s 
2025-07-12 06:46:46.743600:  
2025-07-12 06:46:46.745357: Epoch 732 
2025-07-12 06:46:46.746693: Current learning rate: 0.00306 
2025-07-12 06:47:55.984076: train_loss -0.9799 
2025-07-12 06:47:55.985930: val_loss -0.9354 
2025-07-12 06:47:55.987097: Pseudo dice [np.float32(0.9386)] 
2025-07-12 06:47:55.988256: Epoch time: 69.24 s 
2025-07-12 06:47:56.929506:  
2025-07-12 06:47:56.931415: Epoch 733 
2025-07-12 06:47:56.932486: Current learning rate: 0.00305 
2025-07-12 06:49:06.360234: train_loss -0.9792 
2025-07-12 06:49:06.361903: val_loss -0.9413 
2025-07-12 06:49:06.362863: Pseudo dice [np.float32(0.9434)] 
2025-07-12 06:49:06.363910: Epoch time: 69.43 s 
2025-07-12 06:49:07.332289:  
2025-07-12 06:49:07.334387: Epoch 734 
2025-07-12 06:49:07.335824: Current learning rate: 0.00304 
2025-07-12 06:50:16.583765: train_loss -0.9796 
2025-07-12 06:50:16.585032: val_loss -0.9442 
2025-07-12 06:50:16.586103: Pseudo dice [np.float32(0.9445)] 
2025-07-12 06:50:16.587254: Epoch time: 69.26 s 
2025-07-12 06:50:17.521448:  
2025-07-12 06:50:17.523098: Epoch 735 
2025-07-12 06:50:17.524241: Current learning rate: 0.00303 
2025-07-12 06:51:26.963957: train_loss -0.9795 
2025-07-12 06:51:26.965181: val_loss -0.9429 
2025-07-12 06:51:26.966275: Pseudo dice [np.float32(0.9458)] 
2025-07-12 06:51:26.967432: Epoch time: 69.45 s 
2025-07-12 06:51:27.960869:  
2025-07-12 06:51:27.963060: Epoch 736 
2025-07-12 06:51:27.964114: Current learning rate: 0.00302 
2025-07-12 06:52:37.208430: train_loss -0.9803 
2025-07-12 06:52:37.209948: val_loss -0.9435 
2025-07-12 06:52:37.211250: Pseudo dice [np.float32(0.9458)] 
2025-07-12 06:52:37.212639: Epoch time: 69.25 s 
2025-07-12 06:52:38.137810:  
2025-07-12 06:52:38.139495: Epoch 737 
2025-07-12 06:52:38.140657: Current learning rate: 0.00301 
2025-07-12 06:53:47.467876: train_loss -0.9797 
2025-07-12 06:53:47.469095: val_loss -0.9357 
2025-07-12 06:53:47.470162: Pseudo dice [np.float32(0.939)] 
2025-07-12 06:53:47.471193: Epoch time: 69.33 s 
2025-07-12 06:53:48.410368:  
2025-07-12 06:53:48.412032: Epoch 738 
2025-07-12 06:53:48.413240: Current learning rate: 0.003 
2025-07-12 06:54:57.743737: train_loss -0.9799 
2025-07-12 06:54:57.745045: val_loss -0.9416 
2025-07-12 06:54:57.746193: Pseudo dice [np.float32(0.9443)] 
2025-07-12 06:54:57.747216: Epoch time: 69.34 s 
2025-07-12 06:54:58.902725:  
2025-07-12 06:54:58.904763: Epoch 739 
2025-07-12 06:54:58.905751: Current learning rate: 0.00299 
2025-07-12 06:56:08.309772: train_loss -0.9798 
2025-07-12 06:56:08.311306: val_loss -0.9405 
2025-07-12 06:56:08.312499: Pseudo dice [np.float32(0.9427)] 
2025-07-12 06:56:08.313486: Epoch time: 69.41 s 
2025-07-12 06:56:09.233439:  
2025-07-12 06:56:09.235366: Epoch 740 
2025-07-12 06:56:09.236502: Current learning rate: 0.00297 
2025-07-12 06:57:18.569745: train_loss -0.9802 
2025-07-12 06:57:18.571340: val_loss -0.9393 
2025-07-12 06:57:18.572945: Pseudo dice [np.float32(0.941)] 
2025-07-12 06:57:18.574334: Epoch time: 69.34 s 
2025-07-12 06:57:19.494953:  
2025-07-12 06:57:19.496689: Epoch 741 
2025-07-12 06:57:19.497871: Current learning rate: 0.00296 
2025-07-12 06:58:29.033634: train_loss -0.9795 
2025-07-12 06:58:29.035094: val_loss -0.9473 
2025-07-12 06:58:29.036101: Pseudo dice [np.float32(0.9507)] 
2025-07-12 06:58:29.037070: Epoch time: 69.54 s 
2025-07-12 06:58:29.989335:  
2025-07-12 06:58:29.991069: Epoch 742 
2025-07-12 06:58:29.992043: Current learning rate: 0.00295 
2025-07-12 06:59:39.569412: train_loss -0.9799 
2025-07-12 06:59:39.570765: val_loss -0.9432 
2025-07-12 06:59:39.571733: Pseudo dice [np.float32(0.945)] 
2025-07-12 06:59:39.572810: Epoch time: 69.58 s 
2025-07-12 06:59:40.507359:  
2025-07-12 06:59:40.509596: Epoch 743 
2025-07-12 06:59:40.511168: Current learning rate: 0.00294 
2025-07-12 07:00:49.835784: train_loss -0.9796 
2025-07-12 07:00:49.837323: val_loss -0.9368 
2025-07-12 07:00:49.838415: Pseudo dice [np.float32(0.9391)] 
2025-07-12 07:00:49.839434: Epoch time: 69.33 s 
2025-07-12 07:00:50.777909:  
2025-07-12 07:00:50.779689: Epoch 744 
2025-07-12 07:00:50.780757: Current learning rate: 0.00293 
2025-07-12 07:02:00.147363: train_loss -0.9801 
2025-07-12 07:02:00.148671: val_loss -0.9472 
2025-07-12 07:02:00.149768: Pseudo dice [np.float32(0.9497)] 
2025-07-12 07:02:00.150908: Epoch time: 69.37 s 
2025-07-12 07:02:01.083095:  
2025-07-12 07:02:01.084720: Epoch 745 
2025-07-12 07:02:01.085873: Current learning rate: 0.00292 
2025-07-12 07:03:10.470727: train_loss -0.98 
2025-07-12 07:03:10.472133: val_loss -0.9339 
2025-07-12 07:03:10.473197: Pseudo dice [np.float32(0.9356)] 
2025-07-12 07:03:10.474308: Epoch time: 69.39 s 
2025-07-12 07:03:11.623364:  
2025-07-12 07:03:11.625241: Epoch 746 
2025-07-12 07:03:11.626347: Current learning rate: 0.00291 
2025-07-12 07:04:20.924112: train_loss -0.9803 
2025-07-12 07:04:20.925398: val_loss -0.9416 
2025-07-12 07:04:20.926426: Pseudo dice [np.float32(0.9442)] 
2025-07-12 07:04:20.927419: Epoch time: 69.3 s 
2025-07-12 07:04:21.853709:  
2025-07-12 07:04:21.855478: Epoch 747 
2025-07-12 07:04:21.856611: Current learning rate: 0.0029 
2025-07-12 07:05:31.407030: train_loss -0.9807 
2025-07-12 07:05:31.408486: val_loss -0.9401 
2025-07-12 07:05:31.409689: Pseudo dice [np.float32(0.9416)] 
2025-07-12 07:05:31.410815: Epoch time: 69.56 s 
2025-07-12 07:05:32.351998:  
2025-07-12 07:05:32.353969: Epoch 748 
2025-07-12 07:05:32.355133: Current learning rate: 0.00289 
2025-07-12 07:06:41.622655: train_loss -0.9799 
2025-07-12 07:06:41.624023: val_loss -0.9491 
2025-07-12 07:06:41.625390: Pseudo dice [np.float32(0.9516)] 
2025-07-12 07:06:41.626671: Epoch time: 69.27 s 
2025-07-12 07:06:42.563574:  
2025-07-12 07:06:42.565317: Epoch 749 
2025-07-12 07:06:42.566615: Current learning rate: 0.00288 
2025-07-12 07:07:51.846571: train_loss -0.9799 
2025-07-12 07:07:51.847949: val_loss -0.9392 
2025-07-12 07:07:51.848991: Pseudo dice [np.float32(0.9415)] 
2025-07-12 07:07:51.850493: Epoch time: 69.29 s 
2025-07-12 07:07:54.316657:  
2025-07-12 07:07:54.318254: Epoch 750 
2025-07-12 07:07:54.319222: Current learning rate: 0.00287 
2025-07-12 07:09:03.920948: train_loss -0.9791 
2025-07-12 07:09:03.922446: val_loss -0.9407 
2025-07-12 07:09:03.923610: Pseudo dice [np.float32(0.9442)] 
2025-07-12 07:09:03.924647: Epoch time: 69.61 s 
2025-07-12 07:09:04.831181:  
2025-07-12 07:09:04.832989: Epoch 751 
2025-07-12 07:09:04.833998: Current learning rate: 0.00286 
2025-07-12 07:10:14.492750: train_loss -0.9793 
2025-07-12 07:10:14.494382: val_loss -0.9417 
2025-07-12 07:10:14.495646: Pseudo dice [np.float32(0.9449)] 
2025-07-12 07:10:14.496577: Epoch time: 69.67 s 
2025-07-12 07:10:15.433880:  
2025-07-12 07:10:15.435789: Epoch 752 
2025-07-12 07:10:15.436740: Current learning rate: 0.00285 
2025-07-12 07:11:24.797093: train_loss -0.9799 
2025-07-12 07:11:24.798499: val_loss -0.9424 
2025-07-12 07:11:24.799917: Pseudo dice [np.float32(0.9452)] 
2025-07-12 07:11:24.801042: Epoch time: 69.37 s 
2025-07-12 07:11:25.734521:  
2025-07-12 07:11:25.736529: Epoch 753 
2025-07-12 07:11:25.737720: Current learning rate: 0.00284 
2025-07-12 07:12:35.035788: train_loss -0.9792 
2025-07-12 07:12:35.037165: val_loss -0.9452 
2025-07-12 07:12:35.039152: Pseudo dice [np.float32(0.9487)] 
2025-07-12 07:12:35.040354: Epoch time: 69.3 s 
2025-07-12 07:12:35.977758:  
2025-07-12 07:12:35.979824: Epoch 754 
2025-07-12 07:12:35.981187: Current learning rate: 0.00283 
2025-07-12 07:13:45.156492: train_loss -0.9795 
2025-07-12 07:13:45.157691: val_loss -0.9453 
2025-07-12 07:13:45.158770: Pseudo dice [np.float32(0.9487)] 
2025-07-12 07:13:45.160160: Epoch time: 69.18 s 
2025-07-12 07:13:46.112125:  
2025-07-12 07:13:46.113996: Epoch 755 
2025-07-12 07:13:46.114947: Current learning rate: 0.00282 
2025-07-12 07:14:55.409300: train_loss -0.9802 
2025-07-12 07:14:55.410614: val_loss -0.9459 
2025-07-12 07:14:55.411519: Pseudo dice [np.float32(0.9486)] 
2025-07-12 07:14:55.412504: Epoch time: 69.3 s 
2025-07-12 07:14:56.338940:  
2025-07-12 07:14:56.341164: Epoch 756 
2025-07-12 07:14:56.342203: Current learning rate: 0.00281 
2025-07-12 07:16:05.776174: train_loss -0.98 
2025-07-12 07:16:05.777365: val_loss -0.9404 
2025-07-12 07:16:05.778599: Pseudo dice [np.float32(0.9433)] 
2025-07-12 07:16:05.780114: Epoch time: 69.44 s 
2025-07-12 07:16:06.710122:  
2025-07-12 07:16:06.712141: Epoch 757 
2025-07-12 07:16:06.713199: Current learning rate: 0.0028 
2025-07-12 07:17:16.020222: train_loss -0.9797 
2025-07-12 07:17:16.021691: val_loss -0.9379 
2025-07-12 07:17:16.023111: Pseudo dice [np.float32(0.9408)] 
2025-07-12 07:17:16.024411: Epoch time: 69.31 s 
2025-07-12 07:17:16.955438:  
2025-07-12 07:17:16.957400: Epoch 758 
2025-07-12 07:17:16.958452: Current learning rate: 0.00279 
2025-07-12 07:18:26.644395: train_loss -0.9801 
2025-07-12 07:18:26.645678: val_loss -0.9418 
2025-07-12 07:18:26.646597: Pseudo dice [np.float32(0.9439)] 
2025-07-12 07:18:26.647591: Epoch time: 69.69 s 
2025-07-12 07:18:27.584222:  
2025-07-12 07:18:27.585725: Epoch 759 
2025-07-12 07:18:27.586907: Current learning rate: 0.00278 
2025-07-12 07:19:36.925998: train_loss -0.9792 
2025-07-12 07:19:36.927174: val_loss -0.9447 
2025-07-12 07:19:36.928329: Pseudo dice [np.float32(0.9462)] 
2025-07-12 07:19:36.929596: Epoch time: 69.35 s 
2025-07-12 07:19:37.852923:  
2025-07-12 07:19:37.855032: Epoch 760 
2025-07-12 07:19:37.856142: Current learning rate: 0.00277 
2025-07-12 07:20:47.015766: train_loss -0.9802 
2025-07-12 07:20:47.016978: val_loss -0.9436 
2025-07-12 07:20:47.018453: Pseudo dice [np.float32(0.9459)] 
2025-07-12 07:20:47.019531: Epoch time: 69.17 s 
2025-07-12 07:20:48.052711:  
2025-07-12 07:20:48.054428: Epoch 761 
2025-07-12 07:20:48.055782: Current learning rate: 0.00276 
2025-07-12 07:21:57.359844: train_loss -0.98 
2025-07-12 07:21:57.361175: val_loss -0.9436 
2025-07-12 07:21:57.362185: Pseudo dice [np.float32(0.9469)] 
2025-07-12 07:21:57.363362: Epoch time: 69.31 s 
2025-07-12 07:21:58.288515:  
2025-07-12 07:21:58.290469: Epoch 762 
2025-07-12 07:21:58.291503: Current learning rate: 0.00275 
2025-07-12 07:23:07.567091: train_loss -0.9798 
2025-07-12 07:23:07.568213: val_loss -0.9414 
2025-07-12 07:23:07.569326: Pseudo dice [np.float32(0.9448)] 
2025-07-12 07:23:07.570451: Epoch time: 69.28 s 
2025-07-12 07:23:08.724231:  
2025-07-12 07:23:08.726108: Epoch 763 
2025-07-12 07:23:08.727298: Current learning rate: 0.00274 
2025-07-12 07:24:18.139667: train_loss -0.9811 
2025-07-12 07:24:18.140837: val_loss -0.9444 
2025-07-12 07:24:18.141850: Pseudo dice [np.float32(0.9461)] 
2025-07-12 07:24:18.142922: Epoch time: 69.42 s 
2025-07-12 07:24:19.088438:  
2025-07-12 07:24:19.090550: Epoch 764 
2025-07-12 07:24:19.091672: Current learning rate: 0.00273 
2025-07-12 07:25:30.643353: train_loss -0.9806 
2025-07-12 07:25:30.644543: val_loss -0.945 
2025-07-12 07:25:30.645841: Pseudo dice [np.float32(0.9468)] 
2025-07-12 07:25:30.646927: Epoch time: 71.56 s 
2025-07-12 07:25:31.601033:  
2025-07-12 07:25:31.602772: Epoch 765 
2025-07-12 07:25:31.603823: Current learning rate: 0.00272 
2025-07-12 07:26:43.256540: train_loss -0.9804 
2025-07-12 07:26:43.257835: val_loss -0.9412 
2025-07-12 07:26:43.258882: Pseudo dice [np.float32(0.9433)] 
2025-07-12 07:26:43.260146: Epoch time: 71.66 s 
2025-07-12 07:26:44.212993:  
2025-07-12 07:26:44.215242: Epoch 766 
2025-07-12 07:26:44.216477: Current learning rate: 0.00271 
2025-07-12 07:27:53.145303: train_loss -0.98 
2025-07-12 07:27:53.146448: val_loss -0.9433 
2025-07-12 07:27:53.147923: Pseudo dice [np.float32(0.9458)] 
2025-07-12 07:27:53.149048: Epoch time: 68.94 s 
2025-07-12 07:27:54.103419:  
2025-07-12 07:27:54.105378: Epoch 767 
2025-07-12 07:27:54.106524: Current learning rate: 0.0027 
2025-07-12 07:29:02.513991: train_loss -0.9806 
2025-07-12 07:29:02.515303: val_loss -0.9454 
2025-07-12 07:29:02.516461: Pseudo dice [np.float32(0.9484)] 
2025-07-12 07:29:02.517577: Epoch time: 68.41 s 
2025-07-12 07:29:03.464988:  
2025-07-12 07:29:03.466935: Epoch 768 
2025-07-12 07:29:03.468245: Current learning rate: 0.00268 
2025-07-12 07:30:11.805159: train_loss -0.9801 
2025-07-12 07:30:11.806544: val_loss -0.9458 
2025-07-12 07:30:11.807558: Pseudo dice [np.float32(0.9491)] 
2025-07-12 07:30:11.808625: Epoch time: 68.34 s 
2025-07-12 07:30:12.743701:  
2025-07-12 07:30:12.745609: Epoch 769 
2025-07-12 07:30:12.746708: Current learning rate: 0.00267 
2025-07-12 07:31:21.269166: train_loss -0.9799 
2025-07-12 07:31:21.270896: val_loss -0.941 
2025-07-12 07:31:21.272317: Pseudo dice [np.float32(0.9431)] 
2025-07-12 07:31:21.273639: Epoch time: 68.53 s 
2025-07-12 07:31:22.445216:  
2025-07-12 07:31:22.447119: Epoch 770 
2025-07-12 07:31:22.448550: Current learning rate: 0.00266 
2025-07-12 07:32:31.042717: train_loss -0.9796 
2025-07-12 07:32:31.043944: val_loss -0.9421 
2025-07-12 07:32:31.045069: Pseudo dice [np.float32(0.9452)] 
2025-07-12 07:32:31.046214: Epoch time: 68.6 s 
2025-07-12 07:32:31.990528:  
2025-07-12 07:32:31.992296: Epoch 771 
2025-07-12 07:32:31.993372: Current learning rate: 0.00265 
2025-07-12 07:33:40.773038: train_loss -0.9805 
2025-07-12 07:33:40.774215: val_loss -0.945 
2025-07-12 07:33:40.775228: Pseudo dice [np.float32(0.9475)] 
2025-07-12 07:33:40.776239: Epoch time: 68.79 s 
2025-07-12 07:33:41.709356:  
2025-07-12 07:33:41.711144: Epoch 772 
2025-07-12 07:33:41.712343: Current learning rate: 0.00264 
2025-07-12 07:34:50.786561: train_loss -0.98 
2025-07-12 07:34:50.787864: val_loss -0.9455 
2025-07-12 07:34:50.788856: Pseudo dice [np.float32(0.9478)] 
2025-07-12 07:34:50.790219: Epoch time: 69.08 s 
2025-07-12 07:34:51.710474:  
2025-07-12 07:34:51.712121: Epoch 773 
2025-07-12 07:34:51.713070: Current learning rate: 0.00263 
2025-07-12 07:36:01.123907: train_loss -0.9808 
2025-07-12 07:36:01.125369: val_loss -0.9411 
2025-07-12 07:36:01.126228: Pseudo dice [np.float32(0.9454)] 
2025-07-12 07:36:01.127170: Epoch time: 69.42 s 
2025-07-12 07:36:02.075325:  
2025-07-12 07:36:02.077179: Epoch 774 
2025-07-12 07:36:02.078236: Current learning rate: 0.00262 
2025-07-12 07:37:11.370252: train_loss -0.9807 
2025-07-12 07:37:11.371602: val_loss -0.9466 
2025-07-12 07:37:11.372947: Pseudo dice [np.float32(0.9506)] 
2025-07-12 07:37:11.374200: Epoch time: 69.3 s 
2025-07-12 07:37:12.318974:  
2025-07-12 07:37:12.321032: Epoch 775 
2025-07-12 07:37:12.322186: Current learning rate: 0.00261 
2025-07-12 07:38:21.629800: train_loss -0.9804 
2025-07-12 07:38:21.631098: val_loss -0.9394 
2025-07-12 07:38:21.632066: Pseudo dice [np.float32(0.9423)] 
2025-07-12 07:38:21.633412: Epoch time: 69.31 s 
2025-07-12 07:38:22.572748:  
2025-07-12 07:38:22.574883: Epoch 776 
2025-07-12 07:38:22.576076: Current learning rate: 0.0026 
2025-07-12 07:39:31.593522: train_loss -0.9813 
2025-07-12 07:39:31.594639: val_loss -0.9432 
2025-07-12 07:39:31.595665: Pseudo dice [np.float32(0.9455)] 
2025-07-12 07:39:31.596733: Epoch time: 69.02 s 
2025-07-12 07:39:32.793806:  
2025-07-12 07:39:32.795714: Epoch 777 
2025-07-12 07:39:32.797004: Current learning rate: 0.00259 
2025-07-12 07:40:41.829111: train_loss -0.981 
2025-07-12 07:40:41.830317: val_loss -0.9453 
2025-07-12 07:40:41.831372: Pseudo dice [np.float32(0.9474)] 
2025-07-12 07:40:41.832383: Epoch time: 69.04 s 
2025-07-12 07:40:42.764794:  
2025-07-12 07:40:42.766760: Epoch 778 
2025-07-12 07:40:42.768164: Current learning rate: 0.00258 
2025-07-12 07:41:51.926627: train_loss -0.9804 
2025-07-12 07:41:51.927792: val_loss -0.944 
2025-07-12 07:41:51.929043: Pseudo dice [np.float32(0.9465)] 
2025-07-12 07:41:51.930082: Epoch time: 69.17 s 
2025-07-12 07:41:52.892651:  
2025-07-12 07:41:52.894392: Epoch 779 
2025-07-12 07:41:52.895478: Current learning rate: 0.00257 
2025-07-12 07:43:02.132296: train_loss -0.9808 
2025-07-12 07:43:02.133564: val_loss -0.9425 
2025-07-12 07:43:02.134547: Pseudo dice [np.float32(0.9457)] 
2025-07-12 07:43:02.135599: Epoch time: 69.24 s 
2025-07-12 07:43:03.085039:  
2025-07-12 07:43:03.087138: Epoch 780 
2025-07-12 07:43:03.088691: Current learning rate: 0.00256 
2025-07-12 07:44:12.258164: train_loss -0.9802 
2025-07-12 07:44:12.259357: val_loss -0.942 
2025-07-12 07:44:12.260379: Pseudo dice [np.float32(0.9451)] 
2025-07-12 07:44:12.261454: Epoch time: 69.18 s 
2025-07-12 07:44:13.213485:  
2025-07-12 07:44:13.215337: Epoch 781 
2025-07-12 07:44:13.216325: Current learning rate: 0.00255 
2025-07-12 07:45:22.355642: train_loss -0.9807 
2025-07-12 07:45:22.358262: val_loss -0.948 
2025-07-12 07:45:22.359207: Pseudo dice [np.float32(0.9499)] 
2025-07-12 07:45:22.360298: Epoch time: 69.15 s 
2025-07-12 07:45:23.290054:  
2025-07-12 07:45:23.291869: Epoch 782 
2025-07-12 07:45:23.293042: Current learning rate: 0.00254 
2025-07-12 07:46:32.496733: train_loss -0.981 
2025-07-12 07:46:32.498110: val_loss -0.947 
2025-07-12 07:46:32.499122: Pseudo dice [np.float32(0.9496)] 
2025-07-12 07:46:32.500306: Epoch time: 69.21 s 
2025-07-12 07:46:33.449412:  
2025-07-12 07:46:33.451198: Epoch 783 
2025-07-12 07:46:33.452277: Current learning rate: 0.00253 
2025-07-12 07:47:43.138249: train_loss -0.9807 
2025-07-12 07:47:43.139581: val_loss -0.9404 
2025-07-12 07:47:43.140636: Pseudo dice [np.float32(0.9439)] 
2025-07-12 07:47:43.141794: Epoch time: 69.69 s 
2025-07-12 07:47:44.305943:  
2025-07-12 07:47:44.307879: Epoch 784 
2025-07-12 07:47:44.309008: Current learning rate: 0.00252 
2025-07-12 07:48:53.169990: train_loss -0.9811 
2025-07-12 07:48:53.171175: val_loss -0.9432 
2025-07-12 07:48:53.172248: Pseudo dice [np.float32(0.9451)] 
2025-07-12 07:48:53.173252: Epoch time: 68.87 s 
2025-07-12 07:48:54.127377:  
2025-07-12 07:48:54.129195: Epoch 785 
2025-07-12 07:48:54.130339: Current learning rate: 0.00251 
2025-07-12 07:50:03.137910: train_loss -0.9807 
2025-07-12 07:50:03.139146: val_loss -0.9404 
2025-07-12 07:50:03.140320: Pseudo dice [np.float32(0.9434)] 
2025-07-12 07:50:03.141372: Epoch time: 69.01 s 
2025-07-12 07:50:04.075263:  
2025-07-12 07:50:04.077070: Epoch 786 
2025-07-12 07:50:04.078094: Current learning rate: 0.0025 
2025-07-12 07:51:13.241111: train_loss -0.9804 
2025-07-12 07:51:13.242413: val_loss -0.9444 
2025-07-12 07:51:13.243634: Pseudo dice [np.float32(0.9476)] 
2025-07-12 07:51:13.244687: Epoch time: 69.17 s 
2025-07-12 07:51:14.189307:  
2025-07-12 07:51:14.191110: Epoch 787 
2025-07-12 07:51:14.192323: Current learning rate: 0.00249 
2025-07-12 07:52:23.468328: train_loss -0.9805 
2025-07-12 07:52:23.469541: val_loss -0.9415 
2025-07-12 07:52:23.470683: Pseudo dice [np.float32(0.9454)] 
2025-07-12 07:52:23.472131: Epoch time: 69.28 s 
2025-07-12 07:52:24.374354:  
2025-07-12 07:52:24.376562: Epoch 788 
2025-07-12 07:52:24.377554: Current learning rate: 0.00248 
2025-07-12 07:53:33.516321: train_loss -0.9797 
2025-07-12 07:53:33.517663: val_loss -0.9398 
2025-07-12 07:53:33.518576: Pseudo dice [np.float32(0.9432)] 
2025-07-12 07:53:33.520153: Epoch time: 69.15 s 
2025-07-12 07:53:34.428259:  
2025-07-12 07:53:34.429776: Epoch 789 
2025-07-12 07:53:34.431058: Current learning rate: 0.00247 
2025-07-12 07:54:43.698353: train_loss -0.9803 
2025-07-12 07:54:43.699647: val_loss -0.9424 
2025-07-12 07:54:43.700643: Pseudo dice [np.float32(0.9446)] 
2025-07-12 07:54:43.701632: Epoch time: 69.27 s 
2025-07-12 07:54:44.655882:  
2025-07-12 07:54:44.657950: Epoch 790 
2025-07-12 07:54:44.658987: Current learning rate: 0.00245 
2025-07-12 07:55:55.923056: train_loss -0.9811 
2025-07-12 07:55:55.924243: val_loss -0.943 
2025-07-12 07:55:55.925224: Pseudo dice [np.float32(0.9442)] 
2025-07-12 07:55:55.926964: Epoch time: 71.27 s 
2025-07-12 07:55:56.875705:  
2025-07-12 07:55:56.877600: Epoch 791 
2025-07-12 07:55:56.879121: Current learning rate: 0.00244 
2025-07-12 07:57:08.534670: train_loss -0.9811 
2025-07-12 07:57:08.536333: val_loss -0.9406 
2025-07-12 07:57:08.537264: Pseudo dice [np.float32(0.9433)] 
2025-07-12 07:57:08.538202: Epoch time: 71.66 s 
2025-07-12 07:57:09.501326:  
2025-07-12 07:57:09.502898: Epoch 792 
2025-07-12 07:57:09.503974: Current learning rate: 0.00243 
2025-07-12 07:58:18.477451: train_loss -0.9805 
2025-07-12 07:58:18.478553: val_loss -0.9402 
2025-07-12 07:58:18.480183: Pseudo dice [np.float32(0.9423)] 
2025-07-12 07:58:18.481601: Epoch time: 68.98 s 
2025-07-12 07:58:19.397906:  
2025-07-12 07:58:19.399606: Epoch 793 
2025-07-12 07:58:19.400595: Current learning rate: 0.00242 
2025-07-12 07:59:28.499588: train_loss -0.9812 
2025-07-12 07:59:28.501231: val_loss -0.9409 
2025-07-12 07:59:28.502450: Pseudo dice [np.float32(0.943)] 
2025-07-12 07:59:28.503374: Epoch time: 69.11 s 
2025-07-12 07:59:29.462723:  
2025-07-12 07:59:29.464867: Epoch 794 
2025-07-12 07:59:29.465942: Current learning rate: 0.00241 
2025-07-12 08:00:38.584620: train_loss -0.981 
2025-07-12 08:00:38.586093: val_loss -0.9323 
2025-07-12 08:00:38.587263: Pseudo dice [np.float32(0.9351)] 
2025-07-12 08:00:38.588519: Epoch time: 69.13 s 
2025-07-12 08:00:39.529292:  
2025-07-12 08:00:39.531310: Epoch 795 
2025-07-12 08:00:39.532372: Current learning rate: 0.0024 
2025-07-12 08:01:48.703089: train_loss -0.9815 
2025-07-12 08:01:48.704730: val_loss -0.9433 
2025-07-12 08:01:48.706082: Pseudo dice [np.float32(0.9455)] 
2025-07-12 08:01:48.707001: Epoch time: 69.18 s 
2025-07-12 08:01:49.649490:  
2025-07-12 08:01:49.651341: Epoch 796 
2025-07-12 08:01:49.652577: Current learning rate: 0.00239 
2025-07-12 08:02:58.860509: train_loss -0.9808 
2025-07-12 08:02:58.862103: val_loss -0.9454 
2025-07-12 08:02:58.863169: Pseudo dice [np.float32(0.9484)] 
2025-07-12 08:02:58.864141: Epoch time: 69.21 s 
2025-07-12 08:02:59.813371:  
2025-07-12 08:02:59.815721: Epoch 797 
2025-07-12 08:02:59.816989: Current learning rate: 0.00238 
2025-07-12 08:04:09.120654: train_loss -0.9809 
2025-07-12 08:04:09.121886: val_loss -0.9416 
2025-07-12 08:04:09.122895: Pseudo dice [np.float32(0.9444)] 
2025-07-12 08:04:09.124899: Epoch time: 69.31 s 
2025-07-12 08:04:10.068031:  
2025-07-12 08:04:10.069739: Epoch 798 
2025-07-12 08:04:10.070728: Current learning rate: 0.00237 
2025-07-12 08:05:19.241771: train_loss -0.9807 
2025-07-12 08:05:19.242922: val_loss -0.9407 
2025-07-12 08:05:19.244147: Pseudo dice [np.float32(0.9436)] 
2025-07-12 08:05:19.245480: Epoch time: 69.18 s 
2025-07-12 08:05:20.192813:  
2025-07-12 08:05:20.194851: Epoch 799 
2025-07-12 08:05:20.196067: Current learning rate: 0.00236 
2025-07-12 08:06:32.388384: train_loss -0.9817 
2025-07-12 08:06:32.389555: val_loss -0.9425 
2025-07-12 08:06:32.390510: Pseudo dice [np.float32(0.945)] 
2025-07-12 08:06:32.391680: Epoch time: 72.2 s 
2025-07-12 08:06:34.649063:  
2025-07-12 08:06:34.650591: Epoch 800 
2025-07-12 08:06:34.651785: Current learning rate: 0.00235 
2025-07-12 08:07:46.263834: train_loss -0.9812 
2025-07-12 08:07:46.265085: val_loss -0.9443 
2025-07-12 08:07:46.266063: Pseudo dice [np.float32(0.9476)] 
2025-07-12 08:07:46.267173: Epoch time: 71.62 s 
2025-07-12 08:07:47.453693:  
2025-07-12 08:07:47.455338: Epoch 801 
2025-07-12 08:07:47.456817: Current learning rate: 0.00234 
2025-07-12 08:08:56.001795: train_loss -0.981 
2025-07-12 08:08:56.003280: val_loss -0.9452 
2025-07-12 08:08:56.004634: Pseudo dice [np.float32(0.9477)] 
2025-07-12 08:08:56.005749: Epoch time: 68.55 s 
2025-07-12 08:08:56.950421:  
2025-07-12 08:08:56.952270: Epoch 802 
2025-07-12 08:08:56.953692: Current learning rate: 0.00233 
2025-07-12 08:10:05.618367: train_loss -0.9812 
2025-07-12 08:10:05.619668: val_loss -0.9382 
2025-07-12 08:10:05.620576: Pseudo dice [np.float32(0.9404)] 
2025-07-12 08:10:05.622015: Epoch time: 68.67 s 
2025-07-12 08:10:06.635395:  
2025-07-12 08:10:06.637286: Epoch 803 
2025-07-12 08:10:06.638339: Current learning rate: 0.00232 
2025-07-12 08:11:15.620236: train_loss -0.9813 
2025-07-12 08:11:15.621595: val_loss -0.9351 
2025-07-12 08:11:15.622565: Pseudo dice [np.float32(0.9377)] 
2025-07-12 08:11:15.623756: Epoch time: 68.99 s 
2025-07-12 08:11:16.537162:  
2025-07-12 08:11:16.539142: Epoch 804 
2025-07-12 08:11:16.540307: Current learning rate: 0.00231 
2025-07-12 08:12:25.983031: train_loss -0.9819 
2025-07-12 08:12:25.984241: val_loss -0.9471 
2025-07-12 08:12:25.985221: Pseudo dice [np.float32(0.9502)] 
2025-07-12 08:12:25.986199: Epoch time: 69.45 s 
2025-07-12 08:12:26.938093:  
2025-07-12 08:12:26.939727: Epoch 805 
2025-07-12 08:12:26.940806: Current learning rate: 0.0023 
2025-07-12 08:13:36.230136: train_loss -0.9812 
2025-07-12 08:13:36.231387: val_loss -0.9423 
2025-07-12 08:13:36.232882: Pseudo dice [np.float32(0.946)] 
2025-07-12 08:13:36.234346: Epoch time: 69.3 s 
2025-07-12 08:13:37.144367:  
2025-07-12 08:13:37.146320: Epoch 806 
2025-07-12 08:13:37.147301: Current learning rate: 0.00229 
2025-07-12 08:14:46.418939: train_loss -0.9817 
2025-07-12 08:14:46.420617: val_loss -0.95 
2025-07-12 08:14:46.422570: Pseudo dice [np.float32(0.9529)] 
2025-07-12 08:14:46.423713: Epoch time: 69.28 s 
2025-07-12 08:14:47.366988:  
2025-07-12 08:14:47.368611: Epoch 807 
2025-07-12 08:14:47.369955: Current learning rate: 0.00228 
2025-07-12 08:15:56.676795: train_loss -0.9815 
2025-07-12 08:15:56.678088: val_loss -0.9378 
2025-07-12 08:15:56.679146: Pseudo dice [np.float32(0.9401)] 
2025-07-12 08:15:56.680098: Epoch time: 69.31 s 
2025-07-12 08:15:57.633428:  
2025-07-12 08:15:57.634955: Epoch 808 
2025-07-12 08:15:57.635959: Current learning rate: 0.00226 
2025-07-12 08:17:06.958509: train_loss -0.9812 
2025-07-12 08:17:06.959720: val_loss -0.9414 
2025-07-12 08:17:06.960945: Pseudo dice [np.float32(0.9435)] 
2025-07-12 08:17:06.962095: Epoch time: 69.33 s 
2025-07-12 08:17:07.895429:  
2025-07-12 08:17:07.897463: Epoch 809 
2025-07-12 08:17:07.898582: Current learning rate: 0.00225 
2025-07-12 08:18:17.037415: train_loss -0.981 
2025-07-12 08:18:17.038693: val_loss -0.9368 
2025-07-12 08:18:17.039622: Pseudo dice [np.float32(0.9401)] 
2025-07-12 08:18:17.040656: Epoch time: 69.15 s 
2025-07-12 08:18:17.991187:  
2025-07-12 08:18:17.992756: Epoch 810 
2025-07-12 08:18:17.993843: Current learning rate: 0.00224 
2025-07-12 08:19:27.194949: train_loss -0.9817 
2025-07-12 08:19:27.196418: val_loss -0.9428 
2025-07-12 08:19:27.197496: Pseudo dice [np.float32(0.9461)] 
2025-07-12 08:19:27.198639: Epoch time: 69.21 s 
2025-07-12 08:19:28.374482:  
2025-07-12 08:19:28.376480: Epoch 811 
2025-07-12 08:19:28.377592: Current learning rate: 0.00223 
2025-07-12 08:20:37.654724: train_loss -0.9813 
2025-07-12 08:20:37.656155: val_loss -0.9409 
2025-07-12 08:20:37.657184: Pseudo dice [np.float32(0.9425)] 
2025-07-12 08:20:37.658397: Epoch time: 69.28 s 
2025-07-12 08:20:38.603915:  
2025-07-12 08:20:38.605948: Epoch 812 
2025-07-12 08:20:38.607091: Current learning rate: 0.00222 
2025-07-12 08:21:47.661980: train_loss -0.9801 
2025-07-12 08:21:47.663234: val_loss -0.9459 
2025-07-12 08:21:47.664251: Pseudo dice [np.float32(0.9488)] 
2025-07-12 08:21:47.665202: Epoch time: 69.06 s 
2025-07-12 08:21:48.616955:  
2025-07-12 08:21:48.618964: Epoch 813 
2025-07-12 08:21:48.620122: Current learning rate: 0.00221 
2025-07-12 08:22:57.785451: train_loss -0.9806 
2025-07-12 08:22:57.786671: val_loss -0.9423 
2025-07-12 08:22:57.787886: Pseudo dice [np.float32(0.9453)] 
2025-07-12 08:22:57.788999: Epoch time: 69.17 s 
2025-07-12 08:22:58.741099:  
2025-07-12 08:22:58.743225: Epoch 814 
2025-07-12 08:22:58.744578: Current learning rate: 0.0022 
2025-07-12 08:24:07.923324: train_loss -0.9813 
2025-07-12 08:24:07.924728: val_loss -0.9409 
2025-07-12 08:24:07.926105: Pseudo dice [np.float32(0.9443)] 
2025-07-12 08:24:07.927090: Epoch time: 69.19 s 
2025-07-12 08:24:08.851831:  
2025-07-12 08:24:08.853405: Epoch 815 
2025-07-12 08:24:08.854630: Current learning rate: 0.00219 
2025-07-12 08:25:18.152277: train_loss -0.9811 
2025-07-12 08:25:18.153512: val_loss -0.9369 
2025-07-12 08:25:18.154767: Pseudo dice [np.float32(0.939)] 
2025-07-12 08:25:18.155710: Epoch time: 69.3 s 
2025-07-12 08:25:19.109059:  
2025-07-12 08:25:19.110844: Epoch 816 
2025-07-12 08:25:19.111818: Current learning rate: 0.00218 
2025-07-12 08:26:28.553593: train_loss -0.9804 
2025-07-12 08:26:28.554754: val_loss -0.9347 
2025-07-12 08:26:28.555683: Pseudo dice [np.float32(0.9365)] 
2025-07-12 08:26:28.556995: Epoch time: 69.45 s 
2025-07-12 08:26:29.516026:  
2025-07-12 08:26:29.517693: Epoch 817 
2025-07-12 08:26:29.518663: Current learning rate: 0.00217 
2025-07-12 08:27:38.549198: train_loss -0.9802 
2025-07-12 08:27:38.550398: val_loss -0.9443 
2025-07-12 08:27:38.551476: Pseudo dice [np.float32(0.9474)] 
2025-07-12 08:27:38.552598: Epoch time: 69.04 s 
2025-07-12 08:27:39.737895:  
2025-07-12 08:27:39.739657: Epoch 818 
2025-07-12 08:27:39.740680: Current learning rate: 0.00216 
2025-07-12 08:28:48.770358: train_loss -0.981 
2025-07-12 08:28:48.771605: val_loss -0.9445 
2025-07-12 08:28:48.772707: Pseudo dice [np.float32(0.947)] 
2025-07-12 08:28:48.773854: Epoch time: 69.04 s 
2025-07-12 08:28:49.732556:  
2025-07-12 08:28:49.734511: Epoch 819 
2025-07-12 08:28:49.735642: Current learning rate: 0.00215 
2025-07-12 08:29:58.713333: train_loss -0.9818 
2025-07-12 08:29:58.714624: val_loss -0.9496 
2025-07-12 08:29:58.715660: Pseudo dice [np.float32(0.9525)] 
2025-07-12 08:29:58.716805: Epoch time: 68.98 s 
2025-07-12 08:29:59.644036:  
2025-07-12 08:29:59.646029: Epoch 820 
2025-07-12 08:29:59.647275: Current learning rate: 0.00214 
2025-07-12 08:31:08.742408: train_loss -0.9815 
2025-07-12 08:31:08.743852: val_loss -0.9473 
2025-07-12 08:31:08.744916: Pseudo dice [np.float32(0.9493)] 
2025-07-12 08:31:08.745967: Epoch time: 69.1 s 
2025-07-12 08:31:09.651649:  
2025-07-12 08:31:09.653486: Epoch 821 
2025-07-12 08:31:09.654676: Current learning rate: 0.00213 
2025-07-12 08:32:19.081102: train_loss -0.9809 
2025-07-12 08:32:19.082571: val_loss -0.9409 
2025-07-12 08:32:19.083961: Pseudo dice [np.float32(0.9441)] 
2025-07-12 08:32:19.085167: Epoch time: 69.43 s 
2025-07-12 08:32:19.983086:  
2025-07-12 08:32:19.985086: Epoch 822 
2025-07-12 08:32:19.986294: Current learning rate: 0.00212 
2025-07-12 08:33:29.218831: train_loss -0.9814 
2025-07-12 08:33:29.220188: val_loss -0.9461 
2025-07-12 08:33:29.221163: Pseudo dice [np.float32(0.9485)] 
2025-07-12 08:33:29.222379: Epoch time: 69.24 s 
2025-07-12 08:33:30.133208:  
2025-07-12 08:33:30.135208: Epoch 823 
2025-07-12 08:33:30.136280: Current learning rate: 0.0021 
2025-07-12 08:34:39.252999: train_loss -0.9819 
2025-07-12 08:34:39.254194: val_loss -0.9353 
2025-07-12 08:34:39.255171: Pseudo dice [np.float32(0.9381)] 
2025-07-12 08:34:39.256257: Epoch time: 69.12 s 
2025-07-12 08:34:40.172710:  
2025-07-12 08:34:40.174745: Epoch 824 
2025-07-12 08:34:40.175898: Current learning rate: 0.00209 
2025-07-12 08:35:49.340583: train_loss -0.9815 
2025-07-12 08:35:49.341832: val_loss -0.9408 
2025-07-12 08:35:49.342808: Pseudo dice [np.float32(0.9434)] 
2025-07-12 08:35:49.343943: Epoch time: 69.17 s 
2025-07-12 08:35:50.477210:  
2025-07-12 08:35:50.479029: Epoch 825 
2025-07-12 08:35:50.480076: Current learning rate: 0.00208 
2025-07-12 08:37:00.120257: train_loss -0.9813 
2025-07-12 08:37:00.122536: val_loss -0.9457 
2025-07-12 08:37:00.123909: Pseudo dice [np.float32(0.9486)] 
2025-07-12 08:37:00.125036: Epoch time: 69.65 s 
2025-07-12 08:37:01.048483:  
2025-07-12 08:37:01.049518: Epoch 826 
2025-07-12 08:37:01.050460: Current learning rate: 0.00207 
2025-07-12 08:38:10.583128: train_loss -0.9814 
2025-07-12 08:38:10.584437: val_loss -0.9459 
2025-07-12 08:38:10.585372: Pseudo dice [np.float32(0.9488)] 
2025-07-12 08:38:10.586434: Epoch time: 69.54 s 
2025-07-12 08:38:11.498080:  
2025-07-12 08:38:11.499916: Epoch 827 
2025-07-12 08:38:11.501124: Current learning rate: 0.00206 
2025-07-12 08:39:20.251836: train_loss -0.9814 
2025-07-12 08:39:20.253375: val_loss -0.945 
2025-07-12 08:39:20.255072: Pseudo dice [np.float32(0.9481)] 
2025-07-12 08:39:20.256048: Epoch time: 68.76 s 
2025-07-12 08:39:21.159217:  
2025-07-12 08:39:21.161226: Epoch 828 
2025-07-12 08:39:21.162397: Current learning rate: 0.00205 
2025-07-12 08:40:30.321807: train_loss -0.9821 
2025-07-12 08:40:30.323112: val_loss -0.9448 
2025-07-12 08:40:30.324126: Pseudo dice [np.float32(0.9477)] 
2025-07-12 08:40:30.325135: Epoch time: 69.17 s 
2025-07-12 08:40:31.224752:  
2025-07-12 08:40:31.226602: Epoch 829 
2025-07-12 08:40:31.227758: Current learning rate: 0.00204 
2025-07-12 08:41:40.575357: train_loss -0.9813 
2025-07-12 08:41:40.576565: val_loss -0.949 
2025-07-12 08:41:40.577605: Pseudo dice [np.float32(0.9516)] 
2025-07-12 08:41:40.578809: Epoch time: 69.35 s 
2025-07-12 08:41:41.491426:  
2025-07-12 08:41:41.493347: Epoch 830 
2025-07-12 08:41:41.494648: Current learning rate: 0.00203 
2025-07-12 08:42:51.178466: train_loss -0.9817 
2025-07-12 08:42:51.179738: val_loss -0.9411 
2025-07-12 08:42:51.180614: Pseudo dice [np.float32(0.9439)] 
2025-07-12 08:42:51.181670: Epoch time: 69.69 s 
2025-07-12 08:42:52.104756:  
2025-07-12 08:42:52.106502: Epoch 831 
2025-07-12 08:42:52.107568: Current learning rate: 0.00202 
2025-07-12 08:44:01.078141: train_loss -0.9821 
2025-07-12 08:44:01.079551: val_loss -0.9413 
2025-07-12 08:44:01.080606: Pseudo dice [np.float32(0.9442)] 
2025-07-12 08:44:01.081621: Epoch time: 68.98 s 
2025-07-12 08:44:02.006810:  
2025-07-12 08:44:02.008426: Epoch 832 
2025-07-12 08:44:02.009469: Current learning rate: 0.00201 
2025-07-12 08:45:11.301208: train_loss -0.9819 
2025-07-12 08:45:11.302703: val_loss -0.9426 
2025-07-12 08:45:11.304078: Pseudo dice [np.float32(0.9458)] 
2025-07-12 08:45:11.305250: Epoch time: 69.3 s 
2025-07-12 08:45:12.237161:  
2025-07-12 08:45:12.239234: Epoch 833 
2025-07-12 08:45:12.240822: Current learning rate: 0.002 
2025-07-12 08:46:21.383957: train_loss -0.9818 
2025-07-12 08:46:21.385334: val_loss -0.9459 
2025-07-12 08:46:21.386268: Pseudo dice [np.float32(0.9488)] 
2025-07-12 08:46:21.387390: Epoch time: 69.15 s 
2025-07-12 08:46:22.314027:  
2025-07-12 08:46:22.316244: Epoch 834 
2025-07-12 08:46:22.317351: Current learning rate: 0.00199 
2025-07-12 08:47:31.622447: train_loss -0.9819 
2025-07-12 08:47:31.623676: val_loss -0.946 
2025-07-12 08:47:31.624940: Pseudo dice [np.float32(0.9492)] 
2025-07-12 08:47:31.626559: Epoch time: 69.31 s 
2025-07-12 08:47:32.527416:  
2025-07-12 08:47:32.529293: Epoch 835 
2025-07-12 08:47:32.530434: Current learning rate: 0.00198 
2025-07-12 08:48:41.928069: train_loss -0.9816 
2025-07-12 08:48:41.929388: val_loss -0.9443 
2025-07-12 08:48:41.930522: Pseudo dice [np.float32(0.9464)] 
2025-07-12 08:48:41.931631: Epoch time: 69.4 s 
2025-07-12 08:48:42.817281:  
2025-07-12 08:48:42.819021: Epoch 836 
2025-07-12 08:48:42.820130: Current learning rate: 0.00196 
2025-07-12 08:49:52.091421: train_loss -0.9821 
2025-07-12 08:49:52.092847: val_loss -0.947 
2025-07-12 08:49:52.093770: Pseudo dice [np.float32(0.9499)] 
2025-07-12 08:49:52.094815: Epoch time: 69.28 s 
2025-07-12 08:49:53.024285:  
2025-07-12 08:49:53.026411: Epoch 837 
2025-07-12 08:49:53.027596: Current learning rate: 0.00195 
2025-07-12 08:51:02.241692: train_loss -0.9822 
2025-07-12 08:51:02.243808: val_loss -0.9445 
2025-07-12 08:51:02.244999: Pseudo dice [np.float32(0.9465)] 
2025-07-12 08:51:02.246142: Epoch time: 69.22 s 
2025-07-12 08:51:03.165624:  
2025-07-12 08:51:03.167540: Epoch 838 
2025-07-12 08:51:03.168772: Current learning rate: 0.00194 
2025-07-12 08:52:12.488362: train_loss -0.982 
2025-07-12 08:52:12.489586: val_loss -0.9446 
2025-07-12 08:52:12.490633: Pseudo dice [np.float32(0.9486)] 
2025-07-12 08:52:12.491833: Epoch time: 69.33 s 
2025-07-12 08:52:13.401134:  
2025-07-12 08:52:13.402907: Epoch 839 
2025-07-12 08:52:13.404041: Current learning rate: 0.00193 
2025-07-12 08:53:22.982996: train_loss -0.9818 
2025-07-12 08:53:22.984371: val_loss -0.9447 
2025-07-12 08:53:22.985404: Pseudo dice [np.float32(0.9468)] 
2025-07-12 08:53:22.986513: Epoch time: 69.59 s 
2025-07-12 08:53:23.894368:  
2025-07-12 08:53:23.896569: Epoch 840 
2025-07-12 08:53:23.897651: Current learning rate: 0.00192 
2025-07-12 08:54:33.073021: train_loss -0.9822 
2025-07-12 08:54:33.074466: val_loss -0.9447 
2025-07-12 08:54:33.075460: Pseudo dice [np.float32(0.9475)] 
2025-07-12 08:54:33.076572: Epoch time: 69.18 s 
2025-07-12 08:54:33.985974:  
2025-07-12 08:54:33.987944: Epoch 841 
2025-07-12 08:54:33.989178: Current learning rate: 0.00191 
2025-07-12 08:55:43.127837: train_loss -0.9826 
2025-07-12 08:55:43.129086: val_loss -0.9444 
2025-07-12 08:55:43.130188: Pseudo dice [np.float32(0.9476)] 
2025-07-12 08:55:43.131536: Epoch time: 69.15 s 
2025-07-12 08:55:44.051134:  
2025-07-12 08:55:44.053149: Epoch 842 
2025-07-12 08:55:44.054437: Current learning rate: 0.0019 
2025-07-12 08:56:53.460603: train_loss -0.9819 
2025-07-12 08:56:53.461816: val_loss -0.9431 
2025-07-12 08:56:53.462878: Pseudo dice [np.float32(0.9448)] 
2025-07-12 08:56:53.463865: Epoch time: 69.41 s 
2025-07-12 08:56:54.385290:  
2025-07-12 08:56:54.387119: Epoch 843 
2025-07-12 08:56:54.388149: Current learning rate: 0.00189 
2025-07-12 08:58:03.696631: train_loss -0.9817 
2025-07-12 08:58:03.697728: val_loss -0.9387 
2025-07-12 08:58:03.698746: Pseudo dice [np.float32(0.942)] 
2025-07-12 08:58:03.700184: Epoch time: 69.32 s 
2025-07-12 08:58:04.613858:  
2025-07-12 08:58:04.616063: Epoch 844 
2025-07-12 08:58:04.617241: Current learning rate: 0.00188 
2025-07-12 08:59:13.772260: train_loss -0.9816 
2025-07-12 08:59:13.773401: val_loss -0.9431 
2025-07-12 08:59:13.774417: Pseudo dice [np.float32(0.946)] 
2025-07-12 08:59:13.775512: Epoch time: 69.16 s 
2025-07-12 08:59:14.692874:  
2025-07-12 08:59:14.694578: Epoch 845 
2025-07-12 08:59:14.695768: Current learning rate: 0.00187 
2025-07-12 09:00:27.204542: train_loss -0.9821 
2025-07-12 09:00:27.205709: val_loss -0.9445 
2025-07-12 09:00:27.206660: Pseudo dice [np.float32(0.9468)] 
2025-07-12 09:00:27.208434: Epoch time: 72.52 s 
2025-07-12 09:00:28.106278:  
2025-07-12 09:00:28.108564: Epoch 846 
2025-07-12 09:00:28.109668: Current learning rate: 0.00186 
2025-07-12 09:01:40.217189: train_loss -0.9819 
2025-07-12 09:01:40.218371: val_loss -0.9463 
2025-07-12 09:01:40.219666: Pseudo dice [np.float32(0.9489)] 
2025-07-12 09:01:40.221031: Epoch time: 72.11 s 
2025-07-12 09:01:41.107909:  
2025-07-12 09:01:41.109862: Epoch 847 
2025-07-12 09:01:41.111075: Current learning rate: 0.00185 
2025-07-12 09:02:49.708907: train_loss -0.9815 
2025-07-12 09:02:49.710145: val_loss -0.9381 
2025-07-12 09:02:49.711194: Pseudo dice [np.float32(0.9391)] 
2025-07-12 09:02:49.712148: Epoch time: 68.6 s 
2025-07-12 09:02:50.626117:  
2025-07-12 09:02:50.627829: Epoch 848 
2025-07-12 09:02:50.629197: Current learning rate: 0.00184 
2025-07-12 09:03:59.543370: train_loss -0.9807 
2025-07-12 09:03:59.544513: val_loss -0.9362 
2025-07-12 09:03:59.545471: Pseudo dice [np.float32(0.9388)] 
2025-07-12 09:03:59.546518: Epoch time: 68.92 s 
2025-07-12 09:04:00.452887:  
2025-07-12 09:04:00.454882: Epoch 849 
2025-07-12 09:04:00.456014: Current learning rate: 0.00182 
2025-07-12 09:05:09.465926: train_loss -0.9816 
2025-07-12 09:05:09.467422: val_loss -0.9396 
2025-07-12 09:05:09.468409: Pseudo dice [np.float32(0.9425)] 
2025-07-12 09:05:09.469464: Epoch time: 69.02 s 
2025-07-12 09:05:11.507790:  
2025-07-12 09:05:11.509413: Epoch 850 
2025-07-12 09:05:11.510792: Current learning rate: 0.00181 
2025-07-12 09:06:20.613360: train_loss -0.9816 
2025-07-12 09:06:20.614787: val_loss -0.9431 
2025-07-12 09:06:20.615962: Pseudo dice [np.float32(0.9461)] 
2025-07-12 09:06:20.616901: Epoch time: 69.11 s 
2025-07-12 09:06:21.524745:  
2025-07-12 09:06:21.526438: Epoch 851 
2025-07-12 09:06:21.527689: Current learning rate: 0.0018 
2025-07-12 09:07:30.656812: train_loss -0.9818 
2025-07-12 09:07:30.658121: val_loss -0.9409 
2025-07-12 09:07:30.659101: Pseudo dice [np.float32(0.9436)] 
2025-07-12 09:07:30.660020: Epoch time: 69.14 s 
2025-07-12 09:07:31.567611:  
2025-07-12 09:07:31.569465: Epoch 852 
2025-07-12 09:07:31.570447: Current learning rate: 0.00179 
2025-07-12 09:08:40.515022: train_loss -0.9817 
2025-07-12 09:08:40.516321: val_loss -0.9465 
2025-07-12 09:08:40.517294: Pseudo dice [np.float32(0.9492)] 
2025-07-12 09:08:40.518428: Epoch time: 68.95 s 
2025-07-12 09:08:41.646664:  
2025-07-12 09:08:41.648292: Epoch 853 
2025-07-12 09:08:41.649354: Current learning rate: 0.00178 
2025-07-12 09:09:50.941643: train_loss -0.9821 
2025-07-12 09:09:50.943237: val_loss -0.9432 
2025-07-12 09:09:50.944608: Pseudo dice [np.float32(0.9462)] 
2025-07-12 09:09:50.945916: Epoch time: 69.3 s 
2025-07-12 09:09:51.839852:  
2025-07-12 09:09:51.841825: Epoch 854 
2025-07-12 09:09:51.843395: Current learning rate: 0.00177 
2025-07-12 09:11:01.392083: train_loss -0.9822 
2025-07-12 09:11:01.393738: val_loss -0.943 
2025-07-12 09:11:01.395194: Pseudo dice [np.float32(0.9465)] 
2025-07-12 09:11:01.396279: Epoch time: 69.56 s 
2025-07-12 09:11:02.293750:  
2025-07-12 09:11:02.295521: Epoch 855 
2025-07-12 09:11:02.296771: Current learning rate: 0.00176 
2025-07-12 09:12:11.360443: train_loss -0.982 
2025-07-12 09:12:11.361776: val_loss -0.947 
2025-07-12 09:12:11.363247: Pseudo dice [np.float32(0.9493)] 
2025-07-12 09:12:11.364515: Epoch time: 69.07 s 
2025-07-12 09:12:12.269309:  
2025-07-12 09:12:12.271143: Epoch 856 
2025-07-12 09:12:12.272224: Current learning rate: 0.00175 
2025-07-12 09:13:21.446726: train_loss -0.9819 
2025-07-12 09:13:21.447872: val_loss -0.9406 
2025-07-12 09:13:21.448872: Pseudo dice [np.float32(0.9437)] 
2025-07-12 09:13:21.449905: Epoch time: 69.18 s 
2025-07-12 09:13:22.351278:  
2025-07-12 09:13:22.353091: Epoch 857 
2025-07-12 09:13:22.354190: Current learning rate: 0.00174 
2025-07-12 09:14:31.457825: train_loss -0.9818 
2025-07-12 09:14:31.462594: val_loss -0.9424 
2025-07-12 09:14:31.463686: Pseudo dice [np.float32(0.9453)] 
2025-07-12 09:14:31.464646: Epoch time: 69.11 s 
2025-07-12 09:14:32.367310:  
2025-07-12 09:14:32.368889: Epoch 858 
2025-07-12 09:14:32.370082: Current learning rate: 0.00173 
2025-07-12 09:15:41.314830: train_loss -0.982 
2025-07-12 09:15:41.316025: val_loss -0.945 
2025-07-12 09:15:41.317024: Pseudo dice [np.float32(0.9482)] 
2025-07-12 09:15:41.317945: Epoch time: 68.95 s 
2025-07-12 09:15:42.218883:  
2025-07-12 09:15:42.220719: Epoch 859 
2025-07-12 09:15:42.221710: Current learning rate: 0.00172 
2025-07-12 09:16:51.421163: train_loss -0.9824 
2025-07-12 09:16:51.422311: val_loss -0.9419 
2025-07-12 09:16:51.423394: Pseudo dice [np.float32(0.9448)] 
2025-07-12 09:16:51.424708: Epoch time: 69.21 s 
2025-07-12 09:16:52.293837:  
2025-07-12 09:16:52.295326: Epoch 860 
2025-07-12 09:16:52.296387: Current learning rate: 0.0017 
2025-07-12 09:18:01.616154: train_loss -0.982 
2025-07-12 09:18:01.617344: val_loss -0.9466 
2025-07-12 09:18:01.618283: Pseudo dice [np.float32(0.9488)] 
2025-07-12 09:18:01.619255: Epoch time: 69.33 s 
2025-07-12 09:18:02.509603:  
2025-07-12 09:18:02.511362: Epoch 861 
2025-07-12 09:18:02.512530: Current learning rate: 0.00169 
2025-07-12 09:19:11.572069: train_loss -0.9821 
2025-07-12 09:19:11.573524: val_loss -0.9409 
2025-07-12 09:19:11.575167: Pseudo dice [np.float32(0.9435)] 
2025-07-12 09:19:11.576378: Epoch time: 69.07 s 
2025-07-12 09:19:12.488287:  
2025-07-12 09:19:12.489970: Epoch 862 
2025-07-12 09:19:12.491111: Current learning rate: 0.00168 
2025-07-12 09:20:21.646765: train_loss -0.982 
2025-07-12 09:20:21.648031: val_loss -0.9403 
2025-07-12 09:20:21.648952: Pseudo dice [np.float32(0.9436)] 
2025-07-12 09:20:21.650191: Epoch time: 69.16 s 
2025-07-12 09:20:22.546767:  
2025-07-12 09:20:22.548759: Epoch 863 
2025-07-12 09:20:22.550067: Current learning rate: 0.00167 
2025-07-12 09:21:31.768054: train_loss -0.9818 
2025-07-12 09:21:31.769317: val_loss -0.9449 
2025-07-12 09:21:31.770350: Pseudo dice [np.float32(0.9481)] 
2025-07-12 09:21:31.771535: Epoch time: 69.23 s 
2025-07-12 09:21:32.719877:  
2025-07-12 09:21:32.721686: Epoch 864 
2025-07-12 09:21:32.722853: Current learning rate: 0.00166 
2025-07-12 09:22:42.406336: train_loss -0.9814 
2025-07-12 09:22:42.407585: val_loss -0.9443 
2025-07-12 09:22:42.408736: Pseudo dice [np.float32(0.9466)] 
2025-07-12 09:22:42.409793: Epoch time: 69.69 s 
2025-07-12 09:22:43.337909:  
2025-07-12 09:22:43.339874: Epoch 865 
2025-07-12 09:22:43.341022: Current learning rate: 0.00165 
2025-07-12 09:23:52.227913: train_loss -0.9827 
2025-07-12 09:23:52.229094: val_loss -0.9441 
2025-07-12 09:23:52.230575: Pseudo dice [np.float32(0.9481)] 
2025-07-12 09:23:52.231689: Epoch time: 68.89 s 
2025-07-12 09:23:53.128342:  
2025-07-12 09:23:53.130331: Epoch 866 
2025-07-12 09:23:53.131469: Current learning rate: 0.00164 
2025-07-12 09:25:01.525983: train_loss -0.9817 
2025-07-12 09:25:01.527630: val_loss -0.942 
2025-07-12 09:25:01.528578: Pseudo dice [np.float32(0.9454)] 
2025-07-12 09:25:01.529661: Epoch time: 68.4 s 
2025-07-12 09:25:02.416164:  
2025-07-12 09:25:02.417969: Epoch 867 
2025-07-12 09:25:02.419154: Current learning rate: 0.00163 
2025-07-12 09:26:10.936992: train_loss -0.9825 
2025-07-12 09:26:10.938505: val_loss -0.9441 
2025-07-12 09:26:10.939391: Pseudo dice [np.float32(0.9473)] 
2025-07-12 09:26:10.940825: Epoch time: 68.52 s 
2025-07-12 09:26:11.839436:  
2025-07-12 09:26:11.841352: Epoch 868 
2025-07-12 09:26:11.842507: Current learning rate: 0.00162 
2025-07-12 09:27:20.255043: train_loss -0.9826 
2025-07-12 09:27:20.256757: val_loss -0.9455 
2025-07-12 09:27:20.258298: Pseudo dice [np.float32(0.9477)] 
2025-07-12 09:27:20.259504: Epoch time: 68.42 s 
2025-07-12 09:27:21.190842:  
2025-07-12 09:27:21.192666: Epoch 869 
2025-07-12 09:27:21.194102: Current learning rate: 0.00161 
2025-07-12 09:28:29.744476: train_loss -0.9826 
2025-07-12 09:28:29.745640: val_loss -0.9496 
2025-07-12 09:28:29.746565: Pseudo dice [np.float32(0.9523)] 
2025-07-12 09:28:29.747537: Epoch time: 68.56 s 
2025-07-12 09:28:30.637214:  
2025-07-12 09:28:30.639089: Epoch 870 
2025-07-12 09:28:30.640438: Current learning rate: 0.00159 
2025-07-12 09:29:39.374985: train_loss -0.9823 
2025-07-12 09:29:39.376269: val_loss -0.9401 
2025-07-12 09:29:39.377222: Pseudo dice [np.float32(0.9439)] 
2025-07-12 09:29:39.378308: Epoch time: 68.74 s 
2025-07-12 09:29:40.288646:  
2025-07-12 09:29:40.290755: Epoch 871 
2025-07-12 09:29:40.292033: Current learning rate: 0.00158 
2025-07-12 09:30:49.097665: train_loss -0.9822 
2025-07-12 09:30:49.099426: val_loss -0.9407 
2025-07-12 09:30:49.101405: Pseudo dice [np.float32(0.9429)] 
2025-07-12 09:30:49.102560: Epoch time: 68.81 s 
2025-07-12 09:30:50.006999:  
2025-07-12 09:30:50.009083: Epoch 872 
2025-07-12 09:30:50.010374: Current learning rate: 0.00157 
2025-07-12 09:31:59.032868: train_loss -0.9822 
2025-07-12 09:31:59.034161: val_loss -0.9427 
2025-07-12 09:31:59.035141: Pseudo dice [np.float32(0.9463)] 
2025-07-12 09:31:59.036168: Epoch time: 69.03 s 
2025-07-12 09:31:59.928830:  
2025-07-12 09:31:59.930888: Epoch 873 
2025-07-12 09:31:59.931938: Current learning rate: 0.00156 
2025-07-12 09:33:09.766486: train_loss -0.9825 
2025-07-12 09:33:09.767849: val_loss -0.9387 
2025-07-12 09:33:09.768774: Pseudo dice [np.float32(0.9417)] 
2025-07-12 09:33:09.769807: Epoch time: 69.84 s 
2025-07-12 09:33:10.668216:  
2025-07-12 09:33:10.669870: Epoch 874 
2025-07-12 09:33:10.670878: Current learning rate: 0.00155 
2025-07-12 09:34:21.672014: train_loss -0.9824 
2025-07-12 09:34:21.673479: val_loss -0.9468 
2025-07-12 09:34:21.674572: Pseudo dice [np.float32(0.9494)] 
2025-07-12 09:34:21.675931: Epoch time: 71.01 s 
2025-07-12 09:34:22.561717:  
2025-07-12 09:34:22.563430: Epoch 875 
2025-07-12 09:34:22.564429: Current learning rate: 0.00154 
2025-07-12 09:35:31.186486: train_loss -0.9821 
2025-07-12 09:35:31.187853: val_loss -0.938 
2025-07-12 09:35:31.188818: Pseudo dice [np.float32(0.9404)] 
2025-07-12 09:35:31.190080: Epoch time: 68.63 s 
2025-07-12 09:35:32.091987:  
2025-07-12 09:35:32.093608: Epoch 876 
2025-07-12 09:35:32.094650: Current learning rate: 0.00153 
2025-07-12 09:36:40.467615: train_loss -0.9822 
2025-07-12 09:36:40.468894: val_loss -0.9488 
2025-07-12 09:36:40.469959: Pseudo dice [np.float32(0.9515)] 
2025-07-12 09:36:40.471039: Epoch time: 68.38 s 
2025-07-12 09:36:41.384027:  
2025-07-12 09:36:41.385972: Epoch 877 
2025-07-12 09:36:41.387024: Current learning rate: 0.00152 
2025-07-12 09:37:49.782562: train_loss -0.9823 
2025-07-12 09:37:49.783901: val_loss -0.9465 
2025-07-12 09:37:49.784937: Pseudo dice [np.float32(0.9493)] 
2025-07-12 09:37:49.785998: Epoch time: 68.4 s 
2025-07-12 09:37:50.933958:  
2025-07-12 09:37:50.935773: Epoch 878 
2025-07-12 09:37:50.936853: Current learning rate: 0.00151 
2025-07-12 09:38:59.772532: train_loss -0.9824 
2025-07-12 09:38:59.773733: val_loss -0.9344 
2025-07-12 09:38:59.774934: Pseudo dice [np.float32(0.9384)] 
2025-07-12 09:38:59.776536: Epoch time: 68.84 s 
2025-07-12 09:39:00.691032:  
2025-07-12 09:39:00.693081: Epoch 879 
2025-07-12 09:39:00.694480: Current learning rate: 0.00149 
2025-07-12 09:40:09.977854: train_loss -0.9825 
2025-07-12 09:40:09.979362: val_loss -0.9432 
2025-07-12 09:40:09.980768: Pseudo dice [np.float32(0.9459)] 
2025-07-12 09:40:09.981827: Epoch time: 69.29 s 
2025-07-12 09:40:10.886964:  
2025-07-12 09:40:10.888481: Epoch 880 
2025-07-12 09:40:10.889490: Current learning rate: 0.00148 
2025-07-12 09:41:20.306019: train_loss -0.983 
2025-07-12 09:41:20.307202: val_loss -0.9381 
2025-07-12 09:41:20.308490: Pseudo dice [np.float32(0.9426)] 
2025-07-12 09:41:20.309906: Epoch time: 69.42 s 
2025-07-12 09:41:21.209629:  
2025-07-12 09:41:21.211438: Epoch 881 
2025-07-12 09:41:21.212601: Current learning rate: 0.00147 
2025-07-12 09:42:30.849385: train_loss -0.9824 
2025-07-12 09:42:30.850645: val_loss -0.943 
2025-07-12 09:42:30.852228: Pseudo dice [np.float32(0.9468)] 
2025-07-12 09:42:30.853575: Epoch time: 69.64 s 
2025-07-12 09:42:31.743585:  
2025-07-12 09:42:31.745403: Epoch 882 
2025-07-12 09:42:31.746457: Current learning rate: 0.00146 
2025-07-12 09:43:41.221874: train_loss -0.9828 
2025-07-12 09:43:41.223287: val_loss -0.9445 
2025-07-12 09:43:41.224256: Pseudo dice [np.float32(0.9475)] 
2025-07-12 09:43:41.225158: Epoch time: 69.48 s 
2025-07-12 09:43:42.114418:  
2025-07-12 09:43:42.116021: Epoch 883 
2025-07-12 09:43:42.117029: Current learning rate: 0.00145 
2025-07-12 09:44:51.468894: train_loss -0.982 
2025-07-12 09:44:51.470197: val_loss -0.9441 
2025-07-12 09:44:51.471259: Pseudo dice [np.float32(0.9467)] 
2025-07-12 09:44:51.472845: Epoch time: 69.36 s 
2025-07-12 09:44:52.386576:  
2025-07-12 09:44:52.388279: Epoch 884 
2025-07-12 09:44:52.389435: Current learning rate: 0.00144 
2025-07-12 09:46:02.046746: train_loss -0.9823 
2025-07-12 09:46:02.048277: val_loss -0.9436 
2025-07-12 09:46:02.049293: Pseudo dice [np.float32(0.9468)] 
2025-07-12 09:46:02.050308: Epoch time: 69.66 s 
2025-07-12 09:46:03.186264:  
2025-07-12 09:46:03.188123: Epoch 885 
2025-07-12 09:46:03.189111: Current learning rate: 0.00143 
2025-07-12 09:47:12.438636: train_loss -0.9828 
2025-07-12 09:47:12.440001: val_loss -0.9452 
2025-07-12 09:47:12.441712: Pseudo dice [np.float32(0.9476)] 
2025-07-12 09:47:12.442795: Epoch time: 69.26 s 
2025-07-12 09:47:13.339003:  
2025-07-12 09:47:13.340842: Epoch 886 
2025-07-12 09:47:13.342032: Current learning rate: 0.00142 
2025-07-12 09:48:22.681247: train_loss -0.9825 
2025-07-12 09:48:22.682411: val_loss -0.9402 
2025-07-12 09:48:22.683344: Pseudo dice [np.float32(0.9429)] 
2025-07-12 09:48:22.684523: Epoch time: 69.35 s 
2025-07-12 09:48:23.574274:  
2025-07-12 09:48:23.576207: Epoch 887 
2025-07-12 09:48:23.577198: Current learning rate: 0.00141 
2025-07-12 09:49:32.888247: train_loss -0.9824 
2025-07-12 09:49:32.889458: val_loss -0.9438 
2025-07-12 09:49:32.890458: Pseudo dice [np.float32(0.9473)] 
2025-07-12 09:49:32.891390: Epoch time: 69.32 s 
2025-07-12 09:49:33.786955:  
2025-07-12 09:49:33.788957: Epoch 888 
2025-07-12 09:49:33.790063: Current learning rate: 0.00139 
2025-07-12 09:50:45.840294: train_loss -0.9827 
2025-07-12 09:50:45.841564: val_loss -0.9428 
2025-07-12 09:50:45.842582: Pseudo dice [np.float32(0.9453)] 
2025-07-12 09:50:45.843554: Epoch time: 72.06 s 
2025-07-12 09:50:46.752084:  
2025-07-12 09:50:46.754493: Epoch 889 
2025-07-12 09:50:46.755693: Current learning rate: 0.00138 
2025-07-12 09:51:58.291874: train_loss -0.9834 
2025-07-12 09:51:58.293300: val_loss -0.941 
2025-07-12 09:51:58.294448: Pseudo dice [np.float32(0.9433)] 
2025-07-12 09:51:58.295753: Epoch time: 71.54 s 
2025-07-12 09:51:59.198520:  
2025-07-12 09:51:59.200409: Epoch 890 
2025-07-12 09:51:59.201508: Current learning rate: 0.00137 
2025-07-12 09:53:08.098300: train_loss -0.9824 
2025-07-12 09:53:08.099826: val_loss -0.9353 
2025-07-12 09:53:08.101420: Pseudo dice [np.float32(0.9372)] 
2025-07-12 09:53:08.102599: Epoch time: 68.9 s 
2025-07-12 09:53:09.008565:  
2025-07-12 09:53:09.010309: Epoch 891 
2025-07-12 09:53:09.011387: Current learning rate: 0.00136 
2025-07-12 09:54:18.011693: train_loss -0.9831 
2025-07-12 09:54:18.013419: val_loss -0.9406 
2025-07-12 09:54:18.014699: Pseudo dice [np.float32(0.9412)] 
2025-07-12 09:54:18.015658: Epoch time: 69.01 s 
2025-07-12 09:54:18.920140:  
2025-07-12 09:54:18.922067: Epoch 892 
2025-07-12 09:54:18.923148: Current learning rate: 0.00135 
2025-07-12 09:55:28.298913: train_loss -0.9821 
2025-07-12 09:55:28.301239: val_loss -0.9382 
2025-07-12 09:55:28.302200: Pseudo dice [np.float32(0.9407)] 
2025-07-12 09:55:28.303314: Epoch time: 69.38 s 
2025-07-12 09:55:29.206434:  
2025-07-12 09:55:29.208363: Epoch 893 
2025-07-12 09:55:29.209681: Current learning rate: 0.00134 
2025-07-12 09:56:38.166163: train_loss -0.9828 
2025-07-12 09:56:38.167445: val_loss -0.9485 
2025-07-12 09:56:38.168670: Pseudo dice [np.float32(0.9506)] 
2025-07-12 09:56:38.169864: Epoch time: 68.96 s 
2025-07-12 09:56:39.067224:  
2025-07-12 09:56:39.069177: Epoch 894 
2025-07-12 09:56:39.070421: Current learning rate: 0.00133 
2025-07-12 09:57:48.632010: train_loss -0.9828 
2025-07-12 09:57:48.633570: val_loss -0.9446 
2025-07-12 09:57:48.634926: Pseudo dice [np.float32(0.9468)] 
2025-07-12 09:57:48.636446: Epoch time: 69.57 s 
2025-07-12 09:57:49.557094:  
2025-07-12 09:57:49.558845: Epoch 895 
2025-07-12 09:57:49.560030: Current learning rate: 0.00132 
2025-07-12 09:59:05.502914: train_loss -0.9828 
2025-07-12 09:59:05.504114: val_loss -0.9401 
2025-07-12 09:59:05.505087: Pseudo dice [np.float32(0.9428)] 
2025-07-12 09:59:05.506225: Epoch time: 75.95 s 
2025-07-12 09:59:06.412367:  
2025-07-12 09:59:06.414565: Epoch 896 
2025-07-12 09:59:06.415735: Current learning rate: 0.0013 
2025-07-12 10:00:19.849391: train_loss -0.983 
2025-07-12 10:00:19.850731: val_loss -0.9429 
2025-07-12 10:00:19.851726: Pseudo dice [np.float32(0.9453)] 
2025-07-12 10:00:19.852756: Epoch time: 73.44 s 
2025-07-12 10:00:20.750167:  
2025-07-12 10:00:20.752054: Epoch 897 
2025-07-12 10:00:20.753139: Current learning rate: 0.00129 
2025-07-12 10:01:29.316634: train_loss -0.9827 
2025-07-12 10:01:29.318960: val_loss -0.9474 
2025-07-12 10:01:29.319937: Pseudo dice [np.float32(0.9499)] 
2025-07-12 10:01:29.321057: Epoch time: 68.57 s 
2025-07-12 10:01:30.221135:  
2025-07-12 10:01:30.222648: Epoch 898 
2025-07-12 10:01:30.223681: Current learning rate: 0.00128 
2025-07-12 10:02:39.025555: train_loss -0.9829 
2025-07-12 10:02:39.027153: val_loss -0.9426 
2025-07-12 10:02:39.028535: Pseudo dice [np.float32(0.9441)] 
2025-07-12 10:02:39.029659: Epoch time: 68.81 s 
2025-07-12 10:02:39.926589:  
2025-07-12 10:02:39.928360: Epoch 899 
2025-07-12 10:02:39.929521: Current learning rate: 0.00127 
2025-07-12 10:03:49.064423: train_loss -0.9834 
2025-07-12 10:03:49.065692: val_loss -0.9441 
2025-07-12 10:03:49.066630: Pseudo dice [np.float32(0.9464)] 
2025-07-12 10:03:49.067565: Epoch time: 69.14 s 
2025-07-12 10:03:51.116269:  
2025-07-12 10:03:51.117842: Epoch 900 
2025-07-12 10:03:51.118783: Current learning rate: 0.00126 
2025-07-12 10:05:00.167619: train_loss -0.9831 
2025-07-12 10:05:00.169043: val_loss -0.9459 
2025-07-12 10:05:00.170187: Pseudo dice [np.float32(0.9487)] 
2025-07-12 10:05:00.171199: Epoch time: 69.05 s 
2025-07-12 10:05:01.052035:  
2025-07-12 10:05:01.054094: Epoch 901 
2025-07-12 10:05:01.055364: Current learning rate: 0.00125 
2025-07-12 10:06:10.109050: train_loss -0.9829 
2025-07-12 10:06:10.110339: val_loss -0.9362 
2025-07-12 10:06:10.111396: Pseudo dice [np.float32(0.9396)] 
2025-07-12 10:06:10.112386: Epoch time: 69.06 s 
2025-07-12 10:06:10.999866:  
2025-07-12 10:06:11.001646: Epoch 902 
2025-07-12 10:06:11.002712: Current learning rate: 0.00124 
2025-07-12 10:07:20.279217: train_loss -0.9824 
2025-07-12 10:07:20.280423: val_loss -0.9461 
2025-07-12 10:07:20.281392: Pseudo dice [np.float32(0.949)] 
2025-07-12 10:07:20.282638: Epoch time: 69.28 s 
2025-07-12 10:07:21.175739:  
2025-07-12 10:07:21.177371: Epoch 903 
2025-07-12 10:07:21.178369: Current learning rate: 0.00122 
2025-07-12 10:08:30.657723: train_loss -0.9835 
2025-07-12 10:08:30.658821: val_loss -0.9409 
2025-07-12 10:08:30.659704: Pseudo dice [np.float32(0.9434)] 
2025-07-12 10:08:30.660676: Epoch time: 69.49 s 
2025-07-12 10:08:31.550127:  
2025-07-12 10:08:31.551826: Epoch 904 
2025-07-12 10:08:31.552768: Current learning rate: 0.00121 
2025-07-12 10:09:40.919850: train_loss -0.9828 
2025-07-12 10:09:40.921763: val_loss -0.9412 
2025-07-12 10:09:40.923012: Pseudo dice [np.float32(0.9434)] 
2025-07-12 10:09:40.924235: Epoch time: 69.37 s 
2025-07-12 10:09:41.832497:  
2025-07-12 10:09:41.834598: Epoch 905 
2025-07-12 10:09:41.835719: Current learning rate: 0.0012 
2025-07-12 10:10:51.132088: train_loss -0.9827 
2025-07-12 10:10:51.133498: val_loss -0.9406 
2025-07-12 10:10:51.134681: Pseudo dice [np.float32(0.9423)] 
2025-07-12 10:10:51.136232: Epoch time: 69.3 s 
2025-07-12 10:10:52.273548:  
2025-07-12 10:10:52.275306: Epoch 906 
2025-07-12 10:10:52.276278: Current learning rate: 0.00119 
2025-07-12 10:12:01.457980: train_loss -0.9827 
2025-07-12 10:12:01.459632: val_loss -0.945 
2025-07-12 10:12:01.461255: Pseudo dice [np.float32(0.9473)] 
2025-07-12 10:12:01.462535: Epoch time: 69.19 s 
2025-07-12 10:12:02.376859:  
2025-07-12 10:12:02.378378: Epoch 907 
2025-07-12 10:12:02.379304: Current learning rate: 0.00118 
2025-07-12 10:13:11.652597: train_loss -0.9829 
2025-07-12 10:13:11.653789: val_loss -0.9419 
2025-07-12 10:13:11.654995: Pseudo dice [np.float32(0.9439)] 
2025-07-12 10:13:11.656766: Epoch time: 69.28 s 
2025-07-12 10:13:12.573308:  
2025-07-12 10:13:12.575122: Epoch 908 
2025-07-12 10:13:12.576272: Current learning rate: 0.00117 
2025-07-12 10:14:21.643039: train_loss -0.9832 
2025-07-12 10:14:21.644590: val_loss -0.9445 
2025-07-12 10:14:21.645952: Pseudo dice [np.float32(0.9465)] 
2025-07-12 10:14:21.647769: Epoch time: 69.07 s 
2025-07-12 10:14:22.545066:  
2025-07-12 10:14:22.546843: Epoch 909 
2025-07-12 10:14:22.548143: Current learning rate: 0.00116 
2025-07-12 10:15:31.730423: train_loss -0.9825 
2025-07-12 10:15:31.732124: val_loss -0.9455 
2025-07-12 10:15:31.733032: Pseudo dice [np.float32(0.949)] 
2025-07-12 10:15:31.733984: Epoch time: 69.19 s 
2025-07-12 10:15:32.617321:  
2025-07-12 10:15:32.619262: Epoch 910 
2025-07-12 10:15:32.620410: Current learning rate: 0.00115 
2025-07-12 10:16:41.765106: train_loss -0.9832 
2025-07-12 10:16:41.766352: val_loss -0.9402 
2025-07-12 10:16:41.767518: Pseudo dice [np.float32(0.9438)] 
2025-07-12 10:16:41.768685: Epoch time: 69.15 s 
2025-07-12 10:16:42.673678:  
2025-07-12 10:16:42.675518: Epoch 911 
2025-07-12 10:16:42.676927: Current learning rate: 0.00113 
2025-07-12 10:17:51.783747: train_loss -0.9831 
2025-07-12 10:17:51.785356: val_loss -0.9417 
2025-07-12 10:17:51.786418: Pseudo dice [np.float32(0.9444)] 
2025-07-12 10:17:51.788455: Epoch time: 69.11 s 
2025-07-12 10:17:52.703990:  
2025-07-12 10:17:52.706088: Epoch 912 
2025-07-12 10:17:52.707263: Current learning rate: 0.00112 
2025-07-12 10:19:01.655044: train_loss -0.9836 
2025-07-12 10:19:01.656509: val_loss -0.9382 
2025-07-12 10:19:01.658012: Pseudo dice [np.float32(0.9411)] 
2025-07-12 10:19:01.659744: Epoch time: 68.95 s 
2025-07-12 10:19:02.568703:  
2025-07-12 10:19:02.570553: Epoch 913 
2025-07-12 10:19:02.571612: Current learning rate: 0.00111 
2025-07-12 10:20:11.886760: train_loss -0.9831 
2025-07-12 10:20:11.888482: val_loss -0.9428 
2025-07-12 10:20:11.889761: Pseudo dice [np.float32(0.946)] 
2025-07-12 10:20:11.891332: Epoch time: 69.32 s 
2025-07-12 10:20:12.806449:  
2025-07-12 10:20:12.808545: Epoch 914 
2025-07-12 10:20:12.809714: Current learning rate: 0.0011 
2025-07-12 10:21:21.845429: train_loss -0.9829 
2025-07-12 10:21:21.846857: val_loss -0.9473 
2025-07-12 10:21:21.848396: Pseudo dice [np.float32(0.9496)] 
2025-07-12 10:21:21.850095: Epoch time: 69.04 s 
2025-07-12 10:21:22.768845:  
2025-07-12 10:21:22.770761: Epoch 915 
2025-07-12 10:21:22.771848: Current learning rate: 0.00109 
2025-07-12 10:22:31.936497: train_loss -0.983 
2025-07-12 10:22:31.938092: val_loss -0.9435 
2025-07-12 10:22:31.939081: Pseudo dice [np.float32(0.9465)] 
2025-07-12 10:22:31.940038: Epoch time: 69.17 s 
2025-07-12 10:22:32.847841:  
2025-07-12 10:22:32.850251: Epoch 916 
2025-07-12 10:22:32.851428: Current learning rate: 0.00108 
2025-07-12 10:23:42.765551: train_loss -0.9829 
2025-07-12 10:23:42.767748: val_loss -0.9471 
2025-07-12 10:23:42.769318: Pseudo dice [np.float32(0.9495)] 
2025-07-12 10:23:42.770861: Epoch time: 69.92 s 
2025-07-12 10:23:43.659008:  
2025-07-12 10:23:43.661050: Epoch 917 
2025-07-12 10:23:43.662295: Current learning rate: 0.00106 
2025-07-12 10:24:53.726252: train_loss -0.9831 
2025-07-12 10:24:53.727775: val_loss -0.9443 
2025-07-12 10:24:53.729745: Pseudo dice [np.float32(0.9468)] 
2025-07-12 10:24:53.731294: Epoch time: 70.07 s 
2025-07-12 10:24:54.633758:  
2025-07-12 10:24:54.634800: Epoch 918 
2025-07-12 10:24:54.636020: Current learning rate: 0.00105 
2025-07-12 10:26:03.357305: train_loss -0.9828 
2025-07-12 10:26:03.358572: val_loss -0.9438 
2025-07-12 10:26:03.359647: Pseudo dice [np.float32(0.9464)] 
2025-07-12 10:26:03.360868: Epoch time: 68.73 s 
2025-07-12 10:26:04.263923:  
2025-07-12 10:26:04.265745: Epoch 919 
2025-07-12 10:26:04.266947: Current learning rate: 0.00104 
2025-07-12 10:27:12.697512: train_loss -0.9835 
2025-07-12 10:27:12.698810: val_loss -0.9314 
2025-07-12 10:27:12.700576: Pseudo dice [np.float32(0.934)] 
2025-07-12 10:27:12.701892: Epoch time: 68.44 s 
2025-07-12 10:27:13.595122:  
2025-07-12 10:27:13.597092: Epoch 920 
2025-07-12 10:27:13.598151: Current learning rate: 0.00103 
2025-07-12 10:28:22.186757: train_loss -0.9829 
2025-07-12 10:28:22.188971: val_loss -0.9376 
2025-07-12 10:28:22.190211: Pseudo dice [np.float32(0.9412)] 
2025-07-12 10:28:22.191412: Epoch time: 68.6 s 
2025-07-12 10:28:23.108194:  
2025-07-12 10:28:23.110301: Epoch 921 
2025-07-12 10:28:23.111329: Current learning rate: 0.00102 
2025-07-12 10:29:31.710865: train_loss -0.9831 
2025-07-12 10:29:31.712718: val_loss -0.9403 
2025-07-12 10:29:31.713705: Pseudo dice [np.float32(0.9441)] 
2025-07-12 10:29:31.714874: Epoch time: 68.61 s 
2025-07-12 10:29:32.611441:  
2025-07-12 10:29:32.613209: Epoch 922 
2025-07-12 10:29:32.614370: Current learning rate: 0.00101 
2025-07-12 10:30:41.415103: train_loss -0.9829 
2025-07-12 10:30:41.416290: val_loss -0.9403 
2025-07-12 10:30:41.417527: Pseudo dice [np.float32(0.9433)] 
2025-07-12 10:30:41.418792: Epoch time: 68.81 s 
2025-07-12 10:30:42.291904:  
2025-07-12 10:30:42.293707: Epoch 923 
2025-07-12 10:30:42.294833: Current learning rate: 0.001 
2025-07-12 10:31:51.473803: train_loss -0.983 
2025-07-12 10:31:51.475233: val_loss -0.9393 
2025-07-12 10:31:51.476349: Pseudo dice [np.float32(0.9424)] 
2025-07-12 10:31:51.477382: Epoch time: 69.19 s 
2025-07-12 10:31:52.381542:  
2025-07-12 10:31:52.383636: Epoch 924 
2025-07-12 10:31:52.384823: Current learning rate: 0.00098 
2025-07-12 10:33:01.625484: train_loss -0.9835 
2025-07-12 10:33:01.627800: val_loss -0.9397 
2025-07-12 10:33:01.629206: Pseudo dice [np.float32(0.9423)] 
2025-07-12 10:33:01.630266: Epoch time: 69.25 s 
2025-07-12 10:33:02.528697:  
2025-07-12 10:33:02.530249: Epoch 925 
2025-07-12 10:33:02.531454: Current learning rate: 0.00097 
2025-07-12 10:34:11.733056: train_loss -0.983 
2025-07-12 10:34:11.734590: val_loss -0.938 
2025-07-12 10:34:11.735651: Pseudo dice [np.float32(0.9415)] 
2025-07-12 10:34:11.736745: Epoch time: 69.21 s 
2025-07-12 10:34:12.628229:  
2025-07-12 10:34:12.629994: Epoch 926 
2025-07-12 10:34:12.631159: Current learning rate: 0.00096 
2025-07-12 10:35:21.859290: train_loss -0.983 
2025-07-12 10:35:21.860404: val_loss -0.9434 
2025-07-12 10:35:21.861423: Pseudo dice [np.float32(0.9453)] 
2025-07-12 10:35:21.863311: Epoch time: 69.23 s 
2025-07-12 10:35:22.749037:  
2025-07-12 10:35:22.750990: Epoch 927 
2025-07-12 10:35:22.752227: Current learning rate: 0.00095 
2025-07-12 10:36:32.135826: train_loss -0.9836 
2025-07-12 10:36:32.136903: val_loss -0.938 
2025-07-12 10:36:32.137872: Pseudo dice [np.float32(0.9413)] 
2025-07-12 10:36:32.139126: Epoch time: 69.39 s 
2025-07-12 10:36:33.062467:  
2025-07-12 10:36:33.064313: Epoch 928 
2025-07-12 10:36:33.065449: Current learning rate: 0.00094 
2025-07-12 10:37:42.390018: train_loss -0.9832 
2025-07-12 10:37:42.391208: val_loss -0.9462 
2025-07-12 10:37:42.392109: Pseudo dice [np.float32(0.9488)] 
2025-07-12 10:37:42.393245: Epoch time: 69.33 s 
2025-07-12 10:37:43.300330:  
2025-07-12 10:37:43.302262: Epoch 929 
2025-07-12 10:37:43.303393: Current learning rate: 0.00092 
2025-07-12 10:38:52.385372: train_loss -0.9832 
2025-07-12 10:38:52.386790: val_loss -0.9415 
2025-07-12 10:38:52.388499: Pseudo dice [np.float32(0.9445)] 
2025-07-12 10:38:52.390189: Epoch time: 69.09 s 
2025-07-12 10:38:53.284600:  
2025-07-12 10:38:53.286592: Epoch 930 
2025-07-12 10:38:53.287856: Current learning rate: 0.00091 
2025-07-12 10:40:02.706717: train_loss -0.983 
2025-07-12 10:40:02.708765: val_loss -0.9409 
2025-07-12 10:40:02.710385: Pseudo dice [np.float32(0.9425)] 
2025-07-12 10:40:02.711289: Epoch time: 69.43 s 
2025-07-12 10:40:03.624995:  
2025-07-12 10:40:03.626727: Epoch 931 
2025-07-12 10:40:03.628200: Current learning rate: 0.0009 
2025-07-12 10:41:12.728030: train_loss -0.9834 
2025-07-12 10:41:12.729241: val_loss -0.945 
2025-07-12 10:41:12.730490: Pseudo dice [np.float32(0.9476)] 
2025-07-12 10:41:12.731719: Epoch time: 69.11 s 
2025-07-12 10:41:13.615133:  
2025-07-12 10:41:13.616713: Epoch 932 
2025-07-12 10:41:13.617882: Current learning rate: 0.00089 
2025-07-12 10:42:22.863685: train_loss -0.9837 
2025-07-12 10:42:22.865096: val_loss -0.9456 
2025-07-12 10:42:22.866434: Pseudo dice [np.float32(0.9483)] 
2025-07-12 10:42:22.867528: Epoch time: 69.25 s 
2025-07-12 10:42:23.781459:  
2025-07-12 10:42:23.783346: Epoch 933 
2025-07-12 10:42:23.784575: Current learning rate: 0.00088 
2025-07-12 10:43:34.111033: train_loss -0.9838 
2025-07-12 10:43:34.112349: val_loss -0.9412 
2025-07-12 10:43:34.113474: Pseudo dice [np.float32(0.9425)] 
2025-07-12 10:43:34.114691: Epoch time: 70.33 s 
2025-07-12 10:43:35.010252:  
2025-07-12 10:43:35.012108: Epoch 934 
2025-07-12 10:43:35.013292: Current learning rate: 0.00087 
2025-07-12 10:44:44.356872: train_loss -0.9838 
2025-07-12 10:44:44.358235: val_loss -0.9465 
2025-07-12 10:44:44.359435: Pseudo dice [np.float32(0.9488)] 
2025-07-12 10:44:44.360444: Epoch time: 69.35 s 
2025-07-12 10:44:45.235395:  
2025-07-12 10:44:45.237226: Epoch 935 
2025-07-12 10:44:45.238525: Current learning rate: 0.00085 
2025-07-12 10:45:54.125071: train_loss -0.9835 
2025-07-12 10:45:54.126300: val_loss -0.9397 
2025-07-12 10:45:54.127522: Pseudo dice [np.float32(0.9422)] 
2025-07-12 10:45:54.129102: Epoch time: 68.89 s 
2025-07-12 10:45:55.059410:  
2025-07-12 10:45:55.061244: Epoch 936 
2025-07-12 10:45:55.062322: Current learning rate: 0.00084 
2025-07-12 10:47:04.142097: train_loss -0.9836 
2025-07-12 10:47:04.143265: val_loss -0.943 
2025-07-12 10:47:04.144267: Pseudo dice [np.float32(0.946)] 
2025-07-12 10:47:04.145236: Epoch time: 69.09 s 
2025-07-12 10:47:05.031503:  
2025-07-12 10:47:05.033379: Epoch 937 
2025-07-12 10:47:05.034574: Current learning rate: 0.00083 
2025-07-12 10:48:14.412331: train_loss -0.9834 
2025-07-12 10:48:14.413557: val_loss -0.9378 
2025-07-12 10:48:14.414551: Pseudo dice [np.float32(0.9396)] 
2025-07-12 10:48:14.415522: Epoch time: 69.38 s 
2025-07-12 10:48:15.546898:  
2025-07-12 10:48:15.548970: Epoch 938 
2025-07-12 10:48:15.549984: Current learning rate: 0.00082 
2025-07-12 10:49:24.884480: train_loss -0.9834 
2025-07-12 10:49:24.885659: val_loss -0.9406 
2025-07-12 10:49:24.886851: Pseudo dice [np.float32(0.9428)] 
2025-07-12 10:49:24.888132: Epoch time: 69.34 s 
2025-07-12 10:49:25.791406:  
2025-07-12 10:49:25.793303: Epoch 939 
2025-07-12 10:49:25.794397: Current learning rate: 0.00081 
2025-07-12 10:50:35.089387: train_loss -0.9836 
2025-07-12 10:50:35.090975: val_loss -0.9413 
2025-07-12 10:50:35.092008: Pseudo dice [np.float32(0.9442)] 
2025-07-12 10:50:35.092961: Epoch time: 69.3 s 
2025-07-12 10:50:35.988811:  
2025-07-12 10:50:35.990543: Epoch 940 
2025-07-12 10:50:35.991520: Current learning rate: 0.00079 
2025-07-12 10:51:45.330197: train_loss -0.9837 
2025-07-12 10:51:45.331497: val_loss -0.942 
2025-07-12 10:51:45.332668: Pseudo dice [np.float32(0.9445)] 
2025-07-12 10:51:45.334286: Epoch time: 69.34 s 
2025-07-12 10:51:46.217504:  
2025-07-12 10:51:46.219500: Epoch 941 
2025-07-12 10:51:46.221129: Current learning rate: 0.00078 
2025-07-12 10:52:55.545925: train_loss -0.9839 
2025-07-12 10:52:55.547197: val_loss -0.9425 
2025-07-12 10:52:55.548238: Pseudo dice [np.float32(0.9449)] 
2025-07-12 10:52:55.549603: Epoch time: 69.33 s 
2025-07-12 10:52:56.453385:  
2025-07-12 10:52:56.455537: Epoch 942 
2025-07-12 10:52:56.456805: Current learning rate: 0.00077 
2025-07-12 10:54:05.776659: train_loss -0.9838 
2025-07-12 10:54:05.777879: val_loss -0.9451 
2025-07-12 10:54:05.779282: Pseudo dice [np.float32(0.9468)] 
2025-07-12 10:54:05.780442: Epoch time: 69.33 s 
2025-07-12 10:54:06.692263:  
2025-07-12 10:54:06.693274: Epoch 943 
2025-07-12 10:54:06.694223: Current learning rate: 0.00076 
2025-07-12 10:55:16.194120: train_loss -0.9838 
2025-07-12 10:55:16.196112: val_loss -0.9453 
2025-07-12 10:55:16.197341: Pseudo dice [np.float32(0.9467)] 
2025-07-12 10:55:16.198478: Epoch time: 69.51 s 
2025-07-12 10:55:17.106823:  
2025-07-12 10:55:17.108389: Epoch 944 
2025-07-12 10:55:17.109765: Current learning rate: 0.00075 
2025-07-12 10:56:26.683104: train_loss -0.9833 
2025-07-12 10:56:26.684499: val_loss -0.9389 
2025-07-12 10:56:26.685589: Pseudo dice [np.float32(0.9409)] 
2025-07-12 10:56:26.686814: Epoch time: 69.58 s 
2025-07-12 10:56:27.810141:  
2025-07-12 10:56:27.812371: Epoch 945 
2025-07-12 10:56:27.813509: Current learning rate: 0.00074 
2025-07-12 10:57:37.319119: train_loss -0.9833 
2025-07-12 10:57:37.320596: val_loss -0.9464 
2025-07-12 10:57:37.321803: Pseudo dice [np.float32(0.9486)] 
2025-07-12 10:57:37.323730: Epoch time: 69.51 s 
2025-07-12 10:57:38.275154:  
2025-07-12 10:57:38.277493: Epoch 946 
2025-07-12 10:57:38.279173: Current learning rate: 0.00072 
2025-07-12 10:58:46.910027: train_loss -0.9836 
2025-07-12 10:58:46.911555: val_loss -0.9419 
2025-07-12 10:58:46.912538: Pseudo dice [np.float32(0.9442)] 
2025-07-12 10:58:46.913606: Epoch time: 68.64 s 
2025-07-12 10:58:47.864863:  
2025-07-12 10:58:47.866937: Epoch 947 
2025-07-12 10:58:47.868305: Current learning rate: 0.00071 
2025-07-12 10:59:56.796884: train_loss -0.9836 
2025-07-12 10:59:56.798232: val_loss -0.9464 
2025-07-12 10:59:56.799264: Pseudo dice [np.float32(0.9491)] 
2025-07-12 10:59:56.800427: Epoch time: 68.94 s 
2025-07-12 10:59:57.734935:  
2025-07-12 10:59:57.736767: Epoch 948 
2025-07-12 10:59:57.737828: Current learning rate: 0.0007 
2025-07-12 11:01:06.755279: train_loss -0.9836 
2025-07-12 11:01:06.757713: val_loss -0.9465 
2025-07-12 11:01:06.759129: Pseudo dice [np.float32(0.9489)] 
2025-07-12 11:01:06.760722: Epoch time: 69.02 s 
2025-07-12 11:01:07.670242:  
2025-07-12 11:01:07.672374: Epoch 949 
2025-07-12 11:01:07.673464: Current learning rate: 0.00069 
2025-07-12 11:02:16.696784: train_loss -0.9837 
2025-07-12 11:02:16.698078: val_loss -0.9443 
2025-07-12 11:02:16.699331: Pseudo dice [np.float32(0.9461)] 
2025-07-12 11:02:16.700470: Epoch time: 69.03 s 
2025-07-12 11:02:18.757070:  
2025-07-12 11:02:18.758770: Epoch 950 
2025-07-12 11:02:18.760235: Current learning rate: 0.00067 
2025-07-12 11:03:27.345502: train_loss -0.9839 
2025-07-12 11:03:27.346945: val_loss -0.9439 
2025-07-12 11:03:27.348301: Pseudo dice [np.float32(0.946)] 
2025-07-12 11:03:27.349639: Epoch time: 68.59 s 
2025-07-12 11:03:28.253334:  
2025-07-12 11:03:28.255555: Epoch 951 
2025-07-12 11:03:28.256568: Current learning rate: 0.00066 
2025-07-12 11:04:37.020181: train_loss -0.9839 
2025-07-12 11:04:37.022014: val_loss -0.9486 
2025-07-12 11:04:37.023297: Pseudo dice [np.float32(0.9518)] 
2025-07-12 11:04:37.024491: Epoch time: 68.77 s 
2025-07-12 11:04:38.220931:  
2025-07-12 11:04:38.222746: Epoch 952 
2025-07-12 11:04:38.223855: Current learning rate: 0.00065 
2025-07-12 11:05:46.737775: train_loss -0.9833 
2025-07-12 11:05:46.739107: val_loss -0.9421 
2025-07-12 11:05:46.740055: Pseudo dice [np.float32(0.9443)] 
2025-07-12 11:05:46.741259: Epoch time: 68.52 s 
2025-07-12 11:05:47.663227:  
2025-07-12 11:05:47.665791: Epoch 953 
2025-07-12 11:05:47.666943: Current learning rate: 0.00064 
2025-07-12 11:06:56.298392: train_loss -0.9841 
2025-07-12 11:06:56.299601: val_loss -0.9362 
2025-07-12 11:06:56.300812: Pseudo dice [np.float32(0.9399)] 
2025-07-12 11:06:56.301752: Epoch time: 68.64 s 
2025-07-12 11:06:57.230457:  
2025-07-12 11:06:57.232696: Epoch 954 
2025-07-12 11:06:57.234313: Current learning rate: 0.00063 
2025-07-12 11:08:05.957829: train_loss -0.9835 
2025-07-12 11:08:05.959205: val_loss -0.9474 
2025-07-12 11:08:05.960139: Pseudo dice [np.float32(0.9491)] 
2025-07-12 11:08:05.961129: Epoch time: 68.73 s 
2025-07-12 11:08:06.893015:  
2025-07-12 11:08:06.895237: Epoch 955 
2025-07-12 11:08:06.896429: Current learning rate: 0.00061 
2025-07-12 11:09:15.723835: train_loss -0.9836 
2025-07-12 11:09:15.725295: val_loss -0.9396 
2025-07-12 11:09:15.726433: Pseudo dice [np.float32(0.9424)] 
2025-07-12 11:09:15.727582: Epoch time: 68.83 s 
2025-07-12 11:09:16.660375:  
2025-07-12 11:09:16.662999: Epoch 956 
2025-07-12 11:09:16.664406: Current learning rate: 0.0006 
2025-07-12 11:10:25.195869: train_loss -0.9834 
2025-07-12 11:10:25.197526: val_loss -0.9452 
2025-07-12 11:10:25.198621: Pseudo dice [np.float32(0.9485)] 
2025-07-12 11:10:25.200191: Epoch time: 68.54 s 
2025-07-12 11:10:26.129527:  
2025-07-12 11:10:26.131431: Epoch 957 
2025-07-12 11:10:26.132401: Current learning rate: 0.00059 
2025-07-12 11:11:34.836840: train_loss -0.9833 
2025-07-12 11:11:34.838391: val_loss -0.9455 
2025-07-12 11:11:34.840336: Pseudo dice [np.float32(0.9481)] 
2025-07-12 11:11:34.841342: Epoch time: 68.71 s 
2025-07-12 11:11:35.767766:  
2025-07-12 11:11:35.769912: Epoch 958 
2025-07-12 11:11:35.771123: Current learning rate: 0.00058 
2025-07-12 11:12:44.454765: train_loss -0.9838 
2025-07-12 11:12:44.456436: val_loss -0.9472 
2025-07-12 11:12:44.457450: Pseudo dice [np.float32(0.9493)] 
2025-07-12 11:12:44.458691: Epoch time: 68.69 s 
2025-07-12 11:12:45.628006:  
2025-07-12 11:12:45.630256: Epoch 959 
2025-07-12 11:12:45.631732: Current learning rate: 0.00056 
2025-07-12 11:13:54.421437: train_loss -0.9841 
2025-07-12 11:13:54.422808: val_loss -0.9457 
2025-07-12 11:13:54.423990: Pseudo dice [np.float32(0.9482)] 
2025-07-12 11:13:54.424918: Epoch time: 68.8 s 
2025-07-12 11:13:55.353920:  
2025-07-12 11:13:55.356075: Epoch 960 
2025-07-12 11:13:55.357452: Current learning rate: 0.00055 
2025-07-12 11:15:04.212211: train_loss -0.9841 
2025-07-12 11:15:04.213401: val_loss -0.9391 
2025-07-12 11:15:04.214566: Pseudo dice [np.float32(0.9411)] 
2025-07-12 11:15:04.215777: Epoch time: 68.86 s 
2025-07-12 11:15:05.123709:  
2025-07-12 11:15:05.125835: Epoch 961 
2025-07-12 11:15:05.127099: Current learning rate: 0.00054 
2025-07-12 11:16:13.938103: train_loss -0.9838 
2025-07-12 11:16:13.939400: val_loss -0.9446 
2025-07-12 11:16:13.940531: Pseudo dice [np.float32(0.948)] 
2025-07-12 11:16:13.942084: Epoch time: 68.82 s 
2025-07-12 11:16:14.837348:  
2025-07-12 11:16:14.839385: Epoch 962 
2025-07-12 11:16:14.840549: Current learning rate: 0.00053 
2025-07-12 11:17:23.889068: train_loss -0.9844 
2025-07-12 11:17:23.890542: val_loss -0.9426 
2025-07-12 11:17:23.891874: Pseudo dice [np.float32(0.9443)] 
2025-07-12 11:17:23.893093: Epoch time: 69.06 s 
2025-07-12 11:17:24.816212:  
2025-07-12 11:17:24.818456: Epoch 963 
2025-07-12 11:17:24.819840: Current learning rate: 0.00051 
2025-07-12 11:18:33.540389: train_loss -0.9841 
2025-07-12 11:18:33.541684: val_loss -0.9462 
2025-07-12 11:18:33.542703: Pseudo dice [np.float32(0.9483)] 
2025-07-12 11:18:33.543985: Epoch time: 68.73 s 
2025-07-12 11:18:34.472764:  
2025-07-12 11:18:34.474756: Epoch 964 
2025-07-12 11:18:34.476314: Current learning rate: 0.0005 
2025-07-12 11:19:43.064967: train_loss -0.9844 
2025-07-12 11:19:43.066185: val_loss -0.9398 
2025-07-12 11:19:43.067524: Pseudo dice [np.float32(0.9426)] 
2025-07-12 11:19:43.069308: Epoch time: 68.6 s 
2025-07-12 11:19:43.978900:  
2025-07-12 11:19:43.981179: Epoch 965 
2025-07-12 11:19:43.982249: Current learning rate: 0.00049 
2025-07-12 11:20:52.283951: train_loss -0.9837 
2025-07-12 11:20:52.285300: val_loss -0.9442 
2025-07-12 11:20:52.286904: Pseudo dice [np.float32(0.9457)] 
2025-07-12 11:20:52.288052: Epoch time: 68.31 s 
2025-07-12 11:20:53.447021:  
2025-07-12 11:20:53.449290: Epoch 966 
2025-07-12 11:20:53.450573: Current learning rate: 0.00048 
2025-07-12 11:22:02.013113: train_loss -0.9842 
2025-07-12 11:22:02.014612: val_loss -0.9451 
2025-07-12 11:22:02.016208: Pseudo dice [np.float32(0.9475)] 
2025-07-12 11:22:02.017231: Epoch time: 68.57 s 
2025-07-12 11:22:02.927212:  
2025-07-12 11:22:02.929497: Epoch 967 
2025-07-12 11:22:02.930826: Current learning rate: 0.00046 
2025-07-12 11:23:11.407546: train_loss -0.9843 
2025-07-12 11:23:11.408796: val_loss -0.9422 
2025-07-12 11:23:11.410031: Pseudo dice [np.float32(0.9445)] 
2025-07-12 11:23:11.411159: Epoch time: 68.48 s 
2025-07-12 11:23:12.348338:  
2025-07-12 11:23:12.350555: Epoch 968 
2025-07-12 11:23:12.351914: Current learning rate: 0.00045 
2025-07-12 11:24:21.004922: train_loss -0.9835 
2025-07-12 11:24:21.006318: val_loss -0.9406 
2025-07-12 11:24:21.007587: Pseudo dice [np.float32(0.9439)] 
2025-07-12 11:24:21.008624: Epoch time: 68.66 s 
2025-07-12 11:24:21.945199:  
2025-07-12 11:24:21.946974: Epoch 969 
2025-07-12 11:24:21.948357: Current learning rate: 0.00044 
2025-07-12 11:25:30.558499: train_loss -0.9838 
2025-07-12 11:25:30.559787: val_loss -0.942 
2025-07-12 11:25:30.561136: Pseudo dice [np.float32(0.9441)] 
2025-07-12 11:25:30.562602: Epoch time: 68.62 s 
2025-07-12 11:25:31.515597:  
2025-07-12 11:25:31.517279: Epoch 970 
2025-07-12 11:25:31.518593: Current learning rate: 0.00043 
2025-07-12 11:26:40.063242: train_loss -0.9838 
2025-07-12 11:26:40.064485: val_loss -0.9419 
2025-07-12 11:26:40.065486: Pseudo dice [np.float32(0.9435)] 
2025-07-12 11:26:40.066871: Epoch time: 68.55 s 
2025-07-12 11:26:40.994992:  
2025-07-12 11:26:40.997805: Epoch 971 
2025-07-12 11:26:40.998970: Current learning rate: 0.00041 
2025-07-12 11:27:49.579053: train_loss -0.984 
2025-07-12 11:27:49.580370: val_loss -0.945 
2025-07-12 11:27:49.581949: Pseudo dice [np.float32(0.9483)] 
2025-07-12 11:27:49.583450: Epoch time: 68.59 s 
2025-07-12 11:27:50.508371:  
2025-07-12 11:27:50.510392: Epoch 972 
2025-07-12 11:27:50.511494: Current learning rate: 0.0004 
2025-07-12 11:28:59.055659: train_loss -0.9835 
2025-07-12 11:28:59.056797: val_loss -0.9414 
2025-07-12 11:28:59.057896: Pseudo dice [np.float32(0.9439)] 
2025-07-12 11:28:59.058959: Epoch time: 68.55 s 
2025-07-12 11:28:59.976198:  
2025-07-12 11:28:59.978239: Epoch 973 
2025-07-12 11:28:59.979344: Current learning rate: 0.00039 
2025-07-12 11:30:08.861660: train_loss -0.9839 
2025-07-12 11:30:08.863072: val_loss -0.9446 
2025-07-12 11:30:08.864081: Pseudo dice [np.float32(0.9474)] 
2025-07-12 11:30:08.865178: Epoch time: 68.89 s 
2025-07-12 11:30:09.802936:  
2025-07-12 11:30:09.805299: Epoch 974 
2025-07-12 11:30:09.806475: Current learning rate: 0.00037 
2025-07-12 11:31:18.349337: train_loss -0.9839 
2025-07-12 11:31:18.351195: val_loss -0.9407 
2025-07-12 11:31:18.352501: Pseudo dice [np.float32(0.9431)] 
2025-07-12 11:31:18.353555: Epoch time: 68.55 s 
2025-07-12 11:31:19.280221:  
2025-07-12 11:31:19.281695: Epoch 975 
2025-07-12 11:31:19.283128: Current learning rate: 0.00036 
2025-07-12 11:32:28.007594: train_loss -0.9838 
2025-07-12 11:32:28.008887: val_loss -0.9428 
2025-07-12 11:32:28.010163: Pseudo dice [np.float32(0.9446)] 
2025-07-12 11:32:28.011496: Epoch time: 68.73 s 
2025-07-12 11:32:28.931184:  
2025-07-12 11:32:28.933156: Epoch 976 
2025-07-12 11:32:28.934240: Current learning rate: 0.00035 
2025-07-12 11:33:37.985073: train_loss -0.9843 
2025-07-12 11:33:37.986567: val_loss -0.9415 
2025-07-12 11:33:37.987695: Pseudo dice [np.float32(0.9438)] 
2025-07-12 11:33:37.988693: Epoch time: 69.06 s 
2025-07-12 11:33:38.910533:  
2025-07-12 11:33:38.912739: Epoch 977 
2025-07-12 11:33:38.913826: Current learning rate: 0.00034 
2025-07-12 11:34:47.907030: train_loss -0.9848 
2025-07-12 11:34:47.908579: val_loss -0.9464 
2025-07-12 11:34:47.909553: Pseudo dice [np.float32(0.9489)] 
2025-07-12 11:34:47.910669: Epoch time: 69.0 s 
2025-07-12 11:34:48.833399:  
2025-07-12 11:34:48.835672: Epoch 978 
2025-07-12 11:34:48.836864: Current learning rate: 0.00032 
2025-07-12 11:35:57.841732: train_loss -0.9836 
2025-07-12 11:35:57.843087: val_loss -0.9411 
2025-07-12 11:35:57.844336: Pseudo dice [np.float32(0.943)] 
2025-07-12 11:35:57.845869: Epoch time: 69.01 s 
2025-07-12 11:35:58.760243:  
2025-07-12 11:35:58.762256: Epoch 979 
2025-07-12 11:35:58.763522: Current learning rate: 0.00031 
2025-07-12 11:37:07.888260: train_loss -0.9843 
2025-07-12 11:37:07.889428: val_loss -0.9427 
2025-07-12 11:37:07.890920: Pseudo dice [np.float32(0.9445)] 
2025-07-12 11:37:07.892427: Epoch time: 69.13 s 
2025-07-12 11:37:08.817204:  
2025-07-12 11:37:08.819391: Epoch 980 
2025-07-12 11:37:08.820618: Current learning rate: 0.0003 
2025-07-12 11:38:17.898931: train_loss -0.9842 
2025-07-12 11:38:17.900091: val_loss -0.9449 
2025-07-12 11:38:17.901306: Pseudo dice [np.float32(0.9465)] 
2025-07-12 11:38:17.902375: Epoch time: 69.09 s 
2025-07-12 11:38:18.816537:  
2025-07-12 11:38:18.818653: Epoch 981 
2025-07-12 11:38:18.820183: Current learning rate: 0.00028 
2025-07-12 11:39:27.767946: train_loss -0.9848 
2025-07-12 11:39:27.769573: val_loss -0.9461 
2025-07-12 11:39:27.770594: Pseudo dice [np.float32(0.9477)] 
2025-07-12 11:39:27.771801: Epoch time: 68.96 s 
2025-07-12 11:39:28.704224:  
2025-07-12 11:39:28.706034: Epoch 982 
2025-07-12 11:39:28.707495: Current learning rate: 0.00027 
2025-07-12 11:40:40.935427: train_loss -0.9842 
2025-07-12 11:40:40.936862: val_loss -0.9413 
2025-07-12 11:40:40.938233: Pseudo dice [np.float32(0.9428)] 
2025-07-12 11:40:40.939512: Epoch time: 72.24 s 
2025-07-12 11:40:41.866441:  
2025-07-12 11:40:41.868262: Epoch 983 
2025-07-12 11:40:41.869755: Current learning rate: 0.00026 
2025-07-12 11:41:53.617967: train_loss -0.9839 
2025-07-12 11:41:53.619107: val_loss -0.9463 
2025-07-12 11:41:53.620317: Pseudo dice [np.float32(0.9487)] 
2025-07-12 11:41:53.621534: Epoch time: 71.76 s 
2025-07-12 11:41:54.535269:  
2025-07-12 11:41:54.537324: Epoch 984 
2025-07-12 11:41:54.538516: Current learning rate: 0.00024 
2025-07-12 11:43:03.061447: train_loss -0.9836 
2025-07-12 11:43:03.062876: val_loss -0.9412 
2025-07-12 11:43:03.063993: Pseudo dice [np.float32(0.9445)] 
2025-07-12 11:43:03.065055: Epoch time: 68.53 s 
2025-07-12 11:43:03.991622:  
2025-07-12 11:43:03.993716: Epoch 985 
2025-07-12 11:43:03.995222: Current learning rate: 0.00023 
2025-07-12 11:44:12.312108: train_loss -0.9837 
2025-07-12 11:44:12.313519: val_loss -0.9443 
2025-07-12 11:44:12.315126: Pseudo dice [np.float32(0.9467)] 
2025-07-12 11:44:12.316592: Epoch time: 68.32 s 
2025-07-12 11:44:13.243113:  
2025-07-12 11:44:13.245180: Epoch 986 
2025-07-12 11:44:13.246356: Current learning rate: 0.00021 
2025-07-12 11:45:21.371575: train_loss -0.9841 
2025-07-12 11:45:21.373207: val_loss -0.936 
2025-07-12 11:45:21.374545: Pseudo dice [np.float32(0.9382)] 
2025-07-12 11:45:21.375953: Epoch time: 68.13 s 
2025-07-12 11:45:22.319063:  
2025-07-12 11:45:22.321392: Epoch 987 
2025-07-12 11:45:22.323103: Current learning rate: 0.0002 
2025-07-12 11:46:30.634202: train_loss -0.9842 
2025-07-12 11:46:30.635502: val_loss -0.9422 
2025-07-12 11:46:30.636760: Pseudo dice [np.float32(0.9431)] 
2025-07-12 11:46:30.638448: Epoch time: 68.32 s 
2025-07-12 11:46:31.561321:  
2025-07-12 11:46:31.563258: Epoch 988 
2025-07-12 11:46:31.564362: Current learning rate: 0.00019 
2025-07-12 11:47:39.847800: train_loss -0.9845 
2025-07-12 11:47:39.849113: val_loss -0.946 
2025-07-12 11:47:39.850207: Pseudo dice [np.float32(0.9476)] 
2025-07-12 11:47:39.851237: Epoch time: 68.29 s 
2025-07-12 11:47:40.783887:  
2025-07-12 11:47:40.785930: Epoch 989 
2025-07-12 11:47:40.787399: Current learning rate: 0.00017 
2025-07-12 11:48:49.096951: train_loss -0.9851 
2025-07-12 11:48:49.098165: val_loss -0.9464 
2025-07-12 11:48:49.099081: Pseudo dice [np.float32(0.9477)] 
2025-07-12 11:48:49.100343: Epoch time: 68.32 s 
2025-07-12 11:48:50.017908:  
2025-07-12 11:48:50.019493: Epoch 990 
2025-07-12 11:48:50.020625: Current learning rate: 0.00016 
2025-07-12 11:49:58.637415: train_loss -0.9848 
2025-07-12 11:49:58.638502: val_loss -0.9452 
2025-07-12 11:49:58.639636: Pseudo dice [np.float32(0.9465)] 
2025-07-12 11:49:58.640977: Epoch time: 68.62 s 
2025-07-12 11:49:59.549870:  
2025-07-12 11:49:59.552100: Epoch 991 
2025-07-12 11:49:59.553267: Current learning rate: 0.00014 
2025-07-12 11:51:08.261344: train_loss -0.9843 
2025-07-12 11:51:08.262726: val_loss -0.9464 
2025-07-12 11:51:08.263751: Pseudo dice [np.float32(0.9486)] 
2025-07-12 11:51:08.264666: Epoch time: 68.72 s 
2025-07-12 11:51:09.167087:  
2025-07-12 11:51:09.169250: Epoch 992 
2025-07-12 11:51:09.170232: Current learning rate: 0.00013 
2025-07-12 11:52:18.002471: train_loss -0.984 
2025-07-12 11:52:18.003714: val_loss -0.9423 
2025-07-12 11:52:18.005043: Pseudo dice [np.float32(0.9441)] 
2025-07-12 11:52:18.006103: Epoch time: 68.84 s 
2025-07-12 11:52:18.910900:  
2025-07-12 11:52:18.913043: Epoch 993 
2025-07-12 11:52:18.914334: Current learning rate: 0.00011 
2025-07-12 11:53:27.877353: train_loss -0.9843 
2025-07-12 11:53:27.878843: val_loss -0.9492 
2025-07-12 11:53:27.880139: Pseudo dice [np.float32(0.9512)] 
2025-07-12 11:53:27.881623: Epoch time: 68.97 s 
2025-07-12 11:53:28.811486:  
2025-07-12 11:53:28.813500: Epoch 994 
2025-07-12 11:53:28.814777: Current learning rate: 0.0001 
2025-07-12 11:54:38.020128: train_loss -0.984 
2025-07-12 11:54:38.021553: val_loss -0.9502 
2025-07-12 11:54:38.022575: Pseudo dice [np.float32(0.9524)] 
2025-07-12 11:54:38.023713: Epoch time: 69.21 s 
2025-07-12 11:54:38.940073:  
2025-07-12 11:54:38.941190: Epoch 995 
2025-07-12 11:54:38.942323: Current learning rate: 8e-05 
2025-07-12 11:55:48.286955: train_loss -0.9846 
2025-07-12 11:55:48.288298: val_loss -0.9433 
2025-07-12 11:55:48.289451: Pseudo dice [np.float32(0.9455)] 
2025-07-12 11:55:48.290708: Epoch time: 69.35 s 
2025-07-12 11:55:49.219951:  
2025-07-12 11:55:49.222087: Epoch 996 
2025-07-12 11:55:49.223366: Current learning rate: 7e-05 
2025-07-12 11:56:57.873182: train_loss -0.9849 
2025-07-12 11:56:57.874594: val_loss -0.9422 
2025-07-12 11:56:57.876077: Pseudo dice [np.float32(0.9448)] 
2025-07-12 11:56:57.877347: Epoch time: 68.66 s 
2025-07-12 11:56:58.821898:  
2025-07-12 11:56:58.823532: Epoch 997 
2025-07-12 11:56:58.824744: Current learning rate: 5e-05 
2025-07-12 11:58:07.884637: train_loss -0.9843 
2025-07-12 11:58:07.886172: val_loss -0.9428 
2025-07-12 11:58:07.887224: Pseudo dice [np.float32(0.9452)] 
2025-07-12 11:58:07.888139: Epoch time: 69.07 s 
2025-07-12 11:58:08.811840:  
2025-07-12 11:58:08.814323: Epoch 998 
2025-07-12 11:58:08.815350: Current learning rate: 4e-05 
2025-07-12 11:59:17.715531: train_loss -0.9842 
2025-07-12 11:59:17.717271: val_loss -0.9469 
2025-07-12 11:59:17.718517: Pseudo dice [np.float32(0.9492)] 
2025-07-12 11:59:17.720003: Epoch time: 68.91 s 
2025-07-12 11:59:18.641450:  
2025-07-12 11:59:18.643410: Epoch 999 
2025-07-12 11:59:18.644852: Current learning rate: 2e-05 
2025-07-12 12:00:27.548492: train_loss -0.984 
2025-07-12 12:00:27.550307: val_loss -0.9475 
2025-07-12 12:00:27.551723: Pseudo dice [np.float32(0.9494)] 
2025-07-12 12:00:27.553205: Epoch time: 68.91 s 
2025-07-12 12:00:29.837463: Training done. 
2025-07-12 12:00:29.898535: Using splits from existing split file: /data/nnUNet_preprocessed/Dataset010_PTB_all_energies_1mm_no_background_alldata/splits_final.json 
2025-07-12 12:00:29.906234: The split file contains 5 splits. 
2025-07-12 12:00:29.907485: Desired fold for training: 4 
2025-07-12 12:00:29.908710: This split has 1440 training and 360 validation cases. 
2025-07-12 12:00:29.915027: predicting PTB_all_energies_1mm_no_background_0002 
2025-07-12 12:00:29.923330: PTB_all_energies_1mm_no_background_0002, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:10.791150: predicting PTB_all_energies_1mm_no_background_0006 
2025-07-12 12:01:10.801145: PTB_all_energies_1mm_no_background_0006, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:10.858678: predicting PTB_all_energies_1mm_no_background_0017 
2025-07-12 12:01:10.866236: PTB_all_energies_1mm_no_background_0017, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:10.922608: predicting PTB_all_energies_1mm_no_background_0024 
2025-07-12 12:01:10.931639: PTB_all_energies_1mm_no_background_0024, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:10.987058: predicting PTB_all_energies_1mm_no_background_0035 
2025-07-12 12:01:10.995233: PTB_all_energies_1mm_no_background_0035, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.049254: predicting PTB_all_energies_1mm_no_background_0037 
2025-07-12 12:01:11.057563: PTB_all_energies_1mm_no_background_0037, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.131921: predicting PTB_all_energies_1mm_no_background_0040 
2025-07-12 12:01:11.140482: PTB_all_energies_1mm_no_background_0040, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.205673: predicting PTB_all_energies_1mm_no_background_0043 
2025-07-12 12:01:11.213898: PTB_all_energies_1mm_no_background_0043, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.273490: predicting PTB_all_energies_1mm_no_background_0044 
2025-07-12 12:01:11.280805: PTB_all_energies_1mm_no_background_0044, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.336896: predicting PTB_all_energies_1mm_no_background_0045 
2025-07-12 12:01:11.345342: PTB_all_energies_1mm_no_background_0045, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.400230: predicting PTB_all_energies_1mm_no_background_0046 
2025-07-12 12:01:11.408166: PTB_all_energies_1mm_no_background_0046, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.460761: predicting PTB_all_energies_1mm_no_background_0050 
2025-07-12 12:01:11.467945: PTB_all_energies_1mm_no_background_0050, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.518253: predicting PTB_all_energies_1mm_no_background_0070 
2025-07-12 12:01:11.525165: PTB_all_energies_1mm_no_background_0070, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.574597: predicting PTB_all_energies_1mm_no_background_0072 
2025-07-12 12:01:11.582386: PTB_all_energies_1mm_no_background_0072, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.634940: predicting PTB_all_energies_1mm_no_background_0078 
2025-07-12 12:01:11.643424: PTB_all_energies_1mm_no_background_0078, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.718752: predicting PTB_all_energies_1mm_no_background_0079 
2025-07-12 12:01:11.727977: PTB_all_energies_1mm_no_background_0079, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.784835: predicting PTB_all_energies_1mm_no_background_0080 
2025-07-12 12:01:11.792585: PTB_all_energies_1mm_no_background_0080, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.869647: predicting PTB_all_energies_1mm_no_background_0081 
2025-07-12 12:01:11.878036: PTB_all_energies_1mm_no_background_0081, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.939191: predicting PTB_all_energies_1mm_no_background_0082 
2025-07-12 12:01:11.946264: PTB_all_energies_1mm_no_background_0082, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:11.997864: predicting PTB_all_energies_1mm_no_background_0084 
2025-07-12 12:01:12.005884: PTB_all_energies_1mm_no_background_0084, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.056755: predicting PTB_all_energies_1mm_no_background_0087 
2025-07-12 12:01:12.064234: PTB_all_energies_1mm_no_background_0087, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.129272: predicting PTB_all_energies_1mm_no_background_0089 
2025-07-12 12:01:12.137300: PTB_all_energies_1mm_no_background_0089, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.189220: predicting PTB_all_energies_1mm_no_background_0095 
2025-07-12 12:01:12.197515: PTB_all_energies_1mm_no_background_0095, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.261049: predicting PTB_all_energies_1mm_no_background_0097 
2025-07-12 12:01:12.269327: PTB_all_energies_1mm_no_background_0097, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.320281: predicting PTB_all_energies_1mm_no_background_0106 
2025-07-12 12:01:12.327522: PTB_all_energies_1mm_no_background_0106, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.378774: predicting PTB_all_energies_1mm_no_background_0108 
2025-07-12 12:01:12.386339: PTB_all_energies_1mm_no_background_0108, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.441501: predicting PTB_all_energies_1mm_no_background_0109 
2025-07-12 12:01:12.448787: PTB_all_energies_1mm_no_background_0109, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.503223: predicting PTB_all_energies_1mm_no_background_0117 
2025-07-12 12:01:12.510963: PTB_all_energies_1mm_no_background_0117, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.584618: predicting PTB_all_energies_1mm_no_background_0122 
2025-07-12 12:01:12.593176: PTB_all_energies_1mm_no_background_0122, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.656989: predicting PTB_all_energies_1mm_no_background_0123 
2025-07-12 12:01:12.664294: PTB_all_energies_1mm_no_background_0123, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.736172: predicting PTB_all_energies_1mm_no_background_0130 
2025-07-12 12:01:12.744277: PTB_all_energies_1mm_no_background_0130, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.801164: predicting PTB_all_energies_1mm_no_background_0133 
2025-07-12 12:01:12.807806: PTB_all_energies_1mm_no_background_0133, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.878705: predicting PTB_all_energies_1mm_no_background_0141 
2025-07-12 12:01:12.887330: PTB_all_energies_1mm_no_background_0141, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:12.944166: predicting PTB_all_energies_1mm_no_background_0142 
2025-07-12 12:01:12.950983: PTB_all_energies_1mm_no_background_0142, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.004590: predicting PTB_all_energies_1mm_no_background_0143 
2025-07-12 12:01:13.011880: PTB_all_energies_1mm_no_background_0143, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.064342: predicting PTB_all_energies_1mm_no_background_0146 
2025-07-12 12:01:13.072183: PTB_all_energies_1mm_no_background_0146, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.144817: predicting PTB_all_energies_1mm_no_background_0156 
2025-07-12 12:01:13.153785: PTB_all_energies_1mm_no_background_0156, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.210324: predicting PTB_all_energies_1mm_no_background_0162 
2025-07-12 12:01:13.217859: PTB_all_energies_1mm_no_background_0162, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.288475: predicting PTB_all_energies_1mm_no_background_0167 
2025-07-12 12:01:13.296561: PTB_all_energies_1mm_no_background_0167, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.361468: predicting PTB_all_energies_1mm_no_background_0171 
2025-07-12 12:01:13.368635: PTB_all_energies_1mm_no_background_0171, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.445344: predicting PTB_all_energies_1mm_no_background_0173 
2025-07-12 12:01:13.453371: PTB_all_energies_1mm_no_background_0173, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.510262: predicting PTB_all_energies_1mm_no_background_0175 
2025-07-12 12:01:13.516798: PTB_all_energies_1mm_no_background_0175, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.572060: predicting PTB_all_energies_1mm_no_background_0177 
2025-07-12 12:01:13.579815: PTB_all_energies_1mm_no_background_0177, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.633247: predicting PTB_all_energies_1mm_no_background_0183 
2025-07-12 12:01:13.640230: PTB_all_energies_1mm_no_background_0183, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.718142: predicting PTB_all_energies_1mm_no_background_0190 
2025-07-12 12:01:13.726752: PTB_all_energies_1mm_no_background_0190, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.783611: predicting PTB_all_energies_1mm_no_background_0211 
2025-07-12 12:01:13.790350: PTB_all_energies_1mm_no_background_0211, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.842257: predicting PTB_all_energies_1mm_no_background_0212 
2025-07-12 12:01:13.848950: PTB_all_energies_1mm_no_background_0212, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.900210: predicting PTB_all_energies_1mm_no_background_0213 
2025-07-12 12:01:13.907342: PTB_all_energies_1mm_no_background_0213, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:13.962695: predicting PTB_all_energies_1mm_no_background_0215 
2025-07-12 12:01:13.970197: PTB_all_energies_1mm_no_background_0215, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.023399: predicting PTB_all_energies_1mm_no_background_0219 
2025-07-12 12:01:14.030530: PTB_all_energies_1mm_no_background_0219, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.087189: predicting PTB_all_energies_1mm_no_background_0225 
2025-07-12 12:01:14.094244: PTB_all_energies_1mm_no_background_0225, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.149307: predicting PTB_all_energies_1mm_no_background_0226 
2025-07-12 12:01:14.157388: PTB_all_energies_1mm_no_background_0226, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.235976: predicting PTB_all_energies_1mm_no_background_0227 
2025-07-12 12:01:14.243734: PTB_all_energies_1mm_no_background_0227, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.308457: predicting PTB_all_energies_1mm_no_background_0229 
2025-07-12 12:01:14.315354: PTB_all_energies_1mm_no_background_0229, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.389963: predicting PTB_all_energies_1mm_no_background_0231 
2025-07-12 12:01:14.398471: PTB_all_energies_1mm_no_background_0231, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.459255: predicting PTB_all_energies_1mm_no_background_0232 
2025-07-12 12:01:14.466788: PTB_all_energies_1mm_no_background_0232, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.517320: predicting PTB_all_energies_1mm_no_background_0236 
2025-07-12 12:01:14.523782: PTB_all_energies_1mm_no_background_0236, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.574118: predicting PTB_all_energies_1mm_no_background_0238 
2025-07-12 12:01:14.581716: PTB_all_energies_1mm_no_background_0238, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.634983: predicting PTB_all_energies_1mm_no_background_0260 
2025-07-12 12:01:14.642828: PTB_all_energies_1mm_no_background_0260, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.694702: predicting PTB_all_energies_1mm_no_background_0262 
2025-07-12 12:01:14.702489: PTB_all_energies_1mm_no_background_0262, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.752595: predicting PTB_all_energies_1mm_no_background_0264 
2025-07-12 12:01:14.759455: PTB_all_energies_1mm_no_background_0264, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.832275: predicting PTB_all_energies_1mm_no_background_0268 
2025-07-12 12:01:14.840290: PTB_all_energies_1mm_no_background_0268, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.899453: predicting PTB_all_energies_1mm_no_background_0270 
2025-07-12 12:01:14.906826: PTB_all_energies_1mm_no_background_0270, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:14.958536: predicting PTB_all_energies_1mm_no_background_0274 
2025-07-12 12:01:14.966281: PTB_all_energies_1mm_no_background_0274, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.021411: predicting PTB_all_energies_1mm_no_background_0280 
2025-07-12 12:01:15.029209: PTB_all_energies_1mm_no_background_0280, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.081060: predicting PTB_all_energies_1mm_no_background_0289 
2025-07-12 12:01:15.093395: PTB_all_energies_1mm_no_background_0289, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.145875: predicting PTB_all_energies_1mm_no_background_0291 
2025-07-12 12:01:15.154461: PTB_all_energies_1mm_no_background_0291, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.207120: predicting PTB_all_energies_1mm_no_background_0294 
2025-07-12 12:01:15.214665: PTB_all_energies_1mm_no_background_0294, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.270154: predicting PTB_all_energies_1mm_no_background_0298 
2025-07-12 12:01:15.278380: PTB_all_energies_1mm_no_background_0298, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.331173: predicting PTB_all_energies_1mm_no_background_0302 
2025-07-12 12:01:15.339020: PTB_all_energies_1mm_no_background_0302, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.414885: predicting PTB_all_energies_1mm_no_background_0313 
2025-07-12 12:01:15.422858: PTB_all_energies_1mm_no_background_0313, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.490617: predicting PTB_all_energies_1mm_no_background_0319 
2025-07-12 12:01:15.498117: PTB_all_energies_1mm_no_background_0319, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.552789: predicting PTB_all_energies_1mm_no_background_0322 
2025-07-12 12:01:15.560163: PTB_all_energies_1mm_no_background_0322, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.612256: predicting PTB_all_energies_1mm_no_background_0326 
2025-07-12 12:01:15.620642: PTB_all_energies_1mm_no_background_0326, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.695785: predicting PTB_all_energies_1mm_no_background_0334 
2025-07-12 12:01:15.704332: PTB_all_energies_1mm_no_background_0334, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.770998: predicting PTB_all_energies_1mm_no_background_0337 
2025-07-12 12:01:15.778461: PTB_all_energies_1mm_no_background_0337, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.830450: predicting PTB_all_energies_1mm_no_background_0338 
2025-07-12 12:01:15.838266: PTB_all_energies_1mm_no_background_0338, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.891938: predicting PTB_all_energies_1mm_no_background_0345 
2025-07-12 12:01:15.899507: PTB_all_energies_1mm_no_background_0345, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:15.974277: predicting PTB_all_energies_1mm_no_background_0346 
2025-07-12 12:01:15.982054: PTB_all_energies_1mm_no_background_0346, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.046963: predicting PTB_all_energies_1mm_no_background_0354 
2025-07-12 12:01:16.055219: PTB_all_energies_1mm_no_background_0354, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.110030: predicting PTB_all_energies_1mm_no_background_0355 
2025-07-12 12:01:16.116803: PTB_all_energies_1mm_no_background_0355, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.168358: predicting PTB_all_energies_1mm_no_background_0372 
2025-07-12 12:01:16.175997: PTB_all_energies_1mm_no_background_0372, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.250637: predicting PTB_all_energies_1mm_no_background_0379 
2025-07-12 12:01:16.259176: PTB_all_energies_1mm_no_background_0379, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.324099: predicting PTB_all_energies_1mm_no_background_0383 
2025-07-12 12:01:16.332155: PTB_all_energies_1mm_no_background_0383, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.407539: predicting PTB_all_energies_1mm_no_background_0388 
2025-07-12 12:01:16.415083: PTB_all_energies_1mm_no_background_0388, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.465670: predicting PTB_all_energies_1mm_no_background_0390 
2025-07-12 12:01:16.473752: PTB_all_energies_1mm_no_background_0390, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.525198: predicting PTB_all_energies_1mm_no_background_0394 
2025-07-12 12:01:16.532976: PTB_all_energies_1mm_no_background_0394, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.585525: predicting PTB_all_energies_1mm_no_background_0398 
2025-07-12 12:01:16.592802: PTB_all_energies_1mm_no_background_0398, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.647928: predicting PTB_all_energies_1mm_no_background_0399 
2025-07-12 12:01:16.656728: PTB_all_energies_1mm_no_background_0399, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.708627: predicting PTB_all_energies_1mm_no_background_0402 
2025-07-12 12:01:16.716180: PTB_all_energies_1mm_no_background_0402, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.767951: predicting PTB_all_energies_1mm_no_background_0403 
2025-07-12 12:01:16.775890: PTB_all_energies_1mm_no_background_0403, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.828144: predicting PTB_all_energies_1mm_no_background_0406 
2025-07-12 12:01:16.838816: PTB_all_energies_1mm_no_background_0406, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.913757: predicting PTB_all_energies_1mm_no_background_0407 
2025-07-12 12:01:16.922607: PTB_all_energies_1mm_no_background_0407, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:16.977638: predicting PTB_all_energies_1mm_no_background_0410 
2025-07-12 12:01:16.984808: PTB_all_energies_1mm_no_background_0410, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.060432: predicting PTB_all_energies_1mm_no_background_0411 
2025-07-12 12:01:17.070819: PTB_all_energies_1mm_no_background_0411, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.132152: predicting PTB_all_energies_1mm_no_background_0418 
2025-07-12 12:01:17.139731: PTB_all_energies_1mm_no_background_0418, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.193016: predicting PTB_all_energies_1mm_no_background_0434 
2025-07-12 12:01:17.200198: PTB_all_energies_1mm_no_background_0434, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.251657: predicting PTB_all_energies_1mm_no_background_0442 
2025-07-12 12:01:17.259003: PTB_all_energies_1mm_no_background_0442, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.313756: predicting PTB_all_energies_1mm_no_background_0445 
2025-07-12 12:01:17.321398: PTB_all_energies_1mm_no_background_0445, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.375567: predicting PTB_all_energies_1mm_no_background_0451 
2025-07-12 12:01:17.383328: PTB_all_energies_1mm_no_background_0451, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.435556: predicting PTB_all_energies_1mm_no_background_0458 
2025-07-12 12:01:17.443865: PTB_all_energies_1mm_no_background_0458, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.527335: predicting PTB_all_energies_1mm_no_background_0465 
2025-07-12 12:01:17.535494: PTB_all_energies_1mm_no_background_0465, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.597584: predicting PTB_all_energies_1mm_no_background_0476 
2025-07-12 12:01:17.606589: PTB_all_energies_1mm_no_background_0476, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.683505: predicting PTB_all_energies_1mm_no_background_0481 
2025-07-12 12:01:17.691616: PTB_all_energies_1mm_no_background_0481, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.756714: predicting PTB_all_energies_1mm_no_background_0483 
2025-07-12 12:01:17.764044: PTB_all_energies_1mm_no_background_0483, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.814590: predicting PTB_all_energies_1mm_no_background_0493 
2025-07-12 12:01:17.822626: PTB_all_energies_1mm_no_background_0493, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.875062: predicting PTB_all_energies_1mm_no_background_0495 
2025-07-12 12:01:17.882016: PTB_all_energies_1mm_no_background_0495, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.933129: predicting PTB_all_energies_1mm_no_background_0496 
2025-07-12 12:01:17.940841: PTB_all_energies_1mm_no_background_0496, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:17.990703: predicting PTB_all_energies_1mm_no_background_0498 
2025-07-12 12:01:17.998748: PTB_all_energies_1mm_no_background_0498, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.047696: predicting PTB_all_energies_1mm_no_background_0501 
2025-07-12 12:01:18.055161: PTB_all_energies_1mm_no_background_0501, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.110684: predicting PTB_all_energies_1mm_no_background_0506 
2025-07-12 12:01:18.118387: PTB_all_energies_1mm_no_background_0506, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.169629: predicting PTB_all_energies_1mm_no_background_0513 
2025-07-12 12:01:18.176843: PTB_all_energies_1mm_no_background_0513, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.228891: predicting PTB_all_energies_1mm_no_background_0515 
2025-07-12 12:01:18.236284: PTB_all_energies_1mm_no_background_0515, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.288531: predicting PTB_all_energies_1mm_no_background_0519 
2025-07-12 12:01:18.295432: PTB_all_energies_1mm_no_background_0519, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.349862: predicting PTB_all_energies_1mm_no_background_0520 
2025-07-12 12:01:18.357467: PTB_all_energies_1mm_no_background_0520, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.409622: predicting PTB_all_energies_1mm_no_background_0526 
2025-07-12 12:01:18.417322: PTB_all_energies_1mm_no_background_0526, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.470414: predicting PTB_all_energies_1mm_no_background_0534 
2025-07-12 12:01:18.478187: PTB_all_energies_1mm_no_background_0534, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.552799: predicting PTB_all_energies_1mm_no_background_0536 
2025-07-12 12:01:18.561503: PTB_all_energies_1mm_no_background_0536, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.629686: predicting PTB_all_energies_1mm_no_background_0538 
2025-07-12 12:01:18.637647: PTB_all_energies_1mm_no_background_0538, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.690863: predicting PTB_all_energies_1mm_no_background_0543 
2025-07-12 12:01:18.698539: PTB_all_energies_1mm_no_background_0543, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.751042: predicting PTB_all_energies_1mm_no_background_0547 
2025-07-12 12:01:18.759609: PTB_all_energies_1mm_no_background_0547, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.810271: predicting PTB_all_energies_1mm_no_background_0560 
2025-07-12 12:01:18.819409: PTB_all_energies_1mm_no_background_0560, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.875315: predicting PTB_all_energies_1mm_no_background_0562 
2025-07-12 12:01:18.884252: PTB_all_energies_1mm_no_background_0562, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:18.936231: predicting PTB_all_energies_1mm_no_background_0574 
2025-07-12 12:01:18.944347: PTB_all_energies_1mm_no_background_0574, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.019722: predicting PTB_all_energies_1mm_no_background_0575 
2025-07-12 12:01:19.033436: PTB_all_energies_1mm_no_background_0575, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.086051: predicting PTB_all_energies_1mm_no_background_0577 
2025-07-12 12:01:19.093228: PTB_all_energies_1mm_no_background_0577, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.150487: predicting PTB_all_energies_1mm_no_background_0578 
2025-07-12 12:01:19.159435: PTB_all_energies_1mm_no_background_0578, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.212286: predicting PTB_all_energies_1mm_no_background_0593 
2025-07-12 12:01:19.220669: PTB_all_energies_1mm_no_background_0593, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.272495: predicting PTB_all_energies_1mm_no_background_0595 
2025-07-12 12:01:19.279745: PTB_all_energies_1mm_no_background_0595, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.332965: predicting PTB_all_energies_1mm_no_background_0606 
2025-07-12 12:01:19.341232: PTB_all_energies_1mm_no_background_0606, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.395174: predicting PTB_all_energies_1mm_no_background_0608 
2025-07-12 12:01:19.402582: PTB_all_energies_1mm_no_background_0608, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.456413: predicting PTB_all_energies_1mm_no_background_0611 
2025-07-12 12:01:19.464163: PTB_all_energies_1mm_no_background_0611, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.530327: predicting PTB_all_energies_1mm_no_background_0615 
2025-07-12 12:01:19.538222: PTB_all_energies_1mm_no_background_0615, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.591972: predicting PTB_all_energies_1mm_no_background_0617 
2025-07-12 12:01:19.599035: PTB_all_energies_1mm_no_background_0617, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.654323: predicting PTB_all_energies_1mm_no_background_0624 
2025-07-12 12:01:19.663206: PTB_all_energies_1mm_no_background_0624, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.738186: predicting PTB_all_energies_1mm_no_background_0627 
2025-07-12 12:01:19.746260: PTB_all_energies_1mm_no_background_0627, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.806833: predicting PTB_all_energies_1mm_no_background_0631 
2025-07-12 12:01:19.816920: PTB_all_energies_1mm_no_background_0631, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.888409: predicting PTB_all_energies_1mm_no_background_0632 
2025-07-12 12:01:19.896256: PTB_all_energies_1mm_no_background_0632, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:19.956103: predicting PTB_all_energies_1mm_no_background_0640 
2025-07-12 12:01:19.963416: PTB_all_energies_1mm_no_background_0640, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.015854: predicting PTB_all_energies_1mm_no_background_0644 
2025-07-12 12:01:20.022910: PTB_all_energies_1mm_no_background_0644, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.075420: predicting PTB_all_energies_1mm_no_background_0655 
2025-07-12 12:01:20.083803: PTB_all_energies_1mm_no_background_0655, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.158794: predicting PTB_all_energies_1mm_no_background_0658 
2025-07-12 12:01:20.165518: PTB_all_energies_1mm_no_background_0658, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.218581: predicting PTB_all_energies_1mm_no_background_0662 
2025-07-12 12:01:20.228884: PTB_all_energies_1mm_no_background_0662, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.291456: predicting PTB_all_energies_1mm_no_background_0679 
2025-07-12 12:01:20.299464: PTB_all_energies_1mm_no_background_0679, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.351824: predicting PTB_all_energies_1mm_no_background_0680 
2025-07-12 12:01:20.359267: PTB_all_energies_1mm_no_background_0680, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.411443: predicting PTB_all_energies_1mm_no_background_0684 
2025-07-12 12:01:20.418107: PTB_all_energies_1mm_no_background_0684, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.471373: predicting PTB_all_energies_1mm_no_background_0685 
2025-07-12 12:01:20.478587: PTB_all_energies_1mm_no_background_0685, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.531627: predicting PTB_all_energies_1mm_no_background_0691 
2025-07-12 12:01:20.538692: PTB_all_energies_1mm_no_background_0691, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.590975: predicting PTB_all_energies_1mm_no_background_0692 
2025-07-12 12:01:20.598895: PTB_all_energies_1mm_no_background_0692, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.650835: predicting PTB_all_energies_1mm_no_background_0694 
2025-07-12 12:01:20.660078: PTB_all_energies_1mm_no_background_0694, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.711882: predicting PTB_all_energies_1mm_no_background_0700 
2025-07-12 12:01:20.719653: PTB_all_energies_1mm_no_background_0700, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.771464: predicting PTB_all_energies_1mm_no_background_0702 
2025-07-12 12:01:20.779172: PTB_all_energies_1mm_no_background_0702, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.829768: predicting PTB_all_energies_1mm_no_background_0705 
2025-07-12 12:01:20.838361: PTB_all_energies_1mm_no_background_0705, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.919570: predicting PTB_all_energies_1mm_no_background_0713 
2025-07-12 12:01:20.927822: PTB_all_energies_1mm_no_background_0713, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:20.991966: predicting PTB_all_energies_1mm_no_background_0714 
2025-07-12 12:01:20.998616: PTB_all_energies_1mm_no_background_0714, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.067765: predicting PTB_all_energies_1mm_no_background_0718 
2025-07-12 12:01:21.076430: PTB_all_energies_1mm_no_background_0718, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.128891: predicting PTB_all_energies_1mm_no_background_0724 
2025-07-12 12:01:21.136745: PTB_all_energies_1mm_no_background_0724, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.196900: predicting PTB_all_energies_1mm_no_background_0728 
2025-07-12 12:01:21.204338: PTB_all_energies_1mm_no_background_0728, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.259181: predicting PTB_all_energies_1mm_no_background_0730 
2025-07-12 12:01:21.266701: PTB_all_energies_1mm_no_background_0730, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.346767: predicting PTB_all_energies_1mm_no_background_0738 
2025-07-12 12:01:21.354922: PTB_all_energies_1mm_no_background_0738, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.418787: predicting PTB_all_energies_1mm_no_background_0742 
2025-07-12 12:01:21.427346: PTB_all_energies_1mm_no_background_0742, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.479616: predicting PTB_all_energies_1mm_no_background_0745 
2025-07-12 12:01:21.487136: PTB_all_energies_1mm_no_background_0745, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.539561: predicting PTB_all_energies_1mm_no_background_0746 
2025-07-12 12:01:21.547454: PTB_all_energies_1mm_no_background_0746, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.600773: predicting PTB_all_energies_1mm_no_background_0748 
2025-07-12 12:01:21.609368: PTB_all_energies_1mm_no_background_0748, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.665252: predicting PTB_all_energies_1mm_no_background_0760 
2025-07-12 12:01:21.673255: PTB_all_energies_1mm_no_background_0760, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.726388: predicting PTB_all_energies_1mm_no_background_0761 
2025-07-12 12:01:21.733642: PTB_all_energies_1mm_no_background_0761, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.787359: predicting PTB_all_energies_1mm_no_background_0765 
2025-07-12 12:01:21.794379: PTB_all_energies_1mm_no_background_0765, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.849724: predicting PTB_all_energies_1mm_no_background_0770 
2025-07-12 12:01:21.856768: PTB_all_energies_1mm_no_background_0770, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.913745: predicting PTB_all_energies_1mm_no_background_0774 
2025-07-12 12:01:21.921630: PTB_all_energies_1mm_no_background_0774, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:21.971581: predicting PTB_all_energies_1mm_no_background_0775 
2025-07-12 12:01:21.977479: PTB_all_energies_1mm_no_background_0775, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.028632: predicting PTB_all_energies_1mm_no_background_0781 
2025-07-12 12:01:22.037237: PTB_all_energies_1mm_no_background_0781, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.091059: predicting PTB_all_energies_1mm_no_background_0790 
2025-07-12 12:01:22.098380: PTB_all_energies_1mm_no_background_0790, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.150113: predicting PTB_all_energies_1mm_no_background_0792 
2025-07-12 12:01:22.158171: PTB_all_energies_1mm_no_background_0792, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.209603: predicting PTB_all_energies_1mm_no_background_0798 
2025-07-12 12:01:22.218177: PTB_all_energies_1mm_no_background_0798, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.270455: predicting PTB_all_energies_1mm_no_background_0803 
2025-07-12 12:01:22.278850: PTB_all_energies_1mm_no_background_0803, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.332813: predicting PTB_all_energies_1mm_no_background_0806 
2025-07-12 12:01:22.341164: PTB_all_energies_1mm_no_background_0806, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.393773: predicting PTB_all_energies_1mm_no_background_0808 
2025-07-12 12:01:22.401130: PTB_all_energies_1mm_no_background_0808, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.469538: predicting PTB_all_energies_1mm_no_background_0829 
2025-07-12 12:01:22.476704: PTB_all_energies_1mm_no_background_0829, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.529394: predicting PTB_all_energies_1mm_no_background_0833 
2025-07-12 12:01:22.537479: PTB_all_energies_1mm_no_background_0833, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.586902: predicting PTB_all_energies_1mm_no_background_0835 
2025-07-12 12:01:22.593898: PTB_all_energies_1mm_no_background_0835, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.644616: predicting PTB_all_energies_1mm_no_background_0836 
2025-07-12 12:01:22.654440: PTB_all_energies_1mm_no_background_0836, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.703007: predicting PTB_all_energies_1mm_no_background_0845 
2025-07-12 12:01:22.710086: PTB_all_energies_1mm_no_background_0845, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.758961: predicting PTB_all_energies_1mm_no_background_0846 
2025-07-12 12:01:22.765230: PTB_all_energies_1mm_no_background_0846, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.818815: predicting PTB_all_energies_1mm_no_background_0852 
2025-07-12 12:01:22.826193: PTB_all_energies_1mm_no_background_0852, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.878851: predicting PTB_all_energies_1mm_no_background_0856 
2025-07-12 12:01:22.885279: PTB_all_energies_1mm_no_background_0856, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:22.939447: predicting PTB_all_energies_1mm_no_background_0860 
2025-07-12 12:01:22.946522: PTB_all_energies_1mm_no_background_0860, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.001007: predicting PTB_all_energies_1mm_no_background_0862 
2025-07-12 12:01:23.008275: PTB_all_energies_1mm_no_background_0862, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.060830: predicting PTB_all_energies_1mm_no_background_0877 
2025-07-12 12:01:23.067899: PTB_all_energies_1mm_no_background_0877, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.120508: predicting PTB_all_energies_1mm_no_background_0883 
2025-07-12 12:01:23.129119: PTB_all_energies_1mm_no_background_0883, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.182230: predicting PTB_all_energies_1mm_no_background_0885 
2025-07-12 12:01:23.190102: PTB_all_energies_1mm_no_background_0885, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.246232: predicting PTB_all_energies_1mm_no_background_0886 
2025-07-12 12:01:23.254748: PTB_all_energies_1mm_no_background_0886, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.307945: predicting PTB_all_energies_1mm_no_background_0887 
2025-07-12 12:01:23.315364: PTB_all_energies_1mm_no_background_0887, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.367938: predicting PTB_all_energies_1mm_no_background_0889 
2025-07-12 12:01:23.374512: PTB_all_energies_1mm_no_background_0889, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.435647: predicting PTB_all_energies_1mm_no_background_0892 
2025-07-12 12:01:23.442598: PTB_all_energies_1mm_no_background_0892, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.496598: predicting PTB_all_energies_1mm_no_background_0893 
2025-07-12 12:01:23.504542: PTB_all_energies_1mm_no_background_0893, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.556680: predicting PTB_all_energies_1mm_no_background_0909 
2025-07-12 12:01:23.563272: PTB_all_energies_1mm_no_background_0909, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.616364: predicting PTB_all_energies_1mm_no_background_0910 
2025-07-12 12:01:23.623714: PTB_all_energies_1mm_no_background_0910, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.682039: predicting PTB_all_energies_1mm_no_background_0938 
2025-07-12 12:01:23.688720: PTB_all_energies_1mm_no_background_0938, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.739277: predicting PTB_all_energies_1mm_no_background_0945 
2025-07-12 12:01:23.746560: PTB_all_energies_1mm_no_background_0945, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.797744: predicting PTB_all_energies_1mm_no_background_0950 
2025-07-12 12:01:23.805140: PTB_all_energies_1mm_no_background_0950, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.856707: predicting PTB_all_energies_1mm_no_background_0953 
2025-07-12 12:01:23.864340: PTB_all_energies_1mm_no_background_0953, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.922520: predicting PTB_all_energies_1mm_no_background_0961 
2025-07-12 12:01:23.929845: PTB_all_energies_1mm_no_background_0961, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:23.983368: predicting PTB_all_energies_1mm_no_background_0979 
2025-07-12 12:01:23.989642: PTB_all_energies_1mm_no_background_0979, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.043063: predicting PTB_all_energies_1mm_no_background_1006 
2025-07-12 12:01:24.050512: PTB_all_energies_1mm_no_background_1006, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.102916: predicting PTB_all_energies_1mm_no_background_1014 
2025-07-12 12:01:24.110450: PTB_all_energies_1mm_no_background_1014, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.165164: predicting PTB_all_energies_1mm_no_background_1015 
2025-07-12 12:01:24.173298: PTB_all_energies_1mm_no_background_1015, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.225770: predicting PTB_all_energies_1mm_no_background_1022 
2025-07-12 12:01:24.233109: PTB_all_energies_1mm_no_background_1022, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.285421: predicting PTB_all_energies_1mm_no_background_1030 
2025-07-12 12:01:24.292704: PTB_all_energies_1mm_no_background_1030, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.345714: predicting PTB_all_energies_1mm_no_background_1037 
2025-07-12 12:01:24.353384: PTB_all_energies_1mm_no_background_1037, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.408459: predicting PTB_all_energies_1mm_no_background_1039 
2025-07-12 12:01:24.416305: PTB_all_energies_1mm_no_background_1039, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.468585: predicting PTB_all_energies_1mm_no_background_1040 
2025-07-12 12:01:24.475955: PTB_all_energies_1mm_no_background_1040, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.529882: predicting PTB_all_energies_1mm_no_background_1051 
2025-07-12 12:01:24.537129: PTB_all_energies_1mm_no_background_1051, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.593771: predicting PTB_all_energies_1mm_no_background_1054 
2025-07-12 12:01:24.601792: PTB_all_energies_1mm_no_background_1054, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.658601: predicting PTB_all_energies_1mm_no_background_1057 
2025-07-12 12:01:24.667035: PTB_all_energies_1mm_no_background_1057, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.741841: predicting PTB_all_energies_1mm_no_background_1059 
2025-07-12 12:01:24.750108: PTB_all_energies_1mm_no_background_1059, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.810953: predicting PTB_all_energies_1mm_no_background_1062 
2025-07-12 12:01:24.818273: PTB_all_energies_1mm_no_background_1062, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.872630: predicting PTB_all_energies_1mm_no_background_1076 
2025-07-12 12:01:24.880324: PTB_all_energies_1mm_no_background_1076, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.936235: predicting PTB_all_energies_1mm_no_background_1083 
2025-07-12 12:01:24.943487: PTB_all_energies_1mm_no_background_1083, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:24.998543: predicting PTB_all_energies_1mm_no_background_1084 
2025-07-12 12:01:25.005850: PTB_all_energies_1mm_no_background_1084, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.062953: predicting PTB_all_energies_1mm_no_background_1088 
2025-07-12 12:01:25.069495: PTB_all_energies_1mm_no_background_1088, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.124573: predicting PTB_all_energies_1mm_no_background_1097 
2025-07-12 12:01:25.134015: PTB_all_energies_1mm_no_background_1097, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.186052: predicting PTB_all_energies_1mm_no_background_1101 
2025-07-12 12:01:25.193999: PTB_all_energies_1mm_no_background_1101, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.246521: predicting PTB_all_energies_1mm_no_background_1102 
2025-07-12 12:01:25.254354: PTB_all_energies_1mm_no_background_1102, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.306224: predicting PTB_all_energies_1mm_no_background_1103 
2025-07-12 12:01:25.314282: PTB_all_energies_1mm_no_background_1103, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.365819: predicting PTB_all_energies_1mm_no_background_1108 
2025-07-12 12:01:25.373272: PTB_all_energies_1mm_no_background_1108, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.425649: predicting PTB_all_energies_1mm_no_background_1111 
2025-07-12 12:01:25.434528: PTB_all_energies_1mm_no_background_1111, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.488137: predicting PTB_all_energies_1mm_no_background_1116 
2025-07-12 12:01:25.495769: PTB_all_energies_1mm_no_background_1116, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.549602: predicting PTB_all_energies_1mm_no_background_1117 
2025-07-12 12:01:25.556921: PTB_all_energies_1mm_no_background_1117, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.610408: predicting PTB_all_energies_1mm_no_background_1121 
2025-07-12 12:01:25.617305: PTB_all_energies_1mm_no_background_1121, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.669286: predicting PTB_all_energies_1mm_no_background_1123 
2025-07-12 12:01:25.677341: PTB_all_energies_1mm_no_background_1123, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.751284: predicting PTB_all_energies_1mm_no_background_1132 
2025-07-12 12:01:25.759544: PTB_all_energies_1mm_no_background_1132, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.822855: predicting PTB_all_energies_1mm_no_background_1133 
2025-07-12 12:01:25.830345: PTB_all_energies_1mm_no_background_1133, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.884156: predicting PTB_all_energies_1mm_no_background_1138 
2025-07-12 12:01:25.891268: PTB_all_energies_1mm_no_background_1138, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:25.946713: predicting PTB_all_energies_1mm_no_background_1143 
2025-07-12 12:01:25.954508: PTB_all_energies_1mm_no_background_1143, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.008822: predicting PTB_all_energies_1mm_no_background_1149 
2025-07-12 12:01:26.016515: PTB_all_energies_1mm_no_background_1149, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.070244: predicting PTB_all_energies_1mm_no_background_1150 
2025-07-12 12:01:26.078166: PTB_all_energies_1mm_no_background_1150, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.132278: predicting PTB_all_energies_1mm_no_background_1151 
2025-07-12 12:01:26.139666: PTB_all_energies_1mm_no_background_1151, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.192529: predicting PTB_all_energies_1mm_no_background_1156 
2025-07-12 12:01:26.201049: PTB_all_energies_1mm_no_background_1156, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.277214: predicting PTB_all_energies_1mm_no_background_1167 
2025-07-12 12:01:26.286033: PTB_all_energies_1mm_no_background_1167, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.351261: predicting PTB_all_energies_1mm_no_background_1168 
2025-07-12 12:01:26.358240: PTB_all_energies_1mm_no_background_1168, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.409573: predicting PTB_all_energies_1mm_no_background_1171 
2025-07-12 12:01:26.417145: PTB_all_energies_1mm_no_background_1171, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.469409: predicting PTB_all_energies_1mm_no_background_1176 
2025-07-12 12:01:26.477591: PTB_all_energies_1mm_no_background_1176, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.531844: predicting PTB_all_energies_1mm_no_background_1190 
2025-07-12 12:01:26.539657: PTB_all_energies_1mm_no_background_1190, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.591208: predicting PTB_all_energies_1mm_no_background_1192 
2025-07-12 12:01:26.599172: PTB_all_energies_1mm_no_background_1192, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.653713: predicting PTB_all_energies_1mm_no_background_1210 
2025-07-12 12:01:26.661424: PTB_all_energies_1mm_no_background_1210, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.715554: predicting PTB_all_energies_1mm_no_background_1233 
2025-07-12 12:01:26.723113: PTB_all_energies_1mm_no_background_1233, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.781298: predicting PTB_all_energies_1mm_no_background_1234 
2025-07-12 12:01:26.789918: PTB_all_energies_1mm_no_background_1234, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.850058: predicting PTB_all_energies_1mm_no_background_1243 
2025-07-12 12:01:26.857387: PTB_all_energies_1mm_no_background_1243, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.911112: predicting PTB_all_energies_1mm_no_background_1244 
2025-07-12 12:01:26.918390: PTB_all_energies_1mm_no_background_1244, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:26.969820: predicting PTB_all_energies_1mm_no_background_1252 
2025-07-12 12:01:26.977450: PTB_all_energies_1mm_no_background_1252, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.029100: predicting PTB_all_energies_1mm_no_background_1257 
2025-07-12 12:01:27.036292: PTB_all_energies_1mm_no_background_1257, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.088126: predicting PTB_all_energies_1mm_no_background_1261 
2025-07-12 12:01:27.095501: PTB_all_energies_1mm_no_background_1261, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.148725: predicting PTB_all_energies_1mm_no_background_1267 
2025-07-12 12:01:27.155236: PTB_all_energies_1mm_no_background_1267, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.207350: predicting PTB_all_energies_1mm_no_background_1268 
2025-07-12 12:01:27.214440: PTB_all_energies_1mm_no_background_1268, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.270039: predicting PTB_all_energies_1mm_no_background_1270 
2025-07-12 12:01:27.276941: PTB_all_energies_1mm_no_background_1270, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.325891: predicting PTB_all_energies_1mm_no_background_1273 
2025-07-12 12:01:27.333831: PTB_all_energies_1mm_no_background_1273, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.382590: predicting PTB_all_energies_1mm_no_background_1274 
2025-07-12 12:01:27.390631: PTB_all_energies_1mm_no_background_1274, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.445204: predicting PTB_all_energies_1mm_no_background_1276 
2025-07-12 12:01:27.453391: PTB_all_energies_1mm_no_background_1276, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.503537: predicting PTB_all_energies_1mm_no_background_1281 
2025-07-12 12:01:27.510443: PTB_all_energies_1mm_no_background_1281, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.561934: predicting PTB_all_energies_1mm_no_background_1284 
2025-07-12 12:01:27.570739: PTB_all_energies_1mm_no_background_1284, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.621985: predicting PTB_all_energies_1mm_no_background_1286 
2025-07-12 12:01:27.630258: PTB_all_energies_1mm_no_background_1286, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.683115: predicting PTB_all_energies_1mm_no_background_1289 
2025-07-12 12:01:27.693503: PTB_all_energies_1mm_no_background_1289, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.746067: predicting PTB_all_energies_1mm_no_background_1290 
2025-07-12 12:01:27.753056: PTB_all_energies_1mm_no_background_1290, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.810029: predicting PTB_all_energies_1mm_no_background_1299 
2025-07-12 12:01:27.818161: PTB_all_energies_1mm_no_background_1299, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.873290: predicting PTB_all_energies_1mm_no_background_1307 
2025-07-12 12:01:27.880366: PTB_all_energies_1mm_no_background_1307, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.936580: predicting PTB_all_energies_1mm_no_background_1310 
2025-07-12 12:01:27.943645: PTB_all_energies_1mm_no_background_1310, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:27.998233: predicting PTB_all_energies_1mm_no_background_1312 
2025-07-12 12:01:28.005271: PTB_all_energies_1mm_no_background_1312, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.059731: predicting PTB_all_energies_1mm_no_background_1313 
2025-07-12 12:01:28.067182: PTB_all_energies_1mm_no_background_1313, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.121123: predicting PTB_all_energies_1mm_no_background_1318 
2025-07-12 12:01:28.130357: PTB_all_energies_1mm_no_background_1318, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.187729: predicting PTB_all_energies_1mm_no_background_1319 
2025-07-12 12:01:28.194294: PTB_all_energies_1mm_no_background_1319, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.250443: predicting PTB_all_energies_1mm_no_background_1327 
2025-07-12 12:01:28.258008: PTB_all_energies_1mm_no_background_1327, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.311897: predicting PTB_all_energies_1mm_no_background_1332 
2025-07-12 12:01:28.320205: PTB_all_energies_1mm_no_background_1332, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.373127: predicting PTB_all_energies_1mm_no_background_1334 
2025-07-12 12:01:28.380750: PTB_all_energies_1mm_no_background_1334, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.432358: predicting PTB_all_energies_1mm_no_background_1338 
2025-07-12 12:01:28.440620: PTB_all_energies_1mm_no_background_1338, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.494794: predicting PTB_all_energies_1mm_no_background_1340 
2025-07-12 12:01:28.503073: PTB_all_energies_1mm_no_background_1340, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.553598: predicting PTB_all_energies_1mm_no_background_1341 
2025-07-12 12:01:28.561161: PTB_all_energies_1mm_no_background_1341, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.616153: predicting PTB_all_energies_1mm_no_background_1365 
2025-07-12 12:01:28.623654: PTB_all_energies_1mm_no_background_1365, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.675528: predicting PTB_all_energies_1mm_no_background_1382 
2025-07-12 12:01:28.683194: PTB_all_energies_1mm_no_background_1382, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.734860: predicting PTB_all_energies_1mm_no_background_1385 
2025-07-12 12:01:28.742517: PTB_all_energies_1mm_no_background_1385, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.795418: predicting PTB_all_energies_1mm_no_background_1387 
2025-07-12 12:01:28.802628: PTB_all_energies_1mm_no_background_1387, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.857327: predicting PTB_all_energies_1mm_no_background_1393 
2025-07-12 12:01:28.864590: PTB_all_energies_1mm_no_background_1393, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.919231: predicting PTB_all_energies_1mm_no_background_1394 
2025-07-12 12:01:28.926455: PTB_all_energies_1mm_no_background_1394, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:28.980930: predicting PTB_all_energies_1mm_no_background_1396 
2025-07-12 12:01:28.988204: PTB_all_energies_1mm_no_background_1396, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.043086: predicting PTB_all_energies_1mm_no_background_1399 
2025-07-12 12:01:29.050076: PTB_all_energies_1mm_no_background_1399, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.108606: predicting PTB_all_energies_1mm_no_background_1408 
2025-07-12 12:01:29.116311: PTB_all_energies_1mm_no_background_1408, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.176029: predicting PTB_all_energies_1mm_no_background_1414 
2025-07-12 12:01:29.184146: PTB_all_energies_1mm_no_background_1414, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.237221: predicting PTB_all_energies_1mm_no_background_1417 
2025-07-12 12:01:29.244560: PTB_all_energies_1mm_no_background_1417, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.298922: predicting PTB_all_energies_1mm_no_background_1419 
2025-07-12 12:01:29.306600: PTB_all_energies_1mm_no_background_1419, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.361980: predicting PTB_all_energies_1mm_no_background_1421 
2025-07-12 12:01:29.371206: PTB_all_energies_1mm_no_background_1421, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.433001: predicting PTB_all_energies_1mm_no_background_1423 
2025-07-12 12:01:29.440771: PTB_all_energies_1mm_no_background_1423, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.496046: predicting PTB_all_energies_1mm_no_background_1432 
2025-07-12 12:01:29.504212: PTB_all_energies_1mm_no_background_1432, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.558809: predicting PTB_all_energies_1mm_no_background_1437 
2025-07-12 12:01:29.565964: PTB_all_energies_1mm_no_background_1437, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.621697: predicting PTB_all_energies_1mm_no_background_1440 
2025-07-12 12:01:29.629835: PTB_all_energies_1mm_no_background_1440, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.686062: predicting PTB_all_energies_1mm_no_background_1443 
2025-07-12 12:01:29.692981: PTB_all_energies_1mm_no_background_1443, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.744656: predicting PTB_all_energies_1mm_no_background_1444 
2025-07-12 12:01:29.752081: PTB_all_energies_1mm_no_background_1444, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.806957: predicting PTB_all_energies_1mm_no_background_1445 
2025-07-12 12:01:29.814553: PTB_all_energies_1mm_no_background_1445, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.868305: predicting PTB_all_energies_1mm_no_background_1450 
2025-07-12 12:01:29.876527: PTB_all_energies_1mm_no_background_1450, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.931511: predicting PTB_all_energies_1mm_no_background_1458 
2025-07-12 12:01:29.939579: PTB_all_energies_1mm_no_background_1458, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:29.994172: predicting PTB_all_energies_1mm_no_background_1464 
2025-07-12 12:01:30.004197: PTB_all_energies_1mm_no_background_1464, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.056442: predicting PTB_all_energies_1mm_no_background_1469 
2025-07-12 12:01:30.066545: PTB_all_energies_1mm_no_background_1469, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.119237: predicting PTB_all_energies_1mm_no_background_1472 
2025-07-12 12:01:30.127204: PTB_all_energies_1mm_no_background_1472, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.183125: predicting PTB_all_energies_1mm_no_background_1473 
2025-07-12 12:01:30.190567: PTB_all_energies_1mm_no_background_1473, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.246344: predicting PTB_all_energies_1mm_no_background_1476 
2025-07-12 12:01:30.255036: PTB_all_energies_1mm_no_background_1476, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.332381: predicting PTB_all_energies_1mm_no_background_1481 
2025-07-12 12:01:30.340330: PTB_all_energies_1mm_no_background_1481, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.402898: predicting PTB_all_energies_1mm_no_background_1484 
2025-07-12 12:01:30.410385: PTB_all_energies_1mm_no_background_1484, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.465568: predicting PTB_all_energies_1mm_no_background_1497 
2025-07-12 12:01:30.473201: PTB_all_energies_1mm_no_background_1497, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.527635: predicting PTB_all_energies_1mm_no_background_1507 
2025-07-12 12:01:30.535149: PTB_all_energies_1mm_no_background_1507, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.586409: predicting PTB_all_energies_1mm_no_background_1510 
2025-07-12 12:01:30.593900: PTB_all_energies_1mm_no_background_1510, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.645445: predicting PTB_all_energies_1mm_no_background_1517 
2025-07-12 12:01:30.653220: PTB_all_energies_1mm_no_background_1517, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.707384: predicting PTB_all_energies_1mm_no_background_1519 
2025-07-12 12:01:30.715239: PTB_all_energies_1mm_no_background_1519, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.769091: predicting PTB_all_energies_1mm_no_background_1524 
2025-07-12 12:01:30.776522: PTB_all_energies_1mm_no_background_1524, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.832908: predicting PTB_all_energies_1mm_no_background_1525 
2025-07-12 12:01:30.840014: PTB_all_energies_1mm_no_background_1525, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.907742: predicting PTB_all_energies_1mm_no_background_1535 
2025-07-12 12:01:30.914468: PTB_all_energies_1mm_no_background_1535, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:30.968166: predicting PTB_all_energies_1mm_no_background_1537 
2025-07-12 12:01:30.975341: PTB_all_energies_1mm_no_background_1537, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.029169: predicting PTB_all_energies_1mm_no_background_1548 
2025-07-12 12:01:31.037107: PTB_all_energies_1mm_no_background_1548, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.089109: predicting PTB_all_energies_1mm_no_background_1549 
2025-07-12 12:01:31.097128: PTB_all_energies_1mm_no_background_1549, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.151289: predicting PTB_all_energies_1mm_no_background_1561 
2025-07-12 12:01:31.159705: PTB_all_energies_1mm_no_background_1561, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.214998: predicting PTB_all_energies_1mm_no_background_1566 
2025-07-12 12:01:31.223218: PTB_all_energies_1mm_no_background_1566, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.277511: predicting PTB_all_energies_1mm_no_background_1570 
2025-07-12 12:01:31.285638: PTB_all_energies_1mm_no_background_1570, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.360247: predicting PTB_all_energies_1mm_no_background_1574 
2025-07-12 12:01:31.368550: PTB_all_energies_1mm_no_background_1574, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.432097: predicting PTB_all_energies_1mm_no_background_1580 
2025-07-12 12:01:31.440278: PTB_all_energies_1mm_no_background_1580, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.494662: predicting PTB_all_energies_1mm_no_background_1596 
2025-07-12 12:01:31.502053: PTB_all_energies_1mm_no_background_1596, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.553520: predicting PTB_all_energies_1mm_no_background_1599 
2025-07-12 12:01:31.561250: PTB_all_energies_1mm_no_background_1599, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.613295: predicting PTB_all_energies_1mm_no_background_1611 
2025-07-12 12:01:31.620591: PTB_all_energies_1mm_no_background_1611, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.677145: predicting PTB_all_energies_1mm_no_background_1616 
2025-07-12 12:01:31.684561: PTB_all_energies_1mm_no_background_1616, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.741504: predicting PTB_all_energies_1mm_no_background_1617 
2025-07-12 12:01:31.748983: PTB_all_energies_1mm_no_background_1617, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.804805: predicting PTB_all_energies_1mm_no_background_1626 
2025-07-12 12:01:31.812851: PTB_all_energies_1mm_no_background_1626, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.888219: predicting PTB_all_energies_1mm_no_background_1628 
2025-07-12 12:01:31.896680: PTB_all_energies_1mm_no_background_1628, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:31.955662: predicting PTB_all_energies_1mm_no_background_1631 
2025-07-12 12:01:31.963051: PTB_all_energies_1mm_no_background_1631, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.017881: predicting PTB_all_energies_1mm_no_background_1633 
2025-07-12 12:01:32.026222: PTB_all_energies_1mm_no_background_1633, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.083687: predicting PTB_all_energies_1mm_no_background_1636 
2025-07-12 12:01:32.091268: PTB_all_energies_1mm_no_background_1636, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.144126: predicting PTB_all_energies_1mm_no_background_1641 
2025-07-12 12:01:32.152249: PTB_all_energies_1mm_no_background_1641, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.228481: predicting PTB_all_energies_1mm_no_background_1645 
2025-07-12 12:01:32.236512: PTB_all_energies_1mm_no_background_1645, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.299715: predicting PTB_all_energies_1mm_no_background_1650 
2025-07-12 12:01:32.307360: PTB_all_energies_1mm_no_background_1650, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.361217: predicting PTB_all_energies_1mm_no_background_1657 
2025-07-12 12:01:32.369081: PTB_all_energies_1mm_no_background_1657, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.442292: predicting PTB_all_energies_1mm_no_background_1670 
2025-07-12 12:01:32.449962: PTB_all_energies_1mm_no_background_1670, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.514725: predicting PTB_all_energies_1mm_no_background_1675 
2025-07-12 12:01:32.522105: PTB_all_energies_1mm_no_background_1675, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.570431: predicting PTB_all_energies_1mm_no_background_1678 
2025-07-12 12:01:32.578184: PTB_all_energies_1mm_no_background_1678, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.629213: predicting PTB_all_energies_1mm_no_background_1679 
2025-07-12 12:01:32.636871: PTB_all_energies_1mm_no_background_1679, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.684477: predicting PTB_all_energies_1mm_no_background_1683 
2025-07-12 12:01:32.692173: PTB_all_energies_1mm_no_background_1683, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.763021: predicting PTB_all_energies_1mm_no_background_1688 
2025-07-12 12:01:32.771259: PTB_all_energies_1mm_no_background_1688, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.835498: predicting PTB_all_energies_1mm_no_background_1690 
2025-07-12 12:01:32.843520: PTB_all_energies_1mm_no_background_1690, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.896327: predicting PTB_all_energies_1mm_no_background_1691 
2025-07-12 12:01:32.904458: PTB_all_energies_1mm_no_background_1691, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:32.977064: predicting PTB_all_energies_1mm_no_background_1692 
2025-07-12 12:01:32.984916: PTB_all_energies_1mm_no_background_1692, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.045491: predicting PTB_all_energies_1mm_no_background_1694 
2025-07-12 12:01:33.053184: PTB_all_energies_1mm_no_background_1694, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.106341: predicting PTB_all_energies_1mm_no_background_1708 
2025-07-12 12:01:33.113106: PTB_all_energies_1mm_no_background_1708, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.165577: predicting PTB_all_energies_1mm_no_background_1714 
2025-07-12 12:01:33.172792: PTB_all_energies_1mm_no_background_1714, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.222196: predicting PTB_all_energies_1mm_no_background_1718 
2025-07-12 12:01:33.229595: PTB_all_energies_1mm_no_background_1718, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.302118: predicting PTB_all_energies_1mm_no_background_1724 
2025-07-12 12:01:33.310330: PTB_all_energies_1mm_no_background_1724, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.377651: predicting PTB_all_energies_1mm_no_background_1726 
2025-07-12 12:01:33.387310: PTB_all_energies_1mm_no_background_1726, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.442590: predicting PTB_all_energies_1mm_no_background_1728 
2025-07-12 12:01:33.449955: PTB_all_energies_1mm_no_background_1728, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.501726: predicting PTB_all_energies_1mm_no_background_1733 
2025-07-12 12:01:33.509508: PTB_all_energies_1mm_no_background_1733, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.563352: predicting PTB_all_energies_1mm_no_background_1736 
2025-07-12 12:01:33.570434: PTB_all_energies_1mm_no_background_1736, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.624097: predicting PTB_all_energies_1mm_no_background_1739 
2025-07-12 12:01:33.632215: PTB_all_energies_1mm_no_background_1739, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.688721: predicting PTB_all_energies_1mm_no_background_1743 
2025-07-12 12:01:33.696141: PTB_all_energies_1mm_no_background_1743, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.749201: predicting PTB_all_energies_1mm_no_background_1747 
2025-07-12 12:01:33.758534: PTB_all_energies_1mm_no_background_1747, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.834607: predicting PTB_all_energies_1mm_no_background_1750 
2025-07-12 12:01:33.843434: PTB_all_energies_1mm_no_background_1750, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.907325: predicting PTB_all_energies_1mm_no_background_1756 
2025-07-12 12:01:33.914429: PTB_all_energies_1mm_no_background_1756, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:33.966316: predicting PTB_all_energies_1mm_no_background_1767 
2025-07-12 12:01:33.973304: PTB_all_energies_1mm_no_background_1767, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:34.021132: predicting PTB_all_energies_1mm_no_background_1780 
2025-07-12 12:01:34.027273: PTB_all_energies_1mm_no_background_1780, shape torch.Size([1, 1, 504, 504]), rank 0 
2025-07-12 12:01:39.594677: Validation complete 
2025-07-12 12:01:39.596507: Mean Validation Dice:  0.9387112413721868 
